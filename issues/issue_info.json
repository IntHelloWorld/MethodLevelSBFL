{
    "Chart": {
        "owner_repo": "jfree/jfreechart",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2264",
                "commit_sha_fixed": "2266",
                "report_id": "983",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/983",
                "issue_title": "JFreeChart / Bugs / #983 Potential NPE in AbstractCategoryItemRender.getLegendItems()",
                "issue_description": "\nSetting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java:\npublic LegendItemCollection getLegendItems() {\nLegendItemCollection result = new LegendItemCollection();\nif (this.plot == null) {\nreturn result;\n}\nint index = this.plot.getIndexOf(this);\nCategoryDataset dataset = this.plot.getDataset(index);\nif (dataset != null) {\nreturn result;\n}\nint seriesCount = dataset.getRowCount();\n...\n}\nThe warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location, I suppose that the check before that should actually read \"if (dataset == null)\", not \"if (dataset != null)\".\nThis is trunk as of 2010-02-08.\n"
            },
            "2": {
                "commit_sha_buggy": "2240",
                "commit_sha_fixed": "2242",
                "report_id": "959",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/959",
                "issue_title": "JFreeChart / Bugs / #959 Bugs in DatasetUtilities.iterateRangeBounds() methods",
                "issue_description": "\nAll explained in this forum post:\nhttp://www.jfree.org/phpBB2/viewtopic.php?f=3&t=29171\n"
            },
            "3": {
                "commit_sha_buggy": "2225",
                "commit_sha_fixed": "2227",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr2225 | mungady | 2009-09-01 02:45:26 +0800 (Tue, 01 Sep 2009) | 4 lines\n\n2009-08-31  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/chart/plot/Plot.java\n    (DEFAULT_OUTLINE_STROKE): Changed default cap and join.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr2225 | mungady | 2009-09-01 02:45:26 +0800 (Tue, 01 Sep 2009) | 4 lines\n\n2009-08-31  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/chart/plot/Plot.java\n    (DEFAULT_OUTLINE_STROKE): Changed default cap and join.\n------------------------------------------------------------------------\n"
            },
            "4": {
                "commit_sha_buggy": "2182",
                "commit_sha_fixed": "2183",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr2182 | mungady | 2009-06-29 23:01:54 +0800 (Mon, 29 Jun 2009) | 1 line\n\nAdded getAnnotations() to XYItemRenderer.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr2182 | mungady | 2009-06-29 23:01:54 +0800 (Mon, 29 Jun 2009) | 1 line\n\nAdded getAnnotations() to XYItemRenderer.\n------------------------------------------------------------------------\n"
            },
            "5": {
                "commit_sha_buggy": "1695",
                "commit_sha_fixed": "1696",
                "report_id": "862",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/862",
                "issue_title": "JFreeChart / Bugs / #862 XYSeries.addOrUpdate() should add if duplicates are allowed",
                "issue_description": "\nCopied from this post (by Ted Schwartz) in the forum:\nhttp://www.jfree.org/phpBB2/viewtopic.php?t=24523\nI've found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x, Number y) was never modified to support this, and therefore duplicate data were overwriting existing data. This is the fix I've made, but I don't know how to submit a patch...\n$ diff original/jfreechart-1.0.9/source/org/jfree/data/xy/XYSeries.java fixed/org/jfree/data/xy/XYSeries.java\n537c537\n< if (index >= 0) {\n---\n> if (index >= 0 && !allowDuplicateXValues) {\n545a546,559\n> } else if (index >= 0){\n> XYDataItem item = new XYDataItem(x, y);\n> // need to make sure we are adding *after* any duplicates\n> int size = this.data.size();\n> while (index < size\n> && item.compareTo(this.data.get(index)) == 0) {\n> index++;\n> }\n> if (index < this.data.size()) {\n> this.data.add(index, item);\n> }\n> else {\n> this.data.add(item);\n> }\n558,561d571\n< // check if this addition will exceed the maximum item count...\n< if (getItemCount() > this.maximumItemCount) {\n< this.data.remove(0);\n< }\n562a573,576\n> // check if this addition will exceed the maximum item count...\n> if (getItemCount() > this.maximumItemCount) {\n> this.data.remove(0);\n> }\n"
            },
            "6": {
                "commit_sha_buggy": "1164",
                "commit_sha_fixed": "1166",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr1164 | mungady | 2008-06-17 16:35:56 +0800 (Tue, 17 Jun 2008) | 1 line\n\nWhitespace.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr1164 | mungady | 2008-06-17 16:35:56 +0800 (Tue, 17 Jun 2008) | 1 line\n\nWhitespace.\n------------------------------------------------------------------------\n"
            },
            "7": {
                "commit_sha_buggy": "1086",
                "commit_sha_fixed": "1087",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr1086 | mungady | 2008-06-10 17:20:57 +0800 (Tue, 10 Jun 2008) | 1 line\n\nAdded toString() method for debugging.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr1086 | mungady | 2008-06-10 17:20:57 +0800 (Tue, 10 Jun 2008) | 1 line\n\nAdded toString() method for debugging.\n------------------------------------------------------------------------\n"
            },
            "8": {
                "commit_sha_buggy": "1084",
                "commit_sha_fixed": "1085",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr1084 | mungady | 2008-06-10 17:12:17 +0800 (Tue, 10 Jun 2008) | 9 lines\n\n2008-06-10  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/data/time/SimpleTimePeriod.java\n    (start): Changed from Date to long,\n    (end): Likewise,\n    (getStartMillis): New method,\n    (getEndMillis): Likewise,\n    (getStart): Returns new date instance,\n    (getEnd): Likewise.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr1084 | mungady | 2008-06-10 17:12:17 +0800 (Tue, 10 Jun 2008) | 9 lines\n\n2008-06-10  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/data/time/SimpleTimePeriod.java\n    (start): Changed from Date to long,\n    (end): Likewise,\n    (getStartMillis): New method,\n    (getEndMillis): Likewise,\n    (getStart): Returns new date instance,\n    (getEnd): Likewise.\n------------------------------------------------------------------------\n"
            },
            "9": {
                "commit_sha_buggy": "1082",
                "commit_sha_fixed": "1083",
                "report_id": "818",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/818",
                "issue_title": "JFreeChart / Bugs / #818 Error on TimeSeries createCopy() method",
                "issue_description": "\nThe test case at the end fails with :\njava.lang.IllegalArgumentException: Requires start <= end.\nThe problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned, not an exception. This is with jfreechart 1.0.7\npublic class foo {\nstatic public void main(String args[]) {\nTimeSeries foo = new TimeSeries(\"foo\",Day.class);\nfoo.add(new Day(19,4,2005),1);\nfoo.add(new Day(25,5,2005),1);\nfoo.add(new Day(28,5,2005),1);\nfoo.add(new Day(30,5,2005),1);\nfoo.add(new Day(1,6,2005),1);\nfoo.add(new Day(3,6,2005),1);\nfoo.add(new Day(19,8,2005),1);\nfoo.add(new Day(31,1,2006),1);\n    try \\{\n        TimeSeries bar = foo.createCopy\\(new Day\\(1,12,2005\\),new Day\\(18,1,2006\\)\\);\n    \\} catch \\(CloneNotSupportedException e\\) \\{\n\n        e.printStackTrace\\(\\);\n\n}\n}\n"
            },
            "10": {
                "commit_sha_buggy": "1064",
                "commit_sha_fixed": "1065",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr1064 | mungady | 2008-06-10 15:28:02 +0800 (Tue, 10 Jun 2008) | 1 line\n\nUpdated API docs.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr1064 | mungady | 2008-06-10 15:28:02 +0800 (Tue, 10 Jun 2008) | 1 line\n\nUpdated API docs.\n------------------------------------------------------------------------\n"
            },
            "11": {
                "commit_sha_buggy": "1024",
                "commit_sha_fixed": "1025",
                "report_id": "868",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/868",
                "issue_title": "JFreeChart / Bugs / #868 JCommon 1.0.12 ShapeUtilities.equal(path1,path2)",
                "issue_description": "\nThe comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1, GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.\n"
            },
            "12": {
                "commit_sha_buggy": "846",
                "commit_sha_fixed": "852",
                "report_id": "213",
                "report_url": "https://sourceforge.net/p/jfreechart/patches/213",
                "issue_title": "JFreeChart / Patches / #213 Fix for MultiplePiePlot",
                "issue_description": "\nWhen dataset is passed into constructor for MultiplePiePlot, the dataset is not wired to a listener, as it would be if setDataset is called.\n"
            },
            "13": {
                "commit_sha_buggy": "817",
                "commit_sha_fixed": "822",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr817 | mungady | 2008-04-09 02:35:56 +0800 (Wed, 09 Apr 2008) | 9 lines\n\n2008-04-08  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/chart/block/ColorBlock.java\n    (arrange): New method override,\n    (draw): Add code for margin, border and padding,\n    * source/org/jfree/chart/block/EmptyBlock.java\n    (arrange): New method override,\n    (draw(Graphics2D, Rectangle2D)): Delegate,\n    (draw(Graphics2D, Rectangle2D, Object)): New method override.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr817 | mungady | 2008-04-09 02:35:56 +0800 (Wed, 09 Apr 2008) | 9 lines\n\n2008-04-08  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/chart/block/ColorBlock.java\n    (arrange): New method override,\n    (draw): Add code for margin, border and padding,\n    * source/org/jfree/chart/block/EmptyBlock.java\n    (arrange): New method override,\n    (draw(Graphics2D, Rectangle2D)): Delegate,\n    (draw(Graphics2D, Rectangle2D, Object)): New method override.\n------------------------------------------------------------------------\n"
            },
            "14": {
                "commit_sha_buggy": "809",
                "commit_sha_fixed": "811",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr809 | mungady | 2008-04-07 21:20:17 +0800 (Mon, 07 Apr 2008) | 5 lines\n\n2008-04-07  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/data/DefaultKeyedValue.java:\n    (DefaultKeyedValue): Don't allow null key,\n    (equals): Simplified to reflect that this.key is never null.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr809 | mungady | 2008-04-07 21:20:17 +0800 (Mon, 07 Apr 2008) | 5 lines\n\n2008-04-07  David Gilbert  <david.gilbert@object-refinery.com>\n\n    * source/org/jfree/data/DefaultKeyedValue.java:\n    (DefaultKeyedValue): Don't allow null key,\n    (equals): Simplified to reflect that this.key is never null.\n------------------------------------------------------------------------\n"
            },
            "15": {
                "commit_sha_buggy": "747",
                "commit_sha_fixed": "749",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr747 | mungady | 2008-02-26 10:30:43 +0800 (Tue, 26 Feb 2008) | 1 line\n\nAdded testDrawWithNullInfo().\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr747 | mungady | 2008-02-26 10:30:43 +0800 (Tue, 26 Feb 2008) | 1 line\n\nAdded testDrawWithNullInfo().\n------------------------------------------------------------------------\n"
            },
            "16": {
                "commit_sha_buggy": "741",
                "commit_sha_fixed": "743",
                "report_id": "834",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/834",
                "issue_title": "JFreeChart / Bugs / #834 Bug propgated from v1.0.5 on to present",
                "issue_description": "\nThe method getRowCount() in class org.jfree.data.category.DefaultIntervalCategoryDataset says that it \"Returns the number of series in the dataset (possibly zero).\" \nThe implementation from v1.0.5 on no longer checks for a null condition (which would then return a zero) on the seriesKeys as it did in v1.0.4 and previous. This now throws a Null Pointer if seriesKeys never got initialized and the getRowCount() method is called.\n"
            },
            "17": {
                "commit_sha_buggy": "621",
                "commit_sha_fixed": "622",
                "report_id": "803",
                "report_url": "https://sourceforge.net/p/jfreechart/bugs/803",
                "issue_title": "JFreeChart / Bugs / #803 cloning of TimeSeries",
                "issue_description": "\nIt's just a minor bug!\nWhen I clone a TimeSeries which has no items, I get an IllegalArgumentException (\"Requires start <= end\").\nBut I don't think the user should be responsible for checking whether the TimeSeries has any items or not.\n"
            },
            "18": {
                "commit_sha_buggy": "620",
                "commit_sha_fixed": "621",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr620 | mungady | 2007-11-22 17:37:04 +0800 (Thu, 22 Nov 2007) | 7 lines\n\n2007-11-22  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/xy/XYSeries.java\n\t(clone): Reimplemented,\n\t* tests/org/jfree/data/xy/junit/XYSeriesTests.java\n\t(testCloning2): New method,\n\t(testCloning3): Likewise.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr620 | mungady | 2007-11-22 17:37:04 +0800 (Thu, 22 Nov 2007) | 7 lines\n\n2007-11-22  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/xy/XYSeries.java\n\t(clone): Reimplemented,\n\t* tests/org/jfree/data/xy/junit/XYSeriesTests.java\n\t(testCloning2): New method,\n\t(testCloning3): Likewise.\n------------------------------------------------------------------------\n"
            },
            "19": {
                "commit_sha_buggy": "430",
                "commit_sha_fixed": "434",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr430 | mungady | 2007-10-25 19:11:30 +0800 (Thu, 25 Oct 2007) | 1 line\n\nNew tests.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr430 | mungady | 2007-10-25 19:11:30 +0800 (Thu, 25 Oct 2007) | 1 line\n\nNew tests.\n------------------------------------------------------------------------\n"
            },
            "20": {
                "commit_sha_buggy": "281",
                "commit_sha_fixed": "283",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr281 | mungady | 2007-10-08 17:16:30 +0800 (Mon, 08 Oct 2007) | 16 lines\n\n2007-10-08  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/chart/renderer/xy/CandlestickRenderer.java\n\t(volumePaint): New field,\n\t(CandlestickRenderer(double, boolean, XYToolTipGenerator)): Initialise new \n\tfield,\n\t(getVolumePaint): New method,\n\t(setVolumePaint): Likewise,\n\t(drawItem): Use new paint attribute,\n\t(equals): Add check for new field,\n\t(writeObject): Handle serialization for new field,\n\t(readObject): Likewise,\n\t* tests/org/jfree/chart/renderer/xy/junit/CandlestickRendererTests.java\n\t(EPSILON): New field,\n\t(testConstructor): New method,\n\t(testEquals): Added check for new field.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr281 | mungady | 2007-10-08 17:16:30 +0800 (Mon, 08 Oct 2007) | 16 lines\n\n2007-10-08  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/chart/renderer/xy/CandlestickRenderer.java\n\t(volumePaint): New field,\n\t(CandlestickRenderer(double, boolean, XYToolTipGenerator)): Initialise new \n\tfield,\n\t(getVolumePaint): New method,\n\t(setVolumePaint): Likewise,\n\t(drawItem): Use new paint attribute,\n\t(equals): Add check for new field,\n\t(writeObject): Handle serialization for new field,\n\t(readObject): Likewise,\n\t* tests/org/jfree/chart/renderer/xy/junit/CandlestickRendererTests.java\n\t(EPSILON): New field,\n\t(testConstructor): New method,\n\t(testEquals): Added check for new field.\n------------------------------------------------------------------------\n"
            },
            "21": {
                "commit_sha_buggy": "227",
                "commit_sha_fixed": "231",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr227 | mungady | 2007-10-03 18:58:18 +0800 (Wed, 03 Oct 2007) | 18 lines\n\n2007-10-03  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(getObject(Comparable, Comparable)): Check arguments for null or \n\tunrecognised keys,\n\t(setObject(Object, Comparable, Comparable): Check for null arguments,\n\t(removeObject): Check if row or column needs removing, \n\t(removeRow(Comparable)): Check for unrecognised key,\n\t(removeColumn(Comparable)): Likewise,\n\t* tests/org/jfree/data/junit/KeyedObjects2DTests.java\n\t(testGetValueByIndex): New test method,\n\t(testGetValueByKey): Likewise,\n\t(testSetObject): Likewise,\n\t(testRemoveRowByIndex): Likewise,\n\t(testRemoveColumnByIndex): Likewise,\n\t(testRemoveRowByKey): Likewise,\n\t(testRemoveColumnByKey): Likewise,\n\t(testRemoveValue): Likewise.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr227 | mungady | 2007-10-03 18:58:18 +0800 (Wed, 03 Oct 2007) | 18 lines\n\n2007-10-03  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(getObject(Comparable, Comparable)): Check arguments for null or \n\tunrecognised keys,\n\t(setObject(Object, Comparable, Comparable): Check for null arguments,\n\t(removeObject): Check if row or column needs removing, \n\t(removeRow(Comparable)): Check for unrecognised key,\n\t(removeColumn(Comparable)): Likewise,\n\t* tests/org/jfree/data/junit/KeyedObjects2DTests.java\n\t(testGetValueByIndex): New test method,\n\t(testGetValueByKey): Likewise,\n\t(testSetObject): Likewise,\n\t(testRemoveRowByIndex): Likewise,\n\t(testRemoveColumnByIndex): Likewise,\n\t(testRemoveRowByKey): Likewise,\n\t(testRemoveColumnByKey): Likewise,\n\t(testRemoveValue): Likewise.\n------------------------------------------------------------------------\n"
            },
            "22": {
                "commit_sha_buggy": "225",
                "commit_sha_fixed": "227",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr225 | mungady | 2007-10-03 17:24:09 +0800 (Wed, 03 Oct 2007) | 25 lines\n\n2007-10-03  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/DefaultKeyedValues.java\n\t(removeValue(Comparable)): Throw UnknownKeyException for unrecognised key,\n\t* source/org/jfree/data/KeyedObjects.java\n\t(getObject(int)): Allow IndexOutOfBoundsException to be thrown,\n\t(getKey(int)): Likewise,\n\t(getIndex): Check for null argument,\n\t(getObject): Throw UnknownKeyException for unrecognised key,\n\t(insertValue): New method,\n\t(removeValue): Throw UnknownKeyException for unrecognised key,\n\t(clear): New method,\n\t(hashCode): Likewise,\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(getObject): Check for missing key in underlying data structure,\n\t* tests/org/jfree/data/junit/DefaultKeyedValuesTests.java\n\t(testRemoveValue): Updated checks for consistency with KeyedObjects,\n\t* tests/org/jfree/data/junit/KeyedObjectsTests.java\n\t(testInsertAndRetrieve): Updated checks,\n\t(testGetObject): New test method,\n\t(testGetKey): Likewise,\n\t(testGetIndex): Likewise,\n\t(testSetObject): Likewise,\n\t(testRemoveValue): Likewise,\n\t(testRemoveValueInt): Likewise.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr225 | mungady | 2007-10-03 17:24:09 +0800 (Wed, 03 Oct 2007) | 25 lines\n\n2007-10-03  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/DefaultKeyedValues.java\n\t(removeValue(Comparable)): Throw UnknownKeyException for unrecognised key,\n\t* source/org/jfree/data/KeyedObjects.java\n\t(getObject(int)): Allow IndexOutOfBoundsException to be thrown,\n\t(getKey(int)): Likewise,\n\t(getIndex): Check for null argument,\n\t(getObject): Throw UnknownKeyException for unrecognised key,\n\t(insertValue): New method,\n\t(removeValue): Throw UnknownKeyException for unrecognised key,\n\t(clear): New method,\n\t(hashCode): Likewise,\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(getObject): Check for missing key in underlying data structure,\n\t* tests/org/jfree/data/junit/DefaultKeyedValuesTests.java\n\t(testRemoveValue): Updated checks for consistency with KeyedObjects,\n\t* tests/org/jfree/data/junit/KeyedObjectsTests.java\n\t(testInsertAndRetrieve): Updated checks,\n\t(testGetObject): New test method,\n\t(testGetKey): Likewise,\n\t(testGetIndex): Likewise,\n\t(testSetObject): Likewise,\n\t(testRemoveValue): Likewise,\n\t(testRemoveValueInt): Likewise.\n------------------------------------------------------------------------\n"
            },
            "23": {
                "commit_sha_buggy": "209",
                "commit_sha_fixed": "210",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr209 | mungady | 2007-09-28 23:11:58 +0800 (Fri, 28 Sep 2007) | 22 lines\n\n2007-09-28  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/KeyedObjects.java\n\t(equals): Cleaned up,\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(equals): Likewise,\n\t(clone): Clone data storage,\n\t* source/org/jfree/data/statistics/DefaultBoxAndWhiskerCategoryDataset.java\n\t(clone): New method override,\n\t* source/org/jfree/data/statistics/DefaultStatisticalCategoryDataset.java\n\t(clone): Likewise,\n\t* tests/org/jfree/data/junit/KeyedObjects2DTests.java\n\t(testEquals): New test,\n\t(testCloning): Check independence,\n\t* tests/org/jfree/data/junit/KeyedObjectsTests.java\n\t(testCloning2): New test,\n\t* tests/org/jfree/data/junit/KeyedObjectTests.java\n\t(testCloning2): New test,\n\t* tests/org/jfree/data/statistics/junit/DefaultBoxAndWhiskerCategoryDatasetTests.java\n\t(testCloning): Check independence,\n\t* tests/org/jfree/data/statistics/junit/DefaultStatisticalCategoryDatasetTests.java\n\t(testCloning): Check independence.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr209 | mungady | 2007-09-28 23:11:58 +0800 (Fri, 28 Sep 2007) | 22 lines\n\n2007-09-28  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/data/KeyedObjects.java\n\t(equals): Cleaned up,\n\t* source/org/jfree/data/KeyedObjects2D.java\n\t(equals): Likewise,\n\t(clone): Clone data storage,\n\t* source/org/jfree/data/statistics/DefaultBoxAndWhiskerCategoryDataset.java\n\t(clone): New method override,\n\t* source/org/jfree/data/statistics/DefaultStatisticalCategoryDataset.java\n\t(clone): Likewise,\n\t* tests/org/jfree/data/junit/KeyedObjects2DTests.java\n\t(testEquals): New test,\n\t(testCloning): Check independence,\n\t* tests/org/jfree/data/junit/KeyedObjectsTests.java\n\t(testCloning2): New test,\n\t* tests/org/jfree/data/junit/KeyedObjectTests.java\n\t(testCloning2): New test,\n\t* tests/org/jfree/data/statistics/junit/DefaultBoxAndWhiskerCategoryDatasetTests.java\n\t(testCloning): Check independence,\n\t* tests/org/jfree/data/statistics/junit/DefaultStatisticalCategoryDatasetTests.java\n\t(testCloning): Check independence.\n------------------------------------------------------------------------\n"
            },
            "24": {
                "commit_sha_buggy": "188",
                "commit_sha_fixed": "190",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr188 | mungady | 2007-09-26 21:34:39 +0800 (Wed, 26 Sep 2007) | 4 lines\n\n2007-09-26  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/chart/renderer/xy/XYBarRenderer.java\n\t(drawItem): Apply margin in a way that works for inverted axes.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr188 | mungady | 2007-09-26 21:34:39 +0800 (Wed, 26 Sep 2007) | 4 lines\n\n2007-09-26  David Gilbert  <david.gilbert@object-refinery.com>\n\n\t* source/org/jfree/chart/renderer/xy/XYBarRenderer.java\n\t(drawItem): Apply margin in a way that works for inverted axes.\n------------------------------------------------------------------------\n"
            },
            "25": {
                "commit_sha_buggy": "162",
                "commit_sha_fixed": "164",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr162 | nenry | 2007-08-27 18:36:34 +0800 (Mon, 27 Aug 2007) | 1 line\n\n\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr162 | nenry | 2007-08-27 18:36:34 +0800 (Mon, 27 Aug 2007) | 1 line\n\n\n------------------------------------------------------------------------\n"
            },
            "26": {
                "commit_sha_buggy": "102",
                "commit_sha_fixed": "103",
                "report_id": "UNKNOWN",
                "report_url": "UNKNOWN",
                "issue_title": "------------------------------------------------------------------------\nr102 | nenry | 2007-07-06 17:13:45 +0800 (Fri, 06 Jul 2007) | 1 line\n\nfixed NPE when autoranging from popup menu.\n------------------------------------------------------------------------\n",
                "issue_description": "------------------------------------------------------------------------\nr102 | nenry | 2007-07-06 17:13:45 +0800 (Fri, 06 Jul 2007) | 1 line\n\nfixed NPE when autoranging from popup menu.\n------------------------------------------------------------------------\n"
            }
        }
    },
    "Cli": {
        "owner_repo": "apache/commons-cli",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8f46f467a33ace44ccd9f394910940b6c48a3827",
                "commit_sha_fixed": "b0e1b80b6d4a10a9c9f46539bc4c7a3cce55886e",
                "report_id": "CLI-13",
                "report_url": "https://issues.apache.org/jira/browse/CLI-13",
                "issue_title": "[CLI-13] [cli] CommandLine.getOptionValue() behaves contrary to docs - ASF JIRA",
                "issue_description": "\nHi\nIf I have:\nfinal String debugOpt = \"debug\";\n\tOption debug = OptionBuilder\n\t    .withArgName(debugOpt)\n\t    .withDescription(\"turn on debugging\")\n\t    .withLongOpt(debugOpt)\n\t    .create('d');\nand then later I do:\nString dbg = commandLine.getOptionValue(debugOpt);\nthen dbg will be null. Instead, I have to use getOptionValue('d'). This seems\ncontrary to the docs (see bottom of\nhttp://jakarta.apache.org/commons/cli/usage.html), which implies that I should\nbe able to query the commandLine object using a full string, rather than just\nthe string's first character.\nCan I suggest that the API of OptionBuilder be made clearer so that it is\nobvious that you can have long and short option names---perhaps make the\ncreate() method take no arguments (thus forcing long and short arg names to be\nset explicitly). (Also, there seems to be some confusion between the terms\n'argument' and 'option' in the API, but perhaps that is just me).\nAlso, I would hop to be able to query commandLine by either a single char or an\nentire string, as suggested by the docs.\nThanks,\nChris\n"
            },
            "2": {
                "commit_sha_buggy": "b0e1b80b6d4a10a9c9f46539bc4c7a3cce55886e",
                "commit_sha_fixed": "2ff9573ffb08dd52ec3a55a49f2d77a1e94efbdf",
                "report_id": "CLI-51",
                "report_url": "https://issues.apache.org/jira/browse/CLI-51",
                "issue_title": "[CLI-51] [cli] Parameter value \"-something\" misinterpreted as a parameter - ASF JIRA",
                "issue_description": "\nIf a parameter value is passed that contains a hyphen as the (delimited) first \ncharacter, CLI parses this a parameter. For example using the call\njava myclass -t \"-something\"\nResults in the parser creating the invalid parameter -o (noting that it is \nskipping the 's')\nMy code is using the Posix parser as follows\nOptions options = buildCommandLineOptions();\nCommandLineParser parser = new PosixParser();\nCommandLine commandLine = null;\ntry {\n\tcommandLine = parser.parse(options, args);\n}\ncatch (ParseException e) {\n\tSystem.out.println(\"Invalid parameters. \" + e.getMessage() + NEW_LINE);\n\tSystem.exit(EXIT_CODE_ERROR);\n}\nThis has been tested against the nightly build dated 20050503.\n"
            },
            "3": {
                "commit_sha_buggy": "85248e8ae52232ed75c2b4c52d4071bdf192db37",
                "commit_sha_fixed": "d35f2fa7a06457469a617677eeb4c1dc21484006",
                "report_id": "cli-1",
                "report_url": "https://issues.apache.org/jira/browse/CLI-1",
                "issue_title": "[CLI-1] PosixParser interupts \"-target opt\" as \"-t arget opt\" - ASF JIRA",
                "issue_description": "\nThis was posted on the Commons-Developer list and confirmed as a bug.\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try \n{\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       }\n catch (ParseException pe) \n{\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) \n{\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself .  To support special \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non special options. I'll have a look into this and let you know.\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\nThanks,\n-John K\n"
            },
            "4": {
                "commit_sha_buggy": "8ca630b76ebcfe24915a9edb3a6de756cab761c9",
                "commit_sha_fixed": "f78959477b207bf710049aa35730ef7659f0a1b9",
                "report_id": "cli-1",
                "report_url": "https://issues.apache.org/jira/browse/CLI-1",
                "issue_title": "[CLI-1] PosixParser interupts \"-target opt\" as \"-t arget opt\" - ASF JIRA",
                "issue_description": "\nThis was posted on the Commons-Developer list and confirmed as a bug.\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try \n{\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       }\n catch (ParseException pe) \n{\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) \n{\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself .  To support special \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non special options. I'll have a look into this and let you know.\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\nThanks,\n-John K\n"
            },
            "5": {
                "commit_sha_buggy": "2b0a94aee899d9e7d855c402ad40eb4e318f46e7",
                "commit_sha_fixed": "3880640ee6268a2ecb2912e1ae896153dc2229e5",
                "report_id": "CLI-133",
                "report_url": "https://issues.apache.org/jira/browse/CLI-133",
                "issue_title": "[CLI-133] NullPointerException in Util.stripLeadingHyphens when passed a null argument - ASF JIRA",
                "issue_description": "\nIf you try to do a hasOption(null), you get a NPE:\njava.lang.NullPointerException\n\tat org.apache.commons.cli.Util.stripLeadingHyphens(Util.java:39)\n\tat org.apache.commons.cli.CommandLine.resolveOption(CommandLine.java:166)\n\tat org.apache.commons.cli.CommandLine.hasOption(CommandLine.java:68)\nEither hasOption should reject the null argument, or the function should simply return false.  I think the latter makes more since, as this is how Java collections generally work.\n"
            },
            "7": {
                "commit_sha_buggy": "73276486b1f39510bf27cb6c0684da805b121f5d",
                "commit_sha_fixed": "4ee0d6c4f1b553858aeabf3ee6fb37d764f263e2",
                "report_id": "CLI-121",
                "report_url": "https://issues.apache.org/jira/browse/CLI-121",
                "issue_title": "[CLI-121] Tests fail under 1.6 + error at end that may or may not be related - ASF JIRA",
                "issue_description": "\nTestsuite: org.apache.commons.cli2.bug.Bug27575Test\nTests run: 1, Failures: 1, Errors: 0, Time elapsed: 0.058 sec\nTestcase: testRequiredOptions(org.apache.commons.cli2.bug.Bug27575Test):        FAILED\nexpected:<[-h]> but was:<-c <arg>>\njunit.framework.ComparisonFailure: expected:<[-h]> but was:<-c <arg>>\n        at org.apache.commons.cli2.bug.Bug27575Test.testRequiredOptions(Bug27575Test.java:36)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\nand error at end of:\nException in thread \"Thread-1\" javax.xml.transform.TransformerFactoryConfigurationError: Provider for javax.xml.transform.TransformerFactory cannot be found\n        at javax.xml.transform.TransformerFactory.newInstance(Unknown Source)\n        at java.util.prefs.XmlSupport.writeDoc(XmlSupport.java:246)\n        at java.util.prefs.XmlSupport.exportMap(XmlSupport.java:333)\n        at java.util.prefs.FileSystemPreferences$8.run(FileSystemPreferences.java:607)\n"
            },
            "8": {
                "commit_sha_buggy": "6a6bb48840aa0043200a5d9f6fffea47aea1a8db",
                "commit_sha_fixed": "4f407378c93b9e2a8e24c855e8bed5eb12bf7a06",
                "report_id": "CLI-151",
                "report_url": "https://issues.apache.org/jira/browse/CLI-151",
                "issue_title": "[CLI-151] HelpFormatter wraps incorrectly on every line beyond the first - ASF JIRA",
                "issue_description": "\nThe method findWrapPos(...) in the HelpFormatter is a couple of bugs in the way that it deals with the \"startPos\" variable.  This causes it to format every line beyond the first line by \"startPos\" to many characters, beyond the specified width.  \nTo see this, create an option with a long description, and then use the help formatter to print it.  The first line will be the correct length.  The 2nd, 3rd, etc lines will all be too long.\nI don't have a patch (sorry) - but here is a corrected version of the method.\nI fixed it in two places - both were using \"width + startPos\" when they should have been using width.\n\n protected int findWrapPos(String text, int width, int startPos)\n    {\n        int pos = -1;\n\n        // the line ends before the max wrap pos or a new line char found\n        if (((pos = text.indexOf('\\n', startPos)) != -1 && pos <= width)\n            || ((pos = text.indexOf('\\t', startPos)) != -1 && pos <= width))\n        {\n            return pos+1;\n        }\n        else if ((width) >= text.length())\n        {\n            return -1;\n        }\n\n\n        // look for the last whitespace character before startPos+width\n        pos = width;\n\n        char c;\n\n        while ((pos >= startPos) && ((c = text.charAt(pos)) != ' ')\n               && (c != '\\n') && (c != '\\r'))\n        {\n            --pos;\n        }\n\n        // if we found it - just return\n        if (pos > startPos)\n        {\n            return pos;\n        }\n        \n        // must look for the first whitespace chearacter after startPos \n        // + width\n        pos = startPos + width;\n\n        while ((pos <= text.length()) && ((c = text.charAt(pos)) != ' ')\n               && (c != '\\n') && (c != '\\r'))\n        {\n            ++pos;\n        }\n\n        return (pos == text.length())        ? (-1) : pos;\n    }\n\n\n"
            },
            "9": {
                "commit_sha_buggy": "298804b71d4e5f8b621f48a300f421229a3f5c86",
                "commit_sha_fixed": "fea35870b69c0d37ab36ab6783edbc7aacc0842c",
                "report_id": "CLI-149",
                "report_url": "https://issues.apache.org/jira/browse/CLI-149",
                "issue_title": "[CLI-149] MissingOptionException.getMessage() changed from CLI 1.0 > 1.1 - ASF JIRA",
                "issue_description": "\nThe MissingOptionException.getMessage() string changed from CLI 1.0 > 1.1. \nCLI 1.0 was poorly formatted but readable:\nMissing required options: -format-source-properties\nCLI 1.1 is almost unreadable:\nMissing required options: formatsourceproperties\nIn CLI 1.0 Options.addOption(Option) prefixed the stored options with a \"-\" and in CLI 1.1 it doesn't.\nI would suggest changing Parser.checkRequiredOptions() to add the options to the error message with a prefix of \" -\":\nOLD: \n            // loop through the required options\n            while (iter.hasNext())\n            {\n                buff.append(iter.next());\n            }\n\nNEW: \n            // loop through the required options\n            while (iter.hasNext())\n            {\n                buff.append(\" -\" + iter.next());\n            }\n\nResulting in:\nMissing required options: -format -source -properties\n"
            },
            "10": {
                "commit_sha_buggy": "d0f6128191443bbf49e1c9fde616f87c16486db4",
                "commit_sha_fixed": "d72a578a8949e4b1c437ec55997d8786836f139c",
                "report_id": "CLI-156",
                "report_url": "https://issues.apache.org/jira/browse/CLI-156",
                "issue_title": "[CLI-156] Missing required options not throwing MissingOptionException - ASF JIRA",
                "issue_description": "\nWhen an Options object is used to parse a second set of command arguments it won't throw a MissingOptionException.\n\nimport org.apache.commons.cli.CommandLine;\nimport org.apache.commons.cli.GnuParser;\nimport org.apache.commons.cli.OptionBuilder;\nimport org.apache.commons.cli.Options;\nimport org.apache.commons.cli.ParseException;\n\npublic class Example\n{\n\tpublic static void main(String[] args) throws ParseException\n\t{\n\t\tbrokenExample();\n\t\tworkingExample();\n\t}\n\n\t// throws exception as expected\n\tprivate static void workingExample() throws ParseException\n\t{\n\t\tString[] args = {};\n\n\t\tOptions opts = new Options();\n\t\topts.addOption(OptionBuilder.isRequired().create('v'));\n\n\t\tGnuParser parser = new GnuParser();\n\t\tCommandLine secondCL = parser.parse(opts, args);\n\n\t\tSystem.out.println(\"Done workingExample\");\n\t}\n\n\t// fails to throw exception on second invocation of parse\n\tprivate static void brokenExample() throws ParseException\n\t{\n\t\tString[] firstArgs = { \"-v\" };\n\t\tString[] secondArgs = {};\n\n\t\tOptions opts = new Options();\n\t\topts.addOption(OptionBuilder.isRequired().create('v'));\n\n\t\tGnuParser parser = new GnuParser();\n\t\tCommandLine firstCL = parser.parse(opts, firstArgs);\n\t\tCommandLine secondCL = parser.parse(opts, secondArgs);\n\n\t\tSystem.out.println(\"Done brokenExample\");\n\t}\n}\n\n\nThis is a result of the Options object returning the reference to its own list and the parsers modifying that list. The first call is removing the required options as they are found and subsequent calls get back an empty list.\n"
            },
            "11": {
                "commit_sha_buggy": "33abc034037e3ef5d85d1b03010122617c386827",
                "commit_sha_fixed": "d36adebd3547279b709960c902c3fb7b89a9a4ef",
                "report_id": "cli-1",
                "report_url": "https://issues.apache.org/jira/browse/CLI-1",
                "issue_title": "[CLI-1] PosixParser interupts \"-target opt\" as \"-t arget opt\" - ASF JIRA",
                "issue_description": "\nThis was posted on the Commons-Developer list and confirmed as a bug.\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try \n{\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       }\n catch (ParseException pe) \n{\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) \n{\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself .  To support special \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non special options. I'll have a look into this and let you know.\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\nThanks,\n-John K\n"
            },
            "12": {
                "commit_sha_buggy": "b8f825936796e2f5b6663de021aefa53fa728f67",
                "commit_sha_fixed": "aa050a69b2395f496f953f4f9c4f63a475dcf430",
                "report_id": "cli-1",
                "report_url": "https://issues.apache.org/jira/browse/CLI-1",
                "issue_title": "[CLI-1] PosixParser interupts \"-target opt\" as \"-t arget opt\" - ASF JIRA",
                "issue_description": "\nThis was posted on the Commons-Developer list and confirmed as a bug.\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try \n{\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       }\n catch (ParseException pe) \n{\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) \n{\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself .  To support special \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non special options. I'll have a look into this and let you know.\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\nThanks,\n-John K\n"
            },
            "13": {
                "commit_sha_buggy": "e2ba946ea0e01c36c84f97f483e1d22cfd64b917",
                "commit_sha_fixed": "538fb6889f0387a40b821cfb315685e929110736",
                "report_id": "CLI-61",
                "report_url": "https://issues.apache.org/jira/browse/CLI-61",
                "issue_title": "[CLI-61] [cli] argument defaults prevent commandline usage. - ASF JIRA",
                "issue_description": "\nI have found a bug in the following scenario:\nYou have an option which can take a single argument which in turn has a default\nvalue. You supply a value on the command line which is intended to override\nthis default however as the CommandLine already has a value for this Option,\nthis second value is not allowed and the command line cannot be parsed.\nI have created a patch which adds a method to WritableCommandLine and its Impl\nwhich allows you to retrieve the undefaulted values for an Option. I have then\nchanged ArgumentImpl to use this method to determine the argument count\n"
            },
            "14": {
                "commit_sha_buggy": "b7b2069f9d846c6aea5fee98508ec1491fdf1123",
                "commit_sha_fixed": "c338c8aca40d43efda580057f6d41ba228e26ec1",
                "report_id": "CLI-144",
                "report_url": "https://issues.apache.org/jira/browse/CLI-144",
                "issue_title": "[CLI-144] adding a FileValidator results in ClassCastException in parser.parseAndHelp(args) - ASF JIRA",
                "issue_description": "\nWhen I add a FileValidator.getExistingFileInstance() to an Argument, I get a ClassCastException when I parse args.\nBelow is a testcase invoke with\n   java org.apache.commons.cli2.issues.CLI2Sample -classpath commons-cli-2.0-SNAPSHOT.jar --file-name path-to-an-existing-file\nRun it and you get:\nException in thread \"main\" java.lang.ClassCastException: java.io.File cannot be cast to java.lang.String\n\tat org.apache.commons.cli2.validation.FileValidator.validate(FileValidator.java:122)\n\tat org.apache.commons.cli2.option.ArgumentImpl.validate(ArgumentImpl.java:250)\n\tat org.apache.commons.cli2.option.ParentImpl.validate(ParentImpl.java:123)\n\tat org.apache.commons.cli2.option.DefaultOption.validate(DefaultOption.java:175)\n\tat org.apache.commons.cli2.option.GroupImpl.validate(GroupImpl.java:264)\n\tat org.apache.commons.cli2.commandline.Parser.parse(Parser.java:105)\n\tat org.apache.commons.cli2.commandline.Parser.parseAndHelp(Parser.java:125)\n\tat org.apache.commons.cli2.issues.CLI2Sample.main(CLI2Sample.java:38)\nComment out the withValidator call and it runs with no exception. \nI also get a similar ClassCastException if I add a \n  .withValidator(NumberValidator.getIntegerInstance())\nto another option/argument.\nHere is the source\npackage org.apache.commons.cli2.issues;\nimport java.io.File;\nimport org.apache.commons.cli2.CommandLine;\nimport org.apache.commons.cli2.Group;\nimport org.apache.commons.cli2.builder.ArgumentBuilder;\nimport org.apache.commons.cli2.builder.DefaultOptionBuilder;\nimport org.apache.commons.cli2.builder.GroupBuilder;\nimport org.apache.commons.cli2.commandline.Parser;\nimport org.apache.commons.cli2.option.DefaultOption;\nimport org.apache.commons.cli2.validation.FileValidator;\npublic class CLI2Sample\n{\n   public static void main(String[] args)\n   {\n      final DefaultOptionBuilder obuilder = new DefaultOptionBuilder();\n      final ArgumentBuilder abuilder = new ArgumentBuilder();\n      final GroupBuilder gbuilder = new GroupBuilder();\n      DefaultOption fileNameOption = obuilder\n            .withShortName(\"f\")\n            .withLongName(\"file-name\")\n            .withRequired(true)\n            .withDescription(\"name of an existing file\")\n            .withArgument(abuilder\n                  .withName(\"file-name\")\n                  .withValidator(FileValidator.getExistingFileInstance())\n                  .create())\n            .create();\n      Group options = gbuilder\n            .withName(\"options\")\n            .withOption(fileNameOption)\n            .create();\n      Parser parser = new Parser();\n      parser.setHelpTrigger(\"--help\");\n      parser.setGroup(options);\n      CommandLine cl = parser.parseAndHelp(args);\n     }\n}\n"
            },
            "15": {
                "commit_sha_buggy": "c338c8aca40d43efda580057f6d41ba228e26ec1",
                "commit_sha_fixed": "a93139165b160af1c908c85a06b0af6b3dda3387",
                "report_id": "CLI-158",
                "report_url": "https://issues.apache.org/jira/browse/CLI-158",
                "issue_title": "[CLI-158] deafult arguments only works if no arguments are submitted - ASF JIRA",
                "issue_description": "\nWhen using multple arguments and defaults, the behaviour is counter-intuitive and will only pick up a default if no args are passed in.\nFor instance in the code below I have set up so 0, 1, or 2 args may bve accepted, with defaults 100 and 1000.\nI expect it to behave as follows.\n1. for 2 args, 1 and 2 the values should be 1 and 2. This works as expected.\n2. for 0 args passed in the values should be 100 and 1000, picking up both of the defaults. This works as expected\n3. for 1 arg passed in the values should be 1 and 1000, so the second argument picks up the second default value. The valuse become just 1, which is not as expected..\nCurrently, in the second case will only return 1 and ignore the defaults.\n    public void testSingleOptionSingleArgument() throws Exception {\n        String defaulValue1 = \"100\";\n        String defaultValue2 = \"1000\";\n        final DefaultOptionBuilder obuilder = new DefaultOptionBuilder();\n        final ArgumentBuilder abuilder = new ArgumentBuilder();\n        final GroupBuilder gbuilder = new GroupBuilder();\n        DefaultOption bOption = obuilder.withShortName(\"b\")\n                .withLongName(\"b\")\n                .withArgument(abuilder.withName(\"b\")\n                        .withMinimum(0)\n                        .withMaximum(2)\n                        .withDefault(defaulValue1)\n                        .withDefault(defaultValue2)\n                        .create())\n                .create();\n        Group options = gbuilder\n                .withName(\"options\")\n                .withOption(bOption)\n                .create();\n        Parser parser = new Parser();\n        parser.setHelpTrigger(\"--help\");\n        parser.setGroup(options);\n        String enteredValue1 = \"1\";\n        String[] args = new String[]\n{\"-b\", enteredValue1}\n;\n        CommandLine cl = parser.parse(args);\n        CommandLine cmd = cl;\n        assertNotNull(cmd);\n        List b = cmd.getValues(\"-b\");\n        assertEquals(\"[\" + enteredValue1 + \"]\", b + \"\");\n    }\n"
            },
            "16": {
                "commit_sha_buggy": "eed25612b11caf1f4e6e572e58db4306f31803c9",
                "commit_sha_fixed": "f104dd060c6c88450ac9ee9eb818b26374512440",
                "report_id": "CLI-123",
                "report_url": "https://issues.apache.org/jira/browse/CLI-123",
                "issue_title": "[CLI-123] the minimum and maximum constraints on a group do not take other groups into account - ASF JIRA",
                "issue_description": "\nIf you have a Group A as a child of Group B and you set a minimum or maximum on Group B, the presence or not of Group A will not affect GroupB. This is because Groups are never added to a CommandLine so .hasOption(A) returns false and so it isn't counted. WriteableCommandLine#addOption(Option) should be used to indicate that a Group is present if any of a Groups children is present.\n"
            },
            "17": {
                "commit_sha_buggy": "cfbb46adb163d9b8af00e9a29e6b42d597f8804f",
                "commit_sha_fixed": "9c5ce3501938cff01d78b7a1fff10a60abe9e0cf",
                "report_id": "CLI-163",
                "report_url": "https://issues.apache.org/jira/browse/CLI-163",
                "issue_title": "[CLI-163] PosixParser keeps bursting tokens even if a non option character is found - ASF JIRA",
                "issue_description": "\nPosixParser doesn't stop the bursting process of a token if stopAtNonOption is enabled and a non option character is encountered.\nFor example if the options a and b are defined, with stopAtNonOption=true the following command line:\n\n-azb\n\nis turned into:\n\n-a zb -b\n\nthe right output should be:\n\n-a zb\n\n"
            },
            "18": {
                "commit_sha_buggy": "9c5ce3501938cff01d78b7a1fff10a60abe9e0cf",
                "commit_sha_fixed": "c8606251c904dfaf5303f71b788e12f7fff15fab",
                "report_id": "CLI-164",
                "report_url": "https://issues.apache.org/jira/browse/CLI-164",
                "issue_title": "[CLI-164] PosixParser ignores unrecognized tokens starting with '-' - ASF JIRA",
                "issue_description": "\nPosixParser doesn't handle properly unrecognized tokens starting with '-' when stopAtNonOption is enabled, the token is simply ignored.\nFor example, if the option 'a' is defined, the following command line:\n\n-z -a foo\n\nis interpreted as:\n\n-a foo\n\n"
            },
            "19": {
                "commit_sha_buggy": "c8606251c904dfaf5303f71b788e12f7fff15fab",
                "commit_sha_fixed": "b1331806960001da95424315b6103d755107b519",
                "report_id": "CLI-164",
                "report_url": "https://issues.apache.org/jira/browse/CLI-164",
                "issue_title": "[CLI-164] PosixParser ignores unrecognized tokens starting with '-' - ASF JIRA",
                "issue_description": "\nPosixParser doesn't handle properly unrecognized tokens starting with '-' when stopAtNonOption is enabled, the token is simply ignored.\nFor example, if the option 'a' is defined, the following command line:\n\n-z -a foo\n\nis interpreted as:\n\n-a foo\n\n"
            },
            "20": {
                "commit_sha_buggy": "b1331806960001da95424315b6103d755107b519",
                "commit_sha_fixed": "99aa05af2bfef3980ad8f94230cd077e8d30c5ea",
                "report_id": "CLI-165",
                "report_url": "https://issues.apache.org/jira/browse/CLI-165",
                "issue_title": "[CLI-165] PosixParser keeps processing tokens after a non unrecognized long option - ASF JIRA",
                "issue_description": "\nPosixParser keeps processing tokens after a non unrecognized long option when stopAtNonOption is enabled. The tokens after the unrecognized long option are burst, split around '=', etc.. instead of being kept as is.\nFor example, with the options 'a' and 'b' defined, 'b' having an argument, the following command line:\n\n--zop -abfoo\n\nis interpreted as:\n\n--zop -a -b foo\n\nbut the last token should remain unchanged.\n"
            },
            "21": {
                "commit_sha_buggy": "028893dad71e4823f67a427903699999d6eedd4b",
                "commit_sha_fixed": "9cd78b4c83df53ba302baadac4c976ca84f428f9",
                "report_id": "CLI-150",
                "report_url": "https://issues.apache.org/jira/browse/CLI-150",
                "issue_title": "[CLI-150] Negative numbers mistaken for options - ASF JIRA",
                "issue_description": "\nIf an option has a negative numerical argument, the parser mistakes it for another option and throws an error. For example, consider:\nArgument numArg = aBuilder.withValidator(NumberValidator.getNumberInstance()).withMinimum(1).withMaximum(1).create();\nOption numOpt = oBuilder.withLongName(\"num\").withArgument(numArg).create();\nGroup options = gBuilder.withOption(numOpt).create();\nThen parsing --num -0.1 results in:\nUnexpected -0.1 while processing --num\n"
            },
            "22": {
                "commit_sha_buggy": "ae2ff1d12efd8f0f55bfa1febd8c77af4bb433c7",
                "commit_sha_fixed": "db4a638cf642fd7d031fcaebffa306b0a16ba771",
                "report_id": "cli-1",
                "report_url": "https://issues.apache.org/jira/browse/CLI-1",
                "issue_title": "[CLI-1] PosixParser interupts \"-target opt\" as \"-t arget opt\" - ASF JIRA",
                "issue_description": "\nThis was posted on the Commons-Developer list and confirmed as a bug.\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try \n{\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       }\n catch (ParseException pe) \n{\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) \n{\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself .  To support special \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non special options. I'll have a look into this and let you know.\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\nThanks,\n-John K\n"
            },
            "23": {
                "commit_sha_buggy": "88cf9e4ab6e1b127de46fb2540f4d1fffac56442",
                "commit_sha_fixed": "2ddaae14dd23643a4b5f71f8274534b0b34556a4",
                "report_id": "CLI-162",
                "report_url": "https://issues.apache.org/jira/browse/CLI-162",
                "issue_title": "[CLI-162] infinite loop in the wrapping code of HelpFormatter - ASF JIRA",
                "issue_description": "\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\nTest case:\n\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.\n"
            },
            "24": {
                "commit_sha_buggy": "ac6e754ecfc86822aa1ab74d657b0b3f0222b2e6",
                "commit_sha_fixed": "02dd7c20646bf67dcfb6f7da6beeb7cdffc6ac22",
                "report_id": "CLI-162",
                "report_url": "https://issues.apache.org/jira/browse/CLI-162",
                "issue_title": "[CLI-162] infinite loop in the wrapping code of HelpFormatter - ASF JIRA",
                "issue_description": "\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\nTest case:\n\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.\n"
            },
            "25": {
                "commit_sha_buggy": "02dd7c20646bf67dcfb6f7da6beeb7cdffc6ac22",
                "commit_sha_fixed": "6a585453d385449dc23d90479488f92f02cd6b83",
                "report_id": "CLI-162",
                "report_url": "https://issues.apache.org/jira/browse/CLI-162",
                "issue_title": "[CLI-162] infinite loop in the wrapping code of HelpFormatter - ASF JIRA",
                "issue_description": "\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\nTest case:\n\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.\n"
            },
            "26": {
                "commit_sha_buggy": "879c762baac4a9d7aade43d302e730e239a54c21",
                "commit_sha_fixed": "aa2434d301c49d100f50af544333886a6767ce9d",
                "report_id": "CLI-177",
                "report_url": "https://issues.apache.org/jira/browse/CLI-177",
                "issue_title": "[CLI-177] OptionBuilder is not reseted in case of an IAE at create - ASF JIRA",
                "issue_description": "\nIf the call to OptionBuilder.create() fails with an IllegalArgumentException, the OptionBuilder is not resetted and its next usage may contain unwanted settings. Actually this let the CLI-1.2 RCs fail on IBM JDK 6 running on Maven 2.0.10.\n"
            },
            "27": {
                "commit_sha_buggy": "6a999186695d404ccb6c1528df68fe2eb42863c2",
                "commit_sha_fixed": "4c971f08861e8cefb8ca9ac20799bfdad4e973a4",
                "report_id": "CLI-182",
                "report_url": "https://issues.apache.org/jira/browse/CLI-182",
                "issue_title": "[CLI-182] Unable to select a pure long option in a group - ASF JIRA",
                "issue_description": "\nOptionGroup doesn't play nice with options with a long name and no short name. If the selected option hasn't a short name, group.setSelected(option) has no effect.\n"
            },
            "28": {
                "commit_sha_buggy": "10b14afb9ff42a3f216296f526f65d001b545e3f",
                "commit_sha_fixed": "3433f467554985a6bd9bf530a4810376be6fe250",
                "report_id": "CLI-201",
                "report_url": "https://issues.apache.org/jira/browse/CLI-201",
                "issue_title": "[CLI-201] Default options may be partially processed - ASF JIRA",
                "issue_description": "\nThe Properties instance passed to the Parser.parse() method to initialize the default options may be partially processed. This happens when the properties contains an option that doesn't accept arguments and has a default value that isn't evaluated to \"true\". When this case occurs the processing of the properties is stopped and the remaining options are never handled.\nThis is caused by the break statement in Parser.processProperties(Properties), a continue statement should have been used instead.\nThe related test in ValueTest is also wrong, there are two assertions that need to be changed:\n\nOptions opts = new Options();\nopts.addOption(\"a\", false, \"toggle -a\");\nopts.addOption(\"c\", \"c\", false, \"toggle -c\");\nopts.addOption(OptionBuilder.hasOptionalArg().create('e'));\n\nproperties = new Properties();\nproperties.setProperty( \"a\", \"false\" );\nproperties.setProperty( \"c\", \"no\" );\nproperties.setProperty( \"e\", \"0\" );\n\ncmd = parser.parse(opts, null, properties);\nassertTrue( !cmd.hasOption(\"a\") );\nassertTrue( !cmd.hasOption(\"c\") );\nassertTrue( !cmd.hasOption(\"e\") ); // Wrong, this option accepts an argument and should receive the value \"0\"\n\n\n and the second one:\n\nproperties = new Properties();\nproperties.setProperty( \"a\", \"just a string\" );\nproperties.setProperty( \"e\", \"\" );\n\ncmd = parser.parse(opts, null, properties);\nassertTrue( !cmd.hasOption(\"a\") );\nassertTrue( !cmd.hasOption(\"c\") );\nassertTrue( !cmd.hasOption(\"e\") ); // Wrong, this option accepts an argument and should receive an empty string as value\n\n\n"
            },
            "29": {
                "commit_sha_buggy": "a2cf820dd69e55050a8db004c305a6133c3feb2e",
                "commit_sha_fixed": "20002f7f4e971349a1c95dd3b05846c5b824b65c",
                "report_id": "CLI-185",
                "report_url": "https://issues.apache.org/jira/browse/CLI-185",
                "issue_title": "[CLI-185] Commons CLI incorrectly stripping leading and trailing quotes - ASF JIRA",
                "issue_description": "\norg.apache.commons.cli.Parser.processArgs() calls Util.stripLeadingAndTrailingQuotes() for all argument values. IMHO this is incorrect and totally broken.\nIt is trivial to create a simple test for this. Output:\n    $ java -cp target/clitest.jar Clitest --balloo \"this is a \\\"test\\\"\"\n    Value of argument balloo is 'this is a \"test'.\nThe argument 'balloo' should indeed keep its trailing double quote. It is what the shell gives it, so don't try to do something clever to it.\nThe offending code was committed here:\nhttp://svn.apache.org/viewvc?view=rev&revision=129874\nand has been there for more than 6 years . Why was this committed in the first place?\nThe fix is trivial, just get rid of Util.stripLeadingAndTrailingQuotes(), and consequently avoid calling it from Parser.processArgs().\n"
            },
            "30": {
                "commit_sha_buggy": "5560a086886c4d6dba2c30eb75e57e3167765c6e",
                "commit_sha_fixed": "324b7f901b91614927926a5bab1d9e0e2325f018",
                "report_id": "CLI-203",
                "report_url": "https://issues.apache.org/jira/browse/CLI-203",
                "issue_title": "[CLI-203] The state of the option groups is not updated by the default options - ASF JIRA",
                "issue_description": "\nThe state of the option groups is neither checked nor updated when the default options passed as a Properties instance to the parse method are processed. For example if 'a' and 'b' are two mutually exclusive options, the command line argument could specify 'a' and the default options could contain 'b', the parser will not complain and the resulting CommandLine will contain 'a' and 'b'.\n"
            },
            "31": {
                "commit_sha_buggy": "4381ba54c845402f18760fb04ff1f6db1922f6b2",
                "commit_sha_fixed": "4d2c8a22d1e1831858029b8ef225a07f4445a221",
                "report_id": "CLI-205",
                "report_url": "https://issues.apache.org/jira/browse/CLI-205",
                "issue_title": "[CLI-205] HelpFormatter.setArgName() has no effect - ASF JIRA",
                "issue_description": "\nThe default argument name set on the HelpFormatter has no effect because the Option and the OptionBuilder bring automatically a default value 'arg'.\n"
            },
            "32": {
                "commit_sha_buggy": "23df383408513eddaf3e6dc4244c89fd48427695",
                "commit_sha_fixed": "777cb81088d47472df21a452edd5ba568d4b3fdf",
                "report_id": "CLI-193",
                "report_url": "https://issues.apache.org/jira/browse/CLI-193",
                "issue_title": "[CLI-193] StringIndexOutOfBoundsException in HelpFormatter.findWrapPos - ASF JIRA",
                "issue_description": "\nIn the last while loop in HelpFormatter.findWrapPos, it can pass text.length() to text.charAt(int), which throws a StringIndexOutOfBoundsException. The first expression in that while loop condition should use a <, not a <=.\nThis is on line 908 in r779646:\nhttp://svn.apache.org/viewvc/commons/proper/cli/trunk/src/java/org/apache/commons/cli/HelpFormatter.java?revision=779646&view=markup\n"
            },
            "33": {
                "commit_sha_buggy": "99222749ca9b0d9338ed5df796db9c32b82424b8",
                "commit_sha_fixed": "483f811dfefdc6bee162481425f261d983f15e4a",
                "report_id": "CLI-207",
                "report_url": "https://issues.apache.org/jira/browse/CLI-207",
                "issue_title": "[CLI-207] HelpFormatter strips leading whitespaces in the footer - ASF JIRA",
                "issue_description": "\nI discovered a bug in Commons CLI while using it through Groovy's CliBuilder. See the following issue:\nhttp://jira.codehaus.org/browse/GROOVY-4313?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel\nCopied:\nThe following code:\ndef cli = new CliBuilder(footer: \"line1:\\n line2:\\n\")\ncli.usage()\nProduces the following output:\nline1\nline2\nNote that there are no whitespaces before \"line2\". Replacing them with \"\\t\" doesn't solve the problem either.\n"
            },
            "34": {
                "commit_sha_buggy": "40c4892e932afba6ac2ace430ee59a465565bd50",
                "commit_sha_fixed": "62a3b36efc78e53c233c2fb49cc8199c5eabec1d",
                "report_id": "CLI-215",
                "report_url": "https://issues.apache.org/jira/browse/CLI-215",
                "issue_title": "[CLI-215] String as default Option type - ASF JIRA",
                "issue_description": "\ngetParsedOptionValue returns null unless Option.type gets explicitly set. The user expects it to be String unless set to any other type.\nThis coult be either fixed in the Option constructor or in CommandLine.getParsedOptionValue. Mentioning this behaviour in Javadoc would be advisable.\n"
            },
            "35": {
                "commit_sha_buggy": "a154084dbf5af77f6f3a64a7561fd77aadb78429",
                "commit_sha_fixed": "085a1538fa20d8e48faad49eaffd697f024bf1af",
                "report_id": "CLI-252",
                "report_url": "https://issues.apache.org/jira/browse/CLI-252",
                "issue_title": "[CLI-252] LongOpt falsely detected as ambiguous - ASF JIRA",
                "issue_description": "\nOptions options = new Options();\noptions.addOption(Option.builder().longOpt(\"importToOpen\").hasArg().argName(\"FILE\").build());\noptions.addOption(Option.builder(\"i\").longOpt(\"import\").hasArg().argName(\"FILE\").build());\nParsing \"--import=FILE\" is not possible since 1.3 as it throws a AmbiguousOptionException stating that it cannot decide whether import is import or importToOpen. In 1.2 this is not an issue. \nThe root lies in the new DefaultParser which does a startsWith check internally. \n"
            },
            "36": {
                "commit_sha_buggy": "f6af62367494ff8d0d7844f7f435e5ee36c81dcf",
                "commit_sha_fixed": "afc13c445a4c80432e52d735685b272fadfeeddf",
                "report_id": "CLI-266",
                "report_url": "https://issues.apache.org/jira/browse/CLI-266",
                "issue_title": "[CLI-266] HelpFormatter#setOptionComparator(null) doesn't display the values in inserted order - ASF JIRA",
                "issue_description": "\n\nOptionGroup group = new OptionGroup();\nOption h = Option.builder(\"h\").build();\nOption s = Option.builder(\"s\").build();\nOption b = Option.builder(\"b\").build();\nOption t = Option.builder(\"t\").build();\ngroup.addOption(h)\n    .addOption(s)\n    .addOption(b)\n    .addOption(t);\nOptions options = new Options();\noptions.addOptionGroup(group);\noptions.addOption(Option.builder(\"o\").build());\nHelpFormatter formatter = new HelpFormatter();\nformatter.setOptionComparator(null);\nformatter.printHelp(\"cmd\", \"\", options, null);\n\n\nThis code does print the options(1. Group, 2. Option \"o\") in the order of insertion but the groups order of display is messed up.\nThe OptionGroup internally uses a HashMap. If that could be replaced with a LinkedHashMap this issue can be solved.\n"
            },
            "37": {
                "commit_sha_buggy": "9e51962309fac2806f5fe0e4e3df94e0e187607a",
                "commit_sha_fixed": "1bf9e6c551b6a2e7d37291673a1ff77c338ce131",
                "report_id": "CLI-265",
                "report_url": "https://issues.apache.org/jira/browse/CLI-265",
                "issue_title": "[CLI-265] Optional argument picking up next regular option as its argument - ASF JIRA",
                "issue_description": ""
            },
            "38": {
                "commit_sha_buggy": "5764b6270287a74d31cb83f70ab38bdd916e619e",
                "commit_sha_fixed": "ac2a1c85616f0140418de9190389fe7b80296c39",
                "report_id": "CLI-265",
                "report_url": "https://issues.apache.org/jira/browse/CLI-265",
                "issue_title": "[CLI-265] Optional argument picking up next regular option as its argument - ASF JIRA",
                "issue_description": ""
            },
            "39": {
                "commit_sha_buggy": "70a392756c713f404fed0e3ddd48aa18ce20485f",
                "commit_sha_fixed": "0b453953fa5f55cf2e8fd034d4d55972deb7647a",
                "report_id": "CLI-274",
                "report_url": "https://issues.apache.org/jira/browse/CLI-274",
                "issue_title": "[CLI-274] Option parser type EXISTING_FILE_VALUE not check file existing - ASF JIRA",
                "issue_description": "\nWhen the user pass option type FileInputStream.class, I think the expected behavior for the return value is the same type, which the user passed.\nOptions options = new Options();\noptions.addOption(Option.builder(\"f\").hasArg().type(FileInputStream.class).build());\nCommandLine cline = new DefaultParser().parse(options, args);\nFileInputStream file = (FileInputStream) cline.getParsedOptionValue(\"f\"); // it returns \"File\" object, without check File exist.\nI attach a solution for it:\nhttps://github.com/schaumb/commons-cli/commit/abfcc8211f529ab75f3b3edd4a827e484109eb0b\n"
            },
            "40": {
                "commit_sha_buggy": "e400f9256a2af526e9a06b9d5d2965965109a8db",
                "commit_sha_fixed": "b0024d482050a08efc36c3cabee37c0af0e57a10",
                "report_id": "CLI-282",
                "report_url": "https://issues.apache.org/jira/browse/CLI-282",
                "issue_title": "[CLI-282] TypeHandler should throw ParseException for an unsupported class - ASF JIRA",
                "issue_description": "\nJavaDoc for TypeHandler states that createValue will\n\n* @throws ParseException if the value creation for the given object type failedtype\n\n\u00a0However createValue(String str, Class<?> clazz) will return null if the clazz is unknown.\n"
            },
            "41": {
                "commit_sha_buggy": "b20a8e9fd4d7d63621bf61ffaa43b51ea2fca3c7",
                "commit_sha_fixed": "880a9f6c45dbcb14215bb35de21fdbbfaeb89c2e",
                "report_id": "CLI-162",
                "report_url": "https://issues.apache.org/jira/browse/CLI-162",
                "issue_title": "[CLI-162] infinite loop in the wrapping code of HelpFormatter - ASF JIRA",
                "issue_description": "\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\nTest case:\n\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.\n"
            },
            "42": {
                "commit_sha_buggy": "4141904a4bc95471d2f80ecf35d012e7fcf34bb3",
                "commit_sha_fixed": "84234a65638f0e9e4be73dfcccaa6530a5b571af",
                "report_id": "CLI-162",
                "report_url": "https://issues.apache.org/jira/browse/CLI-162",
                "issue_title": "[CLI-162] infinite loop in the wrapping code of HelpFormatter - ASF JIRA",
                "issue_description": "\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\nTest case:\n\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.\n"
            }
        }
    },
    "Closure": {
        "owner_repo": "google/closure-compiler",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2353d807058bc2a20af279a480d6652cdf892f4d",
                "commit_sha_fixed": "1dfad5043a207e032a78ef50c3cba50488bcd300",
                "report_id": "253",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-253.json",
                "issue_title": "function arguments should not be optimized away",
                "issue_description": "function arguments should not be optimized away"
            },
            "2": {
                "commit_sha_buggy": "61095090415cff7cae4f3645fa76ee7cdd3ee23d",
                "commit_sha_fixed": "d1cfe67977d8f3aaa85ec20c262171da394d5977",
                "report_id": "884",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-884.json",
                "issue_title": "combining @interface and multiple @extends can crash compiler",
                "issue_description": "combining @interface and multiple @extends can crash compiler"
            },
            "3": {
                "commit_sha_buggy": "3cc85c3c37aa8bc834a4a86f91ddeb399d854024",
                "commit_sha_fixed": "d80fcc04239ab8c4cf781273c4f9bc54cf06f479",
                "report_id": "864",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-864.json",
                "issue_title": "optimization fails with variable in catch clause",
                "issue_description": "optimization fails with variable in catch clause"
            },
            "4": {
                "commit_sha_buggy": "1c95684b4a6add525b3070cbd27c234981520676",
                "commit_sha_fixed": "efefb736fccc2039b5fb079710b3f2ac82b8c6e4",
                "report_id": "873",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-873.json",
                "issue_title": "Converting from an interface type to a constructor which @implements itself causes stack overflow.",
                "issue_description": "Converting from an interface type to a constructor which @implements itself causes stack overflow."
            },
            "5": {
                "commit_sha_buggy": "722d1192e7ed174a12911dce09594228e31240e9",
                "commit_sha_fixed": "59eec92e364b2ec2cec9dd63449f5c0134983f18",
                "report_id": "851",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-851.json",
                "issue_title": "Compiler ignores 'delete' statements, can break functionality.",
                "issue_description": "Compiler ignores 'delete' statements, can break functionality."
            },
            "6": {
                "commit_sha_buggy": "929b1c8fb38d8a7145f6e6f96255a764d92f5b3c",
                "commit_sha_fixed": "9f7a353385bf0b93cdaeaa56cc5b1450db790127",
                "report_id": "635",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-635.json",
                "issue_title": "better 'this' type checking",
                "issue_description": "better 'this' type checking"
            },
            "7": {
                "commit_sha_buggy": "d93f2d5aaf346749eaa6ae1641a171aeb177de5d",
                "commit_sha_fixed": "e736b1c92981fafdc87f3f41f66918305f173734",
                "report_id": "841",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-841.json",
                "issue_title": "Bad type inference with goog.isFunction and friends",
                "issue_description": "Bad type inference with goog.isFunction and friends"
            },
            "8": {
                "commit_sha_buggy": "e237d2643b102fbea616717806391f48e2ce506a",
                "commit_sha_fixed": "6300a43566d4adcf8828128267808a8740edc835",
                "report_id": "820",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-820.json",
                "issue_title": "Obfuscated code triggers TypeError in Firefox",
                "issue_description": "Obfuscated code triggers TypeError in Firefox"
            },
            "9": {
                "commit_sha_buggy": "19233b94d925c331933feff6268dc2941fa988b1",
                "commit_sha_fixed": "e9c15465c000c19ef4e0b8f68a680589ae4111d7",
                "report_id": "824",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-824.json",
                "issue_title": "Compiler fails to find amd module in a subdirectory",
                "issue_description": "Compiler fails to find amd module in a subdirectory"
            },
            "10": {
                "commit_sha_buggy": "f681fd8045bfa4a41f3a66c942b97fb04335b7cc",
                "commit_sha_fixed": "0884a4cbef1c82153ef306477a12af0480385a35",
                "report_id": "821",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-821.json",
                "issue_title": "Wrong code generated if mixing types in ternary operator",
                "issue_description": "Wrong code generated if mixing types in ternary operator"
            },
            "11": {
                "commit_sha_buggy": "bbf1b138e20a36ca79b2a012ae145c943929a6dd",
                "commit_sha_fixed": "482b767639e6eec7c30d8898851560c41b66d885",
                "report_id": "810",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-810.json",
                "issue_title": "Record type invalid property not reported on function with @this annotation",
                "issue_description": "Record type invalid property not reported on function with @this annotation"
            },
            "12": {
                "commit_sha_buggy": "919fda930ca242e2d1490e6413b601c8bad701b4",
                "commit_sha_fixed": "d06ac163013a3779fcec7c2f544ba99d08f69f58",
                "report_id": "794",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-794.json",
                "issue_title": "Try/catch blocks incorporate code not inside original blocks",
                "issue_description": "Try/catch blocks incorporate code not inside original blocks"
            },
            "13": {
                "commit_sha_buggy": "8b8c01a39b94069a9dac08b92c27dc9b9532ff7f",
                "commit_sha_fixed": "d6d733f461ee5ba26e9326c1c7609f1f00d6d2db",
                "report_id": "787",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-787.json",
                "issue_title": "true/false are not always replaced for !0/!1",
                "issue_description": "true/false are not always replaced for !0/!1"
            },
            "14": {
                "commit_sha_buggy": "b7c2861bf45b358b26ebc5ee1be9b6ce96bec78a",
                "commit_sha_fixed": "4b15b25f400335b6e2820cb690430324748372f9",
                "report_id": "779",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-779.json",
                "issue_title": "bogus 'missing return' warning",
                "issue_description": "bogus 'missing return' warning"
            },
            "15": {
                "commit_sha_buggy": "f9fbad23b8fb59464e395c164197750abb5db296",
                "commit_sha_fixed": "968b3f467f51c6bfec18af1fbcf980a0f19a1fb3",
                "report_id": "773",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-773.json",
                "issue_title": "Switched order of \"delete key\" and \"key in\" statements changes semantic",
                "issue_description": "Switched order of \"delete key\" and \"key in\" statements changes semantic"
            },
            "16": {
                "commit_sha_buggy": "33ab4df84afbdb36216b8a1ea3a526c438615e26",
                "commit_sha_fixed": "3b97e5e4212c769daa22a96094ed19b4658c8760",
                "report_id": "772",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-772.json",
                "issue_title": "JSCompiler does not recursively resolve typedefs",
                "issue_description": "JSCompiler does not recursively resolve typedefs"
            },
            "17": {
                "commit_sha_buggy": "e5e1253ac6d43e26271cc658a42fdb1477454faf",
                "commit_sha_fixed": "33ab4df84afbdb36216b8a1ea3a526c438615e26",
                "report_id": "688",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-688.json",
                "issue_title": "@const dumps type cast information",
                "issue_description": "@const dumps type cast information"
            },
            "18": {
                "commit_sha_buggy": "686146c4de7d2bd985156ae15175365633dd0f94",
                "commit_sha_fixed": "ea119a2d06328852763f9ee447c3bf74fa1f83dc",
                "report_id": "768",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-768.json",
                "issue_title": "Dependency sorting with closurePass set to false no longer works.",
                "issue_description": "Dependency sorting with closurePass set to false no longer works."
            },
            "19": {
                "commit_sha_buggy": "8d91f37d29abd8682e298a23f63b96f2f2def659",
                "commit_sha_fixed": "686146c4de7d2bd985156ae15175365633dd0f94",
                "report_id": "769",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-769.json",
                "issue_title": "Type refining of 'this' raises IllegalArgumentException",
                "issue_description": "Type refining of 'this' raises IllegalArgumentException"
            },
            "20": {
                "commit_sha_buggy": "7e98b9c9511d197ed572b73214814ccb546a4b78",
                "commit_sha_fixed": "ebf229b05f4ee71bc05d70830f5dd5683271d661",
                "report_id": "759",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-759.json",
                "issue_title": "String conversion optimization is incorrect",
                "issue_description": "String conversion optimization is incorrect"
            },
            "21": {
                "commit_sha_buggy": "a9250a5aac439a72f71c248de07f042674fb2076",
                "commit_sha_fixed": "1787d7b2cff83a0f177dd958033c53e4502406d2",
                "report_id": "753",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-753.json",
                "issue_title": "Classify non-rightmost expressions as problematic",
                "issue_description": "Classify non-rightmost expressions as problematic"
            },
            "22": {
                "commit_sha_buggy": "c8e5f7acc524fe629f73876acfb463619a02f34b",
                "commit_sha_fixed": "43a55234ef122a1ed98681ce0350506207b878d5",
                "report_id": "753",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-753.json",
                "issue_title": "Classify non-rightmost expressions as problematic",
                "issue_description": "Classify non-rightmost expressions as problematic"
            },
            "23": {
                "commit_sha_buggy": "30a88df811879f5d389f56257c93ab5f740a0518",
                "commit_sha_fixed": "b59cdd9e2dc64d2db86b90982c200a78f2f85e50",
                "report_id": "747",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-747.json",
                "issue_title": "tryFoldArrayAccess does not check for side effects",
                "issue_description": "tryFoldArrayAccess does not check for side effects"
            },
            "24": {
                "commit_sha_buggy": "59aac0b247db74ec7047132f368953935edd81b8",
                "commit_sha_fixed": "70ca6014779735bdc52ca0e80e528257829a15e7",
                "report_id": "737",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-737.json",
                "issue_title": "goog.scope doesn't properly check declared functions",
                "issue_description": "goog.scope doesn't properly check declared functions"
            },
            "25": {
                "commit_sha_buggy": "372eb11e44b8559004bfe78a5b4003caf0072135",
                "commit_sha_fixed": "2e904fcdc3bc09e3bff557fcfca383ba7e450095",
                "report_id": "729",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-729.json",
                "issue_title": "anonymous object type inference behavior is different when calling constructors",
                "issue_description": "anonymous object type inference behavior is different when calling constructors"
            },
            "26": {
                "commit_sha_buggy": "d36428ed0ba16afb7fa603154be162514303fbcf",
                "commit_sha_fixed": "372eb11e44b8559004bfe78a5b4003caf0072135",
                "report_id": "732",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-732.json",
                "issue_title": "ProcessCommonJSModules module$exports failures when checkTypes enabled",
                "issue_description": "ProcessCommonJSModules module$exports failures when checkTypes enabled"
            },
            "27": {
                "commit_sha_buggy": "1d9ecb5328bbde5ee84dbfe2d74bbd318b89b6d7",
                "commit_sha_fixed": "7a8983042131c5a9c2b5421ae42075cbb8ef1aeb",
                "report_id": "727",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-727.json",
                "issue_title": "Error trying to build try-catch block (AST)",
                "issue_description": "Error trying to build try-catch block (AST)"
            },
            "28": {
                "commit_sha_buggy": "5c46a579786510ff342dcf622148e2bb3da0874e",
                "commit_sha_fixed": "59dbb7a28680caad08ddb1658123fe0cbb1ae689",
                "report_id": "728",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-728.json",
                "issue_title": "constant functions not inlined aggressively enough",
                "issue_description": "constant functions not inlined aggressively enough"
            },
            "29": {
                "commit_sha_buggy": "3587cc3bb550dadee3c9aeac44041aa29087e74e",
                "commit_sha_fixed": "6924915efab89f921fd0779fe200fecc1bf80847",
                "report_id": "724",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-724.json",
                "issue_title": "closure compiler screws up a perfectly valid isFunction() implementation",
                "issue_description": "closure compiler screws up a perfectly valid isFunction() implementation"
            },
            "30": {
                "commit_sha_buggy": "6da361c5865ecac18ee147014c9e84244d19c2a9",
                "commit_sha_fixed": "38e2b8f247423734adec3dbd76fa22da1a3561a8",
                "report_id": "698",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-698.json",
                "issue_title": "Combining temporary strings are over-optimized in advanced build",
                "issue_description": "Combining temporary strings are over-optimized in advanced build"
            },
            "31": {
                "commit_sha_buggy": "82dd7814fd865ac31435cd239cb61c531900bd03",
                "commit_sha_fixed": "0a670cb51fd56c12c19f98884c9513792ebc3f76",
                "report_id": "703",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-703.json",
                "issue_title": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLY",
                "issue_description": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLY"
            },
            "32": {
                "commit_sha_buggy": "116e0d5aea0f0f968a6d2ea4e085930331919752",
                "commit_sha_fixed": "66c8c695fd8130e3ede6f77c6e5cc1ec96a0e9b3",
                "report_id": "701",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-701.json",
                "issue_title": "Preserve doesn't preserve whitespace at start of line",
                "issue_description": "Preserve doesn't preserve whitespace at start of line"
            },
            "33": {
                "commit_sha_buggy": "24c113d396a1c3e175bf70fe572b496ff7a68144",
                "commit_sha_fixed": "382422adae8e9f07fc23c94089c0ebe08a2174bc",
                "report_id": "700",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-700.json",
                "issue_title": "weird object literal invalid property error on unrelated object prototype",
                "issue_description": "weird object literal invalid property error on unrelated object prototype"
            },
            "34": {
                "commit_sha_buggy": "bc018d6c44e70b5c02016431a2f3604b3e6fc45c",
                "commit_sha_fixed": "87b154f89cba3c67045cd7a783b79231d0630a4c",
                "report_id": "691",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-691.json",
                "issue_title": "StackOverflowError exception when running closure compiler (javascript attached)",
                "issue_description": "StackOverflowError exception when running closure compiler (javascript attached)"
            },
            "35": {
                "commit_sha_buggy": "7e3e1a667c866458cca12b7ade9965b4e6ddf3c0",
                "commit_sha_fixed": "22784dc96c391b01692ce686eb93b9aa0ef74ede",
                "report_id": "669",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-669.json",
                "issue_title": "assignment to object in conditional causes type error on function w/ record type return type",
                "issue_description": "assignment to object in conditional causes type error on function w/ record type return type"
            },
            "36": {
                "commit_sha_buggy": "c5ec81dc0b6aaaefcdfd84ee10e43f3312350d23",
                "commit_sha_fixed": "be397ee0d0be2aad8f71d12f097b17563866445a",
                "report_id": "668",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-668.json",
                "issue_title": "goog.addSingletonGetter prevents unused class removal",
                "issue_description": "goog.addSingletonGetter prevents unused class removal"
            },
            "37": {
                "commit_sha_buggy": "375879beef8fcffaae51749a7ac537d2eb140802",
                "commit_sha_fixed": "7e93d521cb67ce33018315234fafe8a5aa30ee1e",
                "report_id": "663",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-663.json",
                "issue_title": "incomplete function definition crashes the compiler when ideMode is enabled",
                "issue_description": "incomplete function definition crashes the compiler when ideMode is enabled"
            },
            "38": {
                "commit_sha_buggy": "f067d0e1d84d631ec0c1e8e8cd812bbda1497958",
                "commit_sha_fixed": "8cf08115c6b252f8c6b54348a4089dccc45a01fb",
                "report_id": "657",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-657.json",
                "issue_title": "Identifier minus a negative number needs a space between the \"-\"s",
                "issue_description": "Identifier minus a negative number needs a space between the \"-\"s"
            },
            "39": {
                "commit_sha_buggy": "9a40e654ee3aa65d01671e4da63f292d2e4e03c0",
                "commit_sha_fixed": "d577973fb378dfe0d05991ec0dfa6c1f40e574ee",
                "report_id": "643",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-643.json",
                "issue_title": "externExport with @typedef can generate invalid externs",
                "issue_description": "externExport with @typedef can generate invalid externs"
            },
            "40": {
                "commit_sha_buggy": "a90f4b4fba37c52376d5f074729233d59ce08408",
                "commit_sha_fixed": "6ebc0c3d7d4da7d2cf95f53d4ea790e89d3abc7a",
                "report_id": "284",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-284.json",
                "issue_title": "smartNameRemoval causing compiler crash",
                "issue_description": "smartNameRemoval causing compiler crash"
            },
            "41": {
                "commit_sha_buggy": "974027e9f66882bc75840bb15cfbaa206e02dd0e",
                "commit_sha_fixed": "00b1517c53912ac6843c257c0a6ead1176e8c5ee",
                "report_id": "368",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-368.json",
                "issue_title": "In ADVANCED mode, Compiler fails to warn about overridden methods with different signatures.",
                "issue_description": "In ADVANCED mode, Compiler fails to warn about overridden methods with different signatures."
            },
            "42": {
                "commit_sha_buggy": "f74939a64a205d89721383c24874fe4e41439cfd",
                "commit_sha_fixed": "fb01427a445ebfeb3af5e220a98ccaced339b73e",
                "report_id": "644",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-644.json",
                "issue_title": "Simple \"Whitespace only\" compression removing \"each\" keyword from \"for each (var x in arr)\" loop",
                "issue_description": "Simple \"Whitespace only\" compression removing \"each\" keyword from \"for each (var x in arr)\" loop"
            },
            "43": {
                "commit_sha_buggy": "29f4990e25842d232922171594d835888627ace0",
                "commit_sha_fixed": "f636f23bdef4b27752ca249a28463ec1b6af1f0b",
                "report_id": "314",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-314.json",
                "issue_title": "@lends does not work unless class is defined beforehand",
                "issue_description": "@lends does not work unless class is defined beforehand"
            },
            "44": {
                "commit_sha_buggy": "3e66c9c827308d2f549a16440e3f0ef7fd844e04",
                "commit_sha_fixed": "64bb2291f9a9bbab67d865dffe603f8a0df8ef30",
                "report_id": "620",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-620.json",
                "issue_title": "alert(/ / / / /)",
                "issue_description": "alert(/ / / / /)"
            },
            "45": {
                "commit_sha_buggy": "a55420ec8457fb0c7be663b2afbdbc0a60064901",
                "commit_sha_fixed": "6aa71f116df0102a98c463f471ad8ddd4dba01f8",
                "report_id": "618",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-618.json",
                "issue_title": "Assignment removed when used as an expression result to Array.push",
                "issue_description": "Assignment removed when used as an expression result to Array.push"
            },
            "46": {
                "commit_sha_buggy": "edb6e4c48c19be681f38e9ee27e67b66a1944640",
                "commit_sha_fixed": "4a1a31c6a50a0fbe25fa33277909bd51f1deb8e9",
                "report_id": "603",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-603.json",
                "issue_title": "ClassCastException during TypeCheck pass",
                "issue_description": "ClassCastException during TypeCheck pass"
            },
            "47": {
                "commit_sha_buggy": "c5d7b308ecf260bf6ccf4b20ac256074fc42768f",
                "commit_sha_fixed": "aedce35970673f20696d5721acba13e986cc764c",
                "report_id": "575",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-575.json",
                "issue_title": "Original source line numbers are one-based in source maps.",
                "issue_description": "Original source line numbers are one-based in source maps."
            },
            "48": {
                "commit_sha_buggy": "5524adbda991632656059566b69cc2771ba42b7d",
                "commit_sha_fixed": "46da17d59abb4f9c48b6ffd31601c212490b970b",
                "report_id": "586",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-586.json",
                "issue_title": "Type checking error when replacing a function with a stub after calling.",
                "issue_description": "Type checking error when replacing a function with a stub after calling."
            },
            "49": {
                "commit_sha_buggy": "62581c697a626f2cd848b98648aa42329d482859",
                "commit_sha_fixed": "1a7ba5cb0111dd3ed9afd9691cab39b3c341e408",
                "report_id": "539",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-539.json",
                "issue_title": "Incorrect output if a function is assigned to a variable, and the function contains a variable with the same name",
                "issue_description": "Incorrect output if a function is assigned to a variable, and the function contains a variable with the same name"
            },
            "50": {
                "commit_sha_buggy": "9d3ed3fb128d2378e76f65e15bc45783eaf4cd57",
                "commit_sha_fixed": "c3b630fc9c2a1c4eb7cb718f8d324bfb306cb9df",
                "report_id": "558",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-558.json",
                "issue_title": "Optimisation: convert array.join(\",\") to array.join()",
                "issue_description": "Optimisation: convert array.join(\",\") to array.join()"
            },
            "51": {
                "commit_sha_buggy": "44c2d71195e5c4a3ded0ef2b2e593cabdeeec08b",
                "commit_sha_fixed": "a02241e5df48e44e23dc0e66dbef3fdc3c91eb3e",
                "report_id": "582",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-582.json",
                "issue_title": "-0.0 becomes 0 even in whitespace mode",
                "issue_description": "-0.0 becomes 0 even in whitespace mode"
            },
            "52": {
                "commit_sha_buggy": "d79072969c2f31860ea1f55e392a146c49bc2d0f",
                "commit_sha_fixed": "5909c3db59b16886917456ab950ef9661a7fe6b1",
                "report_id": "569",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-569.json",
                "issue_title": "Converts string properties into numbers in literal object definitions",
                "issue_description": "Converts string properties into numbers in literal object definitions"
            },
            "53": {
                "commit_sha_buggy": "4adf024b5eb87f6b760b40e9923ed1391bca4152",
                "commit_sha_fixed": "9959716b01fc5231ae68bc7a24454ce45d341606",
                "report_id": "545",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-545.json",
                "issue_title": "compiler-20110811 crashes with index(1) must be less than size(1)",
                "issue_description": "compiler-20110811 crashes with index(1) must be less than size(1)"
            },
            "54": {
                "commit_sha_buggy": "fc307189f141773d0a66c235f8f37f05c8252d8d",
                "commit_sha_fixed": "7e9b8336568ea7f05c33e1b58eb67fa6d4eee756",
                "report_id": "537",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-537.json",
                "issue_title": "Prototype methods can't be used from the constructor in case prototype is explicitly defined.",
                "issue_description": "Prototype methods can't be used from the constructor in case prototype is explicitly defined."
            },
            "55": {
                "commit_sha_buggy": "1d13eac7441b980804c7ddfbe48a10a2ec3431d0",
                "commit_sha_fixed": "f2c0cb1f67ecb3315c0cb11326c9cb04db07ee8a",
                "report_id": "538",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-538.json",
                "issue_title": "Exception when emitting code containing getters",
                "issue_description": "Exception when emitting code containing getters"
            },
            "56": {
                "commit_sha_buggy": "f791e3a7a172728b54a337c94bff4bc27c7adc43",
                "commit_sha_fixed": "9e921fa973c603473f745fff76c44620fd7719e3",
                "report_id": "511",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-511.json",
                "issue_title": "Last warning or error in output is truncated",
                "issue_description": "Last warning or error in output is truncated"
            },
            "57": {
                "commit_sha_buggy": "2d3b9a6c591ef14e8c9208a3f049a1630c993d84",
                "commit_sha_fixed": "f759f431d5a7a2261b44440bca9cfab93ae25302",
                "report_id": "530",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-530.json",
                "issue_title": "compiler crashes when  goog.provide used with non string ",
                "issue_description": "compiler crashes when  goog.provide used with non string "
            },
            "58": {
                "commit_sha_buggy": "7876ab2f80475ead7eb239dda7f65348c5cb7bdb",
                "commit_sha_fixed": "f640b5dec722422c93a9a624cd21d30b5e321858",
                "report_id": "528",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-528.json",
                "issue_title": "Online CC bug: report java error.",
                "issue_description": "Online CC bug: report java error."
            },
            "59": {
                "commit_sha_buggy": "5331b915cf55e8d5f030b6cc62487757cfe50cd6",
                "commit_sha_fixed": "49b4ef31c850611a5c85d95140b4cedda7f4c59a",
                "report_id": "521",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-521.json",
                "issue_title": "Cannot exclude globalThis checks through command line",
                "issue_description": "Cannot exclude globalThis checks through command line"
            },
            "60": {
                "commit_sha_buggy": "042b972a5853424d39be1cb76f2710d4bc3380e0",
                "commit_sha_fixed": "fbaadc736f0031dd84bebea33abae497b47158cb",
                "report_id": "504",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-504.json",
                "issue_title": "void function () {}(); wrongly identified as having no side effects",
                "issue_description": "void function () {}(); wrongly identified as having no side effects"
            },
            "61": {
                "commit_sha_buggy": "bac71221414f7f42d31d3634c935c2ae1a940376",
                "commit_sha_fixed": "34e4616a924bf272c076039e143e20f1d792731e",
                "report_id": "501",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-501.json",
                "issue_title": "Closure removes needed code.",
                "issue_description": "Closure removes needed code."
            },
            "62": {
                "commit_sha_buggy": "1e07047234938543ea364f68ec0f29686dbc12f1",
                "commit_sha_fixed": "b12d1d6489329c989b15635f6f7f06681b3f6582",
                "report_id": "487",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-487.json",
                "issue_title": "Column-indicating caret is sometimes not in error output",
                "issue_description": "Column-indicating caret is sometimes not in error output"
            },
            "64": {
                "commit_sha_buggy": "620fc21fa289cf0fda52c3d310a41d9fc2103be9",
                "commit_sha_fixed": "de726510af4329fb8eeb8a54b2d93d8d37c87545",
                "report_id": "489",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-489.json",
                "issue_title": "--language_in=ECMASCRIPT5_STRICT results in 1 'use strict' per input file",
                "issue_description": "--language_in=ECMASCRIPT5_STRICT results in 1 'use strict' per input file"
            },
            "65": {
                "commit_sha_buggy": "9465f9139201814dc532adc33fe44a169a101937",
                "commit_sha_fixed": "48aea0ff7d027507362007415963a4b662fb10a7",
                "report_id": "486",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-486.json",
                "issue_title": "String escaping mishandles null byte",
                "issue_description": "String escaping mishandles null byte"
            },
            "66": {
                "commit_sha_buggy": "984bce0d9f36b0a21a0f9b51dc68fca0175aa1c8",
                "commit_sha_fixed": "59a30b48325cccadabae8687fdf603d72e26c157",
                "report_id": "482",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-482.json",
                "issue_title": "@enum does not type correctly",
                "issue_description": "@enum does not type correctly"
            },
            "67": {
                "commit_sha_buggy": "8777edb959dfea307495e667c2c01834adabb906",
                "commit_sha_fixed": "aa89d05b48332d68b8e6ebcee427b2ac3b4e3184",
                "report_id": "459",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-459.json",
                "issue_title": "Advanced compilations renames a function and then deletes it, leaving a reference to a renamed but non-existent function",
                "issue_description": "Advanced compilations renames a function and then deletes it, leaving a reference to a renamed but non-existent function"
            },
            "68": {
                "commit_sha_buggy": "f392c8416faeb6dc41e663912ad7f4421d893a90",
                "commit_sha_fixed": "9d5a6e3082dd99f6c44df1b3526b9e83b79aa7da",
                "report_id": "477",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-477.json",
                "issue_title": "Cryptic error message on invalid \"@type function\" annotation",
                "issue_description": "Cryptic error message on invalid \"@type function\" annotation"
            },
            "69": {
                "commit_sha_buggy": "036f2173d91679c7c914da196761c0f7d05e5389",
                "commit_sha_fixed": "63df133d0850805818d1e280ba47dcefc9763c89",
                "report_id": "440",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-440.json",
                "issue_title": "Compiler should warn/error when instance methods are operated on",
                "issue_description": "Compiler should warn/error when instance methods are operated on"
            },
            "70": {
                "commit_sha_buggy": "7433d30ac4cb2334d22e66299846118686efe939",
                "commit_sha_fixed": "ec4a34c2bd87ba54fa8770affdeeea4f3c42089b",
                "report_id": "433",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-433.json",
                "issue_title": "unexpected typed coverage of less than 100%",
                "issue_description": "unexpected typed coverage of less than 100%"
            },
            "71": {
                "commit_sha_buggy": "c498ecb791f2dd8a1b37e74f94c1c119549607bc",
                "commit_sha_fixed": "db1fdf97454a6e4ff2d29cab5f1ef2273b54c0b4",
                "report_id": "254",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-254.json",
                "issue_title": "no warnings when @private prop is redeclared on subclass",
                "issue_description": "no warnings when @private prop is redeclared on subclass"
            },
            "72": {
                "commit_sha_buggy": "3f8896c5f08cd04efabfc1bd9915ebfd93fb832a",
                "commit_sha_fixed": "e323b879de2e53e5eedf6e7afb0d582382c6248d",
                "report_id": "435",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-435.json",
                "issue_title": "Internal Compiler Error on Bullet",
                "issue_description": "Internal Compiler Error on Bullet"
            },
            "73": {
                "commit_sha_buggy": "760bded3242093d86611a82e81fdca302a1487f1",
                "commit_sha_fixed": "ee8344091722c28c9351e78dcb4155fbfddfd1af",
                "report_id": "416",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-416.json",
                "issue_title": "Codepoint U+007f appears raw in output",
                "issue_description": "Codepoint U+007f appears raw in output"
            },
            "74": {
                "commit_sha_buggy": "d5bf6b425c5d52b28136afc9770876139b34acd7",
                "commit_sha_fixed": "03fee32a06ccf8257b2da67b9034270be38805ae",
                "report_id": "413",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-413.json",
                "issue_title": "Obvious optimizations don't works in \"inline if\"",
                "issue_description": "Obvious optimizations don't works in \"inline if\""
            },
            "75": {
                "commit_sha_buggy": "31baadd1293c5ae7af05b3a06a1ba3a06403e4ed",
                "commit_sha_fixed": "c6cc58a9bc617483366141386e047b085b4e83ff",
                "report_id": "395",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-395.json",
                "issue_title": "closure compiled swfobject error",
                "issue_description": "closure compiled swfobject error"
            },
            "76": {
                "commit_sha_buggy": "a6ca7c196cb8f9bcddefd038d80217c3de486e4e",
                "commit_sha_fixed": "78b01c3a435cd175ce3ee70f97b2f8faac342cdc",
                "report_id": "384",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-384.json",
                "issue_title": "Assignments within conditions are sometimes incorrectly removed",
                "issue_description": "Assignments within conditions are sometimes incorrectly removed"
            },
            "77": {
                "commit_sha_buggy": "25827942ba9d45825dfd92faa37a78dbc9034ad0",
                "commit_sha_fixed": "b88400ce0e9c1a0dadfd3417c256b02a82f38fe1",
                "report_id": "383",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-383.json",
                "issue_title": "\\0 \\x00 and \\u0000 are translated to null character",
                "issue_description": "\\0 \\x00 and \\u0000 are translated to null character"
            },
            "78": {
                "commit_sha_buggy": "b40c6c7e0e323f1b69fe7f9686ed8f763b01faf8",
                "commit_sha_fixed": "25829b0395164533782d608399096803321225a7",
                "report_id": "381",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-381.json",
                "issue_title": "division by zero wrongly throws JSC_DIVIDE_BY_0_ERROR",
                "issue_description": "division by zero wrongly throws JSC_DIVIDE_BY_0_ERROR"
            },
            "79": {
                "commit_sha_buggy": "f3c23f757da302483c86414ec8b9c502f10fce00",
                "commit_sha_fixed": "5d397618f3c86d9c444a4c4c6441267b8a89a21d",
                "report_id": "367",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-367.json",
                "issue_title": "RuntimeException when compiling with extern prototype",
                "issue_description": "RuntimeException when compiling with extern prototype"
            },
            "80": {
                "commit_sha_buggy": "a2153e7405e09c8fa413a01874c949b8b2bcd32b",
                "commit_sha_fixed": "58786c3f717fa506280127265cd68fedf17de0a9",
                "report_id": "364",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-364.json",
                "issue_title": "Unexpected expression nodeDELPROP 1",
                "issue_description": "Unexpected expression nodeDELPROP 1"
            },
            "81": {
                "commit_sha_buggy": "a65a72e9dd320790710beed1593dd6358c4bf029",
                "commit_sha_fixed": "084b868bc2fbf9d6d0319e5a362ade1d7f43f899",
                "report_id": "251",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-251.json",
                "issue_title": "An unnamed function statement statements should generate a parse error",
                "issue_description": "An unnamed function statement statements should generate a parse error"
            },
            "82": {
                "commit_sha_buggy": "1a7fbd18b47c102152869c3b046b65ff0f12fc43",
                "commit_sha_fixed": "a857aec27d79fc234fddd4a72c1215af0251b2d8",
                "report_id": "301",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-301.json",
                "issue_title": ".indexOf fails to produce missing property warning",
                "issue_description": ".indexOf fails to produce missing property warning"
            },
            "83": {
                "commit_sha_buggy": "840ddca5b28cea7563a5be20d2624478af67bc02",
                "commit_sha_fixed": "43c245f0ff8d409e81e25687e69d34666b7cf26a",
                "report_id": "319",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-319.json",
                "issue_title": "Cannot see version with --version",
                "issue_description": "Cannot see version with --version"
            },
            "84": {
                "commit_sha_buggy": "9f8345afa4e5eaa24e3ff6a84d16691764698799",
                "commit_sha_fixed": "4839e1ea57f9a1a26debd2cc8f22beef7282b490",
                "report_id": "215",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-215.json",
                "issue_title": "Invalid left-hand side of assignment not detected",
                "issue_description": "Invalid left-hand side of assignment not detected"
            },
            "85": {
                "commit_sha_buggy": "2410995673fcaaaec5d4d48eae9139127c64acac",
                "commit_sha_fixed": "21a2103d7fa5664ea324ef9ee25b4a8922e50955",
                "report_id": "311",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-311.json",
                "issue_title": "Reproduceable crash with switch statement",
                "issue_description": "Reproduceable crash with switch statement"
            },
            "86": {
                "commit_sha_buggy": "5cd9c1efe90dc7c1be33cd7f8c1dcbaa9225909e",
                "commit_sha_fixed": "0907b6618a60b2de23c8f7ec2217a37dc5e9a091",
                "report_id": "303",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-303.json",
                "issue_title": "side-effects analysis incorrectly removing function calls with side effects",
                "issue_description": "side-effects analysis incorrectly removing function calls with side effects"
            },
            "87": {
                "commit_sha_buggy": "e9f7e6114414f68deb90f4116861d7a054365404",
                "commit_sha_fixed": "f64a3f51bd346547ce6e1edb30601df73dff27d9",
                "report_id": "291",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-291.json",
                "issue_title": "IE8 error: Object doesn't support this action",
                "issue_description": "IE8 error: Object doesn't support this action"
            },
            "88": {
                "commit_sha_buggy": "d68322323aa52d943b9dc5618ef8ea81d43d7b4f",
                "commit_sha_fixed": "6a17da87f9e132bdc147b33223826da040c77a6b",
                "report_id": "297",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-297.json",
                "issue_title": "Incorrect assignment removal from expression in simple mode.",
                "issue_description": "Incorrect assignment removal from expression in simple mode."
            },
            "89": {
                "commit_sha_buggy": "e7ad2425c384dcb18a34bec8e147a91c658d5118",
                "commit_sha_fixed": "4b065734d8afb5ab0d241ee5da22af0fa9d75ec3",
                "report_id": "289",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-289.json",
                "issue_title": "Compiler removes function properties that it should not",
                "issue_description": "Compiler removes function properties that it should not"
            },
            "90": {
                "commit_sha_buggy": "97485ec652a6d3471c539d5b0ead4f05707db139",
                "commit_sha_fixed": "c5e143f7df0c3d73f6634488cac8ad8e7054fe05",
                "report_id": "274",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-274.json",
                "issue_title": "@this emits warning when used with a typedef",
                "issue_description": "@this emits warning when used with a typedef"
            },
            "91": {
                "commit_sha_buggy": "8eee751ff9f460c4a769d598c65b1cd643dabc7b",
                "commit_sha_fixed": "7eb2d84de101a125d41d3a1157f4eed789ca4a0d",
                "report_id": "248",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-248.json",
                "issue_title": "support @lends annotation",
                "issue_description": "support @lends annotation"
            },
            "92": {
                "commit_sha_buggy": "39dde4ca5df6263d7058029e081a710d7fa13de9",
                "commit_sha_fixed": "8980b60033b1c6853cbca593ec89d3d332adf7dc",
                "report_id": "261",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-261.json",
                "issue_title": "bug with implicit namespaces across modules",
                "issue_description": "bug with implicit namespaces across modules"
            },
            "94": {
                "commit_sha_buggy": "9d72612f028076aa43a9b259c29b2a940398465f",
                "commit_sha_fixed": "7cc748592670105f9d783b1b85f0f27e938db4ff",
                "report_id": "255",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-255.json",
                "issue_title": "closure-compiler @define annotation does not allow line to be split on 80 characters.",
                "issue_description": "closure-compiler @define annotation does not allow line to be split on 80 characters."
            },
            "95": {
                "commit_sha_buggy": "f93cdf97ea803c4702023daf1326dc45172de611",
                "commit_sha_fixed": "f6607996d6d3bd6820ce3848d147991b27600a12",
                "report_id": "66",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-66.json",
                "issue_title": "Use @public tag to prevent compression of symbol names",
                "issue_description": "Use @public tag to prevent compression of symbol names"
            },
            "96": {
                "commit_sha_buggy": "b9bc1534921f1e98da5a373e39ea2d71a4a39175",
                "commit_sha_fixed": "807aaf2569e9eb09761068c5aeb95654daea30d9",
                "report_id": "229",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-229.json",
                "issue_title": "Missing type-checks for var_args notation",
                "issue_description": "Missing type-checks for var_args notation"
            },
            "97": {
                "commit_sha_buggy": "4cf197f69d8733ac68b02672b2e23d7939e5eb76",
                "commit_sha_fixed": "ee749e286b477f8d6f53ff5960a38453baf50f31",
                "report_id": "200",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-200.json",
                "issue_title": "Unsigned Shift Right (>>>) bug operating on negative numbers",
                "issue_description": "Unsigned Shift Right (>>>) bug operating on negative numbers"
            },
            "98": {
                "commit_sha_buggy": "d768bbc4212ee0d95d20d52426fbad47f0f9c56e",
                "commit_sha_fixed": "d1df970451b5a18956448097b3afb43f3a82263d",
                "report_id": "174",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-174.json",
                "issue_title": "bad variable inlining in closure",
                "issue_description": "bad variable inlining in closure"
            },
            "99": {
                "commit_sha_buggy": "ccbbcbf71b1cb8771c9cdad1d28b367ce6ea0da2",
                "commit_sha_fixed": "8aa879a4eeb18cfc8d13e6c843a32b7f41ccd516",
                "report_id": "125",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-125.json",
                "issue_title": "Prototypes declared with quotes produce a JSC_USED_GLOBAL_THIS warning.",
                "issue_description": "Prototypes declared with quotes produce a JSC_USED_GLOBAL_THIS warning."
            },
            "100": {
                "commit_sha_buggy": "71a6f6049d9359ea047adafc2a77e4dfb1398f41",
                "commit_sha_fixed": "6d00ac1a68612aade8a19d7ecc9b180f00ae5234",
                "report_id": "144",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-144.json",
                "issue_title": "Only assignment to \"this\" issues a \"dangerous use of the global this object\" warning.",
                "issue_description": "Only assignment to \"this\" issues a \"dangerous use of the global this object\" warning."
            },
            "101": {
                "commit_sha_buggy": "2d892b164f41c053de4d56e424f0815576c6dc54",
                "commit_sha_fixed": "369282db85567f1bf2c9635d0c0043d47f114814",
                "report_id": "130",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-130.json",
                "issue_title": "--process_closure_primitives can't be set to false",
                "issue_description": "--process_closure_primitives can't be set to false"
            },
            "102": {
                "commit_sha_buggy": "9a1ddf5f982e54ecbc3e028dfa84ef9bd07a8044",
                "commit_sha_fixed": "d48c365ba8251057a71a2e2b7aabff640209e31b",
                "report_id": "115",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-115.json",
                "issue_title": "compiler assumes that 'arguments' can be shadowed",
                "issue_description": "compiler assumes that 'arguments' can be shadowed"
            },
            "103": {
                "commit_sha_buggy": "67289ae4cbaba3ae70cd2e8fb92f3f2898039dfb",
                "commit_sha_fixed": "2f5cb1622371de540fe20dcbe0411651ec89f952",
                "report_id": "113",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-113.json",
                "issue_title": "Compiler gives false error with respect to unreachable code",
                "issue_description": "Compiler gives false error with respect to unreachable code"
            },
            "104": {
                "commit_sha_buggy": "1be1c2636ef14071afa7da5cb8988972bd90149f",
                "commit_sha_fixed": "67289ae4cbaba3ae70cd2e8fb92f3f2898039dfb",
                "report_id": "114",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-114.json",
                "issue_title": "Typos in externs/html5.js",
                "issue_description": "Typos in externs/html5.js"
            },
            "105": {
                "commit_sha_buggy": "8e121a1fe0cea18df772320da1b663a6d663a0e8",
                "commit_sha_fixed": "113a08f59e8116fb11a7d4ceb11d5bb09b74ac3c",
                "report_id": "106",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-106.json",
                "issue_title": "Array Join Munged Incorrectly",
                "issue_description": "Array Join Munged Incorrectly"
            },
            "106": {
                "commit_sha_buggy": "6a36f04485599820ff86441accee002b4deec2eb",
                "commit_sha_fixed": "e609670bb56e0c7216c9476a5f6a5594e7f1acdb",
                "report_id": "19",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-19.json",
                "issue_title": "Exception thrown from com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties",
                "issue_description": "Exception thrown from com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties"
            },
            "107": {
                "commit_sha_buggy": "aae547f4d911dfbf42ca5a31aeb401ac83725a14",
                "commit_sha_fixed": "49e9565febba904484396e2aef7dbe86f55e9cc5",
                "report_id": "1135",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1135.json",
                "issue_title": "Variable names prefixed with MSG_ cause error with advanced optimizations",
                "issue_description": "Variable names prefixed with MSG_ cause error with advanced optimizations"
            },
            "108": {
                "commit_sha_buggy": "acd31d1221421da27c4fd1a55ec751488ad85744",
                "commit_sha_fixed": "aae547f4d911dfbf42ca5a31aeb401ac83725a14",
                "report_id": "1144",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1144.json",
                "issue_title": "precondition crash: goog.scope local with aliased in the type declaration",
                "issue_description": "precondition crash: goog.scope local with aliased in the type declaration"
            },
            "109": {
                "commit_sha_buggy": "bb893266036cbc7f0b434794d4fd9306513357be",
                "commit_sha_fixed": "7d26b7bcae8311f3c032bae3f1df27b590a4c174",
                "report_id": "1105",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1105.json",
                "issue_title": "Constructor types that return all or unknown fail to parse",
                "issue_description": "Constructor types that return all or unknown fail to parse"
            },
            "110": {
                "commit_sha_buggy": "5917817198c13401d7eb4e15f3e462fa7f46f1fe",
                "commit_sha_fixed": "13fb7fcbcad87f8df63535491627bf7b01471064",
                "report_id": "1111",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1111.json",
                "issue_title": "Allow @private top-level functions in goog.scope",
                "issue_description": "Allow @private top-level functions in goog.scope"
            },
            "111": {
                "commit_sha_buggy": "450f0f6ef5d9b1bea2bc556e6029fa4f2f8554a2",
                "commit_sha_fixed": "6f981f77e5bd9e2eecbd851a2a02933cdb9af0d8",
                "report_id": "1114",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1114.json",
                "issue_title": "goog.isArray doesn't hint compiler",
                "issue_description": "goog.isArray doesn't hint compiler"
            },
            "112": {
                "commit_sha_buggy": "fb0f2fd881cd00766b90d78072ea9ab30e5d7da7",
                "commit_sha_fixed": "b168c8822b2d3d12515ec6477812674c8805bcf3",
                "report_id": "1058",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1058.json",
                "issue_title": "Template types on methods incorrectly trigger inference of a template on the class if that template type is unknown",
                "issue_description": "Template types on methods incorrectly trigger inference of a template on the class if that template type is unknown"
            },
            "113": {
                "commit_sha_buggy": "fa1e469dde0bdfd6978a3266db7803b8d39d1d69",
                "commit_sha_fixed": "0fb76a81bbdd8ab84a00b8be2099abfb83c88668",
                "report_id": "1079",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1079.json",
                "issue_title": "Bug in require calls processing",
                "issue_description": "Bug in require calls processing"
            },
            "114": {
                "commit_sha_buggy": "a44af4540d0f2bf5fc5ecd0a34c9fea656ee574c",
                "commit_sha_fixed": "5f03c6817341d39d8dead76c7511fd6bb0b9009f",
                "report_id": "1085",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1085.json",
                "issue_title": "Crash on the web closure compiler",
                "issue_description": "Crash on the web closure compiler"
            },
            "115": {
                "commit_sha_buggy": "2d6e1c78f41248fbbb1eec43b23e7430e2bc7885",
                "commit_sha_fixed": "4597738e8898f738c1f969fe90479728be81cc80",
                "report_id": "1101",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1101.json",
                "issue_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode",
                "issue_description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode"
            },
            "116": {
                "commit_sha_buggy": "b9262dcd42d1b8f53c2a974c182feba2899dc74c",
                "commit_sha_fixed": "b80dfd3b0e5e4b490b7afb469320d18bac4520b4",
                "report_id": "1101",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1101.json",
                "issue_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode",
                "issue_description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode"
            },
            "117": {
                "commit_sha_buggy": "6c43134465d961e19098964c6be69bf48fe8e860",
                "commit_sha_fixed": "871bca1f36c5c06aa880ce21429da63a76f8f6e9",
                "report_id": "1047",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1047.json",
                "issue_title": "Wrong type name reported on missing property error.",
                "issue_description": "Wrong type name reported on missing property error."
            },
            "118": {
                "commit_sha_buggy": "046e0b226e963bc584c2a6cd3c2b471777c5cc53",
                "commit_sha_fixed": "f17961ae4d3d7cf5ea291d82804239982d009ef7",
                "report_id": "1024",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1024.json",
                "issue_title": "Prototype method incorrectly removed",
                "issue_description": "Prototype method incorrectly removed"
            },
            "119": {
                "commit_sha_buggy": "3e0d176234636b3dfba0a3060b18488c6752ae8c",
                "commit_sha_fixed": "046e0b226e963bc584c2a6cd3c2b471777c5cc53",
                "report_id": "1070",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1070.json",
                "issue_title": "catch(e) yields JSC_UNDEFINED_NAME warning when e is used in catch in advanced mode",
                "issue_description": "catch(e) yields JSC_UNDEFINED_NAME warning when e is used in catch in advanced mode"
            },
            "120": {
                "commit_sha_buggy": "9f890320310e8ecb8dd2b6dc043eb24d8b0a25c6",
                "commit_sha_fixed": "0123fd5303c85d0d26add64aa2e19fee33f73aaa",
                "report_id": "1053",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1053.json",
                "issue_title": "Overzealous optimization confuses variables",
                "issue_description": "Overzealous optimization confuses variables"
            },
            "121": {
                "commit_sha_buggy": "1af41ab430be090a9a6177648b18c1ff9fb88c3f",
                "commit_sha_fixed": "2aee36e667526ff8b0b5e6dad66506acee920ea6",
                "report_id": "1053",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1053.json",
                "issue_title": "Overzealous optimization confuses variables",
                "issue_description": "Overzealous optimization confuses variables"
            },
            "122": {
                "commit_sha_buggy": "f22a0e8b289e8ed26f04ea0d3af3612b6e15414a",
                "commit_sha_fixed": "a8a456b183c9600658bcb0c72091bae1a30a4fda",
                "report_id": "1037",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1037.json",
                "issue_title": "Inconsistent handling of non-JSDoc comments",
                "issue_description": "Inconsistent handling of non-JSDoc comments"
            },
            "123": {
                "commit_sha_buggy": "60dac870c77b5de63d981f4be40106fe1c87b7d1",
                "commit_sha_fixed": "8d11b8cc7a6183222b61c9bd398fed5448c59109",
                "report_id": "1033",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1033.json",
                "issue_title": "Generates code with invalid for/in left-hand assignment",
                "issue_description": "Generates code with invalid for/in left-hand assignment"
            },
            "124": {
                "commit_sha_buggy": "95ff0484a76d60d30145f4e3da4bf9b517029361",
                "commit_sha_fixed": "e7f4269d0289f4d47217207ec456219db8efe47c",
                "report_id": "1017",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1017.json",
                "issue_title": "Different output from RestAPI and command line jar",
                "issue_description": "Different output from RestAPI and command line jar"
            },
            "125": {
                "commit_sha_buggy": "ddc1299802e88b9814250c369e3fe6f7ee07d4e5",
                "commit_sha_fixed": "8cef00180a5cf67d047919c89668a6405030dbab",
                "report_id": "1002",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1002.json",
                "issue_title": "IllegalStateException at com.google.javascript.rhino.jstype.FunctionType.getInstanceType",
                "issue_description": "IllegalStateException at com.google.javascript.rhino.jstype.FunctionType.getInstanceType"
            },
            "126": {
                "commit_sha_buggy": "211dc0161ae737f59cac22f30b048d56a059d14b",
                "commit_sha_fixed": "bd2803b6d9ab600906b262ae51cb3591160b5f3c",
                "report_id": "936",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-936.json",
                "issue_title": "Break in finally block isn't optimized properly",
                "issue_description": "Break in finally block isn't optimized properly"
            },
            "127": {
                "commit_sha_buggy": "437a9e47d1a371f9e6724210b16d11d75366c3a0",
                "commit_sha_fixed": "211dc0161ae737f59cac22f30b048d56a059d14b",
                "report_id": "936",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-936.json",
                "issue_title": "Break in finally block isn't optimized properly",
                "issue_description": "Break in finally block isn't optimized properly"
            },
            "128": {
                "commit_sha_buggy": "79a8906570f44e5f519282bd32595985ed089aed",
                "commit_sha_fixed": "d82fb38b0121bf690cea58df293185c7e91ded9c",
                "report_id": "942",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-942.json",
                "issue_title": "The compiler quotes the \"0\" keys in object literals",
                "issue_description": "The compiler quotes the \"0\" keys in object literals"
            },
            "129": {
                "commit_sha_buggy": "4ff5d0b989360d785c63978faf8eed6284e030e1",
                "commit_sha_fixed": "79a8906570f44e5f519282bd32595985ed089aed",
                "report_id": "937",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-937.json",
                "issue_title": "Casting a function before calling it produces bad code and breaks plugin code",
                "issue_description": "Casting a function before calling it produces bad code and breaks plugin code"
            },
            "130": {
                "commit_sha_buggy": "8a37f1089f62deaebc29fe5c8a22f48d04a6c8b1",
                "commit_sha_fixed": "9fac3ccd2fa9e6137584f079db1a6f5962a65cf4",
                "report_id": "931",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-931.json",
                "issue_title": "arguments is moved to another scope",
                "issue_description": "arguments is moved to another scope"
            },
            "131": {
                "commit_sha_buggy": "602dc3845e92d39a0701396666635ccc4a321599",
                "commit_sha_fixed": "7f6700e2b54af3af409f3e8851a0d98a72beef4b",
                "report_id": "921",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-921.json",
                "issue_title": "unicode characters in property names result in invalid output",
                "issue_description": "unicode characters in property names result in invalid output"
            },
            "132": {
                "commit_sha_buggy": "f5a77bb416ab2223fda83de118da1007e5962498",
                "commit_sha_fixed": "5b9485903b5e7d926f49dc91b915a256df92591c",
                "report_id": "925",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-925.json",
                "issue_title": "if statement",
                "issue_description": "if statement"
            },
            "133": {
                "commit_sha_buggy": "c5e6df9c0f84de1eee287d530ef8721c05e9cf14",
                "commit_sha_fixed": "4fbbc47cb18f241b23dd2d4bf9c15d45b2473523",
                "report_id": "919",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-919.json",
                "issue_title": "Exception when parsing erroneous jsdoc: /**@return {@code foo} bar   *    baz. */",
                "issue_description": "Exception when parsing erroneous jsdoc: /**@return {@code foo} bar   *    baz. */"
            },
            "134": {
                "commit_sha_buggy": "86860111110ec7a96d92fbefb6c3ae15e3575405",
                "commit_sha_fixed": "6d374c3ee4c9c2651ffb44048924e127fd2bf37c",
                "report_id": "86",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-86.json",
                "issue_title": "@inheritDoc doesn't play well with interfaces",
                "issue_description": "@inheritDoc doesn't play well with interfaces"
            },
            "135": {
                "commit_sha_buggy": "37bc6d41f17d17a822bbcd9aed9f17649a3384fd",
                "commit_sha_fixed": "d1f25380b5d74c5303533491e36ae4b33a50e2da",
                "report_id": "59",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-59.json",
                "issue_title": "Inheritance not detected when prototype directly assigned",
                "issue_description": "Inheritance not detected when prototype directly assigned"
            },
            "136": {
                "commit_sha_buggy": "2131059de15ba858adf7646bfba5cbd04b661336",
                "commit_sha_fixed": "938f48a60c544f6b7bdb5d49006f654a51ca9a22",
                "report_id": "103",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-103.json",
                "issue_title": "$super is replaced when it should not be replaced",
                "issue_description": "$super is replaced when it should not be replaced"
            },
            "137": {
                "commit_sha_buggy": "e185090c145950cc1eaba599e9f64bc305dec4c7",
                "commit_sha_fixed": "da30f170f29e983f014fb029fe5779bfd5d3b04f",
                "report_id": "124",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-124.json",
                "issue_title": "Invalid JSC_DETERMINISTIC_TEST",
                "issue_description": "Invalid JSC_DETERMINISTIC_TEST"
            },
            "138": {
                "commit_sha_buggy": "da30f170f29e983f014fb029fe5779bfd5d3b04f",
                "commit_sha_fixed": "1f5edbcd2b5b09ec59151137e643d9ce75ef1055",
                "report_id": "124",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-124.json",
                "issue_title": "Invalid JSC_DETERMINISTIC_TEST",
                "issue_description": "Invalid JSC_DETERMINISTIC_TEST"
            },
            "139": {
                "commit_sha_buggy": "6f2539acd3c37bd7f0d031b43364f75a5cd6d5f7",
                "commit_sha_fixed": "b347ce3a71e23a4ab92dc0a6c07d43e2f497c953",
                "report_id": "33",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-33.json",
                "issue_title": "Redefinition of a function in third party code can be miscompiled",
                "issue_description": "Redefinition of a function in third party code can be miscompiled"
            },
            "140": {
                "commit_sha_buggy": "b347ce3a71e23a4ab92dc0a6c07d43e2f497c953",
                "commit_sha_fixed": "a70a7c599e53a7752cf4b9e6e82b4408c3c4c04b",
                "report_id": "126",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-126.json",
                "issue_title": "Google Common Loader Extern",
                "issue_description": "Google Common Loader Extern"
            },
            "141": {
                "commit_sha_buggy": "8ff053c723ec20f5b8e1e9e87164bbd657f7d2ca",
                "commit_sha_fixed": "3ce4716848eb71b6e78a4545a2cc0c27e74a29b3",
                "report_id": "116",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-116.json",
                "issue_title": "The side effects of function1||function2 are not calculated",
                "issue_description": "The side effects of function1||function2 are not calculated"
            },
            "142": {
                "commit_sha_buggy": "222eafd303155b3eac5cd244584b2cb3c4c11975",
                "commit_sha_fixed": "c25df7eca2462861bf42ad8b74215099c3f81ae6",
                "report_id": "58",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-58.json",
                "issue_title": "Internet Explorer runtime error after compilation.",
                "issue_description": "Internet Explorer runtime error after compilation."
            },
            "143": {
                "commit_sha_buggy": "45fd54a488cfbf27978fc4811a722f1fedb8ddaa",
                "commit_sha_fixed": "7eaa0d8eca2549742649af34671eaf3da83b5c08",
                "report_id": "139",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-139.json",
                "issue_title": "@define does not support strings",
                "issue_description": "@define does not support strings"
            },
            "144": {
                "commit_sha_buggy": "c9e89727dc8063d087d28e42629606f4fd74a6e5",
                "commit_sha_fixed": "465282f1ca28a208b06c47b55fd292d4631c55da",
                "report_id": "143",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-143.json",
                "issue_title": "Auto-identify void functions",
                "issue_description": "Auto-identify void functions"
            },
            "145": {
                "commit_sha_buggy": "b1ffe42efdaaf0266b4ba10e05de124a885cf979",
                "commit_sha_fixed": "dff6e0114f19c20aeb63393d67aa0880ff5745b5",
                "report_id": "190",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-190.json",
                "issue_title": "Bug with labeled loops and breaks",
                "issue_description": "Bug with labeled loops and breaks"
            },
            "146": {
                "commit_sha_buggy": "8d53308bb1d34c16af002ce5fe46cf0ae6c38128",
                "commit_sha_fixed": "35d56dd1fadec0ed50797d222de4e05f78bbf1c9",
                "report_id": "172",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-172.json",
                "issue_title": "bad type inference for != undefined",
                "issue_description": "bad type inference for != undefined"
            },
            "147": {
                "commit_sha_buggy": "91d0d35fba40aac9316db9e2f8aa94cd3a3b6c2e",
                "commit_sha_fixed": "82a9956c6337d2f5d4a94ebe624d64faa54d9182",
                "report_id": "182",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-182.json",
                "issue_title": "Lost a JSC_USED_GLOBAL_THIS warning in 0616 release vs 0514",
                "issue_description": "Lost a JSC_USED_GLOBAL_THIS warning in 0616 release vs 0514"
            },
            "148": {
                "commit_sha_buggy": "4d09ce45270187fa65a891e56081960a0ae449e5",
                "commit_sha_fixed": "f86b8929454da31fbc59cbf95293c7138e0b8200",
                "report_id": "196",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-196.json",
                "issue_title": "CSS3 'writingMode' not recognised in advanced mode",
                "issue_description": "CSS3 'writingMode' not recognised in advanced mode"
            },
            "149": {
                "commit_sha_buggy": "52547e61d187e102f21e5545c24e8d232fefe92f",
                "commit_sha_fixed": "053636cbd1a8fb97e55b4f82bc4b5bee8beaf47e",
                "report_id": "205",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-205.json",
                "issue_title": "Add option to turn off string escaping",
                "issue_description": "Add option to turn off string escaping"
            },
            "150": {
                "commit_sha_buggy": "07dd3707c1a61ff21de3f7a7f15585bbb5f70573",
                "commit_sha_fixed": "bf8fc4533884f914182f861576808e71c18410cc",
                "report_id": "61",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-61.json",
                "issue_title": "Type checker misses annotations on functions defined within functions",
                "issue_description": "Type checker misses annotations on functions defined within functions"
            },
            "151": {
                "commit_sha_buggy": "d00fc0c64dba6762b649f9690cd52c68b849e118",
                "commit_sha_fixed": "fe58a5d1750bab2c5d1d0ef16102c1000e761bd8",
                "report_id": "74",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-74.json",
                "issue_title": "Add a --version option for the compiler.",
                "issue_description": "Add a --version option for the compiler."
            },
            "152": {
                "commit_sha_buggy": "08fc2551ca3c811a02407d593b6ae39d2439a88c",
                "commit_sha_fixed": "de491e70b971caca03f07531c2caf97b878cd1ff",
                "report_id": "268",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-268.json",
                "issue_title": "resolveTypes: jstype.UnionType cannot be cast to jstype.ObjectType",
                "issue_description": "resolveTypes: jstype.UnionType cannot be cast to jstype.ObjectType"
            },
            "153": {
                "commit_sha_buggy": "ff1a3d71ca63efdfc79112b6212fd10bd9aecce8",
                "commit_sha_fixed": "86caf52b53f53d8b83e9c1092f4b15ddeb6ca5bb",
                "report_id": "290",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-290.json",
                "issue_title": "Namespace definition in Prototype is broken",
                "issue_description": "Namespace definition in Prototype is broken"
            },
            "154": {
                "commit_sha_buggy": "d8624db8004fc8ef596d4ccedff7f307f444ad30",
                "commit_sha_fixed": "09ed556367fbe81b3003881dfacad643939664c0",
                "report_id": "204",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-204.json",
                "issue_title": "Add support for data members on interfaces",
                "issue_description": "Add support for data members on interfaces"
            },
            "155": {
                "commit_sha_buggy": "86a7d25f3cc1177f35dc6480260fb807912c03fa",
                "commit_sha_fixed": "ba0119710233a1be87c10c5e71424dc5922cc627",
                "report_id": "378",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-378.json",
                "issue_title": "Overzealous arguments optimisation",
                "issue_description": "Overzealous arguments optimisation"
            },
            "156": {
                "commit_sha_buggy": "bae144ca994994d3ada90c9311286e9277f86288",
                "commit_sha_fixed": "f39bbdd39c9ec2136f0a58a677bd2fdae77075a2",
                "report_id": "389",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-389.json",
                "issue_title": "Compiler crashes on assign statement",
                "issue_description": "Compiler crashes on assign statement"
            },
            "157": {
                "commit_sha_buggy": "9f19220fbd022e8fbcee16d117564d5412e4ffa7",
                "commit_sha_fixed": "41acde3e8e5e8d37ade765b41d9fd29861f03e5e",
                "report_id": "347",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-347.json",
                "issue_title": "Numbers and quoted property names reject for get and set properties.",
                "issue_description": "Numbers and quoted property names reject for get and set properties."
            },
            "158": {
                "commit_sha_buggy": "87ff82f73e843495a887ef08bc92a98b4c7c105c",
                "commit_sha_fixed": "fcccf543e85a214f0948d1ac5cab3fa05363e845",
                "report_id": "407",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-407.json",
                "issue_title": "Order of jscomp_error, jscomp_warning, jscomp_off flags are not preserved",
                "issue_description": "Order of jscomp_error, jscomp_warning, jscomp_off flags are not preserved"
            },
            "159": {
                "commit_sha_buggy": "303a90a0e1fea556eec005e8b0934e87045810a3",
                "commit_sha_fixed": "a4f32ed8acef2880288fe9559f8c60fba444bbe3",
                "report_id": "423",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-423.json",
                "issue_title": "Closure Compiler failed to translate all instances of a function name",
                "issue_description": "Closure Compiler failed to translate all instances of a function name"
            },
            "160": {
                "commit_sha_buggy": "d5dad765e6cbdf512f80a1331e08d3e54baea3fa",
                "commit_sha_fixed": "29312d9f6d01e6c1fce4da0a644881c83864549f",
                "report_id": "467",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-467.json",
                "issue_title": "checkVars / undefinedVars diagnostics not working from command line",
                "issue_description": "checkVars / undefinedVars diagnostics not working from command line"
            },
            "161": {
                "commit_sha_buggy": "dffa868e080b54544e05b96c81dceef522439180",
                "commit_sha_fixed": "89441fcc27e2d7f36d7b2f3990bbc894235bb5b4",
                "report_id": "522",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-522.json",
                "issue_title": "peephole constants folding pass is trying to fold [][11] as if it were a property lookup instead of a property assignment",
                "issue_description": "peephole constants folding pass is trying to fold [][11] as if it were a property lookup instead of a property assignment"
            },
            "162": {
                "commit_sha_buggy": "6b825fb7dbe65d4523f2af9c850ed7e7f43862c2",
                "commit_sha_fixed": "3395eb68a19a8492196df62fb9e38c814de80f08",
                "report_id": "548",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-548.json",
                "issue_title": "Type aliases cannot be used in type annotations before their definitions",
                "issue_description": "Type aliases cannot be used in type annotations before their definitions"
            },
            "163": {
                "commit_sha_buggy": "acc3c458096b1eb7bfc5d7371eafb30af5f7b66c",
                "commit_sha_fixed": "f5bcee992bf149fa39f9eafc870ea2046d5809b4",
                "report_id": "600",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-600.json",
                "issue_title": "VarCheck Crash When Using Modules",
                "issue_description": "VarCheck Crash When Using Modules"
            },
            "164": {
                "commit_sha_buggy": "32f4884ca5aa648d48d988d8d7dada88212d6dbe",
                "commit_sha_fixed": "e414f154d5c4dae483f251ebeb2d9ef598aaa0f6",
                "report_id": "634",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-634.json",
                "issue_title": "{function(number, string)} should not be assignable to {function(number)}",
                "issue_description": "{function(number, string)} should not be assignable to {function(number)}"
            },
            "165": {
                "commit_sha_buggy": "2e904fcdc3bc09e3bff557fcfca383ba7e450095",
                "commit_sha_fixed": "61336bdc14f94b57ba58042f958c2a3227a55a3f",
                "report_id": "725",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-725.json",
                "issue_title": "Properties defined on any record type applying to unrelated record types",
                "issue_description": "Properties defined on any record type applying to unrelated record types"
            },
            "166": {
                "commit_sha_buggy": "4f663a93dcdc8130cf92c3ad31ce8a8ac1fd0804",
                "commit_sha_fixed": "8d58355140bfdfbfc85c4629b90ed1d78225b520",
                "report_id": "785",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-785.json",
                "issue_title": "anonymous object type inference inconsistency when used in union",
                "issue_description": "anonymous object type inference inconsistency when used in union"
            },
            "167": {
                "commit_sha_buggy": "d9b11f3334dcb04cd35abe5f7a5fbfb000fa0986",
                "commit_sha_fixed": "d58006a939b740ea78dc61128065a6fdb8f303ca",
                "report_id": "783",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-783.json",
                "issue_title": "invalid property not erroring in for loop in prototype function",
                "issue_description": "invalid property not erroring in for loop in prototype function"
            },
            "168": {
                "commit_sha_buggy": "d06ac163013a3779fcec7c2f544ba99d08f69f58",
                "commit_sha_fixed": "b675d1da9d5f8b36849db4943f580969105901a4",
                "report_id": "726",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-726.json",
                "issue_title": "Wrong argument count error not reported on this aliasing (on function with @this annotation)",
                "issue_description": "Wrong argument count error not reported on this aliasing (on function with @this annotation)"
            },
            "169": {
                "commit_sha_buggy": "b4c6a605c0aee776bf195c8d71fe2aeebb47665a",
                "commit_sha_fixed": "ac239c7c53aa4d6c3105f600dec8af69da530883",
                "report_id": "791",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-791.json",
                "issue_title": "Strange \"wrong parameter\" warning for callback function",
                "issue_description": "Strange \"wrong parameter\" warning for callback function"
            },
            "170": {
                "commit_sha_buggy": "d5b7f2d9a109eefee69a6554eb4a899e60139101",
                "commit_sha_fixed": "49f54b28376a4ed5f72ec52d314020bd1f6cf3c6",
                "report_id": "965",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-965.json",
                "issue_title": "Overly aggressive comma removal",
                "issue_description": "Overly aggressive comma removal"
            },
            "171": {
                "commit_sha_buggy": "d38ce5675419b30040bc44413e77e7317ed0c7f2",
                "commit_sha_fixed": "6d38965a1e0a3a61435b9bebc91ff1ba0a64013a",
                "report_id": "1023",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1023.json",
                "issue_title": "Assigning object literals to obj.prototype in a immediately executed function not recognized.",
                "issue_description": "Assigning object literals to obj.prototype in a immediately executed function not recognized."
            },
            "172": {
                "commit_sha_buggy": "a8a456b183c9600658bcb0c72091bae1a30a4fda",
                "commit_sha_fixed": "ce86cc8e460060e1280f365f22ccd5c375e2f5ed",
                "report_id": "1042",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1042.json",
                "issue_title": "Type of prototype property incorrectly inferred to string",
                "issue_description": "Type of prototype property incorrectly inferred to string"
            },
            "173": {
                "commit_sha_buggy": "ecd0a7791a772cfa27a6f7dc071b2bd711517b80",
                "commit_sha_fixed": "e96ce395944edfe9ba8e9de6b475cb64a7f8d626",
                "report_id": "1062",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1062.json",
                "issue_title": "Operator precedence breaks with certain combinations of *, / and %.",
                "issue_description": "Operator precedence breaks with certain combinations of *, / and %."
            },
            "174": {
                "commit_sha_buggy": "095dd84b712332cd74dff3d1d2fc236aa93e7b78",
                "commit_sha_fixed": "d2b3ca66b6088c1c08437c120ae215d91d313b7c",
                "report_id": "1103",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1103.json",
                "issue_title": "compiler crash on goog.scope locals",
                "issue_description": "compiler crash on goog.scope locals"
            },
            "175": {
                "commit_sha_buggy": "94623ace4074dea70ffdde117a2d5e11c76de5fa",
                "commit_sha_fixed": "038da2119223818ee1c56eaf600a583f755f9b30",
                "report_id": "1101",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1101.json",
                "issue_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode",
                "issue_description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode"
            },
            "176": {
                "commit_sha_buggy": "d6eebf3357f6f06b44cefbe55aabeab5bf25216e",
                "commit_sha_fixed": "aeed47f424d93d9ff82e0782fca53259829362b1",
                "report_id": "1056",
                "report_url": "https://storage.googleapis.com/google-code-archive/v2/code.google.com/closure-compiler/issues/issue-1056.json",
                "issue_title": "initial type of variable wrong when initialize in a \"var\" statement with type declaration.",
                "issue_description": "initial type of variable wrong when initialize in a \"var\" statement with type declaration."
            }
        }
    },
    "Codec": {
        "owner_repo": "apache/commons-codec",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "9c0cabead7cf075308b11362172ae1a48d41321c",
                "commit_sha_fixed": "52d82d1dfff8c2b2ded9d843e0b03017af6d747c",
                "report_id": "CODEC-65",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-65",
                "issue_title": "[CODEC-65] Fix case-insensitive string handling - ASF JIRA",
                "issue_description": "\nThe language codecs are platform-depedent, please see Common Bug #3 for details.\n"
            },
            "2": {
                "commit_sha_buggy": "2f7454a01e4c2992bffc3d86137e632e80c5027f",
                "commit_sha_fixed": "b8c2d9d9dc9aab45f83cf49ac93cfa8546e4c08e",
                "report_id": "CODEC-77",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-77",
                "issue_title": "[CODEC-77] Base64 bug with empty input (new byte[0]) - ASF JIRA",
                "issue_description": "\nBase64.encode(new byte[0]) doesn't return an empty byte array back!  It returns CRLF.\n"
            },
            "3": {
                "commit_sha_buggy": "d7b01850ef418b1d261cdb2029f8f85ab4031553",
                "commit_sha_fixed": "a5dfe5cbc95d7f3ce0b4829756690c2cb8439f4c",
                "report_id": "CODEC-84",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-84",
                "issue_title": "[CODEC-84] Double Metaphone bugs in alternative encoding - ASF JIRA",
                "issue_description": "\nThe new test case (CODEC-83) has highlighted a number of issues with the \"alternative\" encoding in the Double Metaphone implementation\n1) Bug in the handleG method when \"G\" is followed by \"IER\" \n\nThe alternative encoding of \"Angier\" results in \"ANKR\" rather than \"ANJR\"\nThe alternative encoding of \"rogier\" results in \"RKR\" rather than \"RJR\"\n\nThe problem is in the handleG() method and is caused by the wrong length (4 instead of 3) being used in the contains() method:\n\n } else if (contains(value, index + 1, 4, \"IER\")) {\n\n\n...this should be\n\n } else if (contains(value, index + 1, 3, \"IER\")) {\n\n\n2)  Bug in the handleL method\n\nThe alternative encoding of \"cabrillo\" results in \"KPRL \" rather than \"KPR\"\n\nThe problem is that the first thing this method does is append an \"L\" to both primary & alternative encoding. When the conditionL0() method returns true then the \"L\" should not be appended for the alternative encoding\n\nresult.append('L');\nif (charAt(value, index + 1) == 'L') {\n    if (conditionL0(value, index)) {\n        result.appendAlternate(' ');\n    }\n    index += 2;\n} else {\n    index++;\n}\nreturn index;\n\n\nSuggest refeactoring this to\n\nif (charAt(value, index + 1) == 'L') {\n    if (conditionL0(value, index)) {\n        result.appendPrimary('L');\n    } else {\n        result.append('L');\n    }\n    index += 2;\n} else {\n    result.append('L');\n    index++;\n}\nreturn index;\n\n\n3) Bug in the conditionL0() method for words ending in \"AS\" and \"OS\"\n\nThe alternative encoding of \"gallegos\" results in \"KLKS\" rather than \"KKS\"\n\nThe problem is caused by the wrong start position being used in the contains() method, which means its not checking the last two characters of the word but checks the previous & current position instead:\n\n        } else if ((contains(value, index - 1, 2, \"AS\", \"OS\") || \n\n\n...this should be\n\n        } else if ((contains(value, value.length() - 2, 2, \"AS\", \"OS\") || \n\n\nI'll attach a patch for review\n"
            },
            "4": {
                "commit_sha_buggy": "38ba13232cb37374e3c333e2121ebad8a793935c",
                "commit_sha_fixed": "bcfef8906931a7929a6db14b9d82d387fd3f17f6",
                "report_id": "CODEC-89",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-89",
                "issue_title": "[CODEC-89] new Base64().encode() appends a CRLF, and chunks results into 76 character lines - ASF JIRA",
                "issue_description": "\nThe instance encode() method (e.g. new Base64().encode()) appends a CRLF.  Actually it's fully chunking the output into 76 character lines.  Commons-Codec-1.3 did not do this.  The static Base64.encodeBase64() method behaves the same in both 1.3 and 1.4, so this problem only affects the instance encode() method.\n\nimport org.apache.commons.codec.binary.*;\n\npublic class B64 {\n\n  public static void main(String[] args) throws Exception {\n    Base64 b64 = new Base64();\n\n    String s1 = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\";\n    String s2 = \"aaaaaaaaaa\";\n    String s3 = \"a\";\n    \n    byte[] b1 = s1.getBytes(\"UTF-8\");\n    byte[] b2 = s2.getBytes(\"UTF-8\");\n    byte[] b3 = s3.getBytes(\"UTF-8\");\n\n    byte[] result;\n    result = Base64.encodeBase64(b1);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b1);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n    result = Base64.encodeBase64(b2);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b2);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n    result = Base64.encodeBase64(b3);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b3);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n  }\n}\n\n\nHere's my output:\n\n$ java -cp commons-codec-1.3.jar:. B64\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==]\n[YQ==]\n[YQ==]\n\n\n$ java -cp commons-codec-1.4.jar:. B64\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFh\nYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==\n]\n[YWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==\n]\n[YQ==]\n[YQ==\n]\n\n\n"
            },
            "5": {
                "commit_sha_buggy": "4c6eea410d34d7ff4aa5c30fb7a2fa7c349dae18",
                "commit_sha_fixed": "800f0531068ebaf2f2d257bb1bd805781ddd4760",
                "report_id": "CODEC-98",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-98",
                "issue_title": "[CODEC-98] Base64InputStream causes NullPointerException on some input - ASF JIRA",
                "issue_description": "\nCertain (malformed?) input to Base64InputStream causes a NullPointerException in Base64.decode.\nThe exception occurs when Base64.decode is entered with the following conditions:\n\nbuffer is null\nmodulus is 3 from a previous entry.\ninAvail is -1 because Base64InputStream.read reached EOF on line 150.\n\nUnder these conditions, Base64.decode reaches line 581 with buffer still null and throws a NullPointerException.\nHere is some input data that will trigger it:\n\nH4sIAAAAAAAAAFvzloG1uIhBKiuxLFGvODW5tCizpFIvODM9LzXFPykrNbmE8//eDC2bq/+ZGJij\nGdiT8/NKUvNKShiYop2iGTiLgQoTS0qLUgsZ6hgYfRh4SjJSE3PS84GmZOSWMAj5gMzVz0nMS9cP\nLinKzEu3rigoLQJpXvNZ/AcbR8gDJgaGigIGBqbLayAuMUxNKdVLTyxJTc7QS07WSyzKLC7JL8lJ\n1StJLErMKynNSdTLyUxOzStO1fOB0AwQwMjEwOrJwJMbn+mSWFkclpiTmeID4joml2SWpYZk5qaW\nMEj45Bel62flpyTqlwAF9F2A9oBkrMEqnYtSoXyob1hy4z1dShgEIL4oLcnM0Q8N9XQBqubKjYfa\nDjTV1AfoZn2Im/WTk/XhbtaHu1kf6mZ9T5g2YED8BwKgj8WAbtIDuUkP5CY9mJt22FSkZEXf/QkK\noCIGeVRFSYlA/zsBCZjq//9/PvSP1VvMxMDkxcCe6ZuZk5NZ7MPAnemcUZSfl5+Tn15ZwiCF5n2E\nnDUoDhjVfhrpNABdpI5qWTJYmZ5nsD9Cg0pwSWnSyhOCaYXmAerMoDgsxnAkzG1R+XmpYPXL9Bln\n1RhJPQarL+dgYNM1MLUyMKioKAYFOCvIBb8vl8qCOFxA4/jAiRIU7HqgYN8zk/n7jNxWfbAXeXJS\nE4tLgOnUKbOk2IuBOzcfzqso6M1QmrzKkedPzcYO3QZu129As4xITlZI6QqYFNhz44v9EkFpCGua\nLmEQdkktS83JL8gF5g4FqBGlIJ+wAI1gKJtZEvTws/j3FluPu4lcr7ra9OfHKXIZNTa4FPd8n33J\nQXPFLte9AZe5uBaJvGrKVl+rbrTaXDZO6NwU7gnHOVgzzsmnGX2Y5GDqrst8wcTear0Ab1yj6PrD\nF977vL/5iUMg773My5qLLK8OVAu6Tz7Xcyjy9Uym02Z/+xY7m85nYo/t4E93FXFKOf9/a3X78neS\njE5Tu066K3Mdf17m66mbpXN9y34ZZ3ErRobfn+RfzVBIWj0vc82vY7YPvM5eLHHOulV77M6CoB4h\nxb/FjHWHRR+ldb6QmSP1ROGwGs+nx2quwitN7+mIpsRFhU37JPRoZe2ZjiX/70j7CS1tz51YP/3W\n/xfnV2i/4rAoYeAN9nA0NTQqBxYMQcGOAG5\n\n\nSay this is read from file with a byte[] of size 1024 using Base64InputStream.read(byte[]).  In the first iteration, all 1190 bytes get read into buf, then it enters Base64.setInitialBuffer and assigns the byte[1024] to buffer and does a round of decoding.  When it then enters Base64.readResults on line 162 in Base64InputStream, it sets buffer to null, modulus has the left-over value 3, and the NPE occurs the next iteration.\nBase64InputStream could avoid this by returning right away on EOF (-1), but I think the real fix needs to happen in Base64 since it this same situation could be created by direct use.  My guess is either more needs to happen in the body of the if on line 542 (set modulus to 0?) or the condition on line 573 is flawed and needs adjusting.\n"
            },
            "6": {
                "commit_sha_buggy": "5a0d6b1d2b38a8026b1e160b0de9d9d56b07665c",
                "commit_sha_fixed": "d74fc31604c805a47c44d7853f63a3b06ad6c016",
                "report_id": "CODEC-101",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-101",
                "issue_title": "[CODEC-101] Base64InputStream#read(byte[]) incorrectly returns 0 at end of any stream which is multiple of 3 bytes long - ASF JIRA",
                "issue_description": "\nUsing new InputStreamReader(new Base64InputStream(in, true)) sometimes fails with \"java.io.IOException: Underlying input stream returned zero bytes\".\nThis is been tracked down that Base64InputStream#read(byte[]) incorrectly returns 0 at end of any stream which is multiple of 3 bytes long.\n"
            },
            "7": {
                "commit_sha_buggy": "f7966c1b374ebdd3fccb28370d9cb80a2115d807",
                "commit_sha_fixed": "954d995c5603b616c3c4a9ffb1823f36dd7ebcb0",
                "report_id": "CODEC-99",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-99",
                "issue_title": "[CODEC-99] Base64.encodeBase64String() shouldn't chunk - ASF JIRA",
                "issue_description": "\nBase64.encodeBase64String() shouldn't chunk.\nChange this:\n\npublic static String encodeBase64String(byte[] binaryData) {\n    return StringUtils.newStringUtf8(encodeBase64(binaryData, true));\n}\n\n\nTo this:\n\npublic static String encodeBase64String(byte[] binaryData) {\n    return StringUtils.newStringUtf8(encodeBase64(binaryData, false));\n}\n\n\nThis will fix the following tests ggregory added a few minutes ago:\n        //assertEquals(\"Zg==\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"f\")));\n        //assertEquals(\"Zm8=\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"fo\")));\n        //assertEquals(\"Zm9v\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foo\")));\n        //assertEquals(\"Zm9vYg==\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foob\")));\n        //assertEquals(\"Zm9vYmE=\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"fooba\")));\n        //assertEquals(\"Zm9vYmFy\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foobar\")));\n"
            },
            "8": {
                "commit_sha_buggy": "931e25921dc0ec705a0055655aa2b2237a0888d7",
                "commit_sha_fixed": "2c13032a16e37b7bc9e0272d25fc185b5c82b42e",
                "report_id": "CODEC-105",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-105",
                "issue_title": "[CODEC-105] ArrayIndexOutOfBoundsException when doing multiple reads() on encoding Base64InputStream - ASF JIRA",
                "issue_description": "\nWhen encoding a sizable stream byte by byte (so, just calling Base64InputStream.read()), after 10920 successful read()s, this happens: \njava.lang.ArrayIndexOutOfBoundsException: 2\n        at org.apache.commons.codec.binary.Base64.encode(Base64.java:502)\n        at org.apache.commons.codec.binary.Base64InputStream.read(Base64InputStream.java:157)\n        at org.apache.commons.codec.binary.Base64InputStream.read(Base64InputStream.java:109)\nBased on this, the necessary conditions seem to be that buffer = null and modulus = 2. Then, if a read() is done, a single-byte buffer is used, whose length is doubled by resizeBuffer(), but that still doesn't make it big enough to hold the 4 bytes written to it because modulus was just incremented to 0. \nHere's some sample code:\nimport org.apache.commons.codec.binary.Base64InputStream;\npublic class TestReads {\n    public static void main(String[] args) {\n        Base64InputStream b64stream = new Base64InputStream(System.in, true, 0, null);\n        int n = 0;\n        try \n{\n            while (b64stream.read() != -1) n++;\n        }\n catch (Exception x) \n{\n            System.out.println(n);\n            x.printStackTrace();\n        }\n    }\n}\n"
            },
            "9": {
                "commit_sha_buggy": "b396c535ff143cf94ea0d11f50739da1709ec290",
                "commit_sha_fixed": "c5291ab1ca4d4d7a041874a66b1c05b7d5c02ccb",
                "report_id": "CODEC-112",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-112",
                "issue_title": "[CODEC-112] Base64.encodeBase64(byte[] binaryData, boolean isChunked, boolean urlSafe, int maxResultSize) throws IAE for valid maxResultSize if isChunked is false - ASF JIRA",
                "issue_description": "\nIf isChunked is false, Base64.encodeBase64(byte[] binaryData, boolean isChunked, boolean urlSafe, int maxResultSize) throws IAE for valid maxResultSize.\nTest case and fix will be applied shortly.\n"
            },
            "10": {
                "commit_sha_buggy": "2a8fd84f1f380fc472ecf415b771cb5fd789719b",
                "commit_sha_fixed": "41c68e9ef470696009d72133c7f05a20e2728e34",
                "report_id": "CODEC-117",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-117",
                "issue_title": "[CODEC-117] Caverphone encodes names starting and ending with \"mb\" incorrectly. - ASF JIRA",
                "issue_description": "\nCaverphone encode names starting and ending with \"mb\" incorrectly.\nAccording to the spec:\n\"If the name ends with mb make it m2\".\nThis has been coded as:\n\"If the name starts with mb make it m2\".\n"
            },
            "11": {
                "commit_sha_buggy": "9999937922dc0ebe50f913fbbfb147a19eb8c0f3",
                "commit_sha_fixed": "7e8c20bd1b0593c3496a168be573aed40609a433",
                "report_id": "CODEC-121",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-121",
                "issue_title": "[CODEC-121] QuotedPrintableCodec does not support soft line break per the 'quoted-printable' example on Wikipedia - ASF JIRA",
                "issue_description": "\nWriting a unit test I discovered that the example Wikipedia uses for quoted-printable data does not decode but instead throws an exception.  \nTheir example is here:  http://en.wikipedia.org/wiki/Quoted-printable#Example\ntest:\n  String qpdata   = \"If you believe that truth=3Dbeauty, then surely=20=\\r\\n\" +\n\t\t    \"mathematics is the most beautiful branch of philosophy.\";\n  String expected = \"If you believe that truth=beauty, then surely \" +\n\t\t    \"mathematics is the most beautiful branch of philosophy.\";\n  assertEquals( expected,  new QuotedPrintableCodec().decode(qpdata) );\nI suppose I could fix if you like but currently I'm not a registered developer.  \n"
            },
            "12": {
                "commit_sha_buggy": "caa142d0399f10ce3ec6fb843e679e2d8c07c43f",
                "commit_sha_fixed": "1fc451c79779bdbf788e8bfbec6dc031a47495d8",
                "report_id": "CODEC-130",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-130",
                "issue_title": "[CODEC-130] Base64InputStream.skip skips underlying stream, not output - ASF JIRA",
                "issue_description": "\nBase64InputStream.skip() skips within underlying stream, leading to unexpected behaviour.\nThe following code will reproduce the issue:\n@Test\npublic void testSkip() throws Throwable {\n    InputStream ins =\n            new ByteArrayInputStream(\"AAAA////\".getBytes(\"ISO-8859-1\"));//should decode to \n{0, 0, 0, 255, 255, 255}\n    Base64InputStream instance = new Base64InputStream(ins);\n    assertEquals(3L, instance.skip(3L)); //should skip 3 decoded characters, or 4 encoded characters\n    assertEquals(255, instance.read()); //Currently returns 3, as it is decoding \"A/\", not \"//\" \n}\nThe following code, if added to Base64InputStream, or (BaseNCodecInputStream in the dev build) would resolve the issue:\n@Override\npublic long skip(long n) throws IOException {\n    //delegate to read()\n    long bytesRead = 0;\n    while ((bytesRead < n) && (read() != -1)) \n{\n        bytesRead++;\n    }\n    return bytesRead;\n}\nMore efficient code may be possible.\n"
            },
            "13": {
                "commit_sha_buggy": "8c145775da55fb33104751199a28809acb657c1f",
                "commit_sha_fixed": "37ba197e62d6b60037d18afc33801e6221f1b8c6",
                "report_id": "CODEC-184",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-184",
                "issue_title": "[CODEC-184] NullPointerException in DoubleMetaPhone.isDoubleMetaphoneEqual when using empty strings - ASF JIRA",
                "issue_description": "\nisDoubleMetaphoneEqual does not work with empty strings: The following test throws a NullPointerException:\n\n  public void test1() throws Throwable {\n    org.apache.commons.codec.language.DoubleMetaphone var0 = new org.apache.commons.codec.language.DoubleMetaphone();\n    boolean var3 = var0.isDoubleMetaphoneEqual(\"\", \"\", false);\n  }\n\n\n"
            },
            "14": {
                "commit_sha_buggy": "50a1d17b5402accbdd59e62e68fa96172c9e3764",
                "commit_sha_fixed": "39d5df29fb768fd257f9d328b99f00bc69ec864a",
                "report_id": "CODEC-187",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-187",
                "issue_title": "[CODEC-187] Beider Morse Phonetic Matching producing incorrect tokens - ASF JIRA",
                "issue_description": "\nI believe the Beider Morse Phonetic Matching algorithm was added in Commons Codec 1.6\nThe BMPM algorithm is an EVOLVING algorithm that is currently on version 3.02 though it had been static since version 3.01 dated 19 Dec 2011 (it was first available as opensource as version 1.00 on 6 May 2009).\nI can see nothing in the Commons Codec Docs to say which version of BMPM was implemented so I am not sure if the problem with the algorithm as coded in the Codec is simply an old version or whether there are more basic problems with the implementation.\nHow do I determine the version of the algorithm that was implemented in the Commons Codec?\nHow do we ensure that the algorithm is updated if/when the BMPM algorithm changes?\nHow do we ensure that the algorithm as coded in the Commons Codec is accurate and working as expected?\n"
            },
            "15": {
                "commit_sha_buggy": "8fc193527df27beeeb638e6e812e8c4df6c72f46",
                "commit_sha_fixed": "28b7b958d39730fc278fd1919bf335c52133a1a2",
                "report_id": "CODEC-199",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-199",
                "issue_title": "[CODEC-199] Bug in HW rule in Soundex - ASF JIRA",
                "issue_description": "\nThe Soundex algorithm says that if two characters that map to the same code are separated by H or W, the second one is not encoded.\nHowever, in the implementation (in Soundex.getMappingCode() line 191), a character that is preceded by two characters that are either H or W, is not encoded, regardless of what the last consonant was.\nSource: http://en.wikipedia.org/wiki/Soundex#American_Soundex\n"
            },
            "16": {
                "commit_sha_buggy": "38357dffa2dd39c91c4523beade08c12e8009acb",
                "commit_sha_fixed": "c82fe35c48bd0082c16644d16d82d1be79d6b9d1",
                "report_id": "CODEC-200",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-200",
                "issue_title": "[CODEC-200] Base32.HEX_DECODE_TABLE contains the wrong value 32 - ASF JIRA",
                "issue_description": "\nAt line 99:\n            25, 26, 27, 28, 29, 30, 31, 32,                                 // 50-57 O-V\nthe value 32 should not be included. That disallows to use 'W' as padding with hex table.\n"
            },
            "17": {
                "commit_sha_buggy": "1a4d9cc2572d220664f1b7c377cd318cd253052e",
                "commit_sha_fixed": "d2f27093d7d95a07da901902f894d88b4ecc3e95",
                "report_id": "CODEC-229",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-229",
                "issue_title": "[CODEC-229] StringUtils.newStringxxx(null) should return null, not NPE - ASF JIRA",
                "issue_description": "\nMethod calls such as StringUtils.newStringIso8859_1(null) should return null, not NPE.\nIt looks like this capability was lost with the fix for CODEC-136, i.e.\nhttp://svn.apache.org/viewvc?rev=1306366&view=rev\nSeveral methods were changed from\n\nreturn StringUtils.newString(bytes, CharEncoding.xxx);\nto\nreturn new String(bytes, Charsets.xxx);\n\n\nThe new code should have been:\n\nreturn newString(bytes, Charsets.xxx);\n\n\nThe newString method handles null input.\nThere were no tests for null input so the change in behaviour was missed.\n"
            },
            "18": {
                "commit_sha_buggy": "ca30fae3acb59a5caef3c3c21eecae7c928827e0",
                "commit_sha_fixed": "5ef5bd199a4e3df74479b4b363fa29b0b3092547",
                "report_id": "CODEC-231",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-231",
                "issue_title": "[CODEC-231] StringUtils.equals(CharSequence cs1, CharSequence cs2) can fail with String Index OBE - ASF JIRA",
                "issue_description": "\nStringUtils.equals(CharSequence cs1, CharSequence cs2) fails with String Index OBE if the two sequences are different lengths.\n"
            },
            "19": {
                "commit_sha_buggy": "e65d67e1c41746e811503255fadacef6de645eec",
                "commit_sha_fixed": "a50a203248662d2b4fe6f5b6952d3066ab3ab8ba",
                "report_id": "CODEC-56",
                "report_url": "https://issues.apache.org/jira/browse/CODEC-56",
                "issue_title": "[CODEC-56] RefinedSoundex creates instance before al fields have been initialized - ASF JIRA",
                "issue_description": "\nThe RefinedSoundex code creates an instance of itself in the variable US_ENGLISH; however this appears before some of the other static final variables.\nThe variable US_ENGLISH needs to be moved after the other variables.\nSee patch to follow.\n"
            }
        }
    },
    "Collections": {
        "owner_repo": "apache/commons-collections",
        "bug_infos": {
            "25": {
                "commit_sha_buggy": "7c99c6234c7b403449420b2688fff3d516662591",
                "commit_sha_fixed": "73d69dfe8677210e44049bc1a2a7d1ff85bc1ca7",
                "report_id": "COLLECTIONS-566",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-566",
                "issue_title": "[COLLECTIONS-566] IteratorUtils.collatedIterator do not use natural ordering if no comparator was provided - ASF JIRA",
                "issue_description": "\nIn case a null comparator was provided natural ordering should be used, as stated in the javadoc.\nIn fact an exception is thrown the first time the returned iterator is used.\n"
            },
            "26": {
                "commit_sha_buggy": "3a9c4718ee0fd2eeef8b3ce151ee829fadbef5ae",
                "commit_sha_fixed": "f8bd75d37ca12c5d49c1b628c33c0b45e2d082eb",
                "report_id": "COLLECTIONS-576",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-576",
                "issue_title": "[COLLECTIONS-576] MultiKey subclassing has deserialization problem since COLLECTIONS-266: either declare protected readResolve() or MultiKey must be final - ASF JIRA",
                "issue_description": "\nMultiKey from collections 4 provides a transient hashCode and a private readResolve to resolve COLLECTIONS-266: Issue with MultiKey when serialized/deserialized via RMI.\nUnfortunately the solution does not work in case of subclassing: readResolve in MultiKey should be declared protected readResolve() to be called during deserialization of the subclass. Otherwise MultiKey must be final to avoid such subclassing.\nTestcase:\nMultiKeySerializationTest.java\npackage de.ivu.test.common.collections4;\n\nimport static org.junit.Assert.assertEquals;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\n\nimport org.apache.commons.collections4.keyvalue.MultiKey;\nimport org.junit.Test;\n\npublic class MultiKeySerializationTest {\n\n    @Test\n    @SuppressWarnings(\"unchecked\")\n    public void testReadResolveEqualHashCode()\n            throws IOException, ClassNotFoundException {\n        class MultiKey2<A, B>\n                extends MultiKey {\n\n            private static final long serialVersionUID = 1928896152249821416L;\n\n            public MultiKey2(A key1, B key2) {\n                super(key1, key2);\n            }\n\n            public A getFirst() {\n                return (A) getKey(0);\n            }\n\n            public B getSecond() {\n                return (B) getKey(1);\n            }\n            \n            // FIXME: MultiKey should either declare protected readResolve() or must be final.\n        }\n        MultiKey2<String, String> one = new MultiKey2<>(\"bla\", \"blub\");\n        System.out.println(one.hashCode());\n        ByteArrayOutputStream byteOut = new ByteArrayOutputStream();\n        ObjectOutputStream out = new ObjectOutputStream(byteOut);\n        out.writeObject(one);\n        out.close();\n        byte[] serialized = byteOut.toByteArray();\n        ByteArrayInputStream byteIn = new ByteArrayInputStream(serialized);\n        ObjectInputStream in = new ObjectInputStream(byteIn);\n        MultiKey2<String, String> two = (MultiKey2<String, String>) in.readObject();\n        System.out.println(two.hashCode());\n        assertEquals(\"hashCode must be equal - please check for protected readResolve in MultiKey*\", one.hashCode(),\n            two.hashCode());\n    }\n}\n\n\nFix:\nMultiKey.java\n@@ -274,7 +274,7 @@\n      * only stable for the same process).\n      * @return the instance with recalculated hash code\n      */\n-    private Object readResolve() {\n+    protected Object readResolve() {\n         calculateHashCode(keys);\n         return this;\n     }\n\n\n"
            },
            "27": {
                "commit_sha_buggy": "7a72b1983c03f7b33e397cdfc5e8f0636bcd924e",
                "commit_sha_fixed": "3eee44cf63b1ebb0da6925e98b3dcc6ef1e4d610",
                "report_id": "COLLECTIONS-580",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-580",
                "issue_title": "[COLLECTIONS-580] Arbitrary remote code execution with InvokerTransformer - ASF JIRA",
                "issue_description": "\nWith InvokerTransformer serializable collections can be build that execute arbitrary Java code. sun.reflect.annotation.AnnotationInvocationHandler#readObject invokes #entrySet and #get on a deserialized collection. If you have an endpoint that accepts serialized Java objects (JMX, RMI, remote EJB, ...) you can combine the two to create arbitrary remote code execution vulnerability.\nI don't know of a good fix short of removing InvokerTransformer or making it not Serializable. Both probably break existing applications.\nThis is not my research, but has been discovered by other people.\nhttps://github.com/frohoff/ysoserial\nhttp://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/\n"
            },
            "28": {
                "commit_sha_buggy": "796114ea4a9cc57ab17170536e1caa5933520c47",
                "commit_sha_fixed": "a270ff62852e62b5ac0f943a7e57292a72b77271",
                "report_id": "COLLECTIONS-586",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-586",
                "issue_title": "[COLLECTIONS-586] PatriciaTrie prefixMap clear throws NullPointerException - ASF JIRA",
                "issue_description": "\nClearing all entries of a prefixMap returned by PatriciaTrie using the clear method throws a NullPointerException. The workaround of removing each entry using the remove method seems to work.\nHere are the test cases for the bug and the workaround:\n\npublic class PatriciaTrieTest {\n\n    private Trie<String, Integer> trie;\n\n    @Before\n    public void setUp() {\n        trie = new PatriciaTrie<Integer>();\n        trie.put(\"Anna\", 1);\n        trie.put(\"Anael\", 2);\n        trie.put(\"Analu\", 3);\n        trie.put(\"Andreas\", 4);\n        trie.put(\"Andrea\", 5);\n        trie.put(\"Andres\", 6);\n        trie.put(\"Anatole\", 7);\n    }\n\n    @Test\n    public void testPrefixMapClear() {\n        SortedMap<String, Integer> prefixMap = trie.prefixMap(\"And\");\n        assertEquals(new HashSet<>(Arrays.asList(\"Andrea\", \"Andreas\", \"Andres\")), prefixMap.keySet());\n        assertEquals(Arrays.asList(5, 4, 6), new ArrayList<>(prefixMap.values()));\n\n        prefixMap.clear();\n        assertTrue(prefixMap.keySet().isEmpty());\n        assertTrue(prefixMap.values().isEmpty());\n        assertEquals(new HashSet<>(Arrays.asList(\"Anael\", \"Analu\", \"Anatole\", \"Anna\")), trie.keySet());\n        assertEquals(Arrays.asList(2, 3, 7, 1), new ArrayList<>(trie.values()));\n    }\n\n    @Test\n    public void testPrefixMapClearUsingRemove() {\n        SortedMap<String, Integer> prefixMap = trie.prefixMap(\"And\");\n        assertEquals(new HashSet<>(Arrays.asList(\"Andrea\", \"Andreas\", \"Andres\")), prefixMap.keySet());\n        assertEquals(Arrays.asList(5, 4, 6), new ArrayList<>(prefixMap.values()));\n\n        Set<String> keys = new HashSet<String>(prefixMap.keySet());\n        for (final String key : keys) {\n            prefixMap.remove(key);\n        }\n        assertTrue(prefixMap.keySet().isEmpty());\n        assertTrue(prefixMap.values().isEmpty());\n        assertEquals(new HashSet<>(Arrays.asList(\"Anael\", \"Analu\", \"Anatole\", \"Anna\")), trie.keySet());\n        assertEquals(Arrays.asList(2, 3, 7, 1), new ArrayList<>(trie.values()));\n    }\n\n}\n\n\nThe stacktrace of the NullPointerException thrown by the testPrefixMapClear test case is:\n\njava.lang.NullPointerException\n\tat org.apache.commons.collections4.trie.AbstractPatriciaTrie$PrefixRangeEntrySet$EntryIterator.remove(AbstractPatriciaTrie.java:2370)\n\tat java.util.AbstractCollection.clear(AbstractCollection.java:432)\n\tat java.util.AbstractMap.clear(AbstractMap.java:288)\n\tat PatriciaTrieTest.testPrefixMapClear(PatriciaTrieTest.java:39)\n\n\n"
            },
            "29": {
                "commit_sha_buggy": "1e6435ec103c1d52b119602a3aa48bfa5775d01d",
                "commit_sha_fixed": "4a9bcd0f5211c91c4c2f47313c8f8013d0dfe03e",
                "report_id": "COLLECTIONS-599",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-599",
                "issue_title": "[COLLECTIONS-599] HashEntry array object naming data initialized with double the size during deserialization - ASF JIRA",
                "issue_description": "\nCommon collections 3.1 and 3.2 are used at many places and frameworks including struts2. \nSupose a LinkedMap object it is created and have size greater than zero is serialized. While deserializing this object , array of HashEntry naming data delacred in AbstractHashedMap always initialises with a new capacity of double its double of the serialized object. \nPlease see the below API declared in AbstractHashedMap class :\n\n\r\nprotected void checkCapacity()\r\n  {\r\n    if (this.size >= this.threshold)\r\n    {\r\n      int newCapacity = this.data.length * 2;\r\n      if (newCapacity <= 1073741824) {\r\n        ensureCapacity(newCapacity);\r\n      }\r\n    }\r\n  }\r\n\n\n"
            },
            "30": {
                "commit_sha_buggy": "274c9c1d37a47ae9bc1cdec1b0b0e4189dd44845",
                "commit_sha_fixed": "b88b065aa955d7a7d8f74c427b05d2243eda0779",
                "report_id": "COLLECTIONS-673",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-673",
                "issue_title": "[COLLECTIONS-673] ListUtils.partition potential integer overflow - ASF JIRA",
                "issue_description": "\nWhen calling ListUtils.partition() with a large size and large list, it is possible that an integer overflow will occur in the size()\u00a0method that causes incorrect behavior. This will occur when using a size that, when added to list.size() will be larger than Integer.MAX_VALUE\nCurrent version of Guava's Lists.partition() handle this correctly, so perhaps the code for ListUtils.partition() needs to be updated based on the latest Guava code.\nA simple illustration of this:\n\n\r\nList<String> aList = Arrays.asList(\"1\", \"2\", \"3\", \"4\", \"5\");\r\nList<List<String>> partitioned = ListUtils.partition(aList, Integer.MAX_VALUE);\r\nSystem.out.println(\"Number of partitions: \" + partitioned.size());\r\nfor(List<String> l : partitioned)  {\r\n     System.out.println(l);\r\n}\r\n\n\nThe above code works correctly when using Guava's Lists.partition() instead.\n"
            },
            "31": {
                "commit_sha_buggy": "dc828f8b16a4e34d474b2470041eb0d757853a09",
                "commit_sha_fixed": "1979a6e31067a18c9ede59ad4518f738512eba82",
                "report_id": "COLLECTIONS-701",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-701",
                "issue_title": "[COLLECTIONS-701] StackOverflowError in SetUniqueList.add() when it receives itself - ASF JIRA",
                "issue_description": "\nHi.\nWe found that the following test case\u00a0fails\u00a0with a StackOverFlowError exception:\n\n\r\ntest() {\u00a0 \u00a0 \u00a0 \u00a0 \r\n   SetUniqueList l = new SetUniqueList(new LinkedList<Object>()) ;\u00a0 \u00a0 \u00a0 \u00a0 \r\n   l.add((Object) l) ;\u00a0 \u00a0 \r\n}\n\nThe\u00a0add() execution traps into an infinite recursion which crashes the program.\nFrom the stack trace, we found that\u00a0the\u00a0infinite recursion occurs\nat AbstractList.hashCode() since it invokes\u00a0hashCode() of each of its elements.\n\u00a0\n"
            },
            "35": {
                "commit_sha_buggy": "f08623354efe4d801e4c1e29c0eb970b166b2c8c",
                "commit_sha_fixed": "45b6865b59d344910dd8cf09b54e6ea91347752d",
                "report_id": "COLLECTIONS-734",
                "report_url": "https://issues.apache.org/jira/browse/COLLECTIONS-734",
                "issue_title": "[COLLECTIONS-734]  Encountered an IllegalStateException while traversing with Flat3Map.entrySet() - ASF JIRA",
                "issue_description": "\n Encountered an IllegalStateException while traversing with Flat3Map.entrySet()\n\n\r\n//\u4ee3\u7801\u793a\u4f8b\r\n    public void testEntrySet() {\r\n        final Flat3Map<Integer, String> map = new Flat3Map<>();\r\n        map.put(1, \"A\");\r\n        map.put(2, \"B\");\r\n        map.put(3, \"C\");\r\n        Iterator<Map.Entry<Integer, String>> it = map.entrySet().iterator();        Map.Entry<Integer, String> mapEntry1 = it.next();\r\n        Map.Entry<Integer, String> mapEntry2 = it.next();\r\n        Map.Entry<Integer, String> mapEntry3 = it.next();\r\n        it.remove();        assertEquals(2, map.size());\r\n    }\r\n\n\nUsing the above code will generate an IllegalStateException.\nThe reason for this problem is that there is a problem with the EntryIterator.remove() method in the Flat3Map java class.\nI submitted a PR(https://github.com/apache/commons-collections/pull/115) to fix this bug.\n"
            }
        }
    },
    "Compress": {
        "owner_repo": "apache/commons-compress",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "728b4e814ec88cab556533fa114be0efdde963be",
                "commit_sha_fixed": "004124ac5dbf5edbf925078652526267468821e7",
                "report_id": "COMPRESS-28",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-28",
                "issue_title": "[COMPRESS-28] CPIO reports unexpected EOF - ASF JIRA",
                "issue_description": "\nWhen unpacking an CPIO archive (made with the compress classes or even made with OSX cpio comandline tool) an EOF exception is thrown.\nHere is the testcode:\n        final File input = getFile(\"cmdcreated.cpio\");\n        final InputStream in = new FileInputStream(input);\n        CpioArchiveInputStream cin = new CpioArchiveInputStream(in);\n        CpioArchiveEntry entry = null;\n        while ((entry = (CpioArchiveEntry) cin.getNextCPIOEntry()) != null) \n{\n            File target = new File(dir, entry.getName());\n            final OutputStream out = new FileOutputStream(target);\n            IOUtils.copy(in, out);\n            out.close();\n        }\n\n        cin.close();\nStacktrace is here:\njava.io.EOFException\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream.readFully(CpioArchiveInputStream.java:293)\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream.getNextCPIOEntry(CpioArchiveInputStream.java:168)\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStreamTest.testCpioUnpack(CpioArchiveInputStreamTest.java:26)\n\t...\nThis happens with the first read access to the archive. It occured while my try to improve the testcases.\n"
            },
            "2": {
                "commit_sha_buggy": "1cde8827c953a56b2fcabad676f8cf2ddd6ec182",
                "commit_sha_fixed": "d09177b98f4e956c1d366110f73c3341ea110bee",
                "report_id": "COMPRESS-11",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-11",
                "issue_title": "[COMPRESS-11] Ar doesn't delete correct - ASF JIRA",
                "issue_description": "\nWhen working on the Testcases i figured out that a deletion from an Ar Archive is not as successful as it look at first glance.\nFor example: my bla.ar file contains test1.xml and test2.xml. I delete test2.xml\nThe \"getNextEntry\" Method just delivers test1.xml. Looks correct.\nBut checking the result file at commandline brings the following:\n$> ar -t /tmp/dir26673/bla.ar\ntest1.xml\ntest2.xml\nvi shows me that there is still the test2.xml entry in the archive,\neven when getNextEntry returns null.\nDeleting test2.xml and adding test.txt afterward brings the following:\n$> ar -t /tmp/dir24825/bla.ar\ntest.txt\nar: /tmp/dir24825/bla.ar: Inappropriate file type or format\n"
            },
            "3": {
                "commit_sha_buggy": "ddbd61f0e75b7d98873b9a9bf6398218edcfd17b",
                "commit_sha_fixed": "d170f34fa65e19b604f5a9e04e6ed5f81d35658c",
                "report_id": "COMPRESS-64",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-64",
                "issue_title": "[COMPRESS-64] Are the public finish() methods ArchiveOutputStream implementations necessary and safe? - ASF JIRA",
                "issue_description": "\nSome of the ArchiveOutputStream implementations have public finish() methods. These are currently only called from the close() methods.\nSeems to me that there is no need to allow the finish() methods to be called externally, and the user can corrupt the output if they do.\nSurely the close() method is all that is needed?\n"
            },
            "4": {
                "commit_sha_buggy": "d170f34fa65e19b604f5a9e04e6ed5f81d35658c",
                "commit_sha_fixed": "6273f3a6b804aa845747c8859d659373b14199e1",
                "report_id": "COMPRESS-64",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-64",
                "issue_title": "[COMPRESS-64] Are the public finish() methods ArchiveOutputStream implementations necessary and safe? - ASF JIRA",
                "issue_description": "\nSome of the ArchiveOutputStream implementations have public finish() methods. These are currently only called from the close() methods.\nSeems to me that there is no need to allow the finish() methods to be called externally, and the user can corrupt the output if they do.\nSurely the close() method is all that is needed?\n"
            },
            "5": {
                "commit_sha_buggy": "c520d00b707fe6ecf4f3d7d062af09ffea6812e8",
                "commit_sha_fixed": "dc3fc4703211876fb38cccf55adc92ee5cbc28d0",
                "report_id": "COMPRESS-87",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-87",
                "issue_title": "[COMPRESS-87] ZipArchiveInputStream doesn't report the end of a truncated archive - ASF JIRA",
                "issue_description": "\nIf a Zip archive is truncated, (e.g. because it is the first volume in a multi-volume archive) the ZipArchiveInputStream.read() method will not detect that fact. All calls to read() will return 0 bytes read. They will not return -1 (end of stream), nor will they throw any exception (which would seem like a good idea to me because the archive is truncated).\nI have tracked this problem to ZipArchiveInputStream.java, line 239. It contains a check\nif (read == 0 && inf.finished()) {\n    return -1;\n}\nFor truncated archives the read is always zero but the inf is never finished(). I suggest adding two lines below:\nif (read == 0 && inf.finished()) {\n    return -1;\n} else if (read == 0 && lengthOfLastRead == -1) {\n\tthrow new IOException(\"Truncated ZIP file\");\n}\nThis solves the problem in my tests.\n"
            },
            "6": {
                "commit_sha_buggy": "41aa509d836dcdd316a40e68680cc54e0f6c1e04",
                "commit_sha_fixed": "5066e9aeb98f386b29a31cd4acb97aa43844cd30",
                "report_id": "COMPRESS-94",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-94",
                "issue_title": "[COMPRESS-94] Creating zip files with many entries will ocassionally produce corrupted output - ASF JIRA",
                "issue_description": "\nOur application produces large numbers of zip files, often with 1000's of similarly named files contained within the zip. \nWhen we switched from the standard JDK zip classes to those in commons compress, we would ocassionally produce a zip file that had corrupted index entries and would fail to unzip successfully using 7-zip, winzip, etc.\nDebugging the zip creation showed that the the wrong offsets were being returned from the hashmap in ZipOutputStream for the entries that were being corrupted.  Further analysis revealed that this occurred when the filenames being added had a hash collision with another entry in the same output zip (which appears to happen quite frequently for us).\nThe issue appears to stem from the fact that ZipArchiveEntry can store the entry name either in its superclass if passed in on the ctor or in its own member attribute if set later via setName().  Not sure whether this functionality is really required?  Regardless, the root cause of the bug is that the equals() and hashCode() methods in ZipArchiveEntry do not always use the same filename value in their comparisons.  In fact if the filename of the entry is set in the ctor it will always treat two ZipArchiveEntries as equal.  This will break the offset hashmap whenever there is a hash collision as it will overwrite the previous entry, believeing it to be equal.\nPatch to follow.\n"
            },
            "7": {
                "commit_sha_buggy": "2419bb55d2683142443626482c85d6086ae3bf72",
                "commit_sha_fixed": "2d858d5c7cc30313c9c3c8ef4a5e8d34d67a395e",
                "report_id": "COMPRESS-114",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-114",
                "issue_title": "[COMPRESS-114] TarUtils.parseName does not properly handle characters outside the range 0-127 - ASF JIRA",
                "issue_description": "\nif a tarfile contains files with special characters, the names of the tar entries are wrong.\nexample:\ncorrect name: 0302-0601-3\u00b1\u00b1\u00b1F06\u00b1W220\u00b1ZB\u00b1LALALA\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1CAN\u00b1\u00b1DC\u00b1\u00b1\u00b104\u00b1060302\u00b1MOE.model\nname resolved by TarUtils.parseName: 0302-0101-3\uffb1\uffb1\uffb1F06\uffb1W220\uffb1ZB\uffb1HECKMODUL\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1ECE\uffb1\uffb1DC\uffb1\uffb1\uffb107\uffb1060302\uffb1DOERN.model\nplease use: \nresult.append(new String(new byte[] \n{ buffer[i] }\n));\ninstead of: \nresult.append((char) buffer[i]);\nto solve this encoding problem.\n"
            },
            "8": {
                "commit_sha_buggy": "d7398f46ccd552eb315d94bf652cc264ea21799a",
                "commit_sha_fixed": "35e4e4fb6848ddfa3878270523f3f9336ae7f9b8",
                "report_id": "COMPRESS-113",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-113",
                "issue_title": "[COMPRESS-113] TarArchiveEntry.parseTarHeader() includes the trailing space/NUL when parsing the octal size - ASF JIRA",
                "issue_description": "\nTarArchiveEntry.parseTarHeader() includes the trailing space/NUL when parsing the octal size.\nAlthough the size field in the header is 12 bytes, the last byte is supposed to be space or NUL - i.e. only 11 octal digits are allowed for the size.\n"
            },
            "9": {
                "commit_sha_buggy": "ec0db741b7e53d6fbe3887f8720f76a625d2277f",
                "commit_sha_fixed": "fdac1475918e93444b08a024d096b4ec39d6733d",
                "report_id": "COMPRESS-160",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-160",
                "issue_title": "[COMPRESS-160] TarArchiveOutputStream.getBytesWritten() returns invalid value - ASF JIRA",
                "issue_description": "\nIt appears the TarArchiveOutputStream.getBytesWritten()returns zero or invalid value when queried.\nIn the code sample below, it returns zero, even after an sizeable file was processed.\nI've printed it twice, once before closing the output stream, and once after, just for the reference.\nIt is also demonstrable on multiple processed files.\nWithin the TarArchiveOutputStream.getBytesWritten() implementation, it appears the call for count(numToWrite) is made after the numToWrite is depleted in the process of actual byte writing. When call for count(numToWrite); is moved up, the returned values for TarArchiveOutputStream.getBytesWritten() are getting equal to the sum of the sizes of processed files. This is much closer to expected value (\"Returns the current number of bytes written to this stream.\") but still not correct, for that number should include the tar header sizes as well.\nAt any rate, please find the proposed patch below, merely moving count(numToWrite); up a few lines. This makes TarArchiveOutputStream.getBytesWritten() closer to true value.\nTest code:\n\n@Test\n\tpublic void tartest() throws Exception {\n\t\t\n\t\tFileOutputStream myOutputStream = new FileOutputStream(\"C:/temp/tartest.tar\");\n\t\t\n\t\tArchiveOutputStream sTarOut = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.TAR, myOutputStream);\n\t\t\n\t\tFile sSource = new File(\"C:/share/od_l.txt\");\n\t\tTarArchiveEntry sEntry = new TarArchiveEntry(sSource);\n\t\tsTarOut.putArchiveEntry(sEntry);\n\t\t\n\t\tFileInputStream sInput = new FileInputStream(sSource);\n\t\tbyte[] cpRead = new byte[8192];\n\t\t\n\t\tint iRead = 0;\n\t\twhile ((iRead = sInput.read(cpRead)) > 0) {\n\t\t\tsTarOut.write(cpRead, 0, iRead);\n\t\t}\n\t\t\n\t\tsLog.info(\"Processed: \"+sTarOut.getBytesWritten()+\" bytes. File Len: \"+sSource.length());\n\t\t\n\t\tsInput.close();\n\t\tsTarOut.closeArchiveEntry();\n\t\tsTarOut.close();\n\n\t\tsLog.info(\"Processed: \"+sTarOut.getBytesWritten()+\" bytes. File Len: \"+sSource.length());\n\n\t\t\n\t\treturn;\n\t\t\t\n\t}\n\n\nTest Output:\n\nOct 21, 2011 9:09:28 AM com.cronsult.jndmpd.test.Backup tartest\nINFO: Processed: 0 bytes. File Len: 186974208\nOct 21, 2011 9:09:28 AM com.cronsult.jndmpd.test.Backup tartest\nINFO: Processed: 0 bytes. File Len: 186974208\n\n\nProposed Patch:\n\nIndex: src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n===================================================================\n--- src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\t(revision 1187150)\n+++ src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\t(working copy)\n@@ -276,6 +276,8 @@\n             // eliminate some of the buffer copying.\n             //\n         }\n+        \n+        count(numToWrite);\n \n         if (assemLen > 0) {\n             if ((assemLen + numToWrite) >= recordBuf.length) {\n@@ -325,7 +327,7 @@\n             wOffset += num;\n         }\n         \n-        count(numToWrite);\n+        \n     }\n \n     /**\n\n\n\n"
            },
            "10": {
                "commit_sha_buggy": "8cece7223349341d5ab44234d1f62897cb849511",
                "commit_sha_fixed": "347660646cfad588481c13058842d49fa3779f84",
                "report_id": "COMPRESS-164",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-164",
                "issue_title": "[COMPRESS-164] Cannot Read Winzip Archives With Unicode Extra Fields - ASF JIRA",
                "issue_description": "\nI have a zip file created with WinZip containing Unicode extra fields. Upon attempting to extract it with org.apache.commons.compress.archivers.zip.ZipFile, ZipFile.getInputStream() returns null for ZipArchiveEntries previously retrieved with ZipFile.getEntry() or even ZipFile.getEntries(). See UTF8ZipFilesTest.patch in the attachments for a test case exposing the bug. The original test case stopped short of trying to read the entries, that's why this wasn't flagged up before. \nThe problem lies in the fact that inside ZipFile.java entries are stored in a HashMap. However, at one point after populating the HashMap, the unicode extra fields are read, which leads to a change of the ZipArchiveEntry name, and therefore a change of its hash code. Because of this, subsequent gets on the HashMap fail to retrieve the original values.\nZipFile.patch contains an (admittedly simple-minded) fix for this problem by reconstructing the entries HashMap after the Unicode extra fields have been parsed. The purpose of this patch is mainly to show that the problem is indeed what I think, rather than providing a well-designed solution.\nThe patches have been tested against revision 1210416.\n"
            },
            "11": {
                "commit_sha_buggy": "00cc49e76b4cb5837f91bdcae2b3dff6a2809f2a",
                "commit_sha_fixed": "a933173f486614073b68b6c0a6ef09a9c72c94fc",
                "report_id": "COMPRESS-171",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-171",
                "issue_title": "[COMPRESS-171] createArchiveInputStream detects text files less than 100 bytes as tar archives - ASF JIRA",
                "issue_description": "\nThe fix for COMPRESS-117 which modified ArchiveStreamFactory().createArchiveInputStream(inputstream) results in short text files (empirically seems to be those <= 100 bytes) being detected as tar archives which obviously is not desirable if one wants to know whether or not the files are archives.\nI'm not an expert on compressed archives but perhaps the heuristic that if a stream is interpretable as a tar file without an exception being thrown should only be applied on archives greater than 100 bytes?\n"
            },
            "12": {
                "commit_sha_buggy": "b23b5c8533846374a22b417f7d66c7cb8ceb8962",
                "commit_sha_fixed": "bc84d2083e4b1da77547bb4e810a06553e8f0bed",
                "report_id": "COMPRESS-178",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-178",
                "issue_title": "[COMPRESS-178] TarArchiveInputStream throws IllegalArgumentException instead of IOException - ASF JIRA",
                "issue_description": "\nTarArchiveInputStream is throwing  IllegalArgumentException instead of IOException on corrupt files, in direct contradiction to the Javadoc. Here is a stack-trace:\n\njava.lang.IllegalArgumentException: Invalid byte -1 at offset 7 in '<some bytes>' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:86)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:790)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:308)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:198)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextEntry(TarArchiveInputStream.java:380)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarInputShop.<init>(TarInputShop.java:91)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newTarInputShop(TarDriver.java:159)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarGZipDriver.newTarInputShop(TarGZipDriver.java:82)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newInputShop(TarDriver.java:151)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newInputShop(TarDriver.java:47)\n\tat de.schlichtherle.truezip.fs.archive.FsDefaultArchiveController.mount(FsDefaultArchiveController.java:170)\n\tat de.schlichtherle.truezip.fs.archive.FsFileSystemArchiveController$ResetFileSystem.autoMount(FsFileSystemArchiveController.java:98)\n\tat de.schlichtherle.truezip.fs.archive.FsFileSystemArchiveController.autoMount(FsFileSystemArchiveController.java:47)\n\tat de.schlichtherle.truezip.fs.archive.FsArchiveController.autoMount(FsArchiveController.java:129)\n\tat de.schlichtherle.truezip.fs.archive.FsArchiveController.getEntry(FsArchiveController.java:160)\n\tat de.schlichtherle.truezip.fs.archive.FsContextController.getEntry(FsContextController.java:117)\n\tat de.schlichtherle.truezip.fs.FsDecoratingController.getEntry(FsDecoratingController.java:76)\n\tat de.schlichtherle.truezip.fs.FsDecoratingController.getEntry(FsDecoratingController.java:76)\n\tat de.schlichtherle.truezip.fs.FsConcurrentController.getEntry(FsConcurrentController.java:164)\n\tat de.schlichtherle.truezip.fs.FsSyncController.getEntry(FsSyncController.java:108)\n\tat de.schlichtherle.truezip.fs.FsFederatingController.getEntry(FsFederatingController.java:156)\n\tat de.schlichtherle.truezip.nio.file.TFileSystem.newDirectoryStream(TFileSystem.java:348)\n\tat de.schlichtherle.truezip.nio.file.TPath.newDirectoryStream(TPath.java:963)\n\tat de.schlichtherle.truezip.nio.file.TFileSystemProvider.newDirectoryStream(TFileSystemProvider.java:344)\n\tat java.nio.file.Files.newDirectoryStream(Files.java:400)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.convertToJar(GetSourcesMojo.java:248)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.download(GetSourcesMojo.java:221)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.execute(GetSourcesMojo.java:111)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)\n\t... 20 more\n\n\nExpected behavior: TarArchiveInputStream should wrap the IllegalArgumentException in an IOException.\n"
            },
            "13": {
                "commit_sha_buggy": "576bd034787ca2f7367127432e4b53737d6e690f",
                "commit_sha_fixed": "c75c10faae27781aeb51713f42153cad1fd242a4",
                "report_id": "COMPRESS-176",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-176",
                "issue_title": "[COMPRESS-176] ArchiveInputStream#getNextEntry(): Problems with WinZip directories with Umlauts - ASF JIRA",
                "issue_description": "\nThere is a problem when handling a WinZip-created zip with Umlauts in directories.\nI'm accessing a zip file created with WinZip containing a directory with an umlaut (\"\u00e4\") with ArchiveInputStream. When creating the zip file the unicode-flag of winzip had been active.\nThe following problem occurs when accessing the entries of the zip:\nthe ArchiveEntry for a directory containing an umlaut is not marked as a directory and the file names for the directory and all files contained in that directory contain backslashes instead of slashes (i.e. completely different to all other files in directories with no umlaut in their path).\nThere is no difference when letting the ArchiveStreamFactory decide which ArchiveInputStream to create or when using the ZipArchiveInputStream constructor with the correct encoding (I've tried different encodings CP437, CP850, ISO-8859-15, but still the problem persisted).\nThis problem does not occur when using the very same zip file but compressed by 7zip or the built-in Windows 7 zip functionality.\n"
            },
            "14": {
                "commit_sha_buggy": "d39ba76c50f65698213787901ec8dffbda77e43a",
                "commit_sha_fixed": "40f2e6380094ebfdc73e4adaf4059b80e1327aad",
                "report_id": "COMPRESS-181",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-181",
                "issue_title": "[COMPRESS-181] Tar files created by AIX native tar, and which contain symlinks, cannot be read by TarArchiveInputStream - ASF JIRA",
                "issue_description": "\nA simple tar file created on AIX using the native (/usr/bin/tar tar utility) and which contains a symbolic link, cannot be loaded by TarArchiveInputStream:\n\njava.io.IOException: Error detected parsing the header\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:201)\n\tat Extractor.extract(Extractor.java:13)\n\tat Extractor.main(Extractor.java:28)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tools.ant.taskdefs.ExecuteJava.run(ExecuteJava.java:217)\n\tat org.apache.tools.ant.taskdefs.ExecuteJava.execute(ExecuteJava.java:152)\n\tat org.apache.tools.ant.taskdefs.Java.run(Java.java:771)\n\tat org.apache.tools.ant.taskdefs.Java.executeJava(Java.java:221)\n\tat org.apache.tools.ant.taskdefs.Java.executeJava(Java.java:135)\n\tat org.apache.tools.ant.taskdefs.Java.execute(Java.java:108)\n\tat org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n\tat org.apache.tools.ant.Task.perform(Task.java:348)\n\tat org.apache.tools.ant.Target.execute(Target.java:390)\n\tat org.apache.tools.ant.Target.performTasks(Target.java:411)\n\tat org.apache.tools.ant.Project.executeSortedTargets(Project.java:1399)\n\tat org.apache.tools.ant.Project.executeTarget(Project.java:1368)\n\tat org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)\n\tat org.apache.tools.ant.Project.executeTargets(Project.java:1251)\n\tat org.apache.tools.ant.Main.runBuild(Main.java:809)\n\tat org.apache.tools.ant.Main.startAnt(Main.java:217)\n\tat org.apache.tools.ant.launch.Launcher.run(Launcher.java:280)\n\tat org.apache.tools.ant.launch.Launcher.main(Launcher.java:109)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 0 at offset 0 in '{NUL}1722000726 ' len=12\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:99)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:819)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:314)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:199)\n\t... 29 more\n\n\nTested with 1.2 and the 1.4 nightly build from Feb 23 (Implementation-Build: trunk@r1292625; 2012-02-23 03:20:30+0000)\n"
            },
            "15": {
                "commit_sha_buggy": "306b3d6b551b2fc6a3c9729117d47f7d7dea9e89",
                "commit_sha_fixed": "4becc32881aa983d69359b475892a4f2bc6e5b89",
                "report_id": "COMPRESS-187",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-187",
                "issue_title": "[COMPRESS-187] ZipArchiveInputStream and ZipFile don't produce equals ZipArchiveEntry instances - ASF JIRA",
                "issue_description": "\nI'm trying to use a ZipArchiveEntry coming from ZipArchiveInputStream that I stored somwhere for later with a ZipFile and it does not work.\nThe reason is that it can't find the ZipArchiveEntry in the ZipFile entries map. It is exactly the same zip file but both entries are not equals so the Map#get fail.\nAs far as I can see the main difference is that comment is null in ZipArchiveInputStream while it's en empty string in ZipFile. I looked at ZipArchiveInputStream and it looks like the comment (whatever it is) is simply not parsed while I can find some code related to the comment at the end of ZIipFile#readCentralDirectoryEntry.\nNote that java.util.zip does not have this issue. Did not checked what they do but the zip entries are equals.\n"
            },
            "16": {
                "commit_sha_buggy": "811fb4e1f7cb0b87d9af62cc892ac06a413eb560",
                "commit_sha_fixed": "9bdacbfb9631d3a3710a64f35482c643b78a2e79",
                "report_id": "COMPRESS-191",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-191",
                "issue_title": "[COMPRESS-191] Too relaxed tar detection in ArchiveStreamFactory - ASF JIRA",
                "issue_description": "\nThe relaxed tar detection logic added in COMPRESS-117 unfortunately matches also some non-tar files like a test AIFF file that Apache Tika uses. It would be good to improve the detection heuristics to still match files like the one in COMPRESS-117 but avoid false positives like the AIFF file in Tika.\n"
            },
            "17": {
                "commit_sha_buggy": "db6dda34281d95d495ff4c935b65cf84310bf6be",
                "commit_sha_fixed": "ab456436d20f386641e605c17de24cc8cd3c1770",
                "report_id": "COMPRESS-197",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-197",
                "issue_title": "[COMPRESS-197] Tar file for Android backup cannot be read - ASF JIRA",
                "issue_description": "\nAttached tar file was generated by some kind of backup tool on Android. Normal tar utilities seem to handle it fine, but Commons Compress doesn't.\n\njava.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '01750{NUL}{NUL}{NUL}' len=8\n    at org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:99)\n    at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:788)\n    at org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:308)\n\n\n"
            },
            "18": {
                "commit_sha_buggy": "716666a267169689e3b4559458c1f0d53a96ae0a",
                "commit_sha_fixed": "09b8f6d78e18b927491fc299973146fa74fd977f",
                "report_id": "COMPRESS-203",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-203",
                "issue_title": "[COMPRESS-203] Long directory names can not be stored in a tar archive because of error when writing PAX headers - ASF JIRA",
                "issue_description": "\nTrying to add a directory to the TAR Archive that has a name longer than 100 bytes generates an exception with a stack trace similar to the following:\n\njava.io.IOException: request to write '114' bytes exceeds size in header of '0' bytes for entry './PaxHeaders.X/layers/openstreetmap__osm.disy.net/.tiles/1.0.0/openstreetmap__osm.disy.net/default/'\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.write(TarArchiveOutputStream.java:385)\n\n            at java.io.OutputStream.write(Unknown Source)\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.writePaxHeaders(TarArchiveOutputStream.java:485)\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.putArchiveEntry(TarArchiveOutputStream.java:312)\n\n            at net.disy.lib.io.tar.TarUtilities.addFile(TarUtilities.java:116)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:158)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.tar(TarUtilities.java:77)\n\n            at net.disy.lib.io.tar.TarUtilities.tar(TarUtilities.java:42)\n\n            at net.disy.gisterm.tilecacheset.export.TileCacheSetExporter.tarTreeStructure(TileCacheSetExporter.java:262)\n\n            at net.disy.gisterm.tilecacheset.export.TileCacheSetExporter.export(TileCacheSetExporter.java:111)\n\n            at net.disy.gisterm.tilecacheset.desktop.controller.ExportController$1.run(ExportController.java:81)\n\n            ... 2 more\n\n\nInformal source code investigation points to the problem being that for directory entries the code assumes that the length is 0 in putArchiveEntry (see TarArchiveOutputStream:321 ) but when writing the data, it actually writes some data (the filename) and the length written (filename size) is larger than the length expected (0).\n"
            },
            "19": {
                "commit_sha_buggy": "ed534048b12afcffd45a53f7b0945f49d929a29a",
                "commit_sha_fixed": "e860d2f3eb16d84e146a8a700d9dbd3af01df4ba",
                "report_id": "COMPRESS-228",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-228",
                "issue_title": "[COMPRESS-228] ZipException on reading valid zip64 file - ASF JIRA",
                "issue_description": "\nZipFile zip = new ZipFile(new File(\"ordertest-64.zip\")); throws ZipException \"central directory zip64 extended information extra field's length doesn't match central directory data.  Expected length 16 but is 28\".\nThe archive was created by using DotNetZip-WinFormsTool uzing zip64 flag (forces always to make zip64 archives).\nZip file is tested from the console: $zip -T ordertest-64.zip\nOutput:\ntest of ordertest-64.zip OK\nI can open the archive with FileRoller without problem on my machine, browse and extract it.\n"
            },
            "20": {
                "commit_sha_buggy": "a671a703fe86b69adb8c61495a915065c186362d",
                "commit_sha_fixed": "040e42d0f0bebc15ca80cb80fb6db53804b2e082",
                "report_id": "COMPRESS-236",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-236",
                "issue_title": "[COMPRESS-236] IllegalArgumentException reading CPIO generated by Redline RPM - ASF JIRA",
                "issue_description": "\nhttp://redline-rpm.org/ creates CPIO archives with a non-zero file mode on the trailer. This causes an IllegalArgumentException when reading the file. I've attached a patch and test archive to fix this.\n"
            },
            "21": {
                "commit_sha_buggy": "afce414fb9351fba7e68dc5e77e2e144c3c59722",
                "commit_sha_fixed": "5c2d32b322fa797cf428b35c4c5998173d6403d5",
                "report_id": "COMPRESS-252",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-252",
                "issue_title": "[COMPRESS-252] Writing 7z empty entries produces incorrect or corrupt archive - ASF JIRA",
                "issue_description": "\nI couldn't find an exact rule that causes this incorrect behavior, but I tried to reduce it to some simple scenarios to reproduce it:\nInput: A folder with certain files -> tried to archive it.\nIf the folder contains more than 7 files the incorrect behavior appears.\nScenario 1: 7 empty files\nResult: The created archive contains a single folder entry with the name of the archive (no matter which was the name of the file)\nScenario 2: 7 files, some empty, some with content\nResult: The created archive contains a folder entry with the name of the archive and a number of file entries also with the name of the archive. The number of the entries is equal to the number of non empty files.\nScenario 3: 8 empty files\nResult: 7zip Manager cannot open archive and stops working.\nScenario 4.1: 8 files: some empty, some with content, last file (alphabetically) with content\nResult: same behavior as described for Scenario 2.\nScenario 4.2: 8 files, some empty, some with content, last file empy\nResult: archive is corrupt, the following message is received: \"Cannot open file 'archivename.7z' as archive\" (7Zip Manager does not crash).\n"
            },
            "22": {
                "commit_sha_buggy": "ad634c0c24e883ec4ba509122df4679c2245e37b",
                "commit_sha_fixed": "71e4eeadcfc5eb390eca1142fc1f6ee5b1b4d5c1",
                "report_id": "COMPRESS-253",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-253",
                "issue_title": "[COMPRESS-253] BZip2CompressorInputStream reads fewer bytes from truncated file than CPython's bz2 implementation - ASF JIRA",
                "issue_description": "\nJython includes support for decompressing bz2 files using commons compress and shares regression tests with CPython. The CPython test test_read_truncated in test_bz2.py passes under CPython but fails under Jython.\nThe BZip2CompressorInputStream is able to read 769 bytes from the truncated data rather than the 770 bytes that the CPython bz2 implementation can read.\n"
            },
            "23": {
                "commit_sha_buggy": "71e4eeadcfc5eb390eca1142fc1f6ee5b1b4d5c1",
                "commit_sha_fixed": "cbb5a1ad9b0b80f717ee71dc0fc765afdc1601c0",
                "report_id": "COMPRESS-256",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-256",
                "issue_title": "[COMPRESS-256] 7z: 16 MB dictionary is too big - ASF JIRA",
                "issue_description": "\nI created an archiv with 7zip 9.20 containing the compress-1.7-src directory. Also tried it with 1.6 version and directory. I \ndownloaded the zip file and reziped it as 7z. The standard setting where used:\nCompression level: normal\nCompression method: lzma2\nDictionary size: 16 MB\nWord size: 32\nSolid Block size: 2 GB\nI get an exception if I try to open the file with the simple line of code:\nSevenZFile input = new SevenZFile(new File(arcName));\nMaybe it is a bug in the tukaani library, but I do not know how to report it to them.\nThe exception thrown:\norg.tukaani.xz.UnsupportedOptionsException: LZMA dictionary is too big for this implementation\n\tat org.tukaani.xz.LZMAInputStream.initialize(Unknown Source)\n\tat org.tukaani.xz.LZMAInputStream.<init>(Unknown Source)\n\tat org.apache.commons.compress.archivers.sevenz.Coders$LZMADecoder.decode(Coders.java:117)\n\tat org.apache.commons.compress.archivers.sevenz.Coders.addDecoder(Coders.java:48)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.readEncodedHeader(SevenZFile.java:278)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.readHeaders(SevenZFile.java:190)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.<init>(SevenZFile.java:94)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.<init>(SevenZFile.java:116)\n\tat compress.SevenZipError.main(SevenZipError.java:28)\n"
            },
            "24": {
                "commit_sha_buggy": "c2376685ed5cb56833327cb5f54e5f803a8e8fa9",
                "commit_sha_fixed": "8da377299d085b4ce1f15dbc0732232ea32e601d",
                "report_id": "COMPRESS-262",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-262",
                "issue_title": "[COMPRESS-262] TarArchiveInputStream fails to read entry with big user-id value - ASF JIRA",
                "issue_description": "\nCaused by: java.lang.IllegalArgumentException: Invalid byte 52 at offset 7 in '62410554' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:130)\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:175)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:953)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:247)\n\t... 5 more\n"
            },
            "25": {
                "commit_sha_buggy": "bc741b19e88749d66b03bf8dc292f3ae0fc74156",
                "commit_sha_fixed": "aed56110ff582b96aecf7675a9cfe5247ffa3e7d",
                "report_id": "COMPRESS-264",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-264",
                "issue_title": "[COMPRESS-264] ZIP reads correctly with commons-compress 1.6, gives NUL bytes in 1.7 - ASF JIRA",
                "issue_description": "\nWhen running the code below, commons-compress 1.6 writes:\n Content of test.txt:\n data\nBy comparison, commons-compress 1.7 writes\n Content of test.txt:\n@@@@^@\npackage com.example.jrn;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.lang.System;\n/**\n\nHello world!\n *\n */\npublic class App {\n  public static void main(String[] args) {\n    byte[] zip = \n{\n       (byte)0x50, (byte)0x4b, (byte)0x03, (byte)0x04, (byte)0x0a, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x03, (byte)0x7b,\n       (byte)0xd1, (byte)0x42, (byte)0x82, (byte)0xc5, (byte)0xc1, (byte)0xe6,\n       (byte)0x05, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x05, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x08, (byte)0x00, (byte)0x1c, (byte)0x00,\n       (byte)0x74, (byte)0x65, (byte)0x73, (byte)0x74, (byte)0x2e, (byte)0x74,\n       (byte)0x78, (byte)0x74, (byte)0x55, (byte)0x54, (byte)0x09, (byte)0x00,\n       (byte)0x03, (byte)0x56, (byte)0x62, (byte)0xbf, (byte)0x51, (byte)0x2a,\n       (byte)0x63, (byte)0xbf, (byte)0x51, (byte)0x75, (byte)0x78, (byte)0x0b,\n       (byte)0x00, (byte)0x01, (byte)0x04, (byte)0x01, (byte)0xff, (byte)0x01,\n       (byte)0x00, (byte)0x04, (byte)0x88, (byte)0x13, (byte)0x00, (byte)0x00,\n       (byte)0x64, (byte)0x61, (byte)0x74, (byte)0x61, (byte)0x0a, (byte)0x50,\n       (byte)0x4b, (byte)0x01, (byte)0x02, (byte)0x1e, (byte)0x03, (byte)0x0a,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x03,\n       (byte)0x7b, (byte)0xd1, (byte)0x42, (byte)0x82, (byte)0xc5, (byte)0xc1,\n       (byte)0xe6, (byte)0x05, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x05,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x08, (byte)0x00, (byte)0x18,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x01,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0xa0, (byte)0x81, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x74, (byte)0x65, (byte)0x73,\n       (byte)0x74, (byte)0x2e, (byte)0x74, (byte)0x78, (byte)0x74, (byte)0x55,\n       (byte)0x54, (byte)0x05, (byte)0x00, (byte)0x03, (byte)0x56, (byte)0x62,\n       (byte)0xbf, (byte)0x51, (byte)0x75, (byte)0x78, (byte)0x0b, (byte)0x00,\n       (byte)0x01, (byte)0x04, (byte)0x01, (byte)0xff, (byte)0x01, (byte)0x00,\n       (byte)0x04, (byte)0x88, (byte)0x13, (byte)0x00, (byte)0x00, (byte)0x50,\n       (byte)0x4b, (byte)0x05, (byte)0x06, (byte)0x00, (byte)0x00, (byte)0x00,\n       (byte)0x00, (byte)0x01, (byte)0x00, (byte)0x01, (byte)0x00, (byte)0x4e,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x47, (byte)0x00, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)00\n    }\n;\n\n    ByteArrayInputStream bin = new ByteArrayInputStream(zip);\n    try {\n      ZipArchiveInputStream in = new ZipArchiveInputStream(bin);\n      try {\n        while (true) {\n          ZipArchiveEntry entry = in.getNextZipEntry();\n          if (entry == null) \n{\n            break;\n          }\n          byte[] buf = new byte[(int) entry.getSize()];\n          in.read(buf);\n          System.out.println(\"Content of \" + entry.getName() + \":\");\n          System.out.write(buf);\n        }\n      } finally \n{\n        in.close();\n      }\n    } catch (IOException e) \n{\n      System.err.println(\"IOException: \" + e);\n    }\n  }\n}\n"
            },
            "26": {
                "commit_sha_buggy": "8af0b6c133fe7d147833b70e731c99d179dc8db9",
                "commit_sha_fixed": "557800a53cedad99afc951032a11931f3e39bf13",
                "report_id": "COMPRESS-277",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-277",
                "issue_title": "[COMPRESS-277] IOUtils.skip does not work as advertised - ASF JIRA",
                "issue_description": "\nI am trying to feed a TarInputStream from a CipherInputStream.\nIt does not work, because IOUtils.skip() does not adhere to the contract it claims in javadoc:\n\"     * <p>This method will only skip less than the requested number of\n\nbytes if the end of the input stream has been reached.</p>\"\n\nHowever it does:\n            long skipped = input.skip(numToSkip);\n            if (skipped == 0) \n{\n                break;\n            }\n\nAnd the input stream javadoc says:\n\"     * This may result from any of a number of conditions; reaching end of file\n\nbefore <code>n</code> bytes have been skipped is only one possibility.\"\n\nIn the case of CipherInputStream, it stops at the end of each byte buffer.\nIf you check the IOUtils from colleagues at commons-io, they have considered this case in IOUtils.skip() where they use a read to skip through the stream.\nAn optimized version could combine trying to skip, then read then trying to skip again.\n"
            },
            "27": {
                "commit_sha_buggy": "383d90399e3e2284bca4836197eb92b126095479",
                "commit_sha_fixed": "1ea7e01eb6776071eddf60f7783d650ec7d60e74",
                "report_id": "COMPRESS-278",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-278",
                "issue_title": "[COMPRESS-278] Incorrect handling of NUL username and group Tar.gz entries - ASF JIRA",
                "issue_description": "\nWith version 1.8 of commons-compress it's no longer possible to decompress  files from an archive if the archive contains entries having null (or being empty?) set as username and/or usergroup. With version 1.7 this still worked now I get this exception:\n\njava.io.IOException: Error detected parsing the header\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:249)\n\tat TestBed.AppTest.extractNoFileOwner(AppTest.java:30)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 32 at offset 7 in '       {NUL}' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:134)\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:173)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:953)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:247)\n\t... 27 more\n\n\n\nThis exception leads to my suspision that the regression was introduced with the fix for this ticket COMPRESS-262, which has a nearly identical exception provided.\nSome test code you can run to verify it:\n\npackage TestBed;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\n\nimport org.apache.commons.compress.archivers.tar.TarArchiveEntry;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\nimport org.junit.Test;\n\n/**\n * Unit test for simple App.\n */\npublic class AppTest\n{\n\n    @Test\n    public void extractNoFileOwner()\n    {\n        TarArchiveInputStream tarInputStream = null;\n\n        try\n        {\n            tarInputStream =\n                new TarArchiveInputStream( new GzipCompressorInputStream( new FileInputStream( new File(\n                    \"/home/pknobel/redis-dist-2.8.3_1-linux.tar.gz\" ) ) ) );\n            TarArchiveEntry entry;\n            while ( ( entry = tarInputStream.getNextTarEntry() ) != null )\n            {\n                System.out.println( entry.getName() );\n                System.out.println(entry.getUserName()+\"/\"+entry.getGroupName());\n            }\n\n        }\n        catch ( FileNotFoundException e )\n        {\n            e.printStackTrace();\n        }\n        catch ( IOException e )\n        {\n            e.printStackTrace();\n        }\n    }\n\n}\n\n\nWith 1.7 the TestCase outputed this:\n\nredis-dist-2.8.3_1/bin/\n/\nredis-dist-2.8.3_1/bin/redis-server\njenkins/jenkins\nredis-dist-2.8.3_1/bin/redis-cli\njenkins/jenkins\n\n\nWith 1.8 it's failing once it reaches the null valued entry, which is the first. The archive is created using maven assembly plugin, and I tried the same with maven ant task. Both generating an archive with not set username and groups for at least some entries.\nYou can download the archive from http://heli0s.darktech.org/redis/2.8.3_1/redis-dist-2.8.3_1-linux.tar.gz\nIf you run a tar -tvzf on the file you see this report:\n\ndrwxr-xr-x 0/0               0 2014-04-18 09:43 redis-dist-2.8.3_1-SNAPSHOT/bin/\n-rwxr-xr-x pknobel/pknobel 3824588 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-cli\n-rwxr-xr-x pknobel/pknobel 5217234 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-server\n\n\nThe user 0/0 probably indicates that it's not set although it's the root user id. A correctly root user file would show up as root/root\n"
            },
            "28": {
                "commit_sha_buggy": "1ea7e01eb6776071eddf60f7783d650ec7d60e74",
                "commit_sha_fixed": "ddb5fd6d8e4d5fa9f7fa659c93fb6eb04f238689",
                "report_id": "COMPRESS-279",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-279",
                "issue_title": "[COMPRESS-279] TarArchiveInputStream silently finished when unexpected EOF occured - ASF JIRA",
                "issue_description": "\nI just found the following test case didn't raise an IOException as it used to be for a tar trimmed on purpose \n@Test\n  public void testCorruptedBzip2() throws IOException {\n    String archivePath = PathUtil.join(testdataDir, \"test.tar.bz2\");\n    TarArchiveInputStream input = null;\n    input = new TarArchiveInputStream(new BZip2CompressorInputStream(\n        GoogleFile.SYSTEM.newInputStream(archivePath), true));\n    ArchiveEntry nextMatchedEntry = input.getNextEntry();\n    while (nextMatchedEntry != null) \n{\n      logger.infofmt(\"Extracting %s\", nextMatchedEntry.getName());\n      String outputPath = PathUtil.join(\"/tmp/\", nextMatchedEntry.getName());\n      OutputStream out = new FileOutputStream(outputPath);\n      ByteStreams.copy(input, out);\n      out.close();\n      nextMatchedEntry = input.getNextEntry();\n    }\n  }\n"
            },
            "29": {
                "commit_sha_buggy": "66338dd9c4bf1e76be830749d9bc93c7be35cb2a",
                "commit_sha_fixed": "d50feb67569fb5881b8a2ff5996f656c5f207c2e",
                "report_id": "COMPRESS-306",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-306",
                "issue_title": "[COMPRESS-306] ArchiveStreamFactory fails to pass on the encoding when creating some streams - ASF JIRA",
                "issue_description": "\nArchiveStreamFactory fails to pass on the encoding when creating the following streams (in some or all cases):\n\nArjArchiveInputStream\nCpioArchiveInputStream\nDumpArchiveInputStream\nJarArchiveInputStream\nJarArchiveOutputStream\n\n"
            },
            "30": {
                "commit_sha_buggy": "0bbe5b59af443da2c3101cb9259e7ad68152dd13",
                "commit_sha_fixed": "5cf68bdc46c7bcc0fc5eb3cacd1c84514ef552cf",
                "report_id": "COMPRESS-309",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-309",
                "issue_title": "[COMPRESS-309] BZip2CompressorInputStream return value wrong when told to read to a full buffer. - ASF JIRA",
                "issue_description": "\nBZip2CompressorInputStream.read(buffer, offset, length) returns -1 when given an offset equal to the length of the buffer.\nThis indicates, not that the buffer was full, but that the stream was finished.\nIt seems like a pretty stupid thing to do - but I'm getting this when trying to use Kryo serialization (which is probably a bug on their part, too), so it does occur and has negative affects.\nHere's a JUnit test that shows the problem specifically:\n\n\t@Test\n\tpublic void testApacheCommonsBZipUncompression () throws Exception {\n\t\t// Create a big random piece of data\n\t\tbyte[] rawData = new byte[1048576];\n\t\tfor (int i=0; i<rawData.length; ++i) {\n\t\t\trawData[i] = (byte) Math.floor(Math.random()*256);\n\t\t}\n\n\t\t// Compress it\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n\t\tBZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);\n\t\tbzipOut.write(rawData);\n\t\tbzipOut.flush();\n\t\tbzipOut.close();\n\t\tbaos.flush();\n\t\tbaos.close();\n\n\t\t// Try to read it back in\n\t\tByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());\n\t\tBZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);\n\t\tbyte[] buffer = new byte[1024];\n\t\t// Works fine\n\t\tAssert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));\n\t\t// Fails, returns -1 (indicating the stream is complete rather than that the buffer \n\t\t// was full)\n\t\tAssert.assertEquals(0, bzipIn.read(buffer, 1024, 0));\n\t\t// But if you change the above expected value to -1, the following line still works\n\t\tAssert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));\n\t\tbzipIn.close();\n\t}\n\n\n"
            },
            "31": {
                "commit_sha_buggy": "4355c0d224342b5c94881b7aabb441f765867dfe",
                "commit_sha_fixed": "f8bf45444c49053a92f6f560c5008d5ac43aa27f",
                "report_id": "COMPRESS-301",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-301",
                "issue_title": "[COMPRESS-301] Illegal argument exception when extracting .tgz file  - ASF JIRA",
                "issue_description": "\nWhen attempting to unpack a .tgz file, I am receiving the illegal argument exception: java.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '05412\n{NUL}11' len=8. This is causing a java.io.IOException: Error detected parsing the header error. \n\nThis is being thrown when the function TarArchiveInputStream.getNextTarEntry() is called. \n\nHere is the code I am using. \n\n            TarArchiveInputStream tarIn = new TarArchiveInputStream(\n                    new GZIPInputStream(\n                            new BufferedInputStream(\n                                    new FileInputStream(\n                                            tempDirPath + fileName))));\n\n            TarArchiveEntry entry = tarIn.getNextTarEntry();\n\n            while (entry != null) {\n                File path = new File(tempDirPath, entry.getName());\n                if (entry.isDirectory()) {\n                    path.mkdirs();\n                } else {          \n                    path.createNewFile();\n                    byte[] read = new byte[2048];\n                    BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(path));\n                    int len;\n                    while ((len = tarIn.read(read)) != -1) {\n                        bout.write(read, 0, len);\n                        System.out.print(new String(read, \"UTF-8\"));\n                    }\n                    bout.close();\n                    read = null;\n                }\n                entry = tarIn.getNextTarEntry();\n            }\n            tarIn.close();\n\n\n\nHere is the full stack trace: \n\n[2015-02-12T23:17:31.944+0000] [glassfish 4.0] [SEVERE] [] [] [tid: _ThreadID=123 _ThreadName=Thread-4] [timeMillis: 1423783051944] [levelValue: 1000] [[\n  java.io.IOException: Error detected parsing the header\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:257)\n        at org.unavco.ws.tilt.ExtractTiltFile.extractFile(ExtractTiltFile.java:125)\n        at org.unavco.ws.tilt.ExtractTiltFile.run(ExtractTiltFile.java:59)\n        at org.unavco.ws.cache.ProcessDataFile.getFileData(ProcessDataFile.java:100)\n        at org.unavco.ws.cache.ProcessDataFile.getResultSet(ProcessDataFile.java:81)\n        at org.unavco.ws.tilt.TiltDsClient.write(TiltDsClient.java:47)\n        at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:76)\n        at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:58)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:194)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:103)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:88)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1005)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:471)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:333)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:323)\n        at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:227)\n        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)\n        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:315)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:297)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:267)\n        at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)\n        at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:198)\n        at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:946)\n        at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:323)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:372)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:335)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:218)\n        at org.apache.catalina.core.StandardWrapper.service(StandardWrapper.java:1682)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:344)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:214)\n        at com.thetransactioncompany.cors.CORSFilter.doFilter(Unknown Source)\n        at com.thetransactioncompany.cors.CORSFilter.doFilter(Unknown Source)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:256)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:214)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:316)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:160)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:734)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:673)\n        at com.sun.enterprise.web.WebPipeline.invoke(WebPipeline.java:99)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:174)\n        at org.apache.catalina.connector.CoyoteAdapter.doService(CoyoteAdapter.java:357)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:260)\n        at com.sun.enterprise.v3.services.impl.ContainerMapper.service(ContainerMapper.java:188)\n        at org.glassfish.grizzly.http.server.HttpHandler.runService(HttpHandler.java:191)\n        at org.glassfish.grizzly.http.server.HttpHandler.doHandle(HttpHandler.java:168)\n        at org.glassfish.grizzly.http.server.HttpServerFilter.handleRead(HttpServerFilter.java:189)\n        at org.glassfish.grizzly.filterchain.ExecutorResolver$9.execute(ExecutorResolver.java:119)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.executeFilter(DefaultFilterChain.java:288)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.executeChainPart(DefaultFilterChain.java:206)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.execute(DefaultFilterChain.java:136)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.process(DefaultFilterChain.java:114)\n        at org.glassfish.grizzly.ProcessorExecutor.execute(ProcessorExecutor.java:77)\n        at org.glassfish.grizzly.nio.transport.TCPNIOTransport.fireIOEvent(TCPNIOTransport.java:838)\n        at org.glassfish.grizzly.strategies.AbstractIOStrategy.fireIOEvent(AbstractIOStrategy.java:113)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.run0(WorkerThreadIOStrategy.java:115)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.access$100(WorkerThreadIOStrategy.java:55)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy$WorkerThreadRunnable.run(WorkerThreadIOStrategy.java:135)\n        at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:564)\n        at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.run(AbstractThreadPool.java:544)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '05412{NUL}\n11' len=8\n        at org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:138)\n        at org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:169)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:951)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:255)\n        ... 63 more]]\n"
            },
            "32": {
                "commit_sha_buggy": "24a3100e9897837b513a0d9f2ae26fd02ec91246",
                "commit_sha_fixed": "3c4a09bf28e7cd600b919b8c799fbbfd19a94c0b",
                "report_id": "COMPRESS-314",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-314",
                "issue_title": "[COMPRESS-314] TarArchiveInputStream rejects uid or gid >= 0x80000000 - ASF JIRA",
                "issue_description": "\nA POSIX-format archive that came from sysdiagnose produces NumberFormatException[1] when I try to read it with TarArchiveInputStream.\nThe relevant part of the .tar file looks like this:\n   18 uid=429496729\nThat's the uid of 'nobody' on Mac OS (on Mac OS, uid_t is 'unsigned int').\nPOSIX doesn't say anything about the width of the uid extended header[2], so I assume the tar file is okay. GNU tar doesn't have trouble with it.\nThe relevant code, in applyPaxHeadersToCurrentEntry:\n            } else if (\"gid\".equals(key))\n{\n                currEntry.setGroupId(Integer.parseInt(val));\n...\n            }\n else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\nuid_t and gid_t are typically unsigned 32-bit integers, so these should presumably use Long.parseLong to handle integers with the top bit set (and TarArchiveEntry would need some modifications to handle large uid and gid, too).\n[1] java.lang.NumberFormatException: For input string: \"4294967294\"\n        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n        at java.lang.Integer.parseInt(Integer.java:495)\n        at java.lang.Integer.parseInt(Integer.java:527)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.applyPaxHeadersToCurrentEntry(TarArchiveInputStream.java:488)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.paxHeaders(TarArchiveInputStream.java:415)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:295)\n[2] http://pubs.opengroup.org/onlinepubs/9699919799/utilities/pax.html#tag_20_92_13_03\nuid\nThe user ID of the file owner, expressed as a decimal number using digits from the ISO/IEC 646:1991 standard. This record shall override the uid field in the following header block(s). When used in write or copy mode, pax shall include a uid extended header record for each file whose owner ID is greater than 2097151 (octal 7777777).\n"
            },
            "33": {
                "commit_sha_buggy": "9b3e389fc692513cc701b886a9dcdab6ebf32453",
                "commit_sha_fixed": "b72b5c716ac18150396d05988d9eab745bea02b9",
                "report_id": "COMPRESS-316",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-316",
                "issue_title": "[COMPRESS-316] CompressorStreamFactory doesn't handle deflate streams with a zlib header - ASF JIRA",
                "issue_description": "\nIf you take a zlib / deflate compressed file, with the zlib header (eg the test file bla.tar.deflatez) and pass it to CompressorStreamFactory.createCompressorInputStream, it won't be detected and you'll get a CompressorException(\"No Compressor found for the stream signature.\")\nWhile detecting header-less zlib files is probably too tricky to manage, those with the header ought to be possible to spot and handle\n"
            },
            "34": {
                "commit_sha_buggy": "1dcab3f854e6fffa16c842b8a10a6fa2163795ea",
                "commit_sha_fixed": "e6e24766377e705e89358fb9cf6253e2e9e645db",
                "report_id": "COMPRESS-321",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-321",
                "issue_title": "[COMPRESS-321] Exception in X7875_NewUnix.parseFromLocalFileData when parsing 0-sized \"ux\" local entry - ASF JIRA",
                "issue_description": "\nWhen trying to detect content type of a zip file with Tika 1.10 (which uses Commons Compress 1.9 internally) in manner like this:\n\n        byte[] content = ... // whole zip file.\n        String name = \"TR_01.ZIP\";\n        Tika tika = new Tika();\n        return tika.detect(content, name);\n\n\nit throws an exception:\n\njava.lang.ArrayIndexOutOfBoundsException: 13\n\tat org.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromLocalFileData(X7875_NewUnix.java:199)\n\tat org.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromCentralDirectoryData(X7875_NewUnix.java:220)\n\tat org.apache.commons.compress.archivers.zip.ExtraFieldUtils.parse(ExtraFieldUtils.java:174)\n\tat org.apache.commons.compress.archivers.zip.ZipArchiveEntry.setCentralDirectoryExtra(ZipArchiveEntry.java:476)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.readCentralDirectoryEntry(ZipFile.java:575)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.populateFromCentralDirectory(ZipFile.java:492)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:216)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:192)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:153)\n\tat org.apache.tika.parser.pkg.ZipContainerDetector.detectZipFormat(ZipContainerDetector.java:141)\n\tat org.apache.tika.parser.pkg.ZipContainerDetector.detect(ZipContainerDetector.java:88)\n\tat org.apache.tika.detect.CompositeDetector.detect(CompositeDetector.java:77)\n\tat org.apache.tika.Tika.detect(Tika.java:155)\n\tat org.apache.tika.Tika.detect(Tika.java:183)\n\tat org.apache.tika.Tika.detect(Tika.java:223)\n\n\nThe zip file does contain two .jpg images and is not a \"special\" (JAR, Openoffice, ... ) zip file.\nUnfortunately, the contents of the zip file is confidential and so I cannot attach it to this ticket as it is, although I can provide the parameters supplied to\norg.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromLocalFileData(X7875_NewUnix.java:199) as caught by the debugger:\n\ndata = {byte[13]@2103}\n 0 = 85\n 1 = 84\n 2 = 5\n 3 = 0\n 4 = 7\n 5 = -112\n 6 = -108\n 7 = 51\n 8 = 85\n 9 = 117\n 10 = 120\n 11 = 0\n 12 = 0\noffset = 13\nlength = 0\n\n\nThis data comes from the local zip entry for the first file, it seems the method tries to read more bytes than is actually available in the buffer.\nIt seems that first 9 bytes of the buffer are 'UT' extended field with timestamp, followed by 0-sized 'ux' field (bytes 9-12) that is supposed to contain UID/GID - according to infozip's doc the 0-size is common for global dictionary, but the local dictionary should contain complete data. In this case for some reason it does contain 0-sized data.\nNote that 7zip and unzip can unzip the file without even a warning, so Commons Compress should be also able to handle that file correctly without choking on that exception.\n"
            },
            "35": {
                "commit_sha_buggy": "9431b16c58a3fbb320cf13af80cb36430f2aea79",
                "commit_sha_fixed": "7250daa429020181bb5a4c40d1aaa169631b8496",
                "report_id": "COMPRESS-335",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-335",
                "issue_title": "[COMPRESS-335] TAR checksum fails when checksum is right aligned - ASF JIRA",
                "issue_description": "\nThe linked TAR has a checksum with zero padding on the left instead of the expected NULL-SPACE terminator on the right. As a result the last two digits of the stored checksum are lost and the otherwise valid checksum is treated as invalid.\nGiven that the code already checks for digits being in range before adding them to the stored sum, is it necessary to only look at the first 6 octal digits instead of the whole field?\n"
            },
            "36": {
                "commit_sha_buggy": "ff5158b1662ad5a67ae6041afc89c5fbfd5ddb1a",
                "commit_sha_fixed": "d0501577d37b594c3ff59a39ac211f7a1b170fa7",
                "report_id": "COMPRESS-348",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-348",
                "issue_title": "[COMPRESS-348] Calling SevenZFile.read() on empty SevenZArchiveEntry throws IllegalStateException - ASF JIRA",
                "issue_description": "\nI'm pretty sure COMPRESS-340 breaks reading empty archive entries. When calling getNextEntry() and that entry has no content, the code jumps into the first block at line 830 (SevenZFile.class), clearing the deferredBlockStreams. When calling entry.read(...) afterwards an IllegalStateException (\"No current 7z entry (call getNextEntry() first).\") is thrown. IMHO, there should be another check for entry.getSize() == 0.\nThis worked correctly up until 1.10.\n"
            },
            "37": {
                "commit_sha_buggy": "14b3d1ad8c5efc1f21c94e6d0f72635c374b2bb6",
                "commit_sha_fixed": "19a620c904587dc0397b43bfe9071ff60033c097",
                "report_id": "COMPRESS-355",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-355",
                "issue_title": "[COMPRESS-355] Parsing PAX headers fails with NegativeArraySizeException - ASF JIRA",
                "issue_description": "\nThe TarArchiveInputStream.parsePaxHeaders method fails with a NegativeArraySizeException when there is an empty line at the end of the headers.\nThe inner loop starts reading the length, but it gets a newline (10) and ends up subtracting '0' (48) from it; the result is a negative length that blows up an attempt to allocate the rest array.\nI would say that a check to see if ch is less the '0' and break the loop if it is.\nI used npm pack aws-sdk@2.2.16 to generate a tarball with this issue.\n"
            },
            "38": {
                "commit_sha_buggy": "19a620c904587dc0397b43bfe9071ff60033c097",
                "commit_sha_fixed": "823cdee9b18508e9e51913d110a20a406f55582b",
                "report_id": "COMPRESS-356",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-356",
                "issue_title": "[COMPRESS-356] PAX header entry name ending with / causes problems - ASF JIRA",
                "issue_description": "\nThere seems to be a problem when a PAX header entry (link flag is 'x') has a name ending with \"/\". The TarArchiveEntry.isDirectory() check ends up returning true because of the trailing slash which means no content can be read from the entry. PAX header parsing effectively finds nothing and the stream is not advanced; this leaves the stream in a bad state as the next entry's header is actually read from the header contents.\nIf the name is modified to remove the trailing slash when the link flag indicates a PAX header everything seems to work fine. That would be one potential fix in parseTarHeader. Changing isDirectory to return false if isPaxHeader is true (before the trailing \"/\" check) would probably also fix the issue (though I can't verify that in the debugger like I can with changing the name).\nSo far I have only seen this when using Docker to save images that contain a yum database. For example:\n\ndocker pull centos:latest && docker save centos:latest | tar x --include \"*/layer.tar\"\n\n\nWill produce at least one \"layer.tar\" that exhibits this issue. If I come across a smaller TAR for testing I will attach it.\n"
            },
            "39": {
                "commit_sha_buggy": "593339ab62ce5db71fd42501a9ddea9fe698b9ca",
                "commit_sha_fixed": "11840dfde044fec90b0cb4a715ce9d213acea3ca",
                "report_id": "COMPRESS-351",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-351",
                "issue_title": "[COMPRESS-351] Defective .zip-archive produces problematic error message - ASF JIRA",
                "issue_description": "\nA truncated .zip-File produces an java.io.EOFException conatining a hughe amount of byte[]-data in the error-message - leading to beeps and crippeling workload in an potential console-logger.\n"
            },
            "40": {
                "commit_sha_buggy": "32c30f6f072ccfea6ead90f8eef0c205d88d00d3",
                "commit_sha_fixed": "52dd5908e374973d69c51856b74d4d93d591c90a",
                "report_id": "COMPRESS-363",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-363",
                "issue_title": "[COMPRESS-363] Overflow in BitInputStream - ASF JIRA",
                "issue_description": "\nin Class BitInputStream.java(\\src\\main\\java\\org\\apache\\commons\\compress\\utils),\nfuncion:\n public long readBits(final int count) throws IOException {\n        if (count < 0 || count > MAXIMUM_CACHE_SIZE) \n{\n            throw new IllegalArgumentException(\"count must not be negative or greater than \" + MAXIMUM_CACHE_SIZE);\n        }\n        while (bitsCachedSize < count) {\n            final long nextByte = in.read();\n            if (nextByte < 0) \n{\n                return nextByte;\n            }\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) \n{\n                bitsCached |= (nextByte << bitsCachedSize);\n            }\n else \n{\n                bitsCached <<= 8;\n                bitsCached |= nextByte;\n            }\n            bitsCachedSize += 8;\n        }\n        final long bitsOut;\n        if (byteOrder == ByteOrder.LITTLE_ENDIAN) \n{\n            bitsOut = (bitsCached & MASKS[count]);\n            bitsCached >>>= count;\n        }\n else \n{\n            bitsOut = (bitsCached >> (bitsCachedSize - count)) & MASKS[count];\n        }\n        bitsCachedSize -= count;\n        return bitsOut;\n    }\nI think here \"bitsCached |= (nextByte << bitsCachedSize);\" will overflow in some cases. for example, below is a test case:\npublic static void test() {\n        ByteArrayInputStream in = new ByteArrayInputStream(new byte[]\n{87, 45, 66, 15,\n                                                                      90, 29, 88, 61, 33, 74}\n);\n        BitInputStream bin = new BitInputStream(in, ByteOrder.LITTLE_ENDIAN);\n        try \n{\n            long ret = bin.readBits(5);\n            ret = bin.readBits(63);\n            ret = bin.readBits(12);\n        }\n catch (Exception e) \n{\n            e.printStackTrace();\n        }\n}\noverflow occur in \"bin.readBits(63);\" , so ,result in wrong result from  \"bin.readBits(12);\" \n"
            },
            "41": {
                "commit_sha_buggy": "e0c83d24ed5a59911b0ee59a72104410b91a7c0d",
                "commit_sha_fixed": "f015344879f1bc3505bc616fc7ae517cf9f60838",
                "report_id": "COMPRESS-367",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-367",
                "issue_title": "[COMPRESS-367] ZipArchiveInputStream.getNextZipEntry() should differentiate between \"invalid entry encountered\" and \"no more entries\" - ASF JIRA",
                "issue_description": "\nZipArchiveInputStream.getNextZipEntry() currently returns null if an invalid entry is encountered.  Thus, it's not possible to differentiate between \"no more entries\" and \"invalid entry encountered\" conditions.\nInstead, it should throw an exception if an invalid entry is encountered.\nI've created a test case and fix. I will submit a pull request shortly.\n"
            },
            "42": {
                "commit_sha_buggy": "75ba40cd9236761b4b3e49013eb38f754b4e539b",
                "commit_sha_fixed": "c59fc43c527610ae18d7596eb191817ce674cb29",
                "report_id": "COMPRESS-379",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-379",
                "issue_title": "[COMPRESS-379] isUnixSymlink returns true for Zip entries with Unix permissions 177777 - ASF JIRA",
                "issue_description": "\nThis issue was originally reported in MASSEMBLY-842, but it seems the root cause in inside Commons Compress.\nConsider the attached invalid-entry.jar, whose contents, as shown by the zipinfo utility, is:\n\n?rwsrwsrwt  2.0 unx        0 b- stor 17-Jan-15 16:06 META-INF/maven/\ndrwxr-xr-x  2.0 unx        0 b- stor 17-Jan-15 16:06 META-INF/\n\n\nThere are some JAR files created by the Maven Assembly Plugin with content similar to this, and the entry META-INF/maven/ has permissions 177777 (octal). Constructing a ZipFile from this file, the method isUnixSymlink incorrectly returns true for the entry META-INF/maven/ (and it correctly returns false for the entry META-INF/.\nHere is a sample Java code that can be used to see the behaviour:\n\npublic static void main(String[] args) throws IOException {\n    try (ZipFile zipFile = new ZipFile(new File(\"invalid-entry.jar\"))) {\n        printAttributes(zipFile, \"META-INF/\");\n        printAttributes(zipFile, \"META-INF/maven/\");\n    }\n}\n\nprivate static void printAttributes(ZipFile zipFile, String name) {\n    ZipArchiveEntry entry = zipFile.getEntriesInPhysicalOrder(name).iterator().next();\n    System.out.printf(\"%-17s: symlink:%-5s - unixMode:%s%n\", name, entry.isUnixSymlink(), entry.getUnixMode());\n}\n\n\nThis code outputs:\n\nMETA-INF/        : symlink:false - unixMode:16877\nMETA-INF/maven/  : symlink:true  - unixMode:65535\n\n\nThe ?rwsrwsrwt permissions show that the Zip entry is broken in the first place, but I think isUnixSymlink should still return false in that case, and not consider this entry to be a symlink.\nIt seems the fix would be to update isUnixSymlink and check whether the unix mode is equal to SHORT_MASK, and return false in that case as it would indicate a broken entry. This change does not break any existing tests, but I'm not sure if this is the proper fix.\n\npublic boolean isUnixSymlink() {\n    int unixMode = getUnixMode();\n    return unixMode == SHORT_MASK ? false : (unixMode & UnixStat.LINK_FLAG) == UnixStat.LINK_FLAG;\n}\n\n\n"
            },
            "43": {
                "commit_sha_buggy": "12edac73ec454bfbdd634af474e140cca7522774",
                "commit_sha_fixed": "d75b89856ef29bbec6784cd6aa714eafe0eeb312",
                "report_id": "COMPRESS-394",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-394",
                "issue_title": "[COMPRESS-394] [Zip] Local `Version Needed To Extract` does not match Central Directory - ASF JIRA",
                "issue_description": "\nHi,\nThis is followup on an issue reported on Plexus Archiver - https://github.com/codehaus-plexus/plexus-archiver/issues/57\nPlexus Archiver uses ZipArchiveOutputStream to create zip archives. It constructs the ZipArchiveOutputStream using BufferedOutputStream. As a result the output do not provide random access and additional data descriptor records are added. Unfortunately this leads to different values being set for version needed to extract field in the local file header and in the central directory. It looks like that the root cause is the way the local header version needed to extract field value is calculated:\n\n        if (phased &&  !isZip64Required(entry.entry, zip64Mode)){\n            putShort(INITIAL_VERSION, buf, LFH_VERSION_NEEDED_OFFSET);\n        } else {\n            putShort(versionNeededToExtract(zipMethod, hasZip64Extra(ze)), buf, LFH_VERSION_NEEDED_OFFSET);\n        }\n\n\nAs you can see the need for data descriptors is not taken into account. On other hand when the central directory is created the following is used to determine the minimum required version\n\n    private int versionNeededToExtract(final int zipMethod, final boolean zip64) {\n        if (zip64) {\n            return ZIP64_MIN_VERSION;\n        }\n        // requires version 2 as we are going to store length info\n        // in the data descriptor\n        return (isDeflatedToOutputStream(zipMethod)) ?\n                DATA_DESCRIPTOR_MIN_VERSION :\n                INITIAL_VERSION;\n    }\n\n\nAs a side note: I'm not a zip expert by any means so I could be wrong, but my understanding is that if Deflate compression is used then the minimum required version should be 2.0 regardless if data descriptors are used or not.\n"
            },
            "44": {
                "commit_sha_buggy": "b53ead4b43c6c248b1a39f4a1cce7a0c4062285d",
                "commit_sha_fixed": "6f379134ae1807cd404ed6c9579707e5dc6a6df0",
                "report_id": "COMPRESS-412",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-412",
                "issue_title": "[COMPRESS-412] NullPointerException defect in ChecksumCalculatingInputStream#getValue() - ASF JIRA",
                "issue_description": "\nNullPointerException defect in ChecksumCalculatingInputStream#getValue() detected as stated in pull request 33: https://github.com/apache/commons-compress/pull/33\nFurthermore the following test describes the problem:\n\n    @Test(expected = NullPointerException.class) //I assume this behaviour to be a bug or at least a defect.\n    public void testGetValueThrowsNullPointerException() {\n\n        ChecksumCalculatingInputStream checksumCalculatingInputStream = new ChecksumCalculatingInputStream(null,null);\n\n        checksumCalculatingInputStream.getValue();\n\n\n    }\n\n\n"
            },
            "45": {
                "commit_sha_buggy": "137aa57f9291b5f390de740266042587cfede7ce",
                "commit_sha_fixed": "02735ad7e6313515a846bc15bcc89cf254f8161f",
                "report_id": "COMPRESS-411",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-411",
                "issue_title": "[COMPRESS-411] TarUtils.formatLongOctalOrBinaryBytes never uses result of formatLongBinary - ASF JIRA",
                "issue_description": "\nif the length < 9, formatLongBinary is executed, then overwritten by the results of formatBigIntegerBinary. \nIf the results are not ignored, a unit test would fail.\nAlso, do the binary hacks  need to support negative numbers? \n"
            },
            "46": {
                "commit_sha_buggy": "d0595b7121f57f1f49fe7fdc384479dd73ad64f5",
                "commit_sha_fixed": "cd1d329dba95dae161317c123269c24282001a66",
                "report_id": "COMPRESS-416",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-416",
                "issue_title": "[COMPRESS-416] Tests failing under jdk 9 : one reflection issue, one change to ZipEntry related issue - ASF JIRA",
                "issue_description": "\nX5455_ExtendedTimestampTest is failing under JDK 9 , due to what appears to be a bogus value returned from getTime().  It seems like the test failure might be due to the changes introduced for this: \nhttps://bugs.openjdk.java.net/browse/JDK-8073497\nTests were run using intelliJ TestRunner, using the openjdk9 build from the tip of the jdk9 tree (not dev).  I believe that this is at most one commit away from what will be the RC (which was delayed at the last minute due to two issues, one of which was javadoc related, and the other hotspot. \n"
            },
            "47": {
                "commit_sha_buggy": "a12adc3627ae39baecd132906c05484fee40efe8",
                "commit_sha_fixed": "c66db899cb061c79934986f0efa19a50ca33703f",
                "report_id": "COMPRESS-436",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-436",
                "issue_title": "[COMPRESS-436] ZipArchiveInputStream#getNextZipEntry should verify compressed size is known for bzip2, implode etc. - ASF JIRA",
                "issue_description": "\n\n\r\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\r\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\r\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\r\n                current.in = new ExplodingInputStream(\r\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\r\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\r\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\r\n                current.in = new BZip2CompressorInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            }\r\n        }\r\n\n\nnever sets current.in if the compressed size is unknown which probably leads to a NullPointerException in read later. We should fail early with a useful error message instead.\n"
            },
            "48": {
                "commit_sha_buggy": "25b5956702a2d63da57ab2be32c47fff22391ddd",
                "commit_sha_fixed": "124f97c18eb3fc29fd4e03c982905cadac1feb0b",
                "report_id": "COMPRESS-73",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-73",
                "issue_title": "[COMPRESS-73] ZipArchiveInputStream cannot handle some valid files - ASF JIRA",
                "issue_description": "\nSee COMPRESS-62\n"
            },
            "50": {
                "commit_sha_buggy": "ec0f5850f8342c0b1eecb20eca7286a9a4a362e1",
                "commit_sha_fixed": "f4044dd0d86684959764783583f24f2b8baf44b0",
                "report_id": "COMPRESS-212",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-212",
                "issue_title": "[COMPRESS-212] TarArchiveEntry getName() returns wrongly encoded name even when you set encoding to TarArchiveInputStream - ASF JIRA",
                "issue_description": "\nI have two file systems. One is Red Hat Linux, the other is MS Windows.\nI created a *.tgz file in Red Hat Linux and tried to decompress it in MS Windows using Commons Compress.\nThe default system encoding are different. UTF-8 in Red Hat Linux and CP949 in MS Windows.\nIt seems that the file name encoding follows the default encoding even though when I use the following to untar it.\nFileInputStream fis = new FileInputStream(new File(*.tgz));\nTarArchiveInputStream zis = new TarArchiveInputStream(new BufferedInputStream(fis),encodingOfRedHatLinux);\nwhile ((entry = (TarArchiveEntry)zis.getNextEntry()) != null)\n{\nentry.getName(); // filename is not UTF-8 it is encoded in CP949 and so the filename isn't consistent\n}\nBy referring to this\n    /**\n\nConstructor for TarInputStream.\n@param is the input stream to use\n@param encoding name of the encoding to use for file names\n@since Commons Compress 1.4\n     */\n    public TarArchiveInputStream(InputStream is, String encoding) \n{\n        this(is, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);\n    }\n\nencoding should be used for file names.\nBut actually this doesn't seem to work.\n"
            },
            "52": {
                "commit_sha_buggy": "50cd7550e2b6634c42b93a4c321aae900a672db0",
                "commit_sha_fixed": "dd71368488dd8e0fb0bf8f7aabd4f702502d5615",
                "report_id": "COMPRESS-289",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-289",
                "issue_title": "[COMPRESS-289] TarArchiveOutputStream includes timestamp in long link headers - ASF JIRA",
                "issue_description": "\nWhen I create a Tar Archive Entry with a long name, the Long Link Entry contains a default modification date of the current Date.\nThis results in two archives with the same contents having different MD5 checksums.\n"
            },
            "53": {
                "commit_sha_buggy": "d85561d9017d4fb0d4fa0a75ca97d617aaae549b",
                "commit_sha_fixed": "1930eed89459d1ea726762e362143a5aa2ccaeb4",
                "report_id": "COMPRESS-324",
                "report_url": "https://issues.apache.org/jira/browse/COMPRESS-324",
                "issue_title": "[COMPRESS-324] Tar fails to detect fields for LF_GNUTYPE_LONGNAME archive - ASF JIRA",
                "issue_description": "\nTrying to extract a test tar archive with a simple java code. For a particular tar example fails to extract.\n"
            }
        }
    },
    "Csv": {
        "owner_repo": "apache/commons-csv",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0833f45bffd40f44ba6f294d84e9bac8a9ba0a37",
                "commit_sha_fixed": "de1838ea067f3fbc4c7c21b9eeae077c739ecb73",
                "report_id": "CSV-75",
                "report_url": "https://issues.apache.org/jira/browse/CSV-75",
                "issue_title": "[CSV-75] ExtendedBufferReader does not handle EOL consistently - ASF JIRA",
                "issue_description": "\nExtendedBufferReader checks for '\\n' (LF) in the read() methods, incrementing linecount when found.\nHowever, the readLine() method calls BufferedReader.readLine() which treats CR, LF and CRLF equally (and drops them).\nIf the code is to be flexible in what it accepts, the class should also allow for CR alone as a line terminator.\nIt should work if the code increments the line counter for CR, and for LF if the previous character was not CR.\n"
            },
            "2": {
                "commit_sha_buggy": "5744ee8a1698687fe4acc0c269cbbbb1e234b06d",
                "commit_sha_fixed": "a0d975933d6fe9eb5f359088de43508c1d3109bf",
                "report_id": "CSV-96",
                "report_url": "https://issues.apache.org/jira/browse/CSV-96",
                "issue_title": "[CSV-96] CSVRecord does not verify that the length of the header mapping matches the number of values - ASF JIRA",
                "issue_description": "\nCSVRecord does not verify that the size of the header mapping matches the number of values. The following test will produce a ArrayOutOfBoundsException:\n\n@Test\npublic void testInvalidHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.get(\"C\");\n}\n\n\n"
            },
            "3": {
                "commit_sha_buggy": "e31980892ce9873047db98ab8ef1b3259607b988",
                "commit_sha_fixed": "2c6120826245f89fedf2f936ab4a0c3edd8717f3",
                "report_id": "CSV-58",
                "report_url": "https://issues.apache.org/jira/browse/CSV-58",
                "issue_title": "[CSV-58] Unescape handling needs rethinking - ASF JIRA",
                "issue_description": "\nThe current escape parsing converts <esc><char> to plain <char> if the <char> is not one of the special characters to be escaped.\nThis can affect unicode escapes if the <esc> character is backslash.\nOne way round this is to specifically check for <char> == 'u', but it seems wrong to only do this for 'u'.\nAnother solution would be to leave <esc><char> as is unless the <char> is one of the special characters.\nThere are several possible ways to treat unrecognised escapes:\n\ntreat it as if the escape char had not been present (current behaviour)\nleave the escape char as is\nthrow an exception\n\n"
            },
            "4": {
                "commit_sha_buggy": "2b5f84ede12cfadd7946ffb07a56709b8322a02f",
                "commit_sha_fixed": "22601f647f2ce9a05fa4ce20ea356492c670940c",
                "report_id": "CSV-100",
                "report_url": "https://issues.apache.org/jira/browse/CSV-100",
                "issue_title": "[CSV-100] CSVParser: getHeaderMap throws NPE  - ASF JIRA",
                "issue_description": "\ntitle nearly says it all  \nGiven a CSVParser parser, the following line throws an NPE:\n\nMap<String, Integer> header = parser.getHeaderMap();\n\n\nStacktrace: \n\nCaused by: java.lang.NullPointerException\nat java.util.HashMap.<init>(HashMap.java:318)\nat java.util.LinkedHashMap.<init>(LinkedHashMap.java:212)\nat org.apache.commons.csv.CSVParser.getHeaderMap(CSVParser.java:288)\n\n\nhappens if the format doesn't have a headerMap.\nto fix, check if the parser's headerMap is null before trying to create the returned map:\n\npublic Map<String, Integer> getHeaderMap() {\n    return this.headerMap != null ?\n       new LinkedHashMap<String, Integer>(this.headerMap)\n       : null;\n}\n\n\n\n"
            },
            "5": {
                "commit_sha_buggy": "bf8f23c3104a137cb42e13bd69b10321cdf92135",
                "commit_sha_fixed": "73cc5246cf789db8f459e2f539831b6e91bedd26",
                "report_id": "CSV-106",
                "report_url": "https://issues.apache.org/jira/browse/CSV-106",
                "issue_title": "[CSV-106] CSVFormat.format allways append null - ASF JIRA",
                "issue_description": "\nWhen I now call\nCSVFormat.newFormat(';').withSkipHeaderRecord(true).withHeader(\"H1\",\"H2\").format(\"A\",\"B\")\nI get the output A;Bnull\nThe expected output would be \nA;B\n"
            },
            "6": {
                "commit_sha_buggy": "a84668e0eafc96b88fe133cf4225a586986a5255",
                "commit_sha_fixed": "9f03b06a1ec8cb2cb64aec6068d2a6c1f663fbc9",
                "report_id": "CSV-111",
                "report_url": "https://issues.apache.org/jira/browse/CSV-111",
                "issue_title": "[CSV-111] CSVRecord.toMap() fails if row length shorter than header length - ASF JIRA",
                "issue_description": "\nSimilar to CSV-96, if .toMap() is called on a record that has fewer fields than we have header columns we'll get an ArrayOutOfBoundsException.\n\n@Test\npublic void testToMapWhenHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.toMap();\n}\n\n\n"
            },
            "7": {
                "commit_sha_buggy": "c84328e64a226304d277be6164b85351502edd94",
                "commit_sha_fixed": "ce4e72701b1ad4caabc3bd668bd058fff082f2b6",
                "report_id": "CSV-112",
                "report_url": "https://issues.apache.org/jira/browse/CSV-112",
                "issue_title": "[CSV-112] HeaderMap is inconsistent when it is parsed from an input with duplicate columns names - ASF JIRA",
                "issue_description": "\nGiven a parser format for csv files with a header line:\n\nCSVFormat myFormat = CSVFormat.RFC4180.withDelimiter(\",\").withQuoteChar('\"').withQuotePolicy(Quote.MINIMAL)\n\t\t\t\t.withIgnoreSurroundingSpaces(true).withHeader().withSkipHeaderRecord(true);\n\n\nAnd given a file with duplicate header names:\nCol1,Col2,Col2,Col3,Col4\n1,2,3,4,5\n4,5,6,7,8 \nThe HeaderMap returned by the parser misses an entry because of the Column name being used as a key, leading to wrong behavior when we rely on it.\nIf this is not supposed to happen in the file regarding the CSV format, at least this should raise an error. If not we should come up with a more clever way to store and access the headers.\n"
            },
            "8": {
                "commit_sha_buggy": "692a1e362dfab949006d3419d1addbfe12552c73",
                "commit_sha_fixed": "35d101c2adecd51730f88e43941d85d16034886f",
                "report_id": "CSV-114",
                "report_url": "https://issues.apache.org/jira/browse/CSV-114",
                "issue_title": "[CSV-114] CSVFormat constructor should reject a header array with duplicate entries - ASF JIRA",
                "issue_description": "\nCSVFormat currently accepts whatever header String[] is provided.\nIt cannot be used if there are duplicate entries so these should be rejected.\n"
            },
            "9": {
                "commit_sha_buggy": "0331565fbaf33fab24bfd588948e653475e795d9",
                "commit_sha_fixed": "2480dffa6d8343b189c6fb57b88b325c45f0b83f",
                "report_id": "CSV-118",
                "report_url": "https://issues.apache.org/jira/browse/CSV-118",
                "issue_title": "[CSV-118] CSVRecord.toMap() throws NPE on formats with no headers. - ASF JIRA",
                "issue_description": "\nThe method toMap() on CSVRecord throws a NullPointerExcpetion when called on records derived using a format with no headers.\nThe method documentation states a null map should be returned instead.\n"
            },
            "10": {
                "commit_sha_buggy": "65f110ec14b9e7f202bb1a696c4c58560cfca48c",
                "commit_sha_fixed": "1282503fb97d621b4225bd031757adbfada66181",
                "report_id": "CSV-120",
                "report_url": "https://issues.apache.org/jira/browse/CSV-120",
                "issue_title": "[CSV-120] CSVFormat#withHeader doesn't work with CSVPrinter - ASF JIRA",
                "issue_description": "\nIn the current version CSVFormat#withHeader is only used by CSVParser. It would be nice if CSVPrinter also supported it. Ideally, the following line of code\n\nCSVPrinter csvPrinter\n  = CSVFormat.TDF\n    .withHeader(\"x\")\n    .print(Files.newBufferedWriter(Paths.get(\"data.csv\")));\ncsvPrinter.printRecord(42);\ncsvPrinter.close();\n\n\nshould produce\n\nx\n42\n\n\nIf you're alright with the idea of automatically inserting headers, I can attach a patch.\n"
            },
            "11": {
                "commit_sha_buggy": "d3afa156e4ddf8ec76847504988e7979146d9fd6",
                "commit_sha_fixed": "b67524da7fd146634c7112b23e95d1d45c398b82",
                "report_id": "CSV-122",
                "report_url": "https://issues.apache.org/jira/browse/CSV-122",
                "issue_title": "[CSV-122] NullPointerException when empty header string and and null string of \"\" - ASF JIRA",
                "issue_description": "\nWhen setting the format to have a nullString of \"\" and having an empty header value, a nullPointerException is thrown.\n"
            },
            "12": {
                "commit_sha_buggy": "bc504117fceb2c254eea5158a62de54c80a5d81d",
                "commit_sha_fixed": "c81ad0328eefb438cc875b9c9f081be93f9fdcc2",
                "report_id": "CSV-128",
                "report_url": "https://issues.apache.org/jira/browse/CSV-128",
                "issue_title": "[CSV-128] CSVFormat.EXCEL should ignore empty header names - ASF JIRA",
                "issue_description": "\nI have an Excel file with a first row with N column names\nIf there are additional columns that are not labeled, Excel exports empty columns. For example:\nA,B,C,,\na,b,c,d,e\nThis causes an IAE like:\n\njava.lang.IllegalArgumentException: The header contains a duplicate name: \"\" in [A, B, C, , ]\n\tat org.apache.commons.csv.CSVParser.initializeHeader(CSVParser.java:368)\n\tat org.apache.commons.csv.CSVParser.<init>(CSVParser.java:248)\n\tat org.apache.commons.csv.CSVParser.parse(CSVParser.java:206)\n\n\nIt seems like the simplest solution is to ignore empty column names, such that they cannot be addressable and not attempt to index them.\n"
            },
            "13": {
                "commit_sha_buggy": "913e4a8b97fc4ef6a860cd94a996442ec86cc3a9",
                "commit_sha_fixed": "f8b80e83417c3c7eeed1282118f64fa0e85c4787",
                "report_id": "CSV-168",
                "report_url": "https://issues.apache.org/jira/browse/CSV-168",
                "issue_title": "[CSV-168] CsvFormat.nullString should not be escaped - ASF JIRA",
                "issue_description": "\nHello,\nUse case: I'm generating MySQL dump files (text format) - for more details check this - http://dev.mysql.com/doc/refman/5.7/en/select-into.html. \nIssue: The value null is represented as \"\\N\". Also by default the escape char is '\\N'. The CsvPrinter.printAndEscape method will convert this value into \n\n\"\\\\N\"\n\nI suggest to modify the CsvPrinter in order to not escape the nullString value  - it should be written as it is. I can create a pull request if you want.\nI consider it a minor issue because it can be mitigated by making sure that the escape character is not a part of the nullString - however in my case it means that the LOAD commands should be modified accordingly.\n"
            },
            "14": {
                "commit_sha_buggy": "1023690dc284afaf380b0cf3eb74c411e0663465",
                "commit_sha_fixed": "190390bf5dd83d6137ca3045902fcecbeafa3227",
                "report_id": "CSV-171",
                "report_url": "https://issues.apache.org/jira/browse/CSV-171",
                "issue_title": "[CSV-171] Negative numeric values in the first column are always quoted in minimal mode - ASF JIRA",
                "issue_description": "\nNegative Numeric values are always quoted in minimal mode if (and only if) they are in the first column.\ni.e.\nlong,lat,data\n\"-92.222\",43.333,3\nLooking at the code, this is by design but seem to be for an unknown reason.\nFrom v1.2 CSVPrinter line 230:\n// TODO where did this rule come from?\nif (newRecord && (c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\nI propose this rule to either be remove or at a minimum be changed to:\n// TODO where did this rule come from?\nif (newRecord && (c !='-' && c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\n"
            },
            "15": {
                "commit_sha_buggy": "e76c4d809cf2b39a9d7fe831b63e60891fe47f55",
                "commit_sha_fixed": "8b3de71fd99d0fa07cb6a3a35b583bbb170aab66",
                "report_id": "CSV-219",
                "report_url": "https://issues.apache.org/jira/browse/CSV-219",
                "issue_title": "[CSV-219] The behavior of quote char using is not similar as Excel does when the first string contains CJK char(s) - ASF JIRA",
                "issue_description": "\nWhen using CSVFormat.EXCEL to print a CSV file, the behavior of quote char using is not similar as Microsoft Excel does when the first string contains Chinese, Japanese or Korean (CJK) char(s).\ne.g.\nThere are 3 data members in a record, with Japanese chars: \"\u3042\", \"\u3044\", \"\u3046\":\n  Microsoft Excel outputs:\n  \u3042,\u3044,\u3046\n  Apache Common CSV outputs:\n  \"\u3042\",\u3044,\u3046\n"
            },
            "16": {
                "commit_sha_buggy": "33f662b219b439af5134de4553a1bb9485136999",
                "commit_sha_fixed": "f368f64fa7f9acdcc01084f676e8b9c2b86f946e",
                "report_id": "CSV-224",
                "report_url": "https://issues.apache.org/jira/browse/CSV-224",
                "issue_title": "[CSV-224] Some multi-iterator parsing peek sequences incorrectly consume elements - ASF JIRA",
                "issue_description": "\nRepeated calls to CSVParser Iterable return new Iterators that each reference the same underlying parser lexer. Within the scope of a\u00a0single Iterator, row peeking with Iterator.hasNext() works as intended. When row peeking with Iterator.hasNext()\u00a0under circumstances that create a new Iterator, an element is consumed by the iterator which cannot be\u00a0accessed by subsequent, newly created Iterators and Iterator.next()s. Effectively, the record Iterator and the lexer get out of sequence. See snippet below.\nThe \"right thing\" is keeping the Iterator in sequence with the lexer, and since this is reading from a buffer, there seem to me to be only two resolutions:\n\nOne lexer, one Iterator.\nNew Iterators, but peeking with hasNext doesn't advance the lexer.\n\n\u00a0\nIf there's a consensus on one of these, I can put up a PR.\n\u00a0\n\n\r\n\u00a0 @Test\r\n\r\n\u00a0 public void newIteratorSameLexer() throws Exception {\r\n\r\n\r\n\r\n\u00a0 \u00a0 String fiveRows = \"1\\n2\\n3\\n4\\n5\\n\";\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"Enhanced for loop, no peeking:\");\r\n\r\n\u00a0 \u00a0 CSVParser parser =\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 int recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but the lexer isn't reset so we can pick up\r\n\r\n\u00a0 \u00a0 // where we left off.\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, no peeking:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nEnhanced for loop, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but we call hasNext before next, so we queue\r\n\r\n\u00a0 \u00a0 // one element for consumption. This element is discarded by the new iterator, even though the\r\n\r\n\u00a0 \u00a0 // lexer has advanced a row, so we've consumed an element with the peek!\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + parser.iterator().hasNext());\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 4\r\n\r\n\u00a0 \u00a0 // 4 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nIterator while, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 Iterator<CSVRecord> iter = parser.iterator();\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // When we use the same iterator, iterator and lexer are in sequence.\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + iter.hasNext());\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Iterator while, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\u00a0 }\n\n"
            },
            "17": {
                "commit_sha_buggy": "081b070256afe2e817ca42e35aef154b88733f61",
                "commit_sha_fixed": "65883aa4d9478161d7c526c1f6e1d5f2806da93b",
                "report_id": "CSV-145",
                "report_url": "https://issues.apache.org/jira/browse/CSV-145",
                "issue_title": "[CSV-145] CSVFormat.with* methods clear the header comments - ASF JIRA",
                "issue_description": "\nSome of the CSVFormat.with* methods clear the header comments by just passing null to the constructor. Using header comments works only with set at last.\n"
            }
        }
    },
    "Gson": {
        "owner_repo": "google/gson",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "af68d70cd55826fa7149effd7397d64667ca264c",
                "commit_sha_fixed": "8383f5c7fa34ae68323fe2816ef8c1307b5d0f84",
                "report_id": "769",
                "report_url": "https://github.com/google/gson/pull/769",
                "issue_title": "timezones without minutes should be valid according RFC3339",
                "issue_description": "According to RFC, the format is:\n\ntime-numoffset    = (\"+\" / \"-\") time-hour [[\":\"] time-minute]\n\nit fixes #768 \n"
            },
            "2": {
                "commit_sha_buggy": "791236ac79e535146b07a7dd5c85ab168554f5ff",
                "commit_sha_fixed": "44cad04a639b3a53f4205f93acda37b3f7d10871",
                "report_id": "964",
                "report_url": "https://github.com/google/gson/pull/964",
                "issue_title": "Allow deserialization of a Number represented as a String",
                "issue_description": "This works:\r\n```\r\ngson.fromJson(\"\\\"15\\\"\", int.class)\r\n```\r\n\r\nThis doesn't:\r\n```\r\ngson.fromJson(\"\\\"15\\\"\", Number.class)\r\n```\r\n\r\nThis PR makes it so the second case works too."
            },
            "3": {
                "commit_sha_buggy": "7719e73a108c450666613c279bedaed724cd9cc9",
                "commit_sha_fixed": "9e6f2bab20257b6823a5b753739f047d79e9dcbd",
                "report_id": "1013",
                "report_url": "https://github.com/google/gson/issues/1013",
                "issue_title": "Bug when skipping a value while using the JsonTreeReader",
                "issue_description": "When using a `JsonReader` to read a JSON object, `skipValue()` skips the structure successfully.\r\n```Java\r\n@Test\r\npublic void testSkipValue_JsonReader() throws IOException {\r\n  try (JsonReader in = new JsonReader(new StringReader(\"{}\"))) {\r\n    in.skipValue();\r\n  }\r\n}\r\n```\r\nBut when using a `JsonTreeReader` to read a JSON object, `skipValue()` throws a `ArrayIndexOutOfBoundsException`.\r\n```Java\r\n@Test\r\npublic void testSkipValue_JsonTreeReader() throws IOException {\r\n  try (JsonTreeReader in = new JsonTreeReader(new JsonObject())) {\r\n    in.skipValue();\r\n  }\r\n}\r\n```\r\nStacktrace\r\n```\r\njava.lang.ArrayIndexOutOfBoundsException: -1\r\n\tat com.google.gson.internal.bind.JsonTreeReader.skipValue(JsonTreeReader.java:262)\r\n```\r\nThe method `popStack()` is being called on line 261 with a `stackSize` of `1` and afterwards the `stackSize` is `0` and the call on line 262 must result in an `ArrayIndexOutOfBoundsException`."
            },
            "4": {
                "commit_sha_buggy": "41e48f7aa3a686778e95328693b830856538e9e3",
                "commit_sha_fixed": "9a2421997e83ec803c88ea370a2d102052699d3b",
                "report_id": "1069",
                "report_url": "https://github.com/google/gson/pull/1069",
                "issue_title": "negative zero test and fix",
                "issue_description": "For issue #1053 "
            },
            "5": {
                "commit_sha_buggy": "0aaef0fd1bb1b9729543dc40168adfb829eb75a4",
                "commit_sha_fixed": "ada597e69a78b8b99f79f79493cbf51e16045202",
                "report_id": "1093",
                "report_url": "https://github.com/google/gson/pull/1093",
                "issue_title": "value(double) can write NaN and infinite values when lenient, as value(Number) does",
                "issue_description": "Fixes #1090."
            },
            "6": {
                "commit_sha_buggy": "f0aa1118e9ef66ed324f9a63cdfb551cb4e9eca5",
                "commit_sha_fixed": "7a9fd5962dce7f277efa15fcc996606be0733bac",
                "report_id": "1100",
                "report_url": "https://github.com/google/gson/pull/1100",
                "issue_title": "Fixed DefaultDateTypeAdapter nullability issue and JSON primitives contract",
                "issue_description": "Regression in:\r\n\r\n* b8f616c939c652b8540c95fa2b377b8c628ef3ff - Migrate DefaultDateTypeAdapter to streaming adapter (#1070)\r\n\r\nBug reports:\r\n\r\n* #1096 - 2.8.1 can't serialize and deserialize date null (2.8.0 works fine)\r\n* #1098 - Gson 2.8.1 DefaultDateTypeAdapter is not null safe.\r\n* #1095 - serialize date sometimes TreeTypeAdapter, sometimes DefaultDateTypeAdapter?"
            },
            "7": {
                "commit_sha_buggy": "08bbb226f11a1f7f76835f953e700d905e1fab4d",
                "commit_sha_fixed": "b1fb9ca9a1bea5440bc6a5b506ccf67236b08243",
                "report_id": "1107",
                "report_url": "https://github.com/google/gson/issues/1107",
                "issue_title": "Gson deserializes wildcards to LinkedHashMap",
                "issue_description": "This issue is a successor to #1101.\r\n\r\nModels:\r\n```java\r\n// ? extends causes the issue\r\nclass BigClass { Map<String, ? extends List<SmallClass>> inBig; }\r\n\r\nclass SmallClass { String inSmall; }\r\n```\r\n\r\nJson:\r\n```json\r\n{\r\n  \"inBig\": {\r\n    \"key\": [\r\n      { \"inSmall\": \"hello\" }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nGson call:\r\n```java\r\nSmallClass small = new Gson().fromJson(json, BigClass.class).inBig.get(\"inSmall\").get(0);\r\n```\r\n\r\nThis call will fail with a `ClassCastException` exception \u2013\r\n `com.google.gson.internal.LinkedTreeMap cannot be cast to Entry`. If we remove `? extends` then everything works fine."
            },
            "8": {
                "commit_sha_buggy": "d6c8c1e3cf6749258e3f98d2bc03c973385e31a7",
                "commit_sha_fixed": "f2591b666419e06017b2327f7729440c122bf675",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix bugs in getPath() with arrays of objects and arrays of arrays",
                "issue_description": "Fix bugs in getPath() with arrays of objects and arrays of arrays"
            },
            "9": {
                "commit_sha_buggy": "4c2980e6ff798f3209f00292ead5060c402d9774",
                "commit_sha_fixed": "c7cb503cdb093cf7bb78afdfe125dd2255f029ad",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix a bug in integer parsing.",
                "issue_description": "Fix a bug in integer parsing."
            },
            "10": {
                "commit_sha_buggy": "d5ed0716db573e5785e55d140ade5ab9a3062410",
                "commit_sha_fixed": "296d843afd575a75d7959474aad76ac05afa0706",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix type adapter precedence so that last-registered wins (except for tree type hierarchy adapters, which were always last).",
                "issue_description": "Fix type adapter precedence so that last-registered wins (except for tree type hierarchy adapters, which were always last)."
            },
            "11": {
                "commit_sha_buggy": "4413c299ea09c57b94af8647eec901554c2f5c50",
                "commit_sha_fixed": "c6a4f55d1a9b191dbbd958c366091e567191ccab",
                "report_id": "40",
                "report_url": "https://github.com/google/gson/issues/40",
                "issue_title": "Fails to serialize/deserialize a class where a super-class has a type parameter",
                "issue_description": "```\nUnfortunately, shortly after the Gson 1.2 release, I found a bug in the\nTypeVariable support.  Basically, the following class can not be serialized\nor deserialized using Gson:\n\npublic class Foo<T> {\n  private final T someField;\n\n  public Foo(T value) {\n    this.someField = value;\n  }\n\n  public boolean equals(Object o) {\n    if (!(o instanceof Foo)) {\n      return false;\n    } else {\n        return someField.equals(((Foo)o).someField);\n    }\n  }\n}\n\npublic class Bar extends Foo<Integer> {\n  public Bar(Integer i) {\n    super(i);\n  }\n}\n\nGson gson = new Gson();\nBar bar1 = new Bar(1);\nString json = gson.toJson(bar1);   // Fails\nBar bar2 = gson.fromJson(\"{\\\"someField\\\":1\", Bar.class);    // Fails\n\nassertEquals(bar1, bar2);\n\n```\n\nOriginal issue reported on code.google.com by `joel.leitch@gmail.com` on 29 Aug 2008 at 11:53\n- Merged into: #168\n"
            },
            "12": {
                "commit_sha_buggy": "10714ef0427536b679e9677f8417807e4cce017d",
                "commit_sha_fixed": "fe101c10bc3597d8e715a31d94d2cc0cc54b660f",
                "report_id": "719",
                "report_url": "https://github.com/google/gson/pull/719",
                "issue_title": "Fix type hierarchy adapters to do a runtime check.",
                "issue_description": "Otherwise if we have a type hierarchy adapter for Vehicle, and we\nattempt to decode a JSON string as a Car, we get the right exception\nif the JSON string is actually decoded as a Truck.\n"
            },
            "13": {
                "commit_sha_buggy": "9e5f86d10b3b3ff4ba0dfe7ba0722c9e640fcc20",
                "commit_sha_fixed": "64107353a37e623ed1f8fecb4422c24212cf6fe1",
                "report_id": "730",
                "report_url": "https://github.com/google/gson/pull/730",
                "issue_title": "Added support to serialize/deserialize ConcurrentMap and ConcurrentNa\u2026",
                "issue_description": "\u2026vigableMap. This fixes https://github.com/google/gson/issues/624\n"
            },
            "14": {
                "commit_sha_buggy": "64107353a37e623ed1f8fecb4422c24212cf6fe1",
                "commit_sha_fixed": "00cf46cde434d8a9909bc13ead6664acf1b6240f",
                "report_id": "731",
                "report_url": "https://github.com/google/gson/pull/731",
                "issue_title": "Added support for AtomicInteger, AtomicBoolean, AtomicLong and Atomic\u2026",
                "issue_description": "\u2026IntegerArray.\n"
            },
            "15": {
                "commit_sha_buggy": "5e3d4320cf735b4940a63f79eeb586ea549cb1c1",
                "commit_sha_fixed": "e48c780389e62a8ace3a59f52935c8e79cef134c",
                "report_id": "733",
                "report_url": "https://github.com/google/gson/pull/733",
                "issue_title": "Supported Currency and added additional tests for Vector, Stack and Properties.",
                "issue_description": ""
            },
            "16": {
                "commit_sha_buggy": "e48c780389e62a8ace3a59f52935c8e79cef134c",
                "commit_sha_fixed": "b45cd98ea1a3c5d884c3353aa71392d465752db2",
                "report_id": "740",
                "report_url": "https://github.com/google/gson/pull/740",
                "issue_title": "ISO8601 Date deserialization",
                "issue_description": "Added support for all ISO8601 formats, including milliseconds. You already have `UtcDateTypeAdapter` in `gson-extras` project, which was using the code from https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/util/ISO8601Utils.java to parse dates. Therefore I did the same, I created an utils class in gson project with that code and made it used by `DateTypeAdapter` and `DefaultDateTypeAdapter`\n"
            },
            "17": {
                "commit_sha_buggy": "34f400582973ab41e39d942618398e83ff0efbec",
                "commit_sha_fixed": "57b08bbc31421653481762507cc88ee3eb373563",
                "report_id": "772",
                "report_url": "https://github.com/google/gson/pull/772",
                "issue_title": "Add nullsafe option to JsonAdapter annotation",
                "issue_description": ""
            },
            "18": {
                "commit_sha_buggy": "67bd3a2cf6f9c9c6e7f615969b1918f68e03932d",
                "commit_sha_fixed": "dea305503ad8827121e8212248c271f1f2f90048",
                "report_id": "800",
                "report_url": "https://github.com/google/gson/pull/800",
                "issue_title": "Fixed a regression in Gson 2.6 where Gson caused NPE if the TypeAdapt\u2026",
                "issue_description": "\u2026erFactory.create() returned null.\n"
            },
            "19": {
                "commit_sha_buggy": "a02f575797d9295bff8fb92d266b0f9724e42098",
                "commit_sha_fixed": "2b08c88c09d14e0b1a68a982bab0bb18206df76b",
                "report_id": "809",
                "report_url": "https://github.com/google/gson/pull/809",
                "issue_title": "allow unquoted long and integer keys",
                "issue_description": "Fixes a bug in JsonReader.nextInt() and JsonReader.nextLong() whereby PEEKED_UNQUOTED is not handled.  This bug caused failure to deserialize maps with Long or Integer keys when the key is unquoted.\n\nThis fixes issues #604 and #524 \n"
            },
            "20": {
                "commit_sha_buggy": "6f6af8050799bec5321d2c06cd3230daadbb6535",
                "commit_sha_fixed": "0f66f4fac441f7d7d7bc4afc907454f3fe4c0faa",
                "report_id": "829",
                "report_url": "https://github.com/google/gson/pull/829",
                "issue_title": "Check if class can be instantiated based on class modifiers. Fix for #817",
                "issue_description": "If class can't be instantiated throw an unsupported operation exception. On different android devices attempt to instantiate interface or abstract class would crash the VM sometimes with only a segmentation fault message and no other useful logs (Issue #817). Checking for interface or abstract class modifiers before trying to allocate instance and throwing an exception will help debugging.\n"
            },
            "21": {
                "commit_sha_buggy": "5f63fcec98881e16ff950e9d981ce86a2563fb51",
                "commit_sha_fixed": "c24af304077e4a6d1925db7cd35d0cd1ed488d6a",
                "report_id": "871",
                "report_url": "https://github.com/google/gson/pull/871",
                "issue_title": "Implement JSON Path for JsonTreeReader.",
                "issue_description": "Since @swankjesse did the JSON Path for `JsonReader`, please review this for correctness (although it passes your tests!).\n"
            },
            "22": {
                "commit_sha_buggy": "c24af304077e4a6d1925db7cd35d0cd1ed488d6a",
                "commit_sha_fixed": "b2c00a3b02eec48ed621fa7cfec54ac6da4aa48d",
                "report_id": "873",
                "report_url": "https://github.com/google/gson/pull/873",
                "issue_title": "Add support for JsonSerializer/JsonDeserializer in the JsonAdapter annotation",
                "issue_description": ""
            },
            "23": {
                "commit_sha_buggy": "5848096f3e1f36c038f522a3d7d6b9e3b553cf8e",
                "commit_sha_fixed": "a300148003e3a067875b1444e8268b6e0f0e0e02",
                "report_id": "1075",
                "report_url": "https://github.com/google/gson/pull/1075",
                "issue_title": "Fix StackOverflowError on resolving recursive types by collapsing chains of type bounds",
                "issue_description": "As described in Issue #1074, $Gson$Types.resolve() shall collapse chains of super/extends type bounds to avoid StackOverflowError on attempts to serialize objects of such types or just obtain the type adapter.\r\n\r\nThe suggested change fixes StackOverflowError's in a number of issues, including Issue #440 and Issue #603."
            },
            "24": {
                "commit_sha_buggy": "bc1e5c5c991fe6d06a5a0f6b775684ac91d289d3",
                "commit_sha_fixed": "338758a0d3b30d47a31571e2315c3f2b34e9e894",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Ensured that custom deserializer is invoked with actual type returned for field values.\nFixed a bug where a top-level object was constructed with default values even when the custom deserializer tried to set it to null.",
                "issue_description": "Ensured that custom deserializer is invoked with actual type returned for field values.\nFixed a bug where a top-level object was constructed with default values even when the custom deserializer tried to set it to null."
            },
            "25": {
                "commit_sha_buggy": "a595032a902c0758610a1cb38379b5e91a01adbd",
                "commit_sha_fixed": "3d1f7251c1285148481a2cde6d2a8e9bbcaae158",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixed issue 100 by adding support for deserialization of collections of elements that do not implement Comparable.",
                "issue_description": "Fixed issue 100 by adding support for deserialization of collections of elements that do not implement Comparable."
            }
        }
    },
    "JacksonCore": {
        "owner_repo": "FasterXML/jackson-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a9e5c9f99bcc16d734251f682758004a3ecc3a1b",
                "commit_sha_fixed": "b40ac81d4a81736e2b7536b14db4ad070b598d2e",
                "report_id": "98",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/98",
                "issue_title": "NullPointerException thrown when NaN read as BigDecimal",
                "issue_description": "(moved from https://github.com/FasterXML/jackson/issues/4 reported by @jroper)\n\n---\n\nIf `JsonParser.Feature.ALLOW_NON_NUMERIC_NUMBERS` is turned on, then when NaN is encountered, it will be reported as being a float number token. Subsequently invoking getDecimalNumber throws an NPE:\n\n```\nNullPointerException: null (TextBuffer.java:394)\ncom.fasterxml.jackson.core.util.TextBuffer.contentsAsDecimal(TextBuffer.java:394)\ncom.fasterxml.jackson.core.base.ParserBase._parseSlowFloatValue(ParserBase.java:799)\ncom.fasterxml.jackson.core.base.ParserBase._parseNumericValue(ParserBase.java:781)\n com.fasterxml.jackson.core.base.ParserBase.getDecimalValue(ParserBase.java:711)\n```\n\nBy the way, the expected behaviour here I would say would be to throw NumberFormatException, this is what is thrown by the BigDecimal constructor when you pass in Double.NaN or any of the infinity double values.\n\nI'm not sure, but maybe this NPE is also an issue for integers too, and the expected behaviour for them would also be to throw NumberFormatException.\n"
            },
            "2": {
                "commit_sha_buggy": "098ece8564ed5d37f483c3bfb45be897ed8974cd",
                "commit_sha_fixed": "38d6e35d1f1a9b48193804925517500de8efee1f",
                "report_id": "105",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/105",
                "issue_title": "Parser parsers numbers eagerly; does not report error with missing space",
                "issue_description": "(note: moved from https://github.com/FasterXML/jackson-databind/issues/260)\n\n---\n\nIf you give input like:\n\n```\n123true\n```\n\nit will first successfully parse integer 123, and then boolean `true`. This should instead result in a parse exception.\n"
            },
            "3": {
                "commit_sha_buggy": "7ee38785ecdd2f5a56a41302d4482675ce0d7e68",
                "commit_sha_fixed": "911cca0254267decd90a4b6a9c0610549309a451",
                "report_id": "111",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/111",
                "issue_title": "_currInputRowStart isn't initialized in UTF8StreamJsonParser() constructor. The column position will be wrong. ",
                "issue_description": "The UTF8StreamJson Parser constructor allows to specify the start position. But it doesn't set the  \"_currInputRowStart\" as the same value. It is still 0. So when raise the exception, the column calculation (ParserBase.getCurrentLocation() )will be wrong.\n\nint col = _inputPtr - _currInputRowStart + 1; // 1-based\n\npublic UTF8StreamJsonParser(IOContext ctxt, int features, InputStream in,\n            ObjectCodec codec, BytesToNameCanonicalizer sym,\n            byte[] inputBuffer, int start, int end,\n            boolean bufferRecyclable)\n"
            },
            "4": {
                "commit_sha_buggy": "7317dc95b0c9d09b94f37c8ae3a48de8b37729cc",
                "commit_sha_fixed": "3baa7d6742f7460bfb0af8edf48bf1575658109a",
                "report_id": "152",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/152",
                "issue_title": "What is the maximum key length allowed?",
                "issue_description": "I noticed that even in Jackson 2.4, if a JSON key is longer than 262144 bytes, ArrayIndexOutOfBoundsException is thrown from TextBuffer. Below is the stack trace:\n\n```\njava.lang.ArrayIndexOutOfBoundsException\n    at java.lang.System.arraycopy(Native Method)\n    at com.fasterxml.jackson.core.util.TextBuffer.expandCurrentSegment(TextBuffer.java:604)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.addName(UTF8StreamJsonParser.java:2034)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.findName(UTF8StreamJsonParser.java:1928)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.parseLongFieldName(UTF8StreamJsonParser.java:1534)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.parseMediumFieldName(UTF8StreamJsonParser.java:1502)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseFieldName(UTF8StreamJsonParser.java:1437)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:668)\n    ... <below are our code> ...\n```\n\nLooking at TextBuffer.expandCurrentSegment(TextBuffer.java:604), once the length of _currentSegment is increased to MAX_SEGMENT_LEN + 1 (262145) bytes, the newLen will stay at MAX_SEGMENT_LEN, which is smaller than len. Therefore System.arraycopy() will fail.\n\nI understand it is rare to have key larger than 262144 bytes, but it would be nice if\n- Jackson explicitly throw exception stating that key is too long.\n- Document that the maximum key length is 262144 bytes.\n\nOR\n- Update TextBuffer to support super long key.\n\nThanks!\n"
            },
            "5": {
                "commit_sha_buggy": "bfdc2852923f671452c66ddf261c87e7e2e5b497",
                "commit_sha_fixed": "0d9cd9fa434c0070638332b7f2243af0277461eb",
                "report_id": "173",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/173",
                "issue_title": "An exception is thrown for a valid JsonPointer expression",
                "issue_description": "Json-Patch project leader has noted me that there is a bug on JsonPointer implementation and I have decided to investigate.\n\nBasically if you do something like `JsonPointer.compile(\"/1e0\");` it throws a NumberFormatExpcetion which is not true. This is because this piece of code:\n\n``` java\nprivate final static int _parseInt(String str)\n    {\n        final int len = str.length();\n        if (len == 0) {\n            return -1;\n        }\n        for (int i = 0; i < len; ++i) {\n            char c = str.charAt(i++);\n            if (c > '9' || c < '0') {\n                return -1;\n            }\n        }\n        // for now, we'll assume 32-bit indexes are fine\n        return NumberInput.parseInt(str);\n    }\n```\n\nWhen they found a number it interprets the segment as integer but in reality it should be the whole expression. For this reason I think that the condition should be changed to the inverse condition  (if it doesn't found any char then it is a number.\n\nIf you want I can send you a PR as well.\n\nAlex.\n"
            },
            "6": {
                "commit_sha_buggy": "0d9cd9fa434c0070638332b7f2243af0277461eb",
                "commit_sha_fixed": "d99951470163764b3e01a119dab2822e5fd98204",
                "report_id": "176",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/176",
                "issue_title": "`JsonPointer` should not consider \"00\" to be valid index",
                "issue_description": "Although `00` can be parsed as `0` in some cases, it is not a valid JSON number; and is also not legal numeric index for JSON Pointer. As such, `JsonPointer` class should ensure it can only match property name \"00\" and not array index.\n"
            },
            "7": {
                "commit_sha_buggy": "b0ceb4eeb69f20f0e4242736ae3e19ed2b9c5da3",
                "commit_sha_fixed": "5cddffa133e7de41fa9efb5962cf3d0cff9b3e89",
                "report_id": "177",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/177",
                "issue_title": "Add a check so `JsonGenerator.writeString()` won't work if `writeFieldName()` expected.",
                "issue_description": "Looks like calling `writeString()` (and perhaps other scalar write methods) results in writing invalid output, instead of throwing an exception. It should instead fail; in future we may want to consider allowing this as an alias, but at any rate it should not produce invalid output.\n"
            },
            "8": {
                "commit_sha_buggy": "ac6d8e22847c19b2695cbd7d1f418e07a9a3dbb2",
                "commit_sha_fixed": "11f0b4090937b2aa998734aa2bf032ee8c428e84",
                "report_id": "182",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/182",
                "issue_title": "Inconsistent TextBuffer#getTextBuffer behavior",
                "issue_description": "Hi, I'm using 2.4.2. While I'm working on CBORParser, I noticed that CBORParser#getTextCharacters() returns sometimes `null` sometimes `[]` (empty array) when it's parsing empty string `\"\"`.\n\nWhile debugging, I noticed that TextBuffer#getTextBuffer behaves inconsistently.\n\n```\nTextBuffer buffer = new TextBuffer(new BufferRecycler());\nbuffer.resetWithEmpty();\nbuffer.getTextBuffer(); // returns null\nbuffer.contentsAsString(); // returns empty string \"\"\nbuffer.getTextBuffer(); // returns empty array []\n```\n\nI think getTextBuffer should return the same value. Not sure which (`null` or `[]`) is expected though.\n"
            },
            "9": {
                "commit_sha_buggy": "4b041e97686325afb2341ea009eb005e0b42d112",
                "commit_sha_fixed": "698f3a73d4e20594357e10fc7bb5db57bb8f7780",
                "report_id": "188",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/188",
                "issue_title": "`JsonParser.getValueAsString()` should return field name for `JsonToken.FIELD_NAME`, not `null`",
                "issue_description": "(note: offshoot of https://github.com/FasterXML/jackson-databind/issues/745)\n\nAlthough Javadocs do not specify expected behavior for `JsonParser.getValueAsString()`, when current token is `JsonToken.FIELD_NAME`, it makes more sense to return name as-is, instead of null.\nThis will simplify handling of code that requires a String representation; and code that does need to know the difference can use token type if that is relevant.\n\nWhile this can be seen as a fix it is still a minor API change, so it needs to go in 2.6.0, not a 2.5.x patch release.\n"
            },
            "10": {
                "commit_sha_buggy": "a71a00e595f87a8eb4a58778e21cf8dab788eb04",
                "commit_sha_fixed": "c2823b4de28120d86aeba9215f0231d990a8eb47",
                "report_id": "207",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/207",
                "issue_title": "ArrayIndexOutOfBoundsException in com.fasterxml.jackson.core.sym.ByteQuadsCanonicalizer",
                "issue_description": "The following code demonstrates a bug in jackson-core, version 2.6.0, in the hash table implementation of `com.fasterxml.jackson.core.sym.ByteQuadsCanonicalizer`. From a quick glance, it looks to me as if the \"primary hash information area\" `_hashArea` has a spillover area that is not accounted for properly in the `String` array `_names`.\n\n``` java\nimport com.fasterxml.jackson.core.JsonFactory;\nimport com.fasterxml.jackson.core.sym.ByteQuadsCanonicalizer;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.testng.annotations.Test;\n\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Method;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Map;\n\n/**\n * Simple test case for demonstrating bug in class {@link ByteQuadsCanonicalizer}.\n *\n * <p>In some cases, it is possible to work around this bug by disabling the\n * {@link JsonFactory.Feature#CANONICALIZE_FIELD_NAMES} feature. In that case\n * {@link com.fasterxml.jackson.core.json.ByteSourceJsonBootstrapper#constructParser(int, com.fasterxml.jackson.core.ObjectCodec, ByteQuadsCanonicalizer, com.fasterxml.jackson.core.sym.CharsToNameCanonicalizer, int)}\n * creates a {@link com.fasterxml.jackson.core.json.ReaderBasedJsonParser} instead of a\n * {@link com.fasterxml.jackson.core.json.UTF8StreamJsonParser}.\n */\npublic class UTF8ByteStreamTest {\n    private static final int SEED = -523743345;\n\n    private static void injectReproducibleSeed(ObjectMapper objectMapper) throws Exception {\n        JsonFactory jsonFactory = objectMapper.getFactory();\n        // As a workaround, uncomment the following line.\n        // jsonFactory.disable(JsonFactory.Feature.CANONICALIZE_FIELD_NAMES);\n        Field byteSymbolCanonicalizerField = JsonFactory.class.getDeclaredField(\"_byteSymbolCanonicalizer\");\n        byteSymbolCanonicalizerField.setAccessible(true);\n\n        Method factoryMethod = ByteQuadsCanonicalizer.class.getDeclaredMethod(\"createRoot\", int.class);\n        factoryMethod.setAccessible(true);\n        byteSymbolCanonicalizerField.set(jsonFactory, factoryMethod.invoke(null, SEED));\n    }\n\n    @Test\n    public void testRead() throws Exception {\n        ObjectMapper objectMapper = new ObjectMapper();\n        injectReproducibleSeed(objectMapper);\n        StringBuilder stringBuilder = new StringBuilder();\n        stringBuilder.append(\"{\\n\");\n        stringBuilder.append(\"    \\\"expectedGCperPosition\\\": null\");\n        for (int i = 0; i < 60; ++i) {\n            stringBuilder.append(\",\\n    \\\"\").append(i + 1).append(\"\\\": null\");\n        }\n        stringBuilder.append(\"\\n}\");\n        objectMapper.readValue(stringBuilder.toString().getBytes(StandardCharsets.UTF_8), Map.class);\n    }\n}\n```\n"
            },
            "11": {
                "commit_sha_buggy": "7ca3d1cb6f1317863b5b04a1b0a7bac2aee5eefd",
                "commit_sha_fixed": "be4386724ff18232aff492cb9145288df86ea61c",
                "report_id": "216",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/216",
                "issue_title": "ArrayIndexOutOfBoundsException: 128 when repeatedly serializing to a byte array",
                "issue_description": "```\njava.lang.ArrayIndexOutOfBoundsException: 128\n    at com.fasterxml.jackson.core.sym.ByteQuadsCanonicalizer.addName(ByteQuadsCanonicalizer.java:853)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.addName(UTF8StreamJsonParser.java:2340)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.findName(UTF8StreamJsonParser.java:2224)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.parseLongName(UTF8StreamJsonParser.java:1831)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.parseMediumName2(UTF8StreamJsonParser.java:1786)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.parseMediumName(UTF8StreamJsonParser.java:1743)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseName(UTF8StreamJsonParser.java:1678)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:1007)\n    at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringMap(MapDeserializer.java:471)\n    at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:341)\n    at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:26)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3702)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2824)\n    at com.kryptnostic.services.v1.SmokeTests.spamAddIndexPair(SmokeTests.java:605)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n```\n\nRepro: \n\n```\n@Test\npublic void spamTest() {\n        ObjectMapper mapper = new ObjectMapper();\n        Map<ObjectUserKey, ServerIndexPair> ssip = Maps.newConcurrentMap();\n        for ( int i = 0; i < 10000; ++i ) {\n            byte[] indexPairBytes = new byte[ 2080 ];\n            new Random().nextBytes( indexPairBytes );\n            ServerIndexPair sip = new ServerIndexPair( indexPairBytes );\n\n            byte[] s = mapper.writeValueAsBytes( ImmutableMap.of( UUID\n                    .randomUUID().toString(), sip ) );\n            Map<String, ServerIndexPair> metadata = mapper.readValue( s,\n                    new TypeReference<Map<String, ServerIndexPair>>() {} );\n            for ( Entry<String, ServerIndexPair> metadataEntry : metadata.entrySet() ) {\n                ServerIndexPair indexPair = metadataEntry.getValue();\n                ssip.put( new ObjectUserKey( metadataEntry.getKey(), user ),\n                        indexPair );\n            }\n            logger.error( \"Iteration: {}\", i );\n        }\n}\n```\n\n```\npublic class ServerIndexPair {\n    public static final String INDEX_PAIR_FIELD = \"indexPair\";\n    private final byte[]       indexPair;\n\n    @JsonCreator\n    public ServerIndexPair( @JsonProperty( INDEX_PAIR_FIELD ) byte[] indexPair ) {\n        Preconditions.checkState( indexPair.length == 2080, \"Index pair must be 2080 bytes long.\" );\n        this.indexPair = indexPair;\n    }\n\n    @JsonProperty( INDEX_PAIR_FIELD )\n    public byte[] getIndexPair() {\n        return indexPair;\n    }\n}\n```\n\n```\npublic class ObjectUserKey {\n    public static final String SEPARATOR = \":\";\n    private final String       objectId;\n    private final UUID         userKey;\n\n    @JsonCreator\n    public ObjectUserKey(\n            @JsonProperty( Names.ID_FIELD ) String objectId,\n            @JsonProperty( Names.USER_FIELD ) UUID userKey ) {\n        super();\n        this.objectId = objectId;\n        this.userKey = userKey;\n    }\n\n    @JsonProperty( Names.ID_FIELD )\n    public String getObjectId() {\n        return objectId;\n    }\n\n    @JsonProperty( Names.USER_FIELD )\n    public UUID getUserKey() {\n        return userKey;\n    }\n\n    @Override\n    public int hashCode() {\n        final int prime = 31;\n        int result = 1;\n        result = prime * result + ( ( objectId == null ) ? 0 : objectId.hashCode() );\n        return result;\n    }\n\n    @Override\n    public boolean equals( Object obj ) {\n        if ( this == obj ) {\n            return true;\n        }\n        if ( obj == null ) {\n            return false;\n        }\n        if ( !( obj instanceof ObjectUserKey ) ) {\n            return false;\n        }\n        ObjectUserKey other = (ObjectUserKey) obj;\n        if ( objectId == null ) {\n            if ( other.objectId != null ) {\n                return false;\n            }\n        }\n        if ( userKey == null ) {\n            if ( other.userKey != null ) {\n                return false;\n            }\n        }\n        if ( !objectId.equals( other.objectId ) ) {\n            return false;\n        }\n        if ( !userKey.equals( other.userKey ) ) {\n            return false;\n        }\n        return true;\n    }\n\n    @Override\n    public String toString() {\n        return userKey + SEPARATOR + objectId;\n    }\n\n    public static ObjectUserKey fromString( String value ) {\n        int index = value.lastIndexOf( ObjectUserKey.SEPARATOR );\n        Preconditions.checkState( index > -1, \"Separator character \" + SEPARATOR\n                + \" should be present for ObjectUserKey\" );\n        String userKeyString = value.substring( 0, index );\n        String objectIdString = value.substring( index + 1 );\n        UUID userKey = UUID.fromString( userKeyString );\n        return new ObjectUserKey( objectIdString, userKey );\n    }\n\n    public byte[] asBytes() {\n        return this.toString().getBytes();\n    }\n\n}\n```\n"
            },
            "12": {
                "commit_sha_buggy": "8d200d4ac45a37d4fba68064961b0c68d0f076b2",
                "commit_sha_fixed": "fede6c9df74d370f2e728b5c46e14bd570abb83c",
                "report_id": "37",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/37",
                "issue_title": "JsonParser.getTokenLocation() doesn't update after field names.",
                "issue_description": "There's a unit test to repro the issue below.  Basically, when you're on a FIELD_NAME token, if you call getTokenLocation() and then nextToken() and then getTokenLocation() again, you'll get the same location for both calls to getTokenLocation(), even though you've advanced to a new token.\n\nThe issue seems to be the _nextToken logic in ReaderBasedJsonParser and UTF8StreamJsonParser.  When calling nextToken() on a FIELD_NAME, it calls _nextAfterName(), which updates _currToken but doesn't update _tokenInputRow and _tokenInputCol for the new token's location.\n\nI started to try to fix it, but the _nextToken logic is spread across so much code that it looked like it'd be a pretty major surgery.  Not something I'm willing to do at this point. :-)\n\n```\npublic void testTokenLocationAfterFieldName() throws Exception\n{\n    _testTokenLocationAfterFieldName(false);\n    _testTokenLocationAfterFieldName(true);\n}\n\nprivate void _testTokenLocationAfterFieldName(Boolean useStream) throws Exception\n{\n    final String DOC = \"{\\\"name\\\":123}\";\n    JsonFactory jf = new JsonFactory();\n    JsonParser jp = useStream ?\n            jf.createJsonParser(new ByteArrayInputStream(DOC.getBytes(\"UTF-8\")))\n            : jf.createJsonParser(new StringReader(DOC));\n\n    assertEquals(JsonToken.START_OBJECT, jp.nextToken());\n    assertEquals(JsonToken.FIELD_NAME, jp.nextToken());\n    assertEquals(JsonToken.VALUE_NUMBER_INT, jp.nextToken());\n    assertEquals(1, jp.getTokenLocation().getLineNr());\n    assertEquals(9, jp.getTokenLocation().getColumnNr());\n    jp.close();\n}\n```\n"
            },
            "13": {
                "commit_sha_buggy": "350bb8f1d2727defbf75d5de38df694857505688",
                "commit_sha_fixed": "d58d420f116e854bfd7b155cc1aed4e32939e1da",
                "report_id": "246",
                "report_url": "https://github.com/FasterXML/jackson-core/pull/246",
                "issue_title": "Fix UTF8JsonGenerator to allow QUOTE_FIELD_NAMES to be toggled.",
                "issue_description": ""
            },
            "14": {
                "commit_sha_buggy": "383f63242c59628d7bcef15a73eb1c9d44d7fb56",
                "commit_sha_fixed": "3c2c9610b6c76e2b348eb057d0a8268681d573a6",
                "report_id": "255",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/255",
                "issue_title": "Relax ownership checks for buffers not to require increase in size",
                "issue_description": "Checks in `IOContext` expect buffer to either be the same or grow. But it should actually be completely legal to return another buffer with similar size, given that most allocation strategies will eventually converge into maximum allowed block size.\n"
            },
            "15": {
                "commit_sha_buggy": "df96e221d14616b532e45657d584d2fc4b42df03",
                "commit_sha_fixed": "ecf088c391de0deb5a4297e51e9ce960b3924e09",
                "report_id": "209",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/209",
                "issue_title": "Make use of `_allowMultipleMatches` in `FilteringParserDelegate`",
                "issue_description": "Currently, it looks like that the _allowMultipleMatches attribute in FilteringGeneratorDelegate is not utilised (i.e. no value is assigned to this variable). Re. the documentation this attribute offers some useful functionality. So it would be nice, if it could be implemented properly. See https://groups.google.com/d/msg/jackson-user/VzZ94G9hvrs/JGFozl6lCQAJ\n"
            },
            "16": {
                "commit_sha_buggy": "4601785ebbfe44dfdd40f55405cfdab544e58586",
                "commit_sha_fixed": "e052c319eccd6086c28fa5371807d887ebe302cf",
                "report_id": "296",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/296",
                "issue_title": "JsonParserSequence skips a token on a switched Parser.",
                "issue_description": "Having 2 parsers concatenated with `JsonParserSequence.createFlattened(parser1, parser2)`.\n\nIf the second parser is on a token that is not null and should not be skipped, the JsonParserSequence will still skip it. JsonParserSequence's [nextToken()](https://github.com/FasterXML/jackson-core/blob/master/src/main/java/com/fasterxml/jackson/core/util/JsonParserSequence.java#L102) calls nextToken() on the new delegate which may cause that we miss a token.\n\nFor more details : [forum question](http://jackson-users.ning.com/forum/topics/jsonparsersequence-behaviour-seems-misleading)\n\nI'll open a PR for this.\nThanks.\n"
            },
            "17": {
                "commit_sha_buggy": "d32c85f8081f96d0cccbc9193407601fec95d406",
                "commit_sha_fixed": "554f8db0f940b2a53f974852a2af194739d65200",
                "report_id": "307",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/307",
                "issue_title": "JsonGenerationException: Split surrogate on writeRaw() input thrown for input of a certain size",
                "issue_description": "In short, I am seeing the following exception while processing text that includes valid multi-byte Unicode characters, and adding or removing characters before the \"problematic\" characters can affect whether the exception is thrown.\n\n`$ java -classpath .:../../jackson-core/target/jackson-core-2.8.2-SNAPSHOT.jar BadMsg\ncom.fasterxml.jackson.core.JsonGenerationException: Split surrogate on writeRaw() input (last character)\n    at com.fasterxml.jackson.core.JsonGenerator._reportError(JsonGenerator.java:1887)\n    at com.fasterxml.jackson.core.json.UTF8JsonGenerator._outputRawMultiByteChar(UTF8JsonGenerator.java:1916)\n    at com.fasterxml.jackson.core.json.UTF8JsonGenerator._writeSegmentedRaw(UTF8JsonGenerator.java:697)\n    at com.fasterxml.jackson.core.json.UTF8JsonGenerator.writeRaw(UTF8JsonGenerator.java:611)\n    at com.fasterxml.jackson.core.json.UTF8JsonGenerator.writeRaw(UTF8JsonGenerator.java:560)\n    at com.fasterxml.jackson.core.base.GeneratorBase.writeRawValue(GeneratorBase.java:306)\n    at BadMsg.main(BadMsg.java:17)\n`\n\nThe simplest way to demonstrate this is code, so I will attach a sample program with a document that causes the error. Sorry for the ugly redacted text, but you can imagine some real words and other interesting strings in place of all the x's. Note that if I delete or add enough of the 'x' characters (doesn't matter where in the JSON they appear, as long as it's before the character that causes the exception) the exception will not be thrown. I believe the problem is in buffering the data that is passed to the lower level functions, but I have not debugged to that level.\n"
            },
            "18": {
                "commit_sha_buggy": "956e0ce3e982947385a71f3e64748a2a6404cb4f",
                "commit_sha_fixed": "96642978dcf1b69cba68ec72cb2f652d59a8b5be",
                "report_id": "315",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/315",
                "issue_title": "`OutOfMemoryError` when writing BigDecimal",
                "issue_description": "(note: moved from https://github.com/FasterXML/jackson-databind/issues/1316 reported by @gmethvin)\n\nWhen I've enabled the `WRITE_BIGDECIMAL_AS_PLAIN` setting on Jackson 2.7.5, Jackson will attempt to write out the whole number, no matter how large the exponent.\n\nFor example, the following code:\n\n``` java\nObjectMapper mapper = new ObjectMapper().enable(JsonGenerator.Feature.WRITE_BIGDECIMAL_AS_PLAIN);\nmapper.writeValueAsString(new java.math.BigDecimal(\"9.223372E+1010671858\"));\n```\n\ntriggers the exception:\n\n```\njava.lang.OutOfMemoryError: Java heap space\n  at java.lang.AbstractStringBuilder.<init>(AbstractStringBuilder.java:68)\n  at java.lang.StringBuilder.<init>(StringBuilder.java:101)\n  at java.math.BigDecimal.toPlainString(BigDecimal.java:2964)\n  at com.fasterxml.jackson.core.json.WriterBasedJsonGenerator.writeNumber(WriterBasedJsonGenerator.java:690)\n  at com.fasterxml.jackson.databind.ser.std.NumberSerializer.serialize(NumberSerializer.java:45)\n  at com.fasterxml.jackson.databind.ser.std.NumberSerializer.serialize(NumberSerializer.java:19)\n  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:130)\n  at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3612)\n  at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2980)\n  ... 23 elided\n```\n\nI know technically Jackson is doing what you're telling it to do (so if you don't feel this is an issue feel free to close it). But it would be nice if `WRITE_BIGDECIMAL_AS_PLAIN` set a reasonable length on the number, so as not to leave users open to denial of service vulnerabilities.\n\n(Actually, I think this might technically be an issue in jackson-core; let me know if I should resubmit.)\n"
            },
            "19": {
                "commit_sha_buggy": "930edea65e6382c0158876ad773ab1d87f67e5dd",
                "commit_sha_fixed": "345cad5b2f4c06a1bcc6794311a31226e9f2bce7",
                "report_id": "317",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/317",
                "issue_title": "ArrayIndexOutOfBoundsException: 200 on floating point number with exactly 200-length decimal part",
                "issue_description": "Very similar issue to #160 and #157 \nWith `jackson-core 2.8.1` when attempting to parse fractional number that has exactly 200 numbers in the decimal part and some random fractional part then java.lang.ArrayIndexOutOfBoundsException: 200 is thrown.\n\n```\npublic class Test {\n    public static void main(String[] args) throws IOException {\n        StringBuilder input = new StringBuilder();\n        for (int i = 1; i < 201; i++) {\n            input.append(1);\n        }\n        input.append(\".0\");\n\n        JsonFactory factory = new JsonFactory();\n\n        JsonParser parser =\n                factory.createParser(new ByteArrayInputStream(input.toString().getBytes(Charset.forName(\"UTF-8\"))));\n        parser.nextToken();\n    }\n}\n```\n\nProduces:\n`Exception in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 200\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseFloat(UTF8StreamJsonParser.java:1576)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parseNumber2(UTF8StreamJsonParser.java:1509)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._parsePosNumber(UTF8StreamJsonParser.java:1410)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:876)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:772)`\n"
            },
            "20": {
                "commit_sha_buggy": "1a5c3655e2b1646c2b68bb40c99f7a7e62fa958a",
                "commit_sha_fixed": "fa64390b1bd5f1435daa9d2b17a58594cfb22817",
                "report_id": "318",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/318",
                "issue_title": "Add support for writing `byte[]` via `JsonGenerator.writeEmbeddedObject()`",
                "issue_description": "(note: should be safe for patch, that is, 2.8.3)\n\nDefault implementation of 2.8-added `writeEmbeddedObject()` throws exception (unsupported operation) for all values, since JSON does not have any native object types.\nThis is different from handling of `writeObject()`, which tries to either delegate to `ObjectCodec` (if one registered), or even encode \"simple\" values.\n\nHowever: since support for binary data is already handled in some cases using `VALUE_EMBEDDED_OBJECT`, it would actually make sense to handle case of `byte[]` (and, if feasible, perhaps `ByteBuffer` for extra points), and also ensure `null` can be written.\n\nThis is likely necessary to support https://github.com/FasterXML/jackson-databind/issues/1361 and should in general make system more robust.\n"
            },
            "21": {
                "commit_sha_buggy": "8296172c76c43edfb9831eac7fc012e4a32806ad",
                "commit_sha_fixed": "96faf2ecd985dfc838e2bf6f6ae4d9d4b310861b",
                "report_id": "330",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/330",
                "issue_title": "`FilteringParserDelegate` seems to miss last closing `END_OBJECT`",
                "issue_description": "(note: adding a failing test for this case)\r\n\r\nLooks like with settings like:\r\n\r\n```java\r\n        JsonParser p = new FilteringParserDelegate(p0,\r\n               new NameMatchFilter(\"value\"),\r\n                   true, // includePath\r\n                   false // multipleMatches\r\n                );\r\n```\r\n\r\nand input\r\n\r\n```json\r\n{\r\n  \"a\":123,\r\n  \"array\":[1,2],\r\n  \"ob\": {\r\n    \"value0\":2,\r\n    \"value\":3,\r\n    \"value2\":4\r\n  },\r\n  \"b\":true\r\n}\r\n```\r\n\r\noutput will be like:\r\n\r\n```json\r\n{\"ob\":{\"value\":3}\r\n```\r\n\r\n(note the missing trailing `}` for closing `END_OBJECT`)\r\n\r\n"
            },
            "22": {
                "commit_sha_buggy": "74564bfb7ca768067b5554dc7c4373f43b8be94b",
                "commit_sha_fixed": "6feec20c842586056aa5b19c402b26be08c88ca3",
                "report_id": "208",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/208",
                "issue_title": "Make use of `_matchCount` in `FilteringParserDelegate`",
                "issue_description": "Currently, it looks like that the _matchCount attribute in FilteringGeneratorDelegate is not utilised (i.e. no value is assigned to this variable). Re. the documentation this attribute offers some useful functionality. So it would be nice, if it could be implemented properly. See https://groups.google.com/d/msg/jackson-user/VzZ94G9hvrs/JGFozl6lCQAJ\n"
            },
            "23": {
                "commit_sha_buggy": "dc5c82e4af87577ac1b540b3f7e9279159185278",
                "commit_sha_fixed": "157f2c490003c7494af8ecb7d57880cda1fde736",
                "report_id": "502",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/502",
                "issue_title": "Make `DefaultPrettyPrinter.createInstance()` to fail for sub-classes",
                "issue_description": "Pattern of \"blueprint object\" (that is, having an instance not used as-is, but that has factory method for creating actual instance) is used by Jackson in couple of places; often for things that implement `Instantiatable`. But one problem is that unless method is left abstract, sub-classing can be problematic -- if sub-class does not override method, then calls will result in an instance of wrong type being created.\r\n\r\nAnd this is what can easily happen with `DefaultPrettyPrinter`.\r\n\r\nA simple solution is for base class to make explicit that if base implementation is called, then instance can not be a sub-class (that is, it is only legal to call on `DefaultPrettyPrinter`, but no sub-class). This is not optimal (ideally check would be done compile-time), but better than getting a mysterious failure.\r\n\r\n\r\n"
            },
            "24": {
                "commit_sha_buggy": "35f3ab4d0512edc2d1ce13a7f43cd75b3c63c797",
                "commit_sha_fixed": "c4dd84e4d505baa90d8d1675c1f60f8d6ce90db8",
                "report_id": "508",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/508",
                "issue_title": "Add new exception type `InputCoercionException` to be used for failed coercions like overflow for `int`",
                "issue_description": "Currently problems like overflow for numeric type (when JSON number value exceeds range of requested target type like `int`) simply use `JsonParseException` to indicate the problem (both at streaming and databind level).\r\n\r\nBut it would be better if we could use more targeted exception, to let calling application potentially handle problems differently. We can also add some metadata about type of failure, such as initial token type and expected target type.\r\nIt is also true that coercion failures -- where we start from valid JSON value, but fail to convert into desired target type -- are not parse (decode) problems at all, but rather mismatch problems.\r\n\r\nSo let's add something like `InputCoercionException`, which extends `JsonProcessingException`, but not `JsonParseException`.\r\n\r\nWith 3.x we may want to tackle other problems: for example, lack of context for \"lower level\" `JsonProcessingException`s (compared to `JsonMappingException`)\r\n\r\n\r\n"
            },
            "25": {
                "commit_sha_buggy": "3d3dedc656e331ab1a9e28efcde96bf71c347daa",
                "commit_sha_fixed": "ad47c206f4fbf22f439f3d66871757891f549f6a",
                "report_id": "510",
                "report_url": "https://github.com/FasterXML/jackson-core/pull/510",
                "issue_title": "Fix ArrayIndexOutofBoundsException found by LGTM.com",
                "issue_description": "Seen on LGTM.com [here](https://lgtm.com/projects/g/FasterXML/jackson-core/alerts/?mode=tree)\r\n\r\nAs `codes.length == maxCode` so if `i == maxCode` an `ArrayIndexOutOfBoundsException` is thrown. This happens when `ALLOW_UNQUOTED_FIELD_NAMES` is enabled and character `256` is found as part of a field name after needing to consume more data from the reader.\r\n\r\nA gist containing code to trigger this path can be found [here](https://gist.github.com/aeyerstaylor/90128cca75e69303254a0d5a5dbe6762). I could find any tests for this class but if there is a place to add tests I can add the example as a test.\r\n\r\n_(Full disclosure: I'm part of the company behind LGTM.com)_"
            },
            "26": {
                "commit_sha_buggy": "eb477b85f74a2a1250ba6294cf4086d496830e27",
                "commit_sha_fixed": "d83ce8aec99f4e99afdf8fd172d77ce771f8ea35",
                "report_id": "531",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/531",
                "issue_title": "Non-blocking parser reports incorrect locations when fed with non-zero offset",
                "issue_description": "When feeding a non-blocking parser, the input array offset leaks into the offsets reported by `getCurrentLocation()` and `getTokenLocation()`.\r\n\r\nFor example, feeding with an offset of 7 yields tokens whose reported locations are 7 greater than they should be. Likewise the current location reported by the parser is 7 greater than the correct location.\r\n\r\nIt's not possible for a user to work around this issue by subtracting 7 from the reported locations, because the token location may have been established by an earlier feeding with a different offset.\r\n\r\nJackson version: 2.9.8\r\n\r\nUnit test:\r\n```java\r\nimport com.fasterxml.jackson.core.JsonFactory;\r\nimport com.fasterxml.jackson.core.JsonParser;\r\nimport com.fasterxml.jackson.core.JsonToken;\r\nimport com.fasterxml.jackson.core.async.ByteArrayFeeder;\r\nimport org.junit.Test;\r\n\r\nimport static java.nio.charset.StandardCharsets.UTF_8;\r\nimport static org.junit.Assert.assertEquals;\r\n\r\npublic class FeedingOffsetTest {\r\n\r\n  @Test\r\n  public void inputOffsetShouldNotAffectLocations() throws Exception {\r\n    JsonFactory jsonFactory = new JsonFactory();\r\n    JsonParser parser = jsonFactory.createNonBlockingByteArrayParser();\r\n    ByteArrayFeeder feeder = (ByteArrayFeeder) parser.getNonBlockingInputFeeder();\r\n\r\n    byte[] input = \"[[[\".getBytes(UTF_8);\r\n\r\n    feeder.feedInput(input, 2, 3);\r\n    assertEquals(JsonToken.START_ARRAY, parser.nextToken());\r\n    assertEquals(1, parser.getCurrentLocation().getByteOffset()); // ACTUAL = 3\r\n    assertEquals(1, parser.getTokenLocation().getByteOffset());   // ACTUAL = 3\r\n\r\n    feeder.feedInput(input, 0, 1);\r\n    assertEquals(JsonToken.START_ARRAY, parser.nextToken());\r\n    assertEquals(2, parser.getCurrentLocation().getByteOffset());\r\n    assertEquals(2, parser.getTokenLocation().getByteOffset());\r\n  }\r\n}\r\n```"
            },
            "28": {
                "commit_sha_buggy": "6f496e7a104700250ad0fa567c7338618f797438",
                "commit_sha_fixed": "cfeaed0a935b3901c1fbccaf979efbac4a819d6d",
                "report_id": "213",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/213",
                "issue_title": "Parser is sometimes wrong when using CANONICALIZE_FIELD_NAMES",
                "issue_description": "If you have a big dictionary (150 000 keys), it will randomly swap one of the field names with another. We traced it down to CANONICALIZE_FIELD_NAMES (if disabled, it doesn't happen).\n\nOut of 1000 parsings of a file with 150 000 keys, around 50 (5 %) will have a single key swapped. I guess if you try with more keys it will fail more often.\n\nOur keys are randomly generated `/[0-9A-Za-z]{17}/`\n"
            },
            "29": {
                "commit_sha_buggy": "bec821b8eadc8130240f942242f1d56f450de24f",
                "commit_sha_fixed": "bf550f3165e37029966b46d8514753a770cdeec2",
                "report_id": "460",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/460",
                "issue_title": "Failing to link `ObjectCodec` with `JsonFactory` copy constructor",
                "issue_description": "(note: came from https://github.com/FasterXML/jackson-databind/issues/2038)\r\n\r\nLooks like the copy constructor of `JsonFactory` is just ignoring passed-in `codec`, instead of assigning.\r\nThis makes JDK serialize/deserialized mappers and associate `JsonFactory` lose linkage.\r\n"
            },
            "30": {
                "commit_sha_buggy": "bf550f3165e37029966b46d8514753a770cdeec2",
                "commit_sha_fixed": "233640bc97d4afe32d34ad2f335098045835cef9",
                "report_id": "516",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/516",
                "issue_title": "_inputPtr off-by-one in UTF8StreamJsonParser._parseNumber2()",
                "issue_description": "When an input contains space separated root level values, and the input is split such that `_parseNumber2()` is invoked, `_inputPtr` will become incremented once in the method\r\n```\r\n        // As per #105, need separating space between root values; check here\r\n        if (_parsingContext.inRoot()) {\r\n            _verifyRootSpace(_inputBuffer[_inputPtr++] & 0xFF);\r\n        }\r\n```\r\nand once in `_verifyRootSpace()`:\r\n```\r\n        // caller had pushed it back, before calling; reset\r\n        ++_inputPtr;\r\n```\r\ncausing the next token to lose its first character.\r\n\r\nRelated to #105.\r\n\r\nFailing test case:\r\n```java\r\npackage test;\r\n\r\nimport com.fasterxml.jackson.core.JsonFactory;\r\nimport com.fasterxml.jackson.core.JsonParser;\r\nimport org.junit.Test;\r\n\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.util.stream.Stream;\r\n\r\nimport static java.nio.charset.StandardCharsets.UTF_8;\r\nimport static org.junit.Assert.assertEquals;\r\nimport static org.junit.Assert.assertTrue;\r\n\r\npublic class JacksonIssue {\r\n    @Test\r\n    public void failingRootLevelParsing() throws IOException {\r\n        // InputStream that forces _parseNumber2 to be invoked.\r\n        InputStream is = TestInputStream.fromStrings(\"1234\", \"5 true\");\r\n\r\n        JsonFactory jsonFactory = new JsonFactory();\r\n        JsonParser parser = jsonFactory.createParser(is);\r\n\r\n        // Works!\r\n        assertEquals(12345, parser.nextIntValue(0));\r\n\r\n        // Fails with com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'rue': was expecting ('true', 'false' or 'null')\r\n        assertTrue(parser.nextBooleanValue());\r\n\r\n    }\r\n\r\n    static class TestInputStream extends InputStream {\r\n        private final byte[][] reads;\r\n        private int currentRead;\r\n\r\n        public static TestInputStream fromStrings(String ... strings) {\r\n            byte[][] reads = Stream.of(strings)\r\n                    .map(s -> s.getBytes(UTF_8))\r\n                    .toArray(byte[][]::new);\r\n            return new TestInputStream(reads);\r\n        }\r\n\r\n        public TestInputStream(byte[][] reads) {\r\n            this.reads = reads;\r\n            this.currentRead = 0;\r\n        }\r\n\r\n        @Override\r\n        public int read() throws IOException {\r\n            throw new UnsupportedOperationException();\r\n        }\r\n\r\n        @Override\r\n        public int read(byte[] b, int off, int len) throws IOException {\r\n            if (currentRead >= reads.length) {\r\n                return -1;\r\n            }\r\n            byte[] bytes = reads[currentRead++];\r\n            if (len < bytes.length) {\r\n                throw new IllegalArgumentException();\r\n            }\r\n            System.arraycopy(bytes, 0, b, off, bytes.length);\r\n            return bytes.length;\r\n        }\r\n    }\r\n}\r\n```"
            },
            "31": {
                "commit_sha_buggy": "26894d0dcf9317aff005797bf58e1ee05809366e",
                "commit_sha_fixed": "ad28e352b60c5b50e13b7535fe003aa1afc7d1a6",
                "report_id": "77",
                "report_url": "https://github.com/FasterXML/jackson-core/issues/77",
                "issue_title": "Improve error message for unexpected input",
                "issue_description": "I am invoking\n\n`GetDepartments entity = response.getEntity(GetDepartments.class);` in Jersey which is invoking Jackson which throws the following exception:\n\n```\ncom.sun.jersey.api.client.ClientHandlerException: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('C' (code 67)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')\n at [Source: java.io.ByteArrayInputStream@3f6c9dec; line: 1, column: 2]\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:575)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:517)\n    at com.foo.client.resource.CompanyToDepartmentsResource.get(CompanyToDepartmentsResource.java:53)\n    at com.foo.web.resource.DepartmentTest.removeDepartmentByCascade(DepartmentTest.java:246)\nCaused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('C' (code 67)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')\n at [Source: java.io.ByteArrayInputStream@3f6c9dec; line: 1, column: 2]\n    at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1369)\n    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:599)\n    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:520)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2267)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:779)\n    at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:665)\n    at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:533)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:565)\n    ... 37 more\n```\n\nThe entity being parsed is `Company not found: http://localhost:9998/companies/1/`. I am expecting Jackson to tell me the actual entity value in addition to what it was expecting.\n\nSo instead of `Unexpected character ('C' (code 67)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')` I expect `Unexpected character ('C' (code 67)): expected a valid value (number, String, array, object, 'true', 'false' or 'null'). Got: Company not found: http://localhost:9998/companies/1/` or something along those lines.\n"
            }
        }
    },
    "JacksonDatabind": {
        "owner_repo": "FasterXML/jackson-databind",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a1bb6f2dcb82eb9f880f87c480d6086a8e0bee34",
                "commit_sha_fixed": "88f44d87d4c2251d7cf55d9aa9c3452a397ae19b",
                "report_id": "223",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/223",
                "issue_title": "NULL values are duplicated when serializing as array [via @JsonFormat(shape = JsonFormat.Shape.ARRAY)]",
                "issue_description": "Example:\n\n``` java\npublic class TestOuter {\n\n    @JsonFormat(shape = JsonFormat.Shape.ARRAY)\n    public ArrayList<TestInner> array;\n\n    public TestOuter() {\n        this.array = new ArrayList<TestInner>();\n        this.array.add(new TestInner(1, \"one\"));\n        this.array.add(new TestInner(0, null));\n    }\n\n    private class TestInner {\n        public int i;\n        public String mayBeNull;\n\n        public TestInner(int i, String s) {\n            this.i = i;\n            this.mayBeNull = s;\n        }\n    }\n}\n```\n\nSerializing an instance of TestOuter will produce the following incorrect result (as of Jackson 2.2.1):\n\n``` json\n\"array\": [[1, \"one\"], [0, null, null]]\n```\n\nwhere the null value is duplicated. The expected result would be:\n\n``` json\n\"array\": [[1, \"one\"], [0, null]]\n```\n\nI tracked the issue down to:\n\n``` java\npackage com.fasterxml.jackson.databind.ser;\n// ...\npublic class BeanPropertyWriter {\n// ...\n    public void serializeAsColumn(Object bean, JsonGenerator jgen, SerializerProvider prov)\n        throws Exception\n    {\n        Object value = get(bean);\n        if (value == null) { // nulls need specialized handling\n            if (_nullSerializer != null) {\n                _nullSerializer.serialize(null, jgen, prov);\n            } else { // can NOT suppress entries in tabular output\n                jgen.writeNull();\n            }\n        }\n        // otherwise find serializer to use\n        JsonSerializer<Object> ser = _serializer;\n    // ... ...\n```\n\nwhere I suspect there is a missing \"return\", to exit the function once handling of the null value in the dedicated branch is done.\nAs it is now, a null value is first serialized in the dedicated branch (jgen.writeNull()), and then execution continues on the \"normal\" (non-null) path and eventually the value is serialized once again.\n"
            },
            "2": {
                "commit_sha_buggy": "01797b0794ac384f5f5ef49cc0cfab8347ae7930",
                "commit_sha_fixed": "9c5fec2302237ede0e797c13c0663a6bb52c798c",
                "report_id": "467",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/467",
                "issue_title": "Unwanted POJO's embedded in tree via serialization to tree",
                "issue_description": "I have a class, more or less:\n\n```\n   class X<T> {\n       String s;\n       List<T> items;\n  };\n```\n\nIt has a custom serializer.\n\nWhen I serialize to a tree, the entire list ends up as a\nVALUE_EMBEDDED_OBJECT: the ArrayList itself.\n\nHere's the serializer class, note the use of writeObjectField.\n\n```\npublic class ListAttributeSerializer extends JsonSerializer<ListAttribute> {\n    @Override\n    public void serialize(ListAttribute value, JsonGenerator jgen,\nSerializerProvider provider) throws IOException {\n        jgen.writeStartObject();\n        jgen.writeStringField(\"itemType\", value.getItemJsonKey());\n        jgen.writeObjectField(\"items\", value.getItems());\n        jgen.writeEndObject();\n    }\n\n    @Override\n    public void serializeWithType(ListAttribute value, JsonGenerator\njgen, SerializerProvider provider, TypeSerializer typeSer) throws\nIOException {\n        typeSer.writeTypePrefixForObject(value, jgen);\n        jgen.writeStringField(\"itemType\", value.getItemJsonKey());\n        jgen.writeObjectField(\"items\", value.getItems());\n        typeSer.writeTypeSuffixForObject(value, jgen);\n}\n}\n```\n\nAnd Tatu wrote me:\n\nOk. valueToTree() uses TokenBuffer as target, so it probably then simply retains Object passed as-is, to defer conversion/serialization, for common use case of buffering. But in your case you would rather get actual serialization into JsonNodes.\n\nYou will probably want to write conversion out then, something like:\n\nbyte[] json = mapper.writeValueAsBytes(referenceText);\nJsonNode tree = mapper.readTree(json);\n\nThis is just the work-around on short term.\nBut this is one thing where configurability might be needed; or possibly different methods. One that forces full serialization into JSON with no POJONodes, other that leaves things as is.\n"
            },
            "3": {
                "commit_sha_buggy": "fd9b65dc45657bb7cd236df5396b901f36469c76",
                "commit_sha_fixed": "fa1d99255915f21c868f28307fd6e3adb2029ea0",
                "report_id": "479",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/479",
                "issue_title": "Regression updating from 2.3.3 to 2.4.0: `null` won't deserialize in `String[]`",
                "issue_description": "Steps to reproduce\n1. Clone the repository at https://github.com/huxi/sulky\n2. Execute the contained `./gradlew` or `gradlew.bat`\n3. Clone the repository at https://github.com/huxi/lilith/\n4. Change jackson-version [in the project.ext.versions map of dependencyDefinitions.gradle](https://github.com/huxi/lilith/blob/master/dependencyDefinitions.gradle#L6) from `'2.3.3'` to `'2.4.0'`.\n5. Execute the contained `./gradlew` or `gradlew.bat`\n\nThere will be six test-failures with 2.4.0 that won't happen with 2.3.3.\n\nThere are actually only 2 test-methods that fail 3 times each.\n\nThose methods reside at [full()](https://github.com/huxi/lilith/blob/master/lilith-data/logging-io-test/src/main/java/de/huxhorn/lilith/data/logging/test/LoggingEventIOTestBase.java#L230) and [nullArgument()](https://github.com/huxi/lilith/blob/master/lilith-data/logging-io-test/src/main/java/de/huxhorn/lilith/data/logging/test/LoggingEventIOTestBase.java#L120).\n\nI first suspected that `AfterburnerModule` might be the culprit but removing it from `LoggingJsonDecoder`/`LoggingJsonEncoder` didn't fix the problem.\n\nSorry for not narrowing down the problem further. I'll give this another look tomorrow but you may already be able to find the issue in the meantime.\n\nThe interesting thing is that several other test cases are working as intended...\n"
            },
            "4": {
                "commit_sha_buggy": "4d532801d3d552c7522888efb61e42f0fa167715",
                "commit_sha_fixed": "9e080e298d8c0cfd7d77a56eb93d85a5da322555",
                "report_id": "506",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/506",
                "issue_title": "Index is never set for Collection and Array in InvalidFormatException.Reference",
                "issue_description": "When a InvalidFormatException is created, index values is always '-1'.\nIndeed, in StringCollectionDeserializer, and CollectionDeserializer the exception is not caught.\nThe JsonMappingException shoud be caught and the index should be added and based on the \"result\" size.\nWithout this information, there is no way to get the index of the item involved in the mapping error.\n"
            },
            "5": {
                "commit_sha_buggy": "64a27bc8e5fd38a48c0c70eddf864542f7198acb",
                "commit_sha_fixed": "fd0f1fefdc19593a040b3dce857715d613cb6458",
                "report_id": "515",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/515",
                "issue_title": "Mixin annotations lost when using a mixin class hierarchy with non-mixin interfaces",
                "issue_description": "In summary, mixin annotations are lost when Jackson scans a parent mixin class with Json annotations followed by an interface implemented by the parent mixin class that does not have the same Json annotations.\nJackson version: 2.4.0\n\nDetail:\nI have the following class structure\n\n``` java\npublic interface Contact {\n    String getCity();\n}\n\npublic class ContactImpl implements Contact {\n    public String getCity() { ... }\n}\n\npublic class ContactMixin implements Contact {\n    @JsonProperty\n    public String getCity() { return null; }\n}\n\npublic interface Person extends Contact {}\n\npublic class PersonImpl extends ContactImpl implements Person {}\n\npublic class PersonMixin extends ContactMixin implements Person {}\n```\n\nand I configure a module as\n\n``` java\n// There are other getters/properties in the Impl class that do not need to be serialized and so\n// I am using the Mixin to match the interface and explicitly annotate all the inherited methods\nmodule.disable(MapperFeature.ALLOW_FINAL_FIELDS_AS_MUTATORS)\n    .disable(MapperFeature.AUTO_DETECT_FIELDS)\n    .disable(MapperFeature.AUTO_DETECT_GETTERS)\n    .disable(MapperFeature.AUTO_DETECT_IS_GETTERS)\n    .disable(MapperFeature.INFER_PROPERTY_MUTATORS);\nmodule.setMixInAnnotation(Person.class, PersonMixin.class);\n```\n\nWhen a `PersonImpl` instance is serialized, `city` is not included.\n\nI debugged the code and this is what happens:\nIn `AnnotatedClass.resolveMemberMethods()` the supertypes of `PersonImpl` are `[Person.class, Contact.class, ContactImpl.class]` in that order.\n\nIt starts with `Person` for which it finds `PersonMixin` and proceeds to `AnnotatedClass._addMethodMixIns()`. Here the `parents` list has `[PersonMixin, ContactMixin, Contact]`. When it processes `ContactMixin` it adds `getCity()` with the `JsonProperty` annotation. Then it processes `Contact`, doesn't find `getCity()` in `methods` map and so creates a new `AnnotatedMethod` for `getCity()` with the one from the interface which has no annotation which replaces the one from `ContactMixin`\n\nThe workaround for this issue is to explicitly add any parent mixins to the module i.e.\n\n``` java\nmodule.setMixInAnnotation(Contact.class, ContactMixin.class);\n```\n"
            },
            "6": {
                "commit_sha_buggy": "a4849c115f097ad8304b385a279871a4d44a9f16",
                "commit_sha_fixed": "5e799a2e2265cbb6a056b37b50f82cc1eebf1d45",
                "report_id": "570",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/570",
                "issue_title": "Add Support for Parsing All Compliant ISO-8601 Date Formats",
                "issue_description": "Some providers create JSON date stamps in ISO-8601 formats that cannot be parsed by the jackson-databind library. Here is a sampling of some valid formats that do not parse correctly:\n\n2014-10-03T18:00:00.6-05:00\n2014-10-03T18:00:00.61-05:00\n1997-07-16T19:20+01:00\n1997-07-16T19:20:30.45+01:00\n\nThe last two actually come from the ISO-8601 notes on http://www.w3.org/TR/NOTE-datetime.\n"
            },
            "7": {
                "commit_sha_buggy": "7471116f2457073ccb895a0eb452591b71c043e4",
                "commit_sha_fixed": "bcccd3e82241db25a2f34ed655dab88395089f39",
                "report_id": "592",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/592",
                "issue_title": "Possibly wrong `TokenBuffer` delegate deserialization using `@JsonCreator`",
                "issue_description": "``` java\nclass Value {\n@JsonCreator\npublic static Value from(TokenBuffer buffer) {\n...\n}\n```\n\nGiven JSON string is  `{ \"a\":1, \"b\":null }`, it is expected that while deserializing using delegate buffer,\ncurrent token will be start object `{`, and rest of the tokens will be available in buffer:\n\n```\n[START_OBJECT, FIELD_NAME, VALUE_NUMBER_INT, FIELD_NAME, VALUE_NULL, END_OBJECT]\n```\n\nBut, buffers ends up being started with field name and then contains single attribute value\n\n```\n[FIELD_NAME, VALUE_NUMBER_INT]\n```\n\nIt's due to how `TokenBuffer#copyCurrentStructure` works when we have current token as a `FIELD_NAME`, rather than `START_OBJECT`, because it's forced to move to next token [BeanDeserializer.java:120](https://github.com/FasterXML/jackson-databind/blob/2.4/src/main/java/com/fasterxml/jackson/databind/deser/BeanDeserializer.java#L120)\n\nHope this helps to nail it down. Is it an intended behavior, or it's regression/bug? \n"
            },
            "8": {
                "commit_sha_buggy": "a399c540e540ac616fd3c19a8e46ce065ef71f8c",
                "commit_sha_fixed": "3b041e3bad5968ade7f7519daeef6695a8f6b7f9",
                "report_id": "667",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/667",
                "issue_title": "Problem with bogus conflict between single-arg-String vs `CharSequence` constructor",
                "issue_description": "Although it is good idea to allow recognizing `CharSequence` as almost like an alias for `String`, this can cause problems for classes like `StringBuilder` that have separate constructors for both.\nThis actually throws a bogus exception for 2.5.0, due to introduction of ability to recognize `CharSequence`.\n"
            },
            "9": {
                "commit_sha_buggy": "ae101c63bc8c74466fc137b766faa8793c1e1f10",
                "commit_sha_fixed": "00bb11edc3581f42e1f3c78a047538c8ea9eb0d9",
                "report_id": "682",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/682",
                "issue_title": "Deserializing Map<Class<? extends Object>, String>",
                "issue_description": "I am having problems deserializing my `Map<Class<? extends Object>, String>`. Simple test case demonstrates it:\n\n``` java\n@Test\npublic void testMapWithClassAsKey() throws Exception {\n    Map<Class<? extends Object>, String> map = new HashMap<>();\n    map.put(ArrayList.class, \"ArrayList\");\n    map.put(HashMap.class, \"HashMap\");\n\n    ObjectMapper mapper = new ObjectMapper();\n\n    String json = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(map);\n    System.out.println(json);\n    mapper.readValue(json, new TypeReference<Map<Class<? extends Object>, String>>(){});\n}\n```\n\nThis test serializes the map as:\n\n``` json\n{\n    \"class java.util.ArrayList\" : \"ArrayList\",\n    \"class java.util.HashMap\" : \"HashMap\"\n}\n```\n\n`mapper.readValue(json, new TypeReference<Map<Class<? extends Object>, String>>(){});` then throws a `Exception`:\n\n```\ncom.fasterxml.jackson.databind.exc.InvalidFormatException: Can not construct     Map key of type java.lang.Class from String \"class java.util.ArrayList\": not a valid representation: Can not construct Map key of type java.lang.Class from String \"class java.util.ArrayList\": unable to parse key as Class\n at [Source: ...\n```\n\nAs i understood from #630 the KeyDeserializer for Class should be part of Jackson. Am I missing something?\n"
            },
            "10": {
                "commit_sha_buggy": "6262dd76625e16d10ee45bc90ae76b02101cd65a",
                "commit_sha_fixed": "466f706901d39ae95393c6c7b1d0b544247922f1",
                "report_id": "705",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/705",
                "issue_title": "JsonAnyGetter doesn't work with JsonSerialize (except with keyUsing)",
                "issue_description": "(This is happening with 2.5.0. Haven't tried 2.5.1 but I couldn't see any related issue anyway)\n\nJackson ignores JsonSerialize annotation when there is JsonAnyGetter annotation.\n\n``` java\n  @JsonSerialize(using = MySerializer.class)\n  // or\n  @JsonSerialize(converter = MyConverter.class)\n  @JsonAnyGetter\n  public Map<String, String> getParameters(){\n    return parameters;\n  }\n```\n\nexcept \n\n``` Java\n@JsonSerialize(keyUsing = MyKeySerializer.class)\n```\n\n(haven't tried each setting. Only tried keyUsing because I've seen a different issue (#661) with it)\nThen it works. But I need the converter, so..\n\nFor the time being I will use\n\n``` Java\n  @JsonAnyGetter\n  public Map<String, JsonNode> getParameters(){\n    return new MyConverter().convert(parameters);\n  }\n```\n\nbut I'd prefer to stick to annotations.\n"
            },
            "11": {
                "commit_sha_buggy": "66e8ac6372bc670d98e9dc74f06ef6faef97032c",
                "commit_sha_fixed": "66bfe6658e6c25e03d1bcd5d4d858e1aaf738a01",
                "report_id": "609",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/609",
                "issue_title": "Problem resolving locally declared generic type",
                "issue_description": "(reported by Hal H)\n\nCase like:\n\n``` java\nclass Something {\n    public <T extends Ruleform> T getEntity()\n    public <T extends Ruleform> void setEntity(T entity) \n}\n```\n\nappears to fail on deserialization.\n"
            },
            "12": {
                "commit_sha_buggy": "36d9b59eb1b74442abeea856dca61ebe8bc7b3a5",
                "commit_sha_fixed": "1d57c20dfd79c64837cf1ec357ab402f2158227e",
                "report_id": "735",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/735",
                "issue_title": "@JsonDeserialize on Map with contentUsing custom deserializer overwrites default behavior",
                "issue_description": "I recently updated from version 2.3.3 to 2.5.1 and encountered a new issue with our custom deserializers. They either seemed to stop working or were active on the wrong fields.\nI could narrow it down to some change in version 2.4.4 (2.4.3 is still working for me)\n\nI wrote a test to show this behavior. It seems to appear when there a two maps with the same key and value types in a bean, and only one of them has a custom deserializer. The deserializer is then falsely used either for both or none of the maps.\n\nThis test works for me in version 2.4.3 and fails with higher versions.\n\n``` java\nimport static org.junit.Assert.assertEquals;\n\nimport java.io.IOException;\nimport java.util.Map;\n\nimport org.junit.Test;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\nimport com.fasterxml.jackson.databind.deser.std.StdDeserializer;\n\npublic class DeserializeTest {\n\n    @Test\n    public void testIt() throws Exception {\n        ObjectMapper om = new ObjectMapper();\n        String json = \"{\\\"map1\\\":{\\\"a\\\":1},\\\"map2\\\":{\\\"a\\\":1}}\";\n        TestBean bean = om.readValue(json.getBytes(), TestBean.class);\n\n        assertEquals(100, bean.getMap1().get(\"a\").intValue());\n        assertEquals(1, bean.getMap2().get(\"a\").intValue());\n    }\n\n    public static class TestBean {\n\n        @JsonProperty(\"map1\")\n        @JsonDeserialize(contentUsing = CustomDeserializer.class)\n        Map<String, Integer> map1;\n\n        @JsonProperty(\"map2\")\n        Map<String, Integer> map2;\n\n        public Map<String, Integer> getMap1() {\n            return map1;\n        }\n\n        public void setMap1(Map<String, Integer> map1) {\n            this.map1 = map1;\n        }\n\n        public Map<String, Integer> getMap2() {\n            return map2;\n        }\n\n        public void setMap2(Map<String, Integer> map2) {\n            this.map2 = map2;\n        }\n    }\n\n    public static class CustomDeserializer extends StdDeserializer<Integer> {\n\n        public CustomDeserializer() {\n            super(Integer.class);\n        }\n\n        @Override\n        public Integer deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException {\n            Integer value = p.readValueAs(Integer.class);\n            return value * 100;\n        }\n    }\n}\n```\n"
            },
            "13": {
                "commit_sha_buggy": "50ea0838d9251240e8dd814c682059ef85b4d0cc",
                "commit_sha_fixed": "59af571c64a169eccd670337f097ff4be44a2262",
                "report_id": "742",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/742",
                "issue_title": "Allow deserialization of `null` Object Id",
                "issue_description": "(note: related to https://github.com/FasterXML/jackson-annotations/issues/56)\n\nFor some use cases (one known case being use from ORM like Hibernate) it makes sense to allow use of `null` (or missing) Object Id, in cases where actual Id will be generated by something other than Jackson. It may also make sense to add matching `DeserializationFeature` which allows such a condition to either be acceptable (default), or not (throw an exception), to allow for strict checks in cases where null/missing Object Id is not a legal use case.\n"
            },
            "14": {
                "commit_sha_buggy": "0ec81c07bc4be13e1382f7191981ed3f0bf9ef39",
                "commit_sha_fixed": "817a45a07040297a5db45dd04e79b010146b7e0d",
                "report_id": "744",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/744",
                "issue_title": "Custom deserializer with parent object update",
                "issue_description": "Hi, I have custom deserializer for `DataA`. An instance of `DataA` is contained in `DataB`, when updating an existing instance of `DataB` (as opposed to creating a new one) I get an exception when deserializing via a `JsonNode` object (deserializing via a `String` object works). \n\n``` java\nimport java.io.IOException;\n\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.JsonToken;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.deser.std.StdDeserializer;\nimport com.fasterxml.jackson.databind.module.SimpleModule;\n\npublic class TestDeserTest {\n    static class DataA {\n        public int i = 1;\n        public int j = 2;\n\n    }\n\n    static class DataB {\n        public DataA da = new DataA();\n        public int k = 3;\n    }\n\n    static class DataADeserializer extends StdDeserializer<DataA> {\n        private static final long serialVersionUID = 1L;\n\n        DataADeserializer() {\n            super(DataA.class);\n        }\n\n        public DataA deserialize(JsonParser jp, DeserializationContext ctxt)\n                throws JsonProcessingException, IOException {\n            assert (jp.getCurrentToken() == JsonToken.START_OBJECT);\n            JsonNode node = jp.getCodec().readTree(jp);\n\n            DataA da = new DataA();\n            da.i = 5;\n            return da;\n        }\n    }\n\n    @Test\n    public void test() throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n        SimpleModule module = new SimpleModule();\n        module.addDeserializer(DataA.class, new DataADeserializer());\n        mapper.registerModule(module);\n\n        DataB db = new DataB();\n        db.da.i = 11;\n        db.k = 13;\n        String jsonBString = mapper.writeValueAsString(db);\n        JsonNode jsonBNode = mapper.valueToTree(db);\n\n        // create parent\n        DataB dbNewViaString = mapper.readValue(jsonBString, DataB.class);\n        Assert.assertEquals(5, dbNewViaString.da.i);\n        Assert.assertEquals(13, dbNewViaString.k);\n\n        DataB dbNewViaNode = mapper.treeToValue(jsonBNode, DataB.class);\n        Assert.assertEquals(5, dbNewViaNode.da.i);\n        Assert.assertEquals(13, dbNewViaNode.k);\n\n        // update parent\n        DataB dbUpdViaString = new DataB();\n        DataB dbUpdViaNode = new DataB();\n\n        Assert.assertEquals(1, dbUpdViaString.da.i);\n        Assert.assertEquals(3, dbUpdViaString.k);\n        mapper.readerForUpdating(dbUpdViaString).readValue(jsonBString);\n        Assert.assertEquals(5, dbUpdViaString.da.i);\n        Assert.assertEquals(13, dbUpdViaString.k);\n\n        Assert.assertEquals(1, dbUpdViaNode.da.i);\n        Assert.assertEquals(3, dbUpdViaNode.k);\n        // FAILS HERE:\n        mapper.readerForUpdating(dbUpdViaNode).readValue(jsonBNode);\n        Assert.assertEquals(5, dbUpdViaNode.da.i);\n        Assert.assertEquals(13, dbUpdViaNode.k);\n    }\n}\n```\n\nThe trace:\n\n``` java\ncom.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \"i\" (class myorg.TestDeserTest$DataB), not marked as ignorable (2 known properties: \"da\", \"k\"])\n at [Source: N/A; line: -1, column: -1] (through reference chain: myorg.DataB[\"da\"]->myorg.DataB[\"i\"])\n    at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:51)\n    at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:817)\n    at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:954)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1324)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1302)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:249)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:136)\n    at com.fasterxml.jackson.databind.ObjectReader._bindAsTree(ObjectReader.java:1478)\n    at com.fasterxml.jackson.databind.ObjectReader.readTree(ObjectReader.java:1020)\n    at myorg.TestDeserTest$DataADeserializer.deserialize(TestDeserTest.java:39)\n    at myorg.TestDeserTest$DataADeserializer.deserialize(TestDeserTest.java:1)\n    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:523)\n    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)\n    at com.fasterxml.jackson.databind.deser.impl.BeanPropertyMap.findDeserializeAndSet(BeanPropertyMap.java:285)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:220)\n    at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1443)\n    at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1154)\n    at myorg.TestDeserTest.test(TestDeserTest.java:81)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n\n```\n"
            },
            "15": {
                "commit_sha_buggy": "fa1c2ff7eefd68061ae0cc3f630e87d16d1b2bb5",
                "commit_sha_fixed": "119ddc9701c94ac184362166742ceaa7437eec8f",
                "report_id": "731",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/731",
                "issue_title": "XmlAdapter result marshaling error in case of ValueType=Object ",
                "issue_description": "Hi,\n\nI have an error \"com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.lang.String and no properties discovered to create BeanSerializer\" in case of using custom XmlAdapter with such declaration:\n\n``` java\npublic static class IntegerListXmlAdapter extends XmlAdapter<Object, List<Integer>> {\n        ...\n        @Override\n        public Object marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n}\n```\n\nIf change declaration of this class to \"extends XmlAdapter<String, List<Integer>>\" it works good.\n\nFull example:\n\n``` java\npublic class IntegerListXmlAdapterTest {\n    @Test\n    public void testBasic() throws JsonProcessingException {\n        ObjectMapper mapper = (new ObjectMapper()).setAnnotationIntrospector(new JaxbAnnotationIntrospector());\n        SomeIntListHolder listHolder = new SomeIntListHolder();\n        listHolder.setListOne(asList(1, 2, 3));\n        System.out.println(mapper.writeValueAsString(listHolder));\n    }\n\n    public static class IntegerListXmlAdapter extends XmlAdapter<Object, List<Integer>> {\n        @Override\n        public List<Integer> unmarshal(Object value) throws Exception {return null;}\n\n        @Override\n        public Object marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n    }\n\n    public static class IntegerListToStringXmlAdapter extends XmlAdapter<String, List<Integer>> {\n        public List<Integer> unmarshal(String value) throws Exception {return null;}\n\n        public String marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n    }\n\n    @XmlRootElement\n    @XmlAccessorType(XmlAccessType.NONE)\n    public static class SomeIntListHolder {\n\n        @XmlAttribute\n        @XmlJavaTypeAdapter(IntegerListXmlAdapter.class)\n        private List<Integer> listOne;\n\n        public List<Integer> getListOne() {\n            return listOne;\n        }\n\n        public void setListOne(List<Integer> listOne) {\n            this.listOne = listOne;\n        }\n    }\n}\n```\n\nIn this state with last Jackson version we will get an error\n\n```\ncom.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.lang.String and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: SomeIntListHolder[\"listOne\"])\n    at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59)\n    at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26)\n    at com.fasterxml.jackson.databind.ser.std.StdDelegatingSerializer.serialize(StdDelegatingSerializer.java:157)\n    at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:575)\n    at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:663)\n    at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:156)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:129)\n    at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3385)\n    at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2779)\n```\n\nBut if we change XmlJavaTypeAdapter to IntegerListToStringXmlAdapter error will be fixed and code will work fine.\nThis error exists only in Jackson 2, we have this code with Object generic on Jackson 1 and get an issue only during migration to new major version.\n\nThis concrete error can be fixed by hack in com.fasterxml.jackson.databind.ser.std.StdDelegatingSerializer:\n\n``` java\n    @Override\n    public void serialize(Object value, JsonGenerator gen, SerializerProvider provider) throws IOException\n    {\n        Object delegateValue = convertValue(value);\n        // should we accept nulls?\n        if (delegateValue == null) {\n            provider.defaultSerializeNull(gen);\n            return;\n        }\n\n        //original code:\n        //_delegateSerializer.serialize(delegateValue, gen, provider);\n\n        JsonSerializer<Object> delegateSerializer;\n        if (_delegateSerializer instanceof UnknownSerializer) {\n            delegateSerializer =  provider.findValueSerializer(delegateValue.getClass());\n        } else {\n            delegateSerializer = _delegateSerializer;\n        }\n\n        delegateSerializer.serialize(delegateValue, gen, provider);\n    }\n```\n\nYou can find test class here: https://github.com/Spikhalskiy/jackson_xmladapter__bug/blob/master/src/test/java/IntegerListXmlAdapterTest.java\n\nand hacked serializer code here: https://github.com/Spikhalskiy/jackson_xmladapter__bug/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/std/StdDelegatingSerializer.java\n\nNow test passing in this repo because of fake StdDelegatingSerializer in classpath - try to delete it to get an issue.\n"
            },
            "16": {
                "commit_sha_buggy": "6dcb13f70fb1c68b0c055bfb1dae2b296ae67b03",
                "commit_sha_fixed": "db612bb3839581d0a88297667880cad548c018b1",
                "report_id": "771",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/771",
                "issue_title": "Annotation bundles ignored when added to Mixin",
                "issue_description": "When updating from v 2.4.4 to 2.5.\\* it appears as though annotation bundles created with `@JacksonAnnotationsInside` are ignored when placed on a mixin.  Moving the annotation bundel to the actual class seems to resolve the issue.  Below is a simple test that attempts to rename a property.  I have more complicated test cases that are also failing but this should provide some context.\n\n``` java\npublic class Fun {\n\n    @Test\n    public void test() throws JsonProcessingException {\n        ObjectMapper mapper = new ObjectMapper().addMixIn(Foo.class, FooMixin.class);\n        String result = mapper.writeValueAsString(new Foo(\"result\"));\n        Assert.assertEquals(\"{\\\"bar\\\":\\\"result\\\"}\", result);\n    }\n\n    @Target(value={ ElementType.CONSTRUCTOR, ElementType.FIELD, ElementType.METHOD })\n    @Retention(value=RetentionPolicy.RUNTIME)\n    @JacksonAnnotationsInside\n    @JsonProperty(\"bar\")\n    public @interface ExposeStuff {\n\n    }\n\n    public abstract class FooMixin {\n        @ExposeStuff\n        public abstract String getStuff();\n    }\n\n    public class Foo {\n\n        private String stuff;\n\n        Foo(String stuff) {\n            this.stuff = stuff;\n        }\n\n        public String getStuff() {\n            return stuff;\n        }\n    }\n}\n```\n\nI'm expecting the \"stuff\" property to be serialized as \"bar\".\n\nI apologize I haven't been able to identify the culprit (and perhaps it's in my usage).  Let me know your thoughts. I'm always happy to provide more details!\n"
            },
            "17": {
                "commit_sha_buggy": "7db1f44069bbcac9d884d829f8052a89b5ec271b",
                "commit_sha_fixed": "a143c05db7a911f98f8bf59beb13cfcb7689395d",
                "report_id": "793",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/793",
                "issue_title": "readTree does not work with defaultTyping enabled but no type info provided",
                "issue_description": "I have enabled `defaultTyping`, and serialized `Foo` entity with no type info. I'm trying to read json as a tree with `mapper.readTree(json)`, and it throws an exception \n\n``` java\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: \nUnexpected token (START_OBJECT), expected START_ARRAY: need JSON Array to contain As.WRAPPER_ARRAY \ntype information for class com.fasterxml.jackson.databind.JsonNode\n at [Source: {\n  \"bar\" : \"bar\"\n}; line: 1, column: 1]\n    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\n    at com.fasterxml.jackson.databind.DeserializationContext.wrongTokenException(DeserializationContext.java:927)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._locateTypeId(AsArrayTypeDeserializer.java:127)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:93)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromAny(AsArrayTypeDeserializer.java:68)\n    at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeWithType(JsonNodeDeserializer.java:144)\n    at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserializeWithType(JsonNodeDeserializer.java:14)\n    at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3562)\n    at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2136)\n    at test.App.main(App.java:23)\n```\n\nHowever, if I disable `defaultTyping`, the same code works fine. So, `readTree(json)` does not actually need type info for the root element, because it works when `defaultTyping` is disabled (i.e. `{\"bar\" : \"bar\"}`), but it throws the exception when `defaultTyping` is enabled, that's why it looks like a bug. The same thing happens for `valueToTree(foo)`. \nJackson version is `2.5.3`\nFull code is provided.\n\n``` java\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.MapperFeature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport java.io.IOException;\n\npublic class App {\n    public static void main(String[] args) throws IOException {\n        ObjectMapper mapper = new ObjectMapper()\n                .enableDefaultTyping() // works fine with disableDefaultTyping()\n                .enable(MapperFeature.AUTO_DETECT_GETTERS)\n                .enable(MapperFeature.REQUIRE_SETTERS_FOR_GETTERS)\n                .disable(MapperFeature.USE_GETTERS_AS_SETTERS)\n                .disable(MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS)\n                .enable(SerializationFeature.INDENT_OUTPUT)\n                .disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);\n\n        Foo foo = new Foo(\"bar\");\n        String serialized = mapper.writeValueAsString(foo); // {\"bar\" : \"bar\"}\n\n        JsonNode jsonNode = mapper.readTree(serialized); // exception here\n        JsonNode node = mapper.valueToTree(foo); // and here\n    }\n\n    public static class Foo {\n        private String bar;\n\n        public Foo() {\n        }\n\n        public Foo(String bar) {\n            this.bar = bar;\n        }\n\n        public String getBar() {\n            return bar;\n        }\n\n        public void setBar(String bar) {\n            this.bar = bar;\n        }\n    }\n}\n```\n"
            },
            "18": {
                "commit_sha_buggy": "de1376e85e247f7e4b185183b6433721dec172bc",
                "commit_sha_fixed": "2abf5a321405a82ed4e0d3a7c876c82bb05188f9",
                "report_id": "734",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/734",
                "issue_title": "Add basic error-recovery for `ObjectReader.readValues()`",
                "issue_description": "(follow up for #733)\n\nIn case of `JsonProcessingException`, `MappingIterator` will currently be left pointing right after whatever token was last tokenized (or character following tokenization error). While this is better than indeterminate state, ideally it should try to do some error recover. And although it may not be possible to recover successfully from all kinds of issues, it should be possible to do best effort given that iterator has some knowledge of state when it was opened; that is, it can try to heuristically match closing `END_OBJECT`, depending on nesting level it was created at.\n\nIn addition it may make sense to add a switch to prevent using of any automated heuristics, for those users who want full control over recovery.\n"
            },
            "19": {
                "commit_sha_buggy": "1a24cc1755d787a576c32157a38e441cfe839964",
                "commit_sha_fixed": "354e1390bc397ef048ffd5d905b0709a3a2585ef",
                "report_id": "810",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/810",
                "issue_title": "Force value coercion for `java.util.Properties`, so that values are `String`s",
                "issue_description": "Currently there is no custom handling for `java.util.Properties`, and although it is possible to use it (since it really is a `Map` under the hood), results are only good if values are already `String`s.\nThe problem here is that `Properties` is actually declared as `Map<String,Object>`, probably due to backwards-compatibility constraints.\n\nBut Jackson should know better: perhaps by `TypeFactory` tweaking parameterizations a bit?\n"
            },
            "20": {
                "commit_sha_buggy": "ea2c9a46bf2a98eb2f1af04fad65016f4648a8de",
                "commit_sha_fixed": "6456a9ac0bee09e2ae45ae56739102a8071f217a",
                "report_id": "815",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/815",
                "issue_title": "Presence of PropertyNamingStrategy Makes Deserialization Fail",
                "issue_description": "I originally came across this issue using Dropwizard - https://github.com/dropwizard/dropwizard/issues/1095.  But it looks like this is a Jackson issue.  Here's the rerproducer:\n\n``` java\npublic class TestPropertyNamingStrategyIssue {\n  public static class ClassWithObjectNodeField {\n    public String id;\n    public ObjectNode json;\n  }\n\n  @Test\n  public void reproducer() throws Exception {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.setPropertyNamingStrategy(PropertyNamingStrategy.LOWER_CASE);\n    ClassWithObjectNodeField deserialized =\n        mapper.readValue(\n            \"{ \\\"id\\\": \\\"1\\\", \\\"json\\\": { \\\"foo\\\": \\\"bar\\\", \\\"baz\\\": \\\"bing\\\" } }\",\n            ClassWithObjectNodeField.class);\n  }\n}\n```\n\nLooks like the presence of any PropertyNamingStrategy make deserialization to ObjectNode fail.  This works fine if I remove the property naming strategy.\n"
            },
            "21": {
                "commit_sha_buggy": "44dea1f292933192ea5287d9b3e14a7daaef3c0f",
                "commit_sha_fixed": "707db7a972e2d088647450f9a890c438fb735933",
                "report_id": "677",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/677",
                "issue_title": "Specifying `Enum` value serialization using `@JsonProperty`",
                "issue_description": "Currently, if I want to deserialize an enum with a value that isn't its `Enum.name()`, I can do either\n\n``` java\npublic enum TestEnum {\n    VALUE_ONE(\"value1\");\n\n    private String valueInJson;\n\n    private TestEnum(String valueInJson) {\n        this.valueInJson = valueInJson;\n    }\n\n    @JsonCreator\n    public static TestEnum getEnumFromValue(String value) {\n        for (TestEnum testEnum : values()) {\n            if (testEnum.valueInJson.equals(value)) {\n                return testEnum;\n            }\n        }\n        throw new IllegalArgumentException();\n    }\n}\n```\n\nor, using `DeserializationFeature.READ_ENUMS_USING_TO_STRING`,\n\n``` java\npublic enum TestEnum {\n    VALUE_ONE(\"value1\");\n\n    private String valueInJson;\n\n    private TestEnum(String valueInJson) {\n        this.valueInJson = valueInJson;\n    }\n\n    @Override\n    public String toString() {\n        return valueInJson;\n    }\n}\n```\n\nThis seems like a lot of boilerplate - is there a simpler way to do this, similar to how `Gson` handles it?\n\n``` java\npublic enum TestEnum {\n    @SerializedName(\"value1\")\n    VALUE_ONE\n}\n```\n\nIt's both more concise and handles both serialization and deserialization.\n"
            },
            "22": {
                "commit_sha_buggy": "80c1bbb7f93b6ec3c79c4ae3f72dbeec5dff62fc",
                "commit_sha_fixed": "a92e2be0ccbe6732e1fef39bf48b0f9dcc559fd6",
                "report_id": "848",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/848",
                "issue_title": "Custom serializer not used if POJO has `@JsonValue`",
                "issue_description": "Looks like serializers constructed for `@JsonValue` have higher precedence than custom serializers; that is, registered custom serializer is not found if POJO type has `@JsonValue` annotation.\nThis is wrong.\n"
            },
            "23": {
                "commit_sha_buggy": "19b897cc8ed0c48995f1aff18ceb32fa8af81c6f",
                "commit_sha_fixed": "6172d7561007a941b01f960dd44d94a92f3ad763",
                "report_id": "849",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/849",
                "issue_title": "Possible problem with `NON_EMPTY` exclusion, `int`s, `Strings`",
                "issue_description": "(from https://github.com/FasterXML/jackson-module-afterburner/issues/55)\n\nIt appears like default handling might not work as expected with 2.5.4, whereas Afterburner does seem to handle things better. Need to investigate, and also see if 2.6.0-rc3 works better.\n"
            },
            "24": {
                "commit_sha_buggy": "6c617384110d2ea10b1bc5543f747c177df6dc8f",
                "commit_sha_fixed": "b4ef0a65150a7311ebb9119b1ac6898e33dc0baf",
                "report_id": "889",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/889",
                "issue_title": "Configuring an ObjectMapper's DateFormat changes time zone when serialising Joda DateTime",
                "issue_description": "The serialisation of Joda `DateTime` instances behaves differently in 2.6.0 vs 2.5.4 when the `ObjectMapper`'s had its `DateFormat` configured. The behaviour change is illustrated by the following code:\n\n``` java\npublic static void main(String[] args) throws JsonProcessingException {\n    System.out.println(createObjectMapper()\n            .writeValueAsString(new DateTime(1988, 6, 25, 20, 30, DateTimeZone.UTC)));\n}\n\nprivate static ObjectMapper createObjectMapper() {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.registerModule(createJodaModule());\n    mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\n    System.out.println(mapper.getSerializationConfig().getTimeZone());\n    mapper.setDateFormat(new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"));\n    System.out.println(mapper.getSerializationConfig().getTimeZone());\n    return mapper;\n}\n\nprivate static SimpleModule createJodaModule() {\n    SimpleModule module = new SimpleModule();\n    module.addSerializer(DateTime.class, new DateTimeSerializer(\n            new JacksonJodaDateFormat(DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\")\n                    .withZoneUTC())));\n        return module;\n    }\n```\n\nWhen run with Jackson 2.5.4 the output is:\n\n```\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\n\"1988-06-25 20:30:00\"\n```\n\nWhen run with Jackson 2.6.0 the output is:\n\n```\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\nsun.util.calendar.ZoneInfo[id=\"Europe/London\",offset=0,dstSavings=3600000,useDaylight=true,transitions=242,lastRule=java.util.SimpleTimeZone[id=Europe/London,offset=0,dstSavings=3600000,useDaylight=true,startYear=0,startMode=2,startMonth=2,startDay=-1,startDayOfWeek=1,startTime=3600000,startTimeMode=2,endMode=2,endMonth=9,endDay=-1,endDayOfWeek=1,endTime=3600000,endTimeMode=2]]\n\"1988-06-25 21:30:00\"\n```\n\nIt looks like the fix for #824 is the cause. In 2.6, the call to `mapper.setDateFormat` causes the `ObjectMapper`'s time zone to be set to the JVM's default time zone. In 2.5.x, calling `mapper.setDateFormat` has no effect on its time zone.\n"
            },
            "25": {
                "commit_sha_buggy": "b4ef0a65150a7311ebb9119b1ac6898e33dc0baf",
                "commit_sha_fixed": "9917c94d94a285ece80e6c9f3d2b9fba06d98fd7",
                "report_id": "890",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/890",
                "issue_title": "Exception deserializing a byte[] when the target type comes from an annotation",
                "issue_description": "When trying to deserialize a `byte[]` from a `Map` when the deserialization type comes from an annotation, I'm seeing the following exception:\n\n```\njava.lang.IllegalArgumentException: Can not deserialize Class [B (of type array) as a Bean\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.isPotentialBeanType(BeanDeserializerFactory.java:808)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:138)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:403)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\n        at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:428)\n        at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:947)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:439)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\n        at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:461)\n        at com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:3804)\n        at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3418)\n        at com.fasterxml.jackson.databind.ObjectMapper.convertValue(ObjectMapper.java:3351)\n```\n\nThe below is a repro.\n\n``` java\npublic class JacksonTest {\n\n    static class Foo {\n        @JsonProperty\n        @JsonDeserialize(as=byte[].class)\n        Object someBytes;\n    }\n\n    public void testFooFromMap() {\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"someBytes\", \"HelloWorld\".getBytes());\n\n        ObjectMapper m = new ObjectMapper();\n        m.convertValue(map, Foo.class);\n    }\n}\n```\n\nI discovered this on 2.5.1, but I tried 2.6.0 and it's exhibiting the same behavior.\n\nThanks!\n"
            },
            "26": {
                "commit_sha_buggy": "eda66cc8173c8e359d68a07bbc8adbbef5f8e7f6",
                "commit_sha_fixed": "2ea6e402d4cf86c3f7e9a16e667a40bab61cf11c",
                "report_id": "899",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/899",
                "issue_title": "Problem serializing `ObjectReader` (and possibly `ObjectMapper`) in 2.6",
                "issue_description": "Looks like serializability is missing for one of new (2.6) helper classes, `CompactStringObjectMap`, leading to problems with systems like Apache Spark that may need to serialize handlers like `ObjectReader` and/or `ObjectWriter`.\n"
            },
            "27": {
                "commit_sha_buggy": "d485ea7da49ed949c81f23513d01d67e170d2a1b",
                "commit_sha_fixed": "f2f611e701c63c8e98e59f315641bd2bf2921aea",
                "report_id": "928",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/928",
                "issue_title": "Problem deserializing External Type Id if type id comes before POJO",
                "issue_description": "(note: seems to be similar or related to https://github.com/FasterXML/jackson-module-afterburner/issues/58)\n\nWith 2.6, looks like handling of External Type Id is broken in some rare (?) cases; existing unit tests did not catch this. At this point I am speculating this is due to some refactoring, or change to use more efficient 'nextFieldName()' method.\n"
            },
            "28": {
                "commit_sha_buggy": "e258ee60edc692c80907fd6e4bb16e641692b721",
                "commit_sha_fixed": "b049739cc66a0f79c19dd1cea47e922d95645023",
                "report_id": "941",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/941",
                "issue_title": "Deserialization from \"{}\" to ObjectNode field causes \"out of END_OBJECT token\" error",
                "issue_description": "I found that deserializing from an empty object (`{}`) to ObjectNode field in a class field fails.\n\nHere is the minimum code to reproduce:\n\n``` java\npublic class Main\n{\n    public static class MyValue\n    {\n        private final ObjectNode object;\n\n        @JsonCreator\n        public MyValue(ObjectNode object) { this.object = object; }\n\n        @JsonValue\n        public ObjectNode getObject() { return object; }\n    }\n\n    public static void main(String[] args)\n            throws Exception\n    {\n        ObjectMapper om = new ObjectMapper();\n\n        ObjectNode object = new ObjectNode(JsonNodeFactory.instance);\n\n        String json = om.writeValueAsString(object);\n        System.out.println(\"json: \"+json);\n\n        ObjectNode de1 = om.readValue(json, ObjectNode.class);  // this works\n        System.out.println(\"Deserialized to ObjectNode: \"+de1);\n\n        MyValue de2 = om.readValue(json, MyValue.class);  // but this throws exception\n        System.out.println(\"Deserialized to MyValue: \"+de2);\n    }\n}\n```\n\nResult is:\n\n```\njson: {}\nDeserialized to ObjectNode: {}\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of com.fasterxml.jackson.databind.node.ObjectNode out of END_OBJECT token\n at [Source: {}; line: 1, column: 2]\n        at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\n        at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:854)\n        at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:850)\n        at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer$ObjectDeserializer.deserialize(JsonNodeDeserializer.java:104)\n        at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer$ObjectDeserializer.deserialize(JsonNodeDeserializer.java:83)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1095)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:294)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:131)\n        at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3731)\n        at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2724)\n        at Main.main(Main.java:35)\n```\n\nIf the object is not empty (e.g. `{\"k\":\"v\"}`), it works:\n\n``` java\n        ...\n        ObjectNode object = new ObjectNode(JsonNodeFactory.instance);\n        object.put(\"k\", \"v\");  // added\n        ...\n```\n\n```\njson: {\"k\":\"v\"}\nDeserialized to ObjectNode: {\"k\":\"v\"}\nDeserialized to MyValue: io.digdag.cli.Main$MyValue@17550481\n```\n\nEnvironment:\n- jackson-core 2.6.2\n- jackson-databind 2.6.2\n- Java 8 (`Java(TM) SE Runtime Environment (build 1.8.0_20-b26)`)\n"
            },
            "29": {
                "commit_sha_buggy": "04cb084c913e82414a7e92803cd037f0169450d6",
                "commit_sha_fixed": "30b5469753686548ca7a590dd1bc5114181e68a9",
                "report_id": "942",
                "report_url": "https://github.com/FasterXML/jackson-databind/pull/942",
                "issue_title": "Handle null type id for polymorphic values that use external type id",
                "issue_description": "Remove exceptions thrown when polymorphic value is null.\nIf there is a need to force non-null value, this could be provided as an extra property in @JsonTypeInfo, or perhaps use an existing property such as JsonProperty.required.\n"
            },
            "30": {
                "commit_sha_buggy": "16aa30572b41b7e643e9ee08def2169681f8e2c5",
                "commit_sha_fixed": "ca6c3fc55eb74e21fe90e18da33723fb99b22f21",
                "report_id": "965",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/965",
                "issue_title": "BigDecimal values via @JsonTypeInfo/@JsonSubTypes get rounded",
                "issue_description": "When using an `ObjectMapper` to serialize/deserialize a class with an `Object` field annotated with a `@JsonSubTypes.Type` that indicate `BigDecimal`, it looks like the value is getting rounded to a double.\n\nI tried configuring `DeserializationFeature.USE_BIG_DECIMAL_FOR_FLOATS`, but that didn't seem to help.\n\nWhat I think is a valid repro is below, but let me know if I'm actually doing something wrong here.\n\nThanks!\n\n``` java\nimport org.junit.Test;\nimport org.junit.Assert;\n\nimport java.math.BigDecimal;\n\nimport com.fasterxml.jackson.annotation.*;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class JacksonTest {\n\n    enum Type { BIG_DECIMAL }\n\n    static class Wrapper {\n\n        @JsonIgnore\n        Type typeEnum;\n\n        @JsonIgnore\n        Object value;\n\n        Wrapper() { }\n\n        @JsonGetter(value = \"type\")\n        String getTypeString() {\n            return typeEnum.name();\n        }\n\n        @JsonSetter(value = \"type\")\n        void setTypeString(String type) {\n            this.typeEnum = Type.valueOf(type);\n        }\n\n        @JsonGetter(value = \"objectValue\") \n        Object getValue() {\n            return value;\n        }\n\n        @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.EXTERNAL_PROPERTY, property = \"type\")\n        @JsonSubTypes({ @JsonSubTypes.Type(name = \"BIG_DECIMAL\", value = BigDecimal.class) })\n        @JsonSetter(value = \"objectValue\") \n        private void setValue(Object value) {\n            this.value = value;\n        }\n    }\n\n    @Test\n    public void test() throws Exception {\n\n        ObjectMapper m = new ObjectMapper();\n        m.configure(DeserializationFeature.USE_BIG_DECIMAL_FOR_FLOATS, true);\n\n        Wrapper w = new Wrapper();\n        w.typeEnum = Type.BIG_DECIMAL;\n        w.value = new BigDecimal(\"-10000000000.0000000001\");\n\n        String json = m.writeValueAsString(w);\n        Wrapper w2 = m.readValue(json, Wrapper.class);\n\n        Assert.assertEquals(w.typeEnum, w2.typeEnum);\n        Assert.assertTrue(String.format(\"Expected %s = %s; got back %s = %s\",\n            w.value.getClass().getSimpleName(), w.value.toString(), w2.value.getClass().getSimpleName(), w2.value.toString()),\n            w.value.equals(w2.value));\n    }\n}\n```\n"
            },
            "31": {
                "commit_sha_buggy": "3bd5de685c1f1116b71e6c51d713528834773fdf",
                "commit_sha_fixed": "fe25f7e14d92f5d4746549e7df22e9af35fdf54b",
                "report_id": "984",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/984",
                "issue_title": "JsonStreamContexts are not build the same way for write.. and convert methods",
                "issue_description": "HI\nI got an issue reported in my jackson-antpathfilter project that the filtering is not working correctly when it is used together with Jackson's convert feature: https://github.com/Antibrumm/jackson-antpathfilter/issues/2\n\nDuring the investigation i found out that the cause is that the writeContext is created differently and I am wondering if this is the desired behavior or if that's a bug for you.\n\nIn this comment (https://github.com/Antibrumm/jackson-antpathfilter/issues/2#issuecomment-145211847) I print out what is found in the writeContext and I have created a TestCase to reproduce the error. \n\nPlease let me know what you think.\n"
            },
            "32": {
                "commit_sha_buggy": "fe25f7e14d92f5d4746549e7df22e9af35fdf54b",
                "commit_sha_fixed": "d5a25f4300a93f4c411a7b8364d34122bc0a1b62",
                "report_id": "989",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/989",
                "issue_title": "Deserialization from \"{}\" to java.lang.Object causes \"out of END_OBJECT token\" error",
                "issue_description": "Hi, I've faced with a problem that is too similar this one #941. I expect that \"{}\" will be parsed correctly to empty Map when I'm using `@JsonCreator`\n\nI've found that this case is invalid https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.6.3/src/main/java/com/fasterxml/jackson/databind/deser/std/UntypedObjectDeserializer.java#L272, but why?\n\nHere is the minimum code to reproduce:\n\n```\nimport java.io.IOException;\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class Main {\n    public static void main(String[] args) throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.readValue(\"[]\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"[{}]\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"{\\\"key\\\":null}\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"{}\", SomeObjectThatCanBeAggregated.class);\n    }\n}\nclass SomeObjectThatCanBeAggregated {\n\n    @JsonCreator\n    public SomeObjectThatCanBeAggregated(Object obj) {\n        System.out.println(obj + \" //\" + obj.getClass());\n    }\n}\n```\n\nOutput: \n\n```\n[] //class java.util.ArrayList\n[{}] //class java.util.ArrayList\n{key=null} //class java.util.LinkedHashMap\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.lang.Object out of END_OBJECT token\n at [Source: {}; line: 1, column: 2]\n...\n```\n"
            },
            "33": {
                "commit_sha_buggy": "1ed7f3834dc77cf76d7477e8165dedb8ae2d61c2",
                "commit_sha_fixed": "660ec8f8c081646413d14adf41d55bbd4362a5a8",
                "report_id": "1013",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1013",
                "issue_title": "@JsonUnwrapped is not treated as assuming @JsonProperty(\"\")",
                "issue_description": "See discussion [here](https://groups.google.com/forum/#!topic/jackson-user/QLpWb8YzIoE) but basically `@JsonUnwrapped` on a private field by itself does not cause that field to be serialized, currently,  You need to add an explicit `@JsonProperty`.  You shouldn't have to do that.  (Following test fails currently, should pass, though you can make it pass by commenting out the line with `@JsonProperty`.  Uses TestNG and AssertJ.)\n\n``` java\npackage com.bakins_bits;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport org.testng.annotations.Test;\n\nimport com.fasterxml.jackson.annotation.JsonUnwrapped;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class TestJsonUnwrappedShouldMakePrivateFieldsSerializable\n{\n    public static class Inner\n    {\n        public String animal;\n    }\n\n    public static class Outer\n    {\n        // @JsonProperty\n        @JsonUnwrapped\n        private Inner inner;\n    }\n\n    @Test\n    public void jsonUnwrapped_should_make_private_fields_serializable() throws JsonProcessingException {\n        // ARRANGE\n        Inner inner = new Inner();\n        inner.animal = \"Zebra\";\n\n        Outer outer = new Outer();\n        outer.inner = inner;\n\n        ObjectMapper sut = new ObjectMapper();\n\n        // ACT\n        String actual = sut.writeValueAsString(outer);\n\n        // ASSERT\n        assertThat(actual).contains(\"animal\");\n        assertThat(actual).contains(\"Zebra\");\n        assertThat(actual).doesNotContain(\"inner\");\n    }\n}\n```\n"
            },
            "34": {
                "commit_sha_buggy": "5e924b21f6f55a918aed08927f8088ddd35ccfa5",
                "commit_sha_fixed": "6b471c37efce0a3205dff387efd3473980be648f",
                "report_id": "1045",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1045",
                "issue_title": "Regression in 2.7.0-rc2, for schema/introspection for `BigDecimal`",
                "issue_description": "(found via Avro module, but surprisingly json schema module has not test to catch it)\n\nLooks like schema type for `BigDecimal` is not correctly produced, due to an error in refactoring (made to simplify introspection for simple serializers): it is seen as `BigInteger` (and for Avro, for example, results in `long` getting written).\n"
            },
            "35": {
                "commit_sha_buggy": "121fc1d3432c7bb69d1030d840fc979f1f16c926",
                "commit_sha_fixed": "cecd409aa97693beb87c4e9ca34ea7f734676216",
                "report_id": "1051",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1051",
                "issue_title": "Problem with Object Id and Type Id as Wrapper Object (regression in 2.5.1)",
                "issue_description": "(note: originally from https://github.com/FasterXML/jackson-module-jaxb-annotations/issues/51)\n\nLooks like fix for #669 caused a regression for the special use case of combining type and object ids, with wrapper-object type id inclusion. The problem started with 2.5.1.\n"
            },
            "36": {
                "commit_sha_buggy": "9d0fae41bdc7fae448acf0b84ba18e24e80ad0b7",
                "commit_sha_fixed": "c48e992652125eb74aea8ead8cbda5fd0b44976a",
                "report_id": "803",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/803",
                "issue_title": "Allow use\tof `StdDateFormat.setLenient()`",
                "issue_description": "ObjectMapper uses the StdDateFormat for date serialization. Jackson date parsing is lenient by default, so 2015-01-32 gets parsed as 2015-02-01.  Jackson\u2019s StdDateParser is matching default behavior of DateParser.  \n\nStdDateParser wasn\u2019t really designed for extension to just enable strict date parsing.  If it were, we could just call objectMapper.setDateFormat(new StdDateFormat().setLenient(false)). But StdDateFomrat doesn't support setting lenient to false. And i.e. the reason date like 2015-01-32 gets parsed as 2015-02-01 ad Jackson date parsing is lenient by defualt.\n\nCan StdDateFormat can be enhanced to support to non lenient date parsing?\n"
            },
            "37": {
                "commit_sha_buggy": "d5e12f74d2224574ef1e220decc514073303ac5c",
                "commit_sha_fixed": "dbf0c6f4c93d922a2ebb4d744661e7090fef2aac",
                "report_id": "1083",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1083",
                "issue_title": "Field in base class is not recognized, when using `@JsonType.defaultImpl`",
                "issue_description": "When deserializing JSON to Java POJOS, a field inherited from a base class is not recognized. Here is the stack:\n\n```\ncom.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \"name\" (class org.apache.calcite.model.JsonMapSchema), not marked as ignorable (2 known properties: \"functions\", \"tables\"])\n at [Source: {\n  version: '1.0',\n   schemas: [\n     {\n       name: 'FoodMart',\n       tables: [\n         {\n           name: 'time_by_day',\n           columns: [\n             {\n               name: 'time_id'\n             }\n           ]\n         },\n         {\n           name: 'sales_fact_1997',\n           columns: [\n             {\n               name: 'time_id'\n             }\n           ]\n         }\n       ]\n     }\n   ]\n}; line: 24, column: 7] (through reference chain: org.apache.calcite.model.JsonRoot[\"schemas\"]->java.util.ArrayList[0]->org.apache.calcite.model.JsonMapSchema[\"name\"])\n\n    at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:62)\n    at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:855)\n    at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1083)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1389)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1367)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:266)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:163)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:136)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:99)\n    at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:142)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:279)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:249)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26)\n    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490)\n    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2779)\n    at org.apache.calcite.test.ModelTest.testRead(ModelTest.java:58)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\n    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234)\n    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\n```\n\nMy `JsonMapSchema` class has a base class `JsonSchema` and it has a public field `name`. See https://github.com/apache/calcite/blob/master/core/src/test/java/org/apache/calcite/test/ModelTest.java.\n\nI have an application that worked in 2.6.3, fails in 2.7.0, so I suspect this is a regression. \n"
            },
            "38": {
                "commit_sha_buggy": "ae85620b0834bd978f8ab080b07150ee8034f8ad",
                "commit_sha_fixed": "21a2e4b7d680bf796f07d5d3b6119a3cd3fc356c",
                "report_id": "1102",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1102",
                "issue_title": "(2.7-regress) Handling of deprecated `SimpleType.construct()` too minimalistic",
                "issue_description": "(note: spun from https://github.com/FasterXML/jackson/issues/48)\n\nDue to changes in type resolution, most direct construction methods in `JavaType` sub-classes can not be fully supported. Failure modes are typically with complex cases (and expected to be rare), with one exception: use of `SimpleType.construct(Class)`, because:\n1. This is mostly used for complex types, and not just \"well-known\" interfaces like `List`, `Map`; so actual access to at least immediate fields is necessary (and similarly lack of super-type info is problematic), and\n2. Its usage is likely to be wide-spread, despite existence of preferable methods (`TypeFactory`)\n3. Since refactoring of type resolution was not anticipated early enough in advance, deprecation of methods we want to move users away from could not be done in 2.6, as it should have been (in perfect case)\n\nExact reasoning behind problems is quite complicated: but the fundamental reason is that `TypeFactory` has all the logic to do the generic resolution; `JavaType` has (and should have) very little if any. Since no reference to the factory is passed via constructors/factory methods, they can not properly delegate resolution tasks. This is why direct calls should only be made with all necessary, pre-resolved information; passing `JavaType`s for elements, not `Class`.\nInability to resolve things means that super-types can not be properly resolved, for example. Handling of fields, methods will also be inexact wrt generic types.\n\nThe first immediate problem is something that should be addressable: introspection by POJO deserializer builder does not find any fields or methods. It should be possible to at least find them, even if type resolution for generic types will not work well. This should be acceptable for the common (and reported) case of constructing element types for `Collection`s and `Map`s: generic parameterization will not be accessible anyway.\n\nThere are other potential issues to address as best we can, but first things first.\n"
            },
            "39": {
                "commit_sha_buggy": "e741034db7191de9985a9b3dcd667bbdf262ce3a",
                "commit_sha_fixed": "308ed4ed89b32d119b5994e457597275c6a0af7d",
                "report_id": "1108",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1108",
                "issue_title": "Jackson not continue to parse after DeserializationFeature.FAIL_ON_INVALID_SUBTYPE error",
                "issue_description": "After FAIL_ON_INVALID_SUBTYPE error, jackson should continue to parse, but seems jackson doesn't.\n\nThe output:\n\n```\nCallRecord [version=0.0, application=123, ] // doesn't read item2 which is valid\nCallRecord [version=0.0, application=123, ]\nCallRecord [version=0.0, ] // doesn't read application after invalid item.\n```\n\n``` jaca\n@JsonInclude(Include.NON_NULL)\npublic class CallRecord {\n    public float version;\n    public String application;\n    public Item item;\n    public Item item2;\n    public CallRecord() {}\n\n    public static void main(final String[] args) throws IOException {\n        final ObjectMapper objectMapper = new ObjectMapper().disable(DeserializationFeature.FAIL_ON_INVALID_SUBTYPE,\n                DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES);\n        final CallRecord call = new CallRecord();\n\n        final Event event = new Event();\n        event.location = \"location1\";\n        call.item = event;\n        call.item2 = event;\n        call.application = \"123\";\n        // System.out.println(objectMapper.writeValueAsString(call));\n        String json =\n                \"{\\\"version\\\":0.0,\\\"application\\\":\\\"123\\\",\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"},\\\"item2\\\":{\\\"type\\\":\\\"event\\\",\\\"location\\\":\\\"location1\\\"}}\";\n        // can't read item2 - which is valid\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n\n        json = \"{\\\"version\\\":0.0,\\\"application\\\":\\\"123\\\"},{\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"}\";\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n\n        json = \"{\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"}, \\\"version\\\":0.0,\\\"application\\\":\\\"123\\\"}\";\n        // order matters: move item to the fornt, now it can't read application property\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n    }\n    @Override\n    public String toString() {\n        final StringBuilder builder = new StringBuilder();\n        builder.append(\"CallRecord [version=\").append(version).append(\", \");\n        if (application != null) {\n            builder.append(\"application=\").append(application).append(\", \");\n        }\n        if (item != null) {\n            builder.append(\"item=\").append(item);\n        }\n        builder.append(\"]\");\n        return builder.toString();\n    }\n}\n\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\", visible = true)\n@JsonSubTypes({@Type(value = Event.class, name = Event.TYPE)})\npublic interface Item {\n}\n\npublic final class Event implements Item {\n    public String location;\n    public static final String TYPE = \"event\";\n    public Event() {}\n}\n```\n"
            },
            "40": {
                "commit_sha_buggy": "44f35a9becd891b9401a5879cc7934ec7130846d",
                "commit_sha_fixed": "21ca92134c900809278c987cd02d0b2335f4fb1f",
                "report_id": "1095",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1095",
                "issue_title": "Prevent coercion of `int` from empty String to `null` if `DeserializationFeature .FAIL_ON_NULL_FOR_PRIMITIVES` is `true`",
                "issue_description": "I got 0 from the code below.\n\n``` java\nint i = mapper.readValue(\"\\\"\\\"\", int.class);\nSystem.out.println(i);\n```\n\nIt seems that Json Number type cannot start with \".\nCould I make the code throw some Exceptions?\n"
            },
            "41": {
                "commit_sha_buggy": "97bbfa7827044224b86b6767e720dbd52f9d81e7",
                "commit_sha_fixed": "729c0fecc5ba6ac7749c7ea84d4a33dcb5cfa4e4",
                "report_id": "1115",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1115",
                "issue_title": "Problems with deprecated `TypeFactory.constructType(type, ctxt)` methods if `ctxt` is `null`",
                "issue_description": "(note: continuation of #1079)\n\nLooks like earlier fix was incomplete, and there is one more edge case to handle: if passed-in context is `null`, attempt to resolve that will fail. This should not occur since previously passing of `null` would simply have used \"empty\" bindings. Code needs to take care to handle this as version 2.6 did.\n"
            },
            "42": {
                "commit_sha_buggy": "89559a204e5aed69a58d45837d65bbe7f6dab95a",
                "commit_sha_fixed": "2d90441ef0440f3a2f910b210234cb8b709ca727",
                "report_id": "1123",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1123",
                "issue_title": "Serializing and Deserializing Locale.ROOT",
                "issue_description": "Serializing and Deserializing Locale objects seems to work just fine, until you try on the Root Locale.\nIt writes it out as an empty string and when it reads it in, the value is null\n\n```\n@Test\n    public void testLocaleDeserialization() throws IOException {\n        ObjectMapper objectMapper = new ObjectMapper();\n        Locale root = Locale.ROOT;\n        String json = objectMapper.writeValueAsString(root);\n        System.out.printf(\"Root Locale: '%s'\", json);\n        Locale actual = objectMapper.readValue(json, Locale.class);\n        Assert.assertEquals(root, actual);\n    }\n```\n\nHere is the output:\nRoot Locale: '\"\"'\njava.lang.AssertionError: \nExpected :\nActual   :null\n"
            },
            "43": {
                "commit_sha_buggy": "ad53425b8173476fa7f6d87ef640e8138241cdbf",
                "commit_sha_fixed": "a290f09c4ba55b7724375099f5cf0cd0a9b48011",
                "report_id": "1150",
                "report_url": "https://github.com/FasterXML/jackson-databind/pull/1150",
                "issue_title": "Problem with Object id handling, explicit `null` token",
                "issue_description": "According to #742, it shouldn't throw an exception if the value of the property is null\n"
            },
            "44": {
                "commit_sha_buggy": "a290f09c4ba55b7724375099f5cf0cd0a9b48011",
                "commit_sha_fixed": "700617aa96fdfb3259a1e8001c1bee24deaec34a",
                "report_id": "1125",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1125",
                "issue_title": "Problem with polymorphic types, losing properties from base type(s)",
                "issue_description": "(background, see: https://github.com/dropwizard/dropwizard/pull/1449)\n\nLooks like sub-type resolution may be broken for one particular case: that of using `defaultImpl`. If so, appears like properties from super-types are not properly resolved; guessing this could be follow-up item for #1083 (even sooner than I thought...).\n"
            },
            "45": {
                "commit_sha_buggy": "700617aa96fdfb3259a1e8001c1bee24deaec34a",
                "commit_sha_fixed": "bacb37f41b4b8db75d6f1731e8c9afd56c6247dd",
                "report_id": "1155",
                "report_url": "https://github.com/FasterXML/jackson-databind/pull/1155",
                "issue_title": "Fix for #1154",
                "issue_description": "Fix for #1154. Partially rolls back to pre-#1111 behavior.\nWe just make sure that the STRING shape is chosen when Shape.ANY (the default) is set on the annotation, but some other annotation attribute was also set (pattern, locale or timezone).\nThis way of fixing the issue has the added benefit of respecting the user config regarding the default serialization of ~~strings~~ dates when @JsonFormat(shape = Shape.ANY) is set on a property.\n"
            },
            "46": {
                "commit_sha_buggy": "d32563c559da846e386b86bbf664b82eadab7c82",
                "commit_sha_fixed": "cb6717764c0460f560e1b09478faa4dac692e8f3",
                "report_id": "1194",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1194",
                "issue_title": "Incorrect signature for generic type via `JavaType.getGenericSignature",
                "issue_description": "(see https://github.com/FasterXML/jackson-modules-base/issues/8 for background)\n\nIt looks like generic signature generation is missing one closing `>` character to produce:\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;;\n```\n\ninstead of expected\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;>;\n```\n\nthat is, closing '>' is missing.\n"
            },
            "47": {
                "commit_sha_buggy": "9d3de8cfcf9b50b92db20240d42abafc2bad98e1",
                "commit_sha_fixed": "ebadfd25ed1244b170f7af2414c35673eb055a29",
                "report_id": "1231",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1231",
                "issue_title": "`@JsonSerialize(as=superType)` behavior disallowed in 2.7.4",
                "issue_description": "#1178 fixed the problem with collections, but I'm seeing a problem with individual objects.\n\nI'm getting:\n\n```\ncom.fasterxml.jackson.databind.JsonMappingException: Failed to widen type [simple type, class org.pharmgkb.model.AccessionIdentifier] with annotation (value org.pharmgkb.model.BaseAccessionIdentifier), from 'getReference': Class org.pharmgkb.model.BaseAccessionIdentifier not a super-type of [simple type, class org.pharmgkb.model.AccessionIdentifier]\n\n    at com.fasterxml.jackson.databind.AnnotationIntrospector.refineSerializationType(AnnotationIntrospector.java:821)\n    at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.refineSerializationType(AnnotationIntrospectorPair.java:488)\n    at com.fasterxml.jackson.databind.ser.PropertyBuilder.findSerializationType(PropertyBuilder.java:194)\n    at com.fasterxml.jackson.databind.ser.PropertyBuilder.buildWriter(PropertyBuilder.java:73)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._constructWriter(BeanSerializerFactory.java:805)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.findBeanProperties(BeanSerializerFactory.java:608)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.constructBeanSerializer(BeanSerializerFactory.java:388)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.findBeanSerializer(BeanSerializerFactory.java:271)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._createSerializer2(BeanSerializerFactory.java:223)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.createSerializer(BeanSerializerFactory.java:157)\n    at com.fasterxml.jackson.databind.SerializerProvider._createUntypedSerializer(SerializerProvider.java:1215)\n    at com.fasterxml.jackson.databind.SerializerProvider._createAndCacheUntypedSerializer(SerializerProvider.java:1167)\n    at com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:490)\n    at com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:688)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:107)\n    at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1428)\n    at com.fasterxml.jackson.databind.ObjectWriter._configAndWriteValue(ObjectWriter.java:1129)\n    at com.fasterxml.jackson.databind.ObjectWriter.writeValueAsString(ObjectWriter.java:1001)\n    at org.pharmgkb.jackson.JacksonTest.testModelObjects(JacksonTest.java:48)\n```\n\nOn something like:\n\n```\npublic class Foo {\n  @JsonSerialize(as = BaseAccessionIdentifier.class)\n  @JsonDeserialize(as = BaseAccessionIdentifier.class)\n  public AccessionIdentifier getReference() {\n  }\n}\n```\n\n```\npublic interface AccessionIdentifier {\n}\n```\n\n```\npublic class BaseAccessionIdentifier implements AccessionIdentifier {\n}\n```\n"
            },
            "48": {
                "commit_sha_buggy": "1e5d34926af2160fc8d19cfc435b608ee60d5c3e",
                "commit_sha_fixed": "fe32b967f6b029a10ec1d40f7e12c8b37ba32ee8",
                "report_id": "1223",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1223",
                "issue_title": "`BasicClassIntrospector.forSerialization(...).findProperties` should respect MapperFeature.AUTO_DETECT_GETTERS/SETTERS",
                "issue_description": "When I set the ObjectMapper MapperConfig to not AutoDetect and use the BasicClassIntrospector to get the properties, I seem to still be getting the Methods.  I am currently using version 2.7.3.\n\nThe following code produces this output:\n        Found property count 2, there should only be one??\n        Found property: name=name, internalName=name\n        Found property: name=groupname, internalName=groupname\n\nI think it should produce only this output:\n        Found property: name=groupname, internalName=groupname\n\n```\npublic static void main(String [] args) {\n    class TCls {\n        @JsonProperty(\"groupname\")\n        private String groupname;\n\n        public void setName(String str) {\n            this.groupname = str;\n        }\n        public String getName() {\n            return groupname;\n        }\n    }\n\n    ObjectMapper om = new ObjectMapper();\n    // Only use explicitly specified values to be serialized/deserialized (i.e., JSONProperty).\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_FIELDS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_GETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_SETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_IS_GETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.USE_GETTERS_AS_SETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.INFER_PROPERTY_MUTATORS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.USE_ANNOTATIONS, true);\n\n    JavaType javaType = om.getTypeFactory().constructType(TCls.class);\n\n    BasicClassIntrospector introspector = new BasicClassIntrospector();\n    BasicBeanDescription bdesc = introspector.forSerialization(om.getSerializationConfig(), javaType, null);\n    List<BeanPropertyDefinition> bprops = bdesc.findProperties();\n\n    if (1 != bprops.size()) {\n        System.out.println(\"Found property count \" + bprops.size() + \", there should only be one??\");\n    }\n    bprops.forEach(prop -> {\n        System.out.println(\"Found property: name=\" + prop.getName() + \", internalName=\" + prop.getInternalName());\n    });\n}\n```\n"
            },
            "49": {
                "commit_sha_buggy": "d15b19f2b47fab18d369defdd2851e70284dbbf0",
                "commit_sha_fixed": "644487bf9b525b26734bfda1780b272b52631c5e",
                "report_id": "1255",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1255",
                "issue_title": "JsonIdentityInfo incorrectly serializing forward references",
                "issue_description": "I wrote this small test program to demonstrate the issue:\n\n``` java\nimport com.fasterxml.jackson.annotation.JsonIdentityInfo;\nimport com.fasterxml.jackson.annotation.JsonIdentityReference;\nimport com.fasterxml.jackson.annotation.ObjectIdGenerators;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class ObjectIdTest {\n\n    public static class Foo {\n\n        @JsonIdentityReference(alwaysAsId = true)\n        public Bar bar1;\n\n        @JsonIdentityReference()\n        public Bar bar2;\n    }\n\n    @JsonIdentityInfo(generator = ObjectIdGenerators.IntSequenceGenerator.class)\n    public static class Bar {\n\n    }\n\n    public static void main(String[] args) throws Exception {\n        ObjectMapper mapper = new ObjectMapper();\n\n        // create structure to serialize\n        Foo mo = new Foo();\n        mo.bar1 = new Bar();\n        mo.bar2 = mo.bar1;\n\n        // serialize it\n        System.out.println(mapper.writeValueAsString(mo));\n    }\n\n}\n```\n\nWhen executing this test program in the latest version (2.7.4), the output will be `{\"bar1\":1,\"bar2\":{\"@id\":2}}` - the second field will be written with a new id even though both fields reference the same object. Because of this, writing forward references is essentially impossible.\n\nThe issue seems to be the fact that BeanSerializerBase will always call WritableObjectId.generateId if the referenced object has not been written in plain format yet (https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/std/BeanSerializerBase.java#L600). This will also happen if an id has been generated before.\nIt might also be smarter to only generate a new id in WritableObjectId.generateId if that hasn't happened before; as that method doesn't have a javadoc I can't tell how it is supposed to work.\n"
            },
            "50": {
                "commit_sha_buggy": "522d8f6ca9aed1d6bfd5b3757dd46835f1ca9527",
                "commit_sha_fixed": "567d6c09a868175626a0b404dc1a8f128f7746f2",
                "report_id": "1261",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1261",
                "issue_title": "`@JsonIdentityInfo` deserialization fails with combination of forward references, `@JsonCreator`",
                "issue_description": "As a follow-up to bug #1255, the patch I provided exposes related deserialization problems.\nI have attached a small project ('jackson-test.zip') to demonstrate these issues. When run with both patches from #1255, the output is provided in the attached 'both.txt'. When run with just the first patch from #1255, the output is provided in the attached 'first.txt'.\nImportant points:\n1. When the object expressed as an id is contained within a collection or map (List in this example), deserialization works correctly. When it is a field of an object, deserialization is broken.\n2. This particular example doesn't have forward references, but it does have cycles. Nevertheless, I have seen situations where non-cyclical forward-references also do not deserialize properly, with the same caveat as in 1.\n[jackson-test.zip](https://github.com/FasterXML/jackson-databind/files/301884/jackson-test.zip)\n[both.txt](https://github.com/FasterXML/jackson-databind/files/301885/both.txt)\n[first.txt](https://github.com/FasterXML/jackson-databind/files/301886/first.txt)\n"
            },
            "51": {
                "commit_sha_buggy": "37eacd8b90b7f7e2393f305db9b154312b693afb",
                "commit_sha_fixed": "36631a98a1199be01b9fbbcc66ac2afa4ad82dfc",
                "report_id": "1270",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1270",
                "issue_title": "Generic type returned from type id resolver seems to be ignored",
                "issue_description": "https://github.com/benson-basis/jackson-custom-mess-tc\n\nHere's the situation, with Jackson 2.7.4.\n\nI have a TypeIdResolver that returns a JavaType for a generic type. However, something seems to be forgetting/erasing the generic, as it is failing to use the generic type param to understand the type of a field in the class.\n\nAll the information is in the test case, so I'm not putting any code to read here in the issue.\n"
            },
            "52": {
                "commit_sha_buggy": "2202ca51cf3e61765c9ac96326633deb2ff37318",
                "commit_sha_fixed": "ab8a20f6447da482bd0430498b482d06867c9c50",
                "report_id": "999",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/999",
                "issue_title": "External property is not deserialized",
                "issue_description": "I think it's easier to show the code than explain the issue, so i prepared a test project:\nhttps://github.com/crew4ok/jackson-databind-test\n\nSo basically the issue is that the external property, by which another's property type is deduced, after deserialization is null.\nSee the failing test:\nhttps://github.com/crew4ok/jackson-databind-test/blob/master/src/test/java/jackson/ExternalIdDeserTest.java\n\nAm i missing something?\n"
            },
            "53": {
                "commit_sha_buggy": "4929735be6bdae0d1853d7d269234a30be18408f",
                "commit_sha_fixed": "75a0953bcf6275a486243a67e91774c8d5ffb6ca",
                "report_id": "1215",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1215",
                "issue_title": "Problem with type specialization for Maps with `@JsonDeserialize(as=subtype)`",
                "issue_description": "If I have json that looks like\n\n```\n{\n  \"something\": [\n        {\n           \"id\": \"a uuid\",\n           \"property\": \"value\"\n         }\n  ]\n}\n```\n\nAnd I have a java pojo with an annotation like this:\n\n```\n    @JsonDeserialize(as = MyHashMap.class)\n    private void setSomething(Map<UUID, Foo> incomingValue) {\n```\n\nWhere MyHashMap.java has some custom logic using generics that allow us to map the array json above into a Map where \"id\" is the key and everything else serializes into the value.  We use generics on MyHashMap to enforce that every value implements a certain interface that respects the contract of returning an \"id\" property.  In this example Foo.java implements this interface MyCustomIdInterface.java.\n\nWhen using 2.6.6 this worked fine, but if I switch to 2.7.x then it breaks with the error:\n\n`Can not construct instance of MyCustomIdInterface, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information`\n\nin 2.7.x, it looks like jackson resolves to using AbstractDeserializer based on MyCustomIdInterface but in 2.6.6 it resolves to using BeanDeserializer based on Foo.java.\n\nIs this a bug or is there some default/feature flag that changed here?\n"
            },
            "54": {
                "commit_sha_buggy": "9c2e89b49aa363292096addfa3f66179f498930d",
                "commit_sha_fixed": "f7e476edb42236ad06ab7084ecd5e6c5405bf99a",
                "report_id": "1256",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1256",
                "issue_title": "`Optional.empty()` not excluded if property declared with type `Object`",
                "issue_description": "Jackson version is 2.6.6\n**Here is the code:**\n\n```\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.setSerializationInclusion(JsonInclude.Include.NON_ABSENT);\n        mapper.registerModule(new Jdk8Module());\n\n        JsonResult result = new JsonResult();\n        result.setA(Optional.empty());\n        result.setB(Optional.empty());\n        System.out.println(mapper.writeValueAsString(result));\n```\n\n```\n@Data\npublic class JsonResult {\n    private Object a;\n    private Optional<Object> b;\n}\n```\n\n**Then I got the output: {\"a\":null}**\n\n**The real value of both is the same, why the results are different?**\n\n**How can I avoid null in such case?**\n\nBy the way, I tried 'NON_EMPTY'. It can work, but it also ignores zero and empty array. I want to keep them.\n"
            },
            "55": {
                "commit_sha_buggy": "958c824560807ca145ea581d26e501ed0cf669fc",
                "commit_sha_fixed": "2936ba525b22c3aabbb2fc914d1a191938b2375b",
                "report_id": "1322",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1322",
                "issue_title": "EnumMap keys not using enum's `@JsonProperty` values unlike Enum values",
                "issue_description": "Based on these issues:\nhttps://github.com/FasterXML/jackson-databind/issues/677\nhttps://github.com/FasterXML/jackson-databind/issues/1148\nhttps://github.com/FasterXML/jackson-annotations/issues/96\n\nI implemented @JsonProperty for my enum constants and they show up nicely when they are property values. But I also have an EnumMap which uses the enum, and it's generated JSON uses the original enum names for the keys and not the JsonProperty values.\n\nUsing 2.8.1 (in spring boot 4.3.2)\n\nThanks!\n"
            },
            "56": {
                "commit_sha_buggy": "e979bc530a86a32d63389acbedd3323185ad4ef6",
                "commit_sha_fixed": "07b6d6636670b2a9f14ac265186790db11cfd52d",
                "report_id": "1344",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1344",
                "issue_title": "Deserializing locale assumes JDK separator (underscore), does not accept RFC specified (hyphen)",
                "issue_description": "When deserializing a locale Jackson currently uses the underscore character as the separator rather than the dash.  Specifically, in FromStringDeserializer.java line 234:\n\n```\nint ix = value.indexOf('_');\n```\n\nMany locale implementations use dash as the separator as per https://tools.ietf.org/html/rfc5646\n\nGiven the RFC states that only the characters a-z A-Z and - are valid it should be possible to leave the current code in for backward-compatibility but it should also check for  '-' as a separator.\n"
            },
            "57": {
                "commit_sha_buggy": "1d930db6a1407a873af65deecf4290e4c4238e94",
                "commit_sha_fixed": "bbd8190030022df404a8f7c47c1bc32e990cb0d2",
                "report_id": "1362",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1362",
                "issue_title": "`ObjectReader.readValues()` ignores offset and length when reading an array",
                "issue_description": "ObjectReader.readValues ignores offset and length when reading an array. If _dataFormatReaders it will always use the full array:\n\nhttps://github.com/FasterXML/jackson-databind/blob/2.7/src/main/java/com/fasterxml/jackson/databind/ObjectReader.java#L1435\n"
            },
            "58": {
                "commit_sha_buggy": "d71de544624bec27e6f4e76548527ae727eb193d",
                "commit_sha_fixed": "b2ccdee0fdc52cd46577a90cb50dc011d6d681bf",
                "report_id": "877",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/877",
                "issue_title": "`@JsonIgnoreProperties`: ignoring the \"cause\" property of `Throwable` on GAE",
                "issue_description": "Deserializing an exception class from json on Google App Engine causes this error:\n\n```\nCaused by: java.lang.IllegalArgumentException: Can not access private java.lang.Throwable java.lang.Throwable.cause (from class java.lang.Throwable; failed to set access: java.lang.IllegalAccessException: Reflection is not allowed on private java.lang.Throwable java.lang.Throwable.cause\n    at com.fasterxml.jackson.databind.util.ClassUtil.checkAndFixAccess(ClassUtil.java:505)\n    at com.fasterxml.jackson.databind.introspect.AnnotatedMember.fixAccess(AnnotatedMember.java:123)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.constructSettableProperty(BeanDeserializerFactory.java:704)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.addBeanProps(BeanDeserializerFactory.java:501)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.buildThrowableDeserializer(BeanDeserializerFactory.java:356)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:114)\n```\n\nI tried preventing this by using `@JsonIgnoreProperties`:\n\n``` java\n@JsonIgnoreProperties(\"cause\")\npublic class MyException extends RuntimeException { ... }\n```\n\n... but the same error still occurs. What am I doing wrong? What else could I do?\n\nI've also considered setting `MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS` to false, but I don't like this solution because I need this setting to be `true` in some other cases (in particular, I provide no-arg constructors for Jackson, but they should't be public in my API).\n"
            },
            "59": {
                "commit_sha_buggy": "b3c65e40abc63a4dde7f63eacf8ee96ccd4341c2",
                "commit_sha_fixed": "e59194aaff0a6e520184138924c69045160ee9d9",
                "report_id": "1384",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1384",
                "issue_title": "@JsonDeserialize(keyUsing = ...) does not work correctly together with DefaultTyping.NON_FINAL",
                "issue_description": "Version 2.8.3 seems to ignore @JsonDeserialize(keyUsing = ...) when used together with DefaultTyping.NON_FINAL setting and Map<,> argument type in constructor with concrete type (e.g. HashMap<,>) specified in JSON.\n\nIn the code below testFails() fails and testSucceeds() passes fine. The only difference is testSucceeds() has a module with deserializer registered explicitly. Both tests pass on version 2.6.\n\n``` java\npackage com.test.testjackson.testjackson;\n\nimport com.fasterxml.jackson.annotation.JsonAutoDetect;\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonGenerator;\nimport com.fasterxml.jackson.core.JsonParseException;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonMappingException;\nimport com.fasterxml.jackson.databind.JsonSerializer;\nimport com.fasterxml.jackson.databind.KeyDeserializer;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectMapper.DefaultTyping;\nimport com.fasterxml.jackson.databind.SerializerProvider;\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\nimport com.fasterxml.jackson.databind.annotation.JsonSerialize;\nimport com.fasterxml.jackson.databind.module.SimpleKeyDeserializers;\nimport com.fasterxml.jackson.databind.module.SimpleModule;\nimport java.io.IOException;\nimport java.util.Map;\nimport org.junit.Test;\n\nimport static com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.ANY;\nimport static junit.framework.Assert.assertEquals;\n\npublic class TestJackson \n{\n    private static String TEST_INSTANCE_SERIALIZED = \"{\\\"mapProperty\\\":[\\\"java.util.HashMap\\\",{\\\"Compound|Key\\\":\\\"Value\\\"}]}\";\n\n    @Test\n    public void testFails() throws JsonParseException, JsonMappingException, IOException\n    {\n        ObjectMapper mapper = new ObjectMapper().enableDefaultTyping(DefaultTyping.NON_FINAL);\n        TestClass testInstance = mapper.readValue(TEST_INSTANCE_SERIALIZED, TestClass.class);\n        String testInstanceSerialized = mapper.writeValueAsString(testInstance);\n        assertEquals(TEST_INSTANCE_SERIALIZED, testInstanceSerialized);\n    }\n\n    @Test\n    public void testSucceeds() throws JsonParseException, JsonMappingException, IOException\n    {\n        ObjectMapper mapper = new ObjectMapper().enableDefaultTyping(DefaultTyping.NON_FINAL).registerModule(new SimpleModule() {\n            private static final long serialVersionUID = 1L;\n            @Override\n            public void setupModule(SetupContext context) {\n                context.addKeyDeserializers(new SimpleKeyDeserializers().addDeserializer(CompoundKey.class, new CompoundKeyDeserializer()));\n            }\n        });\n        TestClass testInstance = mapper.readValue(TEST_INSTANCE_SERIALIZED, TestClass.class);\n        String testInstanceSerialized = mapper.writeValueAsString(testInstance);\n        assertEquals(TEST_INSTANCE_SERIALIZED, testInstanceSerialized);\n    }\n\n    @JsonAutoDetect(fieldVisibility = ANY)\n    public static final class TestClass {\n        @JsonProperty(\"mapProperty\")\n        @JsonSerialize(keyUsing = CompoundKeySerializer.class)\n        private final Map<CompoundKey, String> mapProperty;\n\n        @JsonCreator\n        private TestClass(@JsonDeserialize(keyUsing = CompoundKeyDeserializer.class) @JsonProperty(\"mapProperty\") Map<CompoundKey, String> mapProperty) {\n            this.mapProperty = mapProperty;\n        }\n    }\n\n    public static final class CompoundKey {\n        private String part0;\n        private String part1;\n\n        public CompoundKey(String part0, String part1) {\n            this.part0 = part0;\n            this.part1 = part1;\n        }\n\n        public String getPart0() { return part0; }\n        public String getPart1() { return part1; }\n    }\n\n    public static class CompoundKeyDeserializer extends KeyDeserializer {\n        @Override\n        public Object deserializeKey(String s, DeserializationContext deserializationContext) {\n            String[] parts = s.split(\"\\\\|\");\n            return new CompoundKey(parts[0], parts[1]);\n        }\n    }\n\n    public static class CompoundKeySerializer extends JsonSerializer<CompoundKey> {\n        @Override\n        public void serialize(CompoundKey compoundKey, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {\n            jsonGenerator.writeFieldName(compoundKey.getPart0() + '|' + compoundKey.getPart1());\n        }\n    }\n}\n```\n"
            },
            "60": {
                "commit_sha_buggy": "9f01551c3f875ec7b19ad260683b794e6594a55a",
                "commit_sha_fixed": "be114a9a286c4d194cd268ac8153173c52619a8d",
                "report_id": "1385",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1385",
                "issue_title": "Polymorphic type lost when using `@JsonValue`",
                "issue_description": "When suppressing all getters but one with @JsonIgnore and choosing to use a byte array for serialization (marking its getter with @JsonValue), the typing of the object is changed to \"[B\", which is deserialized to a byte array. I would have expected verbose typing and usage of the constructor  marked with @JsonCreator that accepts the byte array to construct the object on deserialization. The behavior is as expected when choosing more fields for serialization, which is redundant data in this case.\n\nRunning  jackson-databind 2.7.4 on Java 1.8.0_91.\n\nConfiguration of the ObjectMapper:\n\n```\nprivate final ObjectMapper mapper;\npublic JsonFilter() {\n    this.mapper = new ObjectMapper();\n    mapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);\n    mapper.enableDefaultTyping();\n}\n```\n\nSerialization: `mapper.writeValueAsString(message)`\nDeserialization: `mapper.readValue(json, RemoteCall.class)`\n\nGetter and field:\n\n```\n/** @serial */\nprivate byte[] apdu;\n\n@JsonValue\npublic byte[] getBytes() {\n    return apdu.clone();\n}\n```\n\nConstructor:\n\n```\n@JsonCreator\npublic CommandAPDU(@JsonProperty(value = \"bytes\") byte[] apdu) {\n    this.apdu = apdu.clone();\n    parse();\n    LOG.v(\"com.ubitricity.devices.common.pal.CommandAPDU creator (1)\");\n}\n```\n\nSerializes to `\"args\":[[\"[B\",\"AKQEAAnw8fLz9AAAAgA=\"],[\"net.sf.lipermi.call.RemoteInstance\",{\"instanceId\":\"b0e15098-f49e-4328-b072-fc5df42799bd\",\"className\":\"com.ubitricity.devices.common.tasks.ResponseReceiver\"}]]` where \"args\" is an Object array field of the enclosing object.\n"
            },
            "61": {
                "commit_sha_buggy": "be114a9a286c4d194cd268ac8153173c52619a8d",
                "commit_sha_fixed": "82c346ae999e1e250fb52732419aff9a86b1f455",
                "report_id": "1395",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1395",
                "issue_title": "Problems deserializing primitive `long` field while using `TypeResolverBuilder`",
                "issue_description": "When running the following test app\n\n``` java\nimport com.fasterxml.jackson.annotation.JsonTypeInfo;\nimport com.fasterxml.jackson.core.JsonFactory;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.jsontype.impl.StdTypeResolverBuilder;\nimport java.io.IOException;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class Main {\n\n    public static void main(String[] args) throws IOException {\n        // Create test data\n        Data data = new Data();\n        data.key = 1;\n        Map<String, Object> mapData = new HashMap<>();\n        mapData.put(\"longInMap\", 2L);\n        mapData.put(\"longAsField\", data);\n\n        // Configure Jackson to preserve types\n        JsonFactory factory = new JsonFactory();\n        ObjectMapper mapper = new ObjectMapper(factory);\n        StdTypeResolverBuilder resolver = new StdTypeResolverBuilder();\n        resolver.init(JsonTypeInfo.Id.CLASS, null);\n        resolver.inclusion(JsonTypeInfo.As.PROPERTY);\n        resolver.typeProperty(\"__t\");\n        mapper.setDefaultTyping(resolver);\n        mapper.enable(SerializationFeature.INDENT_OUTPUT);\n\n        // Serialize\n        String json = mapper.writeValueAsString(mapData);\n        System.out.println(\"json = \" + json);\n\n        // Deserialize\n        Map deserializedData = mapper.readValue(json, Map.class);\n    }\n\n    static class Data {\n\n        public long key;\n    }\n}\n```\n\nI get this output and exception\n\n``` java\njson = {\n  \"__t\" : \"java.util.HashMap\",\n  \"longInMap\" : [ \"java.lang.Long\", 2 ],\n  \"longAsField\" : {\n    \"__t\" : \"com.pinkmatter.bean.serialization.Main$Data\",\n    \"key\" : [ \"java.lang.Long\", 1 ]\n  }\n}\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Class java.lang.Long not subtype of [simple type, class long] (through reference chain: java.util.HashMap[\"longAsField\"]->com.pinkmatter.bean.serialization.Data[\"key\"])\n  at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:379)\n  at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:339)\n  at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1591)\n  at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:278)\n  ...\nCaused by: java.lang.IllegalArgumentException: Class java.lang.Long not subtype of [simple type, class long]\n  at com.fasterxml.jackson.databind.type.TypeFactory.constructSpecializedType(TypeFactory.java:359)\n  at com.fasterxml.jackson.databind.jsontype.impl.ClassNameIdResolver._typeFromId(ClassNameIdResolver.java:72)\n  at com.fasterxml.jackson.databind.jsontype.impl.ClassNameIdResolver.typeFromId(ClassNameIdResolver.java:42)\n  ...\n```\n\nI am trying to serialize a bunch of basic plain old java objects from libraries we are using (so we cannot modify the classes or add annotations), while also trying to preserve the types of values in collections (\"longInMap\" in the above example must stay a Long object).\n\nThe problem is that Jackson throws the above exception when trying to deserialize the primitive `public long key` in the `Data` class. If I change the type to `public int key` then no exception is thrown and deserialization works.\n\nAlso, since there are many different types of objects and I don't know at compile time exactly what will be serialized I don't think using mix-ins will work.\n\nI am using Jackson 2.8.3.\n"
            },
            "62": {
                "commit_sha_buggy": "987a463a185d25086c29ee2efa0c0e24ecf77cb2",
                "commit_sha_fixed": "4e94c0ed9eca0caccb57feb0ceb252fc91198032",
                "report_id": "1392",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1392",
                "issue_title": "Custom UnmodifiableSetMixin Fails in Jackson 2.7+ but works in Jackson 2.6",
                "issue_description": "I'd like to be able to deserialize an `UnmodifiableSet` with default typing enabled. To do this I have created an `UnmodifiableSetMixin` as shown below:\n\n**NOTE**: You can find a minimal project with all the source code to reproduce this issue at https://github.com/rwinch/jackson-unmodifiableset-mixin\n\n``` java\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.annotation.JsonTypeInfo;\n\nimport java.util.Set;\n\n@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY)\npublic abstract class UnmodifiableSetMixin {\n\n    @JsonCreator\n    public UnmodifiableSetMixin(Set<?> s) {}\n}\n```\n\nI then try to use this to deserialize an empty set.\n\n``` java\npublic class UnmodifiableSetMixinTest {\n    static final String EXPECTED_JSON = \"[\\\"java.util.Collections$UnmodifiableSet\\\",[]]\";\n\n    ObjectMapper mapper;\n\n    @Before\n    public void setup() {\n        mapper = new ObjectMapper();\n        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);\n        mapper.addMixIn(Collections.unmodifiableSet(Collections.<String>emptySet()).getClass(), UnmodifiableSetMixin.class);\n    }    \n    @Test\n    @SuppressWarnings(\"unchecked\")\n    public void read() throws Exception {\n        Set<String> foo = mapper.readValue(EXPECTED_JSON, Set.class);\n        assertThat(foo).isEmpty();\n    }\n}\n```\n\nThe test passes with Jackson 2.6, but fails using Jackson 2.7+ (including Jackson 2.8.3) with the following stack trace:\n\n```\njava.lang.IllegalStateException: No default constructor for [collection type; class java.util.Collections$UnmodifiableSet, contains [simple type, class java.lang.Object]]\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createUsingDefault(StdValueInstantiator.java:240)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:249)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:110)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromArray(AsArrayTypeDeserializer.java:50)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserializeWithType(CollectionDeserializer.java:310)\n    at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2779)\n    at sample.UnmodifiableSetMixinTest.read(UnmodifiableSetMixinTest.java:36)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n```\n\nThis seems like a passivity issue. Is there a workaround for this problem?\n"
            },
            "63": {
                "commit_sha_buggy": "df6ea43bdada52d5265d52c7d6c75e25a14da8ce",
                "commit_sha_fixed": "ab4f17f355402fdfa43994e8b1809f14ccce030e",
                "report_id": "1403",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1403",
                "issue_title": "Reference-chain hints use incorrect class-name for inner classes",
                "issue_description": "``` java\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.databind.JsonMappingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\n\nimport static com.google.common.truth.Truth.assertThat;\nimport static org.junit.jupiter.api.Assertions.expectThrows;\n\npublic class ReferenceChainTest {\n    // illustrates that jackson's \"reference chain\" help-text uses incorrect class-names for inner classes\n    @Test public void incorrectReferenceChain() throws IOException {\n        JsonMappingException jsonMappingException = expectThrows(JsonMappingException.class, () -> {\n            ObjectMapper objectMapper = new ObjectMapper();\n            objectMapper.readValue(objectMapper.writeValueAsBytes(new Outer()), Outer.class);\n        });\n        JsonMappingException.Reference reference = jsonMappingException.getPath().get(0);\n        assertThat(reference.toString()).isEqualTo(\"ReferenceChainTest$Outer[\\\"inner\\\"]\");\n    }\n\n    static class Outer {\n        public Inner inner = new Inner();\n    }\n\n    static class Inner {\n        public int x;\n\n        @JsonCreator public static Inner create(@JsonProperty(\"x\") int x) {\n            throw new RuntimeException(\"test-exception\");\n        }\n    }\n}\n\n```\n"
            },
            "64": {
                "commit_sha_buggy": "8ce13b9da419f61a409f7d57d6a15dcbaea9a71b",
                "commit_sha_fixed": "ea30c7b4d7c4621f777aed4cb4552a2c1e2270a4",
                "report_id": "1417",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1417",
                "issue_title": "Further issues with `@JsonInclude` with `NON_DEFAULT`",
                "issue_description": "(follow-up to #1351)\n\nLooks like there are still cases where class annotation like:\n\n```\n@JsonInclude(JsonInclude.Include.NON_DEFAULT)\n```\n\ndoes not work for default `null` value suppression for `String` type  (at least).\n"
            },
            "65": {
                "commit_sha_buggy": "9257bd6b6a0227c400e1d008d5ad03d2244a6155",
                "commit_sha_fixed": "9a666887d85349b35e0d80885a7c7cb38029467d",
                "report_id": "1429",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1429",
                "issue_title": "`StdKeyDeserializer` can erroneously use a static factory method with more than one argument",
                "issue_description": "While investigating an issue, I found that there was different behavior for normal deserializers and key deserializers where deserializing a value as a field works as expected, but as a map key fails with \"not a valid representation: wrong number of arguments\".\n\nA basic example:\n\n``` java\nimport com.fasterxml.jackson.annotation.*;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.junit.Test;\n\nimport java.io.IOException;\nimport java.util.Map;\nimport java.util.Map.Entry;\n\nimport static org.junit.Assert.assertEquals;\n\npublic class KeyVsFieldTest {\n    @Test\n    public void deserializeAsField() throws IOException {\n        AsField as_field = new ObjectMapper().readValue(\"{\\\"name\\\": \\\"first.last\\\"}\", AsField.class);\n        assertEquals(as_field.getName()._firstname, \"first\");\n        assertEquals(as_field.getName()._lastname, \"last\");\n    }\n\n    @Test\n    public void deserializeAsKey() throws IOException {\n        Map<FullName, Double> map =\n            new ObjectMapper().readValue(\"{\\\"first.last\\\": 42}\", new TypeReference<Map<FullName, Double>>() {\n            });\n       /* \n          Fails with: com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not construct Map key of type KeyVsFieldTest$FullName from String \"first.last\": not a valid representation: wrong number of arguments\n at [Source: java.io.StringReader@7113b13f; line: 1, column: 2]\n       */\n\n        Entry<FullName, Double> entry = map.entrySet().iterator().next();\n\n        assertEquals(entry.getKey()._firstname, \"first\");\n        assertEquals(entry.getKey()._lastname, \"last\");\n        assertEquals(entry.getValue().doubleValue(), 42, 0);\n    }\n\n    public static class AsField {\n        private final FullName _name;\n\n        public AsField(@JsonProperty(\"name\") FullName aName) {\n            _name = aName;\n        }\n\n        public FullName getName() {\n            return _name;\n        }\n    }\n\n    public static class FullName {\n        private final String _firstname;\n        private final String _lastname;\n\n        private FullName(String firstname, String lastname) {\n            _firstname = firstname;\n            _lastname = lastname;\n        }\n\n        @JsonCreator\n        public static FullName valueOf(String value) {\n            String[] mySplit = value.split(\"\\\\.\");\n            return new FullName(mySplit[0], mySplit[1]);\n        }\n\n        public static FullName valueOf(String firstname, String lastname) {\n            return new FullName(firstname, lastname);\n        }\n\n        @JsonValue\n        @Override\n        public String toString() {\n            return _firstname + \".\" + _lastname;\n        }\n    }\n}\n```\n\nIt looks like this is because in `BasicBeanDescriptor`, `findFactoryMethod` has an incorrect assumption about the contents of `_classInfo.getStaticMethods()`, which will have any method named `valueOf` and static methods annotated with `@JsonCreator`:\n\n``` java\n    @Override\n    public Method findFactoryMethod(Class<?>... expArgTypes)\n    {\n        // So, of all single-arg static methods:\n        for (AnnotatedMethod am : _classInfo.getStaticMethods()) {\n            if (isFactoryMethod(am)) {\n                // And must take one of expected arg types (or supertype)\n                Class<?> actualArgType = am.getRawParameterType(0);\n                for (Class<?> expArgType : expArgTypes) {\n                    // And one that matches what we would pass in\n                    if (actualArgType.isAssignableFrom(expArgType)) {\n                        return am.getAnnotated();\n                    }\n                }\n            }\n        }\n        return null;\n    }\n```\n\nThis can be worked around by annotating static factory methods not intended to be used as `@JsonCreator`s with `@JsonIgnore`, due to the resolution in `_classInfo.getStaticMethods()`, so is not really urgent.\n\nPlease let me know if you have any questions about the issue!\n\nThanks,\nChris\n"
            },
            "66": {
                "commit_sha_buggy": "31ceee75592e1767bd1072eb670b43dcced5de26",
                "commit_sha_fixed": "cd5430a91723ff8cd61928524ec21ab4e14b20f6",
                "report_id": "1441",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1441",
                "issue_title": "Failure with custom Enum key deserializer, polymorphic types",
                "issue_description": "Normally the `JsonParser` and the `DeserializationContext` is passed to a `Module`'s `JsonDeserializer`. \r\n\r\nHowever, in the `MapDeserializer`, when deserializing a `Map` with an `Enum` key, the `KeyDeserializer` doesn't accept the `JsonParser` as an argument:\r\n\r\nhttps://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/deser/std/MapDeserializer.java#L453\r\n    Object key = keyDes.deserializeKey(keyStr, ctxt);\r\n\r\nand the `StdKeyDeserializer.DelegatingKD` uses the context's parser\r\n\r\nhttps://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/deser/std/StdKeyDeserializer.java#L315\r\n   Object result = _delegate.deserialize(ctxt.getParser(), ctxt);\r\n\r\nWhen the type info field is missing from the json, the `DeserializationContext`'s `JsonParser`'s token is `END_OBJECT` (presumably because it `nextToken`'d through the object to find type and whiffed). \r\n\r\nThis makes the module fail since the `JsonParser` in the `Module` is wrong, i.e. not the same as the `JsonParser` in the `MapDeserializer`.\r\n\r\nClass:\r\n\r\n    import com.fasterxml.jackson.annotation.JsonTypeInfo;\r\n    \r\n    import java.util.Map;\r\n    \r\n    import static com.fasterxml.jackson.annotation.JsonTypeInfo.Id.NAME;\r\n    \r\n    @JsonTypeInfo(use = NAME, property = \"@type\", defaultImpl = SuperType.class)\r\n    public class SuperType {\r\n        private Map<SuperTypeEnum, String> someMap;\r\n    \r\n        public Map<SuperTypeEnum, String> getSomeMap() {\r\n            return someMap;\r\n        }\r\n    \r\n        public void setSomeMap(Map<SuperTypeEnum, String> someMap) {\r\n            this.someMap = someMap;\r\n        }\r\n    }\r\n\r\nEnum:\r\n\r\n    public enum SuperTypeEnum {\r\n        FOO\r\n    }\r\n\r\n\r\nTest:\r\n\r\n    import com.fasterxml.jackson.core.JsonParser;\r\n    import com.fasterxml.jackson.databind.DeserializationContext;\r\n    import com.fasterxml.jackson.databind.JsonDeserializer;\r\n    import com.fasterxml.jackson.databind.ObjectMapper;\r\n    import com.fasterxml.jackson.databind.module.SimpleModule;\r\n    import org.junit.*;\r\n\r\n    import java.io.IOException;\r\n\r\n    import static org.junit.Assert.assertEquals;\r\n\r\n    public class TestDeserializeType {\r\n\r\n        @Test\r\n        public void testNoTypeShouldDeserialize() throws IOException {\r\n            String json = \"{\\\"someMap\\\": {\\\"FOO\\\": \\\"bar\\\"}}\";\r\n            ObjectMapper mapper = new ObjectMapper();\r\n            SuperType superType = mapper.readValue(json, SuperType.class);\r\n            assertEquals(\"Deserialized someMap.FOO should equal bar\", \"bar\", superType.getSomeMap().get(SuperTypeEnum.FOO));\r\n        }\r\n\r\n        @Test\r\n        public void testNoTypeWithModuleShouldDeserialize() throws IOException {\r\n            String json = \"{\\\"someMap\\\": {\\\"FOO\\\": \\\"bar\\\"}}\";\r\n            ObjectMapper mapper = new ObjectMapper();\r\n            SimpleModule simpleModule = new SimpleModule();\r\n            simpleModule.addDeserializer(SuperTypeEnum.class, new JsonDeserializer<SuperTypeEnum>() {\r\n                @Override\r\n                public SuperTypeEnum deserialize(JsonParser jsonParser, DeserializationContext deserializationContext)\r\n                        throws IOException {\r\n\r\n                    return SuperTypeEnum.valueOf(jsonParser.getText());\r\n                }\r\n            });\r\n            mapper.registerModule(simpleModule);\r\n\r\n            SuperType superType = mapper.readValue(json, SuperType.class);\r\n            assertEquals(\"Deserialized someMap.FOO should equal bar\", \"bar\", superType.getSomeMap().get(SuperTypeEnum.FOO));\r\n        }\r\n    }\r\n"
            },
            "67": {
                "commit_sha_buggy": "cd5430a91723ff8cd61928524ec21ab4e14b20f6",
                "commit_sha_fixed": "d906a34178f27803a08e824e3c2474fc0863edc4",
                "report_id": "1445",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1445",
                "issue_title": "Map key deserializerModifiers ignored",
                "issue_description": "We have a module that extends simple model to allow us to accept enum names in lower case in a fairly generic manner\r\nInside that we add the `modifyKeyDeserializer`\r\n\r\nThe incoming class (using immutables) is mapped to a guava immutable map.\r\nWalking through the code:\r\n\r\n> com.fasterxml.jackson.datatype.guava.deser.ImmutableMapDeserializer.createContextual\r\n>  calls DeserializationContext.findKeyDeserializer\r\n>  calls DeserializerCache.findKeyDeserializer\r\n>  calls BasicDeserializerFactory.createKeyDeserializer\r\n\r\nwhich has the code:\r\n```java\r\n        // the only non-standard thing is this:\r\n        if (deser == null) {\r\n            if (type.isEnumType()) {\r\n                return _createEnumKeyDeserializer(ctxt, type);\r\n            }\r\n            deser = StdKeyDeserializers.findStringBasedKeyDeserializer(config, type);\r\n        }\r\n```\r\n\r\nSince we are an enum type, it returns the value in the `_createEnumKeyDeserializer`, which is the standard enum deserializer.\r\nBelow that block is the check for the hasDeserializerModifiers, but since we have returned already, it is never called, so we can't override the behaviour.\r\n\r\nModule fragment:\r\n```java\r\n    setDeserializerModifier(new BeanDeserializerModifier() {\r\n                @Override\r\n                @SuppressWarnings(\"unchecked\")\r\n                public JsonDeserializer<Enum> modifyEnumDeserializer(\r\n                        DeserializationConfig config,\r\n                        final JavaType type,\r\n                        BeanDescription beanDesc,\r\n                        final JsonDeserializer<?> deserializer) {\r\n                    return new JsonDeserializer<Enum>() {\r\n                        @Override\r\n                        public Enum deserialize(JsonParser jp, DeserializationContext ctxt) throws IOException {\r\n                            Class<? extends Enum> rawClass = (Class<Enum<?>>) type.getRawClass();\r\n                            return Enum.valueOf(rawClass, jp.getValueAsString().toUpperCase());\r\n                        }\r\n                    };\r\n                }\r\n\r\n                @Override\r\n                public KeyDeserializer modifyKeyDeserializer(\r\n                        DeserializationConfig config,\r\n                        JavaType type,\r\n                        KeyDeserializer deserializer) {\r\n                    if (!type.isEnumType()) {\r\n                        return super.modifyKeyDeserializer(config, type, deserializer);\r\n                    }\r\n                    return new KeyDeserializer() {\r\n                        @Override\r\n                        @SuppressWarnings(\"unchecked\")\r\n                        public Object deserializeKey(String key, DeserializationContext ctxt)\r\n                                throws IOException, JsonProcessingException {\r\n                            Class<? extends Enum> rawClass = (Class<Enum<?>>) type.getRawClass();\r\n                            return Enum.valueOf(rawClass, key.toUpperCase());\r\n                        }\r\n                    };\r\n                }\r\n            });\r\n```\r\n\r\nI appreciate the code around here is fairly complex.\r\n\r\n\r\nRelated issues (possibly):\r\nhttps://github.com/FasterXML/jackson-databind/issues/749\r\nhttps://github.com/FasterXML/jackson-databind/issues/1313"
            },
            "68": {
                "commit_sha_buggy": "1aeb52554a104f0a2433788be406d53b39654952",
                "commit_sha_fixed": "d0cfb645350fab16bf61fac140b69ef55f8cba2e",
                "report_id": "1421",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1421",
                "issue_title": "ACCEPT_SINGLE_VALUE_AS_ARRAY partially broken in 2.7.x, 2.8.x",
                "issue_description": "In 2.7.x, 2.8.x versions following test fails with an exception:\r\n\r\n```\r\npublic class Test {\r\n    private static final String JSON = \"[{\\\"message\\\":\\\"messageHere\\\"}]\";\r\n\r\n    static class A {\r\n        List<B> bs = Collections.emptyList();\r\n\r\n        @JsonCreator\r\n        A(final List<B> bs) {\r\n            this.bs = bs;\r\n        }\r\n    }\r\n\r\n    static class B {\r\n        List<C> cs = Collections.emptyList();\r\n\r\n        @JsonCreator\r\n        B(final List<C> cs) {\r\n            this.cs = cs;\r\n        }\r\n    }\r\n\r\n    public static class C {\r\n        String message;\r\n\r\n        @JsonCreator\r\n        C(@JsonProperty(\"message\") String message) {\r\n            this.message = message;\r\n        }\r\n    }\r\n\r\n    @Test\r\n    public void test() throws IOException {\r\n        ObjectMapper om = new ObjectMapper();\r\n        om.configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true);\r\n        om.readValue(JSON, A.class);\r\n    }\r\n}\r\n\r\n\r\ncom.fasterxml.jackson.databind.exc.InputMismatchException: Can not construct instance of com.fasterxml.jackson.databind.creators.JsonCreatorWithCollectionTest$B, problem: no suitable constructor found, can not deserialize from Object value (missing default constructor or creator, or perhaps need to add/enable type information?)\r\n at [Source: [{\"message\":\"site is missing from bid request (breq) object\"}]; line: 1, column: 3] (through reference chain: java.util.ArrayList[0])\r\n\r\n    at com.fasterxml.jackson.databind.exc.InputMismatchException.from(InputMismatchException.java:58)\r\n    at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1354)\r\n    at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1019)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1207)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:314)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:148)\r\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:289)\r\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:261)\r\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromArray(BeanDeserializerBase.java:1336)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:174)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:150)\r\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3806)\r\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2849)\r\n    at com.fasterxml.jackson.databind.creators.JsonCreatorWithCollectionTest.test(JsonCreatorWithCollectionTest.java:51)\r\n```\r\n\r\nWhile on 2.5 and 2.6 it works fine.\r\n"
            },
            "69": {
                "commit_sha_buggy": "002a9a3e9b98ebebf53e43aed0536d3c50851c84",
                "commit_sha_fixed": "d44600d3750e5dba9fac68aee7248ed2a80a2225",
                "report_id": "1476",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1476",
                "issue_title": "Wrong constructor picked up when deserializing object",
                "issue_description": "I discovered an issue with Jackson 2.7.8 (and Jackson 2.8.4) when several constructors have parameters annotated with `@JsonProperty` but only one is annotated with `@JsonCreator`.\r\n\r\nHere's a test case to reproduce it:\r\n```\r\nimport static org.junit.Assert.assertEquals;\r\n\r\nimport java.io.IOException;\r\n\r\nimport org.junit.Test;\r\n\r\nimport com.fasterxml.jackson.annotation.JsonCreator;\r\nimport com.fasterxml.jackson.annotation.JsonProperty;\r\nimport com.fasterxml.jackson.core.JsonParseException;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\n\r\npublic class TestJackson {\r\n  public static final class SimplePojo {\r\n    private final int intField;\r\n    private final String stringField;\r\n\r\n    public SimplePojo(@JsonProperty(\"intField\") int intField) {\r\n      this(intField, \"empty\");\r\n    }\r\n\r\n    public SimplePojo(@JsonProperty(\"stringField\") String stringField) {\r\n      this(-1, stringField);\r\n    }\r\n\r\n    @JsonCreator\r\n    public SimplePojo(@JsonProperty(\"intField\") int intField, @JsonProperty(\"stringField\") String stringField) {\r\n      this.intField = intField;\r\n      this.stringField = stringField;\r\n    }\r\n\r\n    public int getIntField() {\r\n      return intField;\r\n    }\r\n\r\n    public String getStringField() {\r\n      return stringField;\r\n    }\r\n  }\r\n\r\n  @Test\r\n  public void testJackson() throws JsonParseException, IOException {\r\n    ObjectMapper mapper = new ObjectMapper();\r\n    SimplePojo pojo = mapper.readValue(\"{ \\\"intField\\\": 1, \\\"stringField\\\": \\\"foo\\\" }\", SimplePojo.class);\r\n\r\n    assertEquals(1, pojo.getIntField());\r\n    assertEquals(\"foo\", pojo.getStringField());\r\n  }\r\n}\r\n```\r\n\r\nThis test throws an the following exception:\r\n```\r\ncom.fasterxml.jackson.databind.JsonMappingException: Could not find creator property with name 'stringField' (in class org.apache.drill.TestJackson$SimplePojo)\r\n at [Source: { \"intField\": 1, \"stringField\": \"foo\" }; line: 1, column: 1]\r\n\tat com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:270)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.reportMappingException(DeserializationContext.java:1234)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.addBeanProps(BeanDeserializerFactory.java:551)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.buildBeanDeserializer(BeanDeserializerFactory.java:226)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:141)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:403)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:349)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:476)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:3899)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3794)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2842)\r\n\tat TestJackson.testJackson(TestJackson.java:45)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:606)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)\r\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\r\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\r\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)\r\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\r\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\r\n```\r\n\r\nAfter some debugging, it looks like that `BasicDeserializerFactory#_addDeserializerConstructors(...)` is looping over all the constructors, and is not favoring an explicit constructor over a non-explicit one. \r\n\r\nI actually don't know what should be the expected behavior: should jackson fail when two constructors are annotated, or should jackson favor the one annotated with `@JsonCreator`. Both options look reasonable to me (and I'm actually removing one of the constructors)."
            },
            "70": {
                "commit_sha_buggy": "7fe2d4f1aaab61e41f31f792f8a988157a34b34c",
                "commit_sha_fixed": "d7155de6c37db3301b92b755bd0a02388f7dd07f",
                "report_id": "1493",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1493",
                "issue_title": "`ACCEPT_CASE_INSENSITIVE_PROPERTIES` fails with `@JsonUnwrapped`",
                "issue_description": "(note: moved from https://github.com/FasterXML/jackson-dataformat-csv/issues/133)\r\n\r\nWhen trying to deserialize type like:\r\n\r\n```java\r\npublic class Person {\r\n  @JsonUnwrapped(prefix = \"businessAddress.\")\r\n  public Address businessAddress;\r\n}\r\n\r\npublic class Address {\r\n  public String street;\r\n  public String addon;\r\n  public String zip = \"\";\r\n  public String town;    \r\n  public String country;\r\n}\r\n```\r\n\r\nwith case-insensitive mapper (`mapper.enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES);`) I get exception:\r\n\r\n```\r\njava.util.NoSuchElementException: No entry 'businessAddress' found, can't remove\r\n\tat com.fasterxml.jackson.databind.deser.impl.BeanPropertyMap.remove(BeanPropertyMap.java:447)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:534)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)\r\n   ...\r\n```\r\n"
            },
            "71": {
                "commit_sha_buggy": "d44600d3750e5dba9fac68aee7248ed2a80a2225",
                "commit_sha_fixed": "23a733207bc88a06ee486a5896b7b0c4ebbbfef4",
                "report_id": "1506",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1506",
                "issue_title": "Missing `KeyDeserializer` for `CharSequence`",
                "issue_description": "Looks like use of nominal Map key type of `CharSequence` does not work yet (as of 2.7.8 / 2.8.6).\r\nThis is something that is needed to work with certain frameworks, such as Avro's generated POJOs.\r\n\r\n"
            },
            "72": {
                "commit_sha_buggy": "d3874ebf3c0585270f1fe33eb7030667bacb63b7",
                "commit_sha_fixed": "63afa5297a0b8bcbf31b9c91e5d15537e0fdbdd5",
                "report_id": "1501",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1501",
                "issue_title": "ArrayIndexOutOfBoundsException on impossible non-static inner class constructor",
                "issue_description": "Minimal repro:\r\n\r\n```java\r\npublic class Something {\r\n    public InnerSomething a;\r\n\r\n    @JsonCreator\r\n    public Something(@JsonProperty(\"a\") InnerSomething a) {}\r\n\r\n    class InnerSomething {\r\n        @JsonCreator\r\n        public InnerSomething() {}\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n        ObjectMapper mapper = new ObjectMapper();\r\n        String ser = mapper.writeValueAsString(new Something(null));\r\n        mapper.readValue(ser, Something.class);\r\n```\r\n\r\nFails like this:\r\n\r\n```\r\njava.lang.ArrayIndexOutOfBoundsException: -1\r\n\r\n\tat com.fasterxml.jackson.databind.deser.impl.PropertyValueBuffer.assignParameter(PropertyValueBuffer.java:210)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:380)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1123)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:298)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:133)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3807)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2797)\r\n```\r\n\r\nValidation is missing for this impossible constructor. Works as expected when `InnerSomething` is static."
            },
            "73": {
                "commit_sha_buggy": "2bb770bcd4cbc0c0c3ede86cedd4a602e328e2f6",
                "commit_sha_fixed": "4d34006e4d8a566c6c64a3a0e04c17e50d63bb82",
                "report_id": "935",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/935",
                "issue_title": "@JsonProperty(access = Access.READ_ONLY) - unexpected behaviour",
                "issue_description": "Hey,\n\nI was hoping to make use of @JsonProperty(access = Access.READ_ONLY), but failed.\n\nAssume this class:\n\n```\npublic class TestPojo\n{\n    private String firstName;\n\n    private String lastName;\n\n    @JsonProperty(access = Access.READ_ONLY)\n    public String getFullName()\n    {\n        return firstName + \" \" + lastName;\n    }\n\n    public String getFirstName()\n    {\n        return firstName;\n    }\n\n    public void setFirstName(String firstName)\n    {\n        this.firstName = firstName;\n    }\n\n    public String getLastName()\n    {\n        return lastName;\n    }\n\n    public void setLastName(String lastName)\n    {\n        this.lastName = lastName;\n    }\n}\n```\n\nI couldn't find a way to stop the deserializer from attempting to deserialize the field \"fullName\".\nThe only thing that helps is to create a setter and annotate it with `@JsonIgnore`. However, that setter does not make sense and I don't want to have it. Is this a bug in behaviour or am I missing something? Thanks\n"
            },
            "74": {
                "commit_sha_buggy": "ce37efcefbfab0fa91562a492f0f80af018a5313",
                "commit_sha_fixed": "10d5ab37f06f7925bf959312bfb6211f5bc4a1cb",
                "report_id": "1533",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1533",
                "issue_title": "AsPropertyTypeDeserializer ignores DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT",
                "issue_description": "The `AsPropertyTypeDeserializer ` implementation does not respect the `DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT` feature. When deserializing an empty String it throws `DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT` instead of creating a null Object."
            },
            "75": {
                "commit_sha_buggy": "ef17f26b4ad3a28979cd06b1ddaeda99080135b3",
                "commit_sha_fixed": "ce114737139538f72d2a7a994db41befc32362fe",
                "report_id": "1543",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1543",
                "issue_title": "JsonFormat.Shape.NUMBER_INT does not work when defined on enum type in 2.8",
                "issue_description": "Before 2.8 the following worked for years. Now this annotation is not applied and enum is serialized as string. It would work if annotating the field. I am not sure if this is an expected change or not, could you please check?\r\n\r\n```java\r\npublic class Test {\r\n    @JsonFormat(shape = JsonFormat.Shape.NUMBER_INT)\r\n    enum Color {\r\n        RED,\r\n        YELLOW,\r\n        GREEN\r\n    }\r\n\r\n    static class Foo {\r\n        public final Color color;\r\n\r\n        Foo(Color color) {\r\n            this.color = color;\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws JsonProcessingException {\r\n        final ObjectMapper mapper = new ObjectMapper();\r\n        System.out.println(mapper.writeValueAsString(new Foo(Color.GREEN)));\r\n    }\r\n}\r\n```"
            },
            "76": {
                "commit_sha_buggy": "934f485d4c62854dd2ef48ed7ebb238f3abec0b7",
                "commit_sha_fixed": "e08dafef4faa7d71330160dafcbe77536d90e809",
                "report_id": "1573",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1573",
                "issue_title": "Missing properties when deserializing using a builder class with a non-default constructor and a mutator annotated with `@JsonUnwrapped`",
                "issue_description": "When deserializing using a builder class with a non-default constructor and any number of mutator methods annotated with @JsonUnwrapped, the `BuilderBasedDeserializer::deserializeUsingPropertyBasedWithUnwrapped` method cuts short the process of adding SettableBeanProperties.\r\n\r\nThe logic dictates that once all properties necessary to construct the builder have been found, the builder is constructed using all known SettableBeanProperties that have been found up to that point in the tokenizing process.\r\n\r\nTherefore, in the case that the builder has a single property required for construction, and that property is found anywhere other than at the end of the JSON content, any properties subsequent to the constructor property are not evaluated and are left with their default values.\r\n\r\nGiven the following classes:\r\n```java\r\n@JsonDeserialize(builder = Employee.Builder.class)\r\npublic class Employee {\r\n    private final long id;\r\n    private final Name name;\r\n    private final int age;\r\n\r\n    private Employee(Builder builder) {\r\n        id = builder.id;\r\n        name = builder.name;\r\n        age = builder.age;\r\n    }\r\n\r\n    public long getId() {\r\n        return id;\r\n    }\r\n\r\n    public Name getName() {\r\n        return name;\r\n    }\r\n\r\n    public int getAge() {\r\n        return age;\r\n    }\r\n\r\n    @JsonPOJOBuilder(withPrefix = \"set\")\r\n    public static class Builder {\r\n        private final long id;\r\n        private Name name;\r\n        private int age;\r\n\r\n        @JsonCreator\r\n        public Builder(@JsonProperty(\"emp_id\") long id) {\r\n            this.id = id;\r\n        }\r\n\r\n        @JsonUnwrapped\r\n        public void setName(Name name) {\r\n            this.name = name;\r\n        }\r\n\r\n        @JsonProperty(\"emp_age\")\r\n        public void setAge(int age) {\r\n            this.age = age;\r\n        }\r\n\r\n        public Employee build() {\r\n            return new Employee(this);\r\n        }\r\n    }\r\n}\r\n\r\npublic class Name {\r\n    private final String first;\r\n    private final String last;\r\n\r\n    @JsonCreator\r\n    public Name(\r\n        @JsonProperty(\"emp_first_name\") String first,\r\n        @JsonProperty(\"emp_last_name\") String last\r\n    ) {\r\n        this.first = first;\r\n        this.last = last;\r\n    }\r\n\r\n    public String getFirst() {\r\n        return first;\r\n    }\r\n\r\n    public String getLast() {\r\n        return last;\r\n    }\r\n}\r\n```\r\nAnd given the following JSON string:\r\n```json\r\n{\r\n    \"emp_age\": 30,\r\n    \"emp_id\": 1234,\r\n    \"emp_first_name\": \"John\",\r\n    \"emp_last_name\": \"Doe\"\r\n}\r\n```\r\nWe will see the following output:\r\n```java\r\nEmployee emp = new ObjectMapper().readValue(json, Employee.class);\r\n\r\nSystem.out.println(emp.getAge()); // 30\r\nSystem.out.println(emp.getId()); // 1234\r\nSystem.out.println(emp.getName()); // null\r\n```\r\nHowever, if we place the `emp_id` property at the end of the JSON string, we would get the following output:\r\n```java\r\nEmployee emp = new ObjectMapper().readValue(json, Employee.class);\r\n\r\nSystem.out.println(emp.getAge()); // 30\r\nSystem.out.println(emp.getId()); // 1234\r\nSystem.out.println(emp.getName()); // Name Object\r\n```\r\nIf we were to place `emp_age` and `emp_first_name` and `emp_last_name` all after the `emp_id` property in the JSON string, we would get the following output:\r\n```java\r\nEmployee emp = new ObjectMapper().readValue(json, Employee.class);\r\n\r\nSystem.out.println(emp.getAge()); // 0\r\nSystem.out.println(emp.getId()); // 1234\r\nSystem.out.println(emp.getName()); // null\r\n```"
            },
            "77": {
                "commit_sha_buggy": "28ec8a47d381311818f805ae76bf84da30f516f9",
                "commit_sha_fixed": "6ce32ffd18facac6abdbbf559c817b47fcb622c1",
                "report_id": "1599",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1599",
                "issue_title": "Jackson Deserializer security vulnerability via default typing (CVE-2017-7525)",
                "issue_description": "I have send email to info@fasterxml.com\r\n\r\n**EDIT**: (23-Apr-2024)\r\n\r\nFix in:\r\n\r\n* 2.7.9.1\r\n* 2.8.9\r\n* 2.9.0 and all later 2.x releases\r\n"
            },
            "78": {
                "commit_sha_buggy": "b64c7736015d28c20857cdb91584308c78edd8e8",
                "commit_sha_fixed": "60d459cedcf079c6106ae7da2ac562bc32dcabe1",
                "report_id": "1599",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1599",
                "issue_title": "Jackson Deserializer security vulnerability via default typing (CVE-2017-7525)",
                "issue_description": "I have send email to info@fasterxml.com\r\n\r\n**EDIT**: (23-Apr-2024)\r\n\r\nFix in:\r\n\r\n* 2.7.9.1\r\n* 2.8.9\r\n* 2.9.0 and all later 2.x releases\r\n"
            },
            "79": {
                "commit_sha_buggy": "8e98ed66bc262681a38052682ec5b6a42120f7f7",
                "commit_sha_fixed": "ec859af181fa5b2da62077d00154e3c13c9d8f28",
                "report_id": "1607",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1607",
                "issue_title": "@JsonIdentityReference not used when setup on class only",
                "issue_description": "I am trying to setup @JsonIdentityInfo/@JsonIdentityReference in order to serialize all references to a given class as Object Id (and deserialize them later using a custom ObjectIdResolver to retrieve the proper referenced instance)\r\n\r\nI use @JsonIdentityReference(alwaysAsId=true) in order to enforce exporting the object id in all cases.\r\nIt does not work as expected when I define the annotation only on the class (but it works fine when I set it directly on the property). I would rather not have to define it on every property as I will probably miss some...\r\n\r\nFrom what I see in [BeanSerializerBase](https://github.com/FasterXML/jackson-databind/blob/fea0d29eabcb8e4825a318501b35f8a759c91426/src/main/java/com/fasterxml/jackson/databind/ser/std/BeanSerializerBase.java#L473), the alwaysAsId is reset when not ObjectIdInfo is found on the accessor:\r\n\r\n```java\r\n            ObjectIdInfo objectIdInfo = intr.findObjectIdInfo(accessor);\r\n            if (objectIdInfo == null) {\r\n                // no ObjectId override, but maybe ObjectIdRef?\r\n                if (oiw != null) {\r\n                    objectIdInfo = intr.findObjectReferenceInfo(accessor,\r\n                            new ObjectIdInfo(NAME_FOR_OBJECT_REF, null, null, null));\r\noiw = _objectIdWriter.withAlwaysAsId(objectIdInfo.getAlwaysAsId());\r\n```\r\n\r\nShouldn't it be kept to the current value when no override is found ?\r\nI tried to set it back in the default ObjectIdInfo created with NAME_FOR_OBJECT_REF but I am not sure if this is the right way to fix this.\r\n\r\nHere is test I added in [TestObjectIdSerialization](https://github.com/vboulaye/jackson-databind/blob/master/src/test/java/com/fasterxml/jackson/databind/objectid/TestObjectIdSerialization.java#L324) for this case:\r\n```java\r\n\r\n    @JsonIdentityInfo(generator=ObjectIdGenerators.IntSequenceGenerator.class, property=\"id\")\r\n    @JsonIdentityReference(alwaysAsId=true)\r\n    static class ReallyAlwaysAsId\r\n    {\r\n        public int value;\r\n\r\n        public ReallyAlwaysAsId() { this(0); }\r\n        public ReallyAlwaysAsId(int v) {\r\n            value = v;\r\n        }\r\n    }\r\n\r\n    @JsonPropertyOrder(alphabetic=true)\r\n    static class ReallyAlwaysContainer\r\n    {\r\n\r\n        @JsonIdentityReference(alwaysAsId=true)\r\n        public AlwaysAsId a = new AlwaysAsId(13);\r\n\r\n        public ReallyAlwaysAsId b = new ReallyAlwaysAsId(13);\r\n\r\n    }\r\n\r\n    public void testReallyAlwaysAsId() throws Exception\r\n    {\r\n        String json = MAPPER.writeValueAsString(new ReallyAlwaysContainer());\r\n        assertEquals(\"{\\\"a\\\":1,\\\"b\\\":2}\", json);\r\n    }\r\n\r\n```"
            },
            "80": {
                "commit_sha_buggy": "8c20a7670f71958c9af6c8daffab227d2d7ba87a",
                "commit_sha_fixed": "974ccddfd718a06f889da2dcd58ebb6bc22c8dca",
                "report_id": "1616",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1616",
                "issue_title": "Extraneous type id mapping added for base type itself",
                "issue_description": "Looks like type id (name) matching base type is included in type resolution list, automatically. While this might be useful sometimes it seems quite odd, and probably should only be included if:\r\n\r\n1. Base type is concrete and\r\n2. Base type has explicit name (not add if default name used)\r\n"
            },
            "81": {
                "commit_sha_buggy": "974ccddfd718a06f889da2dcd58ebb6bc22c8dca",
                "commit_sha_fixed": "029413a6e381bb04b7b0a420730d3119e9cc0961",
                "report_id": "1592",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1592",
                "issue_title": "Add support for handling primitive/discrepancy problem with type refinements",
                "issue_description": "(note: derived from https://github.com/FasterXML/jackson-module-jaxb-annotations/issues/64)\r\n\r\nThe problem is that although `int` and `java.lang.Integer` are related, logically, they are not related by inheritance (or implementation). Since some legacy code may try refinements in this axis it'd be nice to handle this somehow. Two basic approaches would be:\r\n\r\n1. Just ignore primitive/wrapper override, return original type as is\r\n2. Allow wrapper to \"refine\" primitive, return wrapper.\r\n\r\nThere is also related question of whether to allow \"int to long\" and similar refinements, but start with basics.\r\n"
            },
            "82": {
                "commit_sha_buggy": "dec4a483d9d70a8e7d14e28474058ef50df1204d",
                "commit_sha_fixed": "4a2b1ae08ded66b77e05bf8fa0ac8a2e8c60709d",
                "report_id": "1595",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1595",
                "issue_title": "`JsonIgnoreProperties.allowSetters` is not working in Jackson 2.8",
                "issue_description": "```\r\n@JsonIgnoreProperties(value = { \"password\" }, ignoreUnknown = true, allowSetters = true)\r\npublic class JsonTest {\r\n\tprivate String username;\r\n\tprivate String password;\r\n\r\n\tpublic JsonTest() {\r\n\t\tsuper();\r\n\t\t// TODO Auto-generated constructor stub\r\n\t}\r\n\r\n\tpublic JsonTest(String username, String password) {\r\n\t\tsuper();\r\n\t\tthis.username = username;\r\n\t\tthis.password = password;\r\n\t}\r\n\r\n\tpublic String getUsername() {\r\n\t\treturn username;\r\n\t}\r\n\r\n\tpublic void setUsername(String username) {\r\n\t\tthis.username = username;\r\n\t}\r\n\r\n\tpublic String getPassword() {\r\n\t\treturn password;\r\n\t}\r\n\r\n\tpublic void setPassword(String password) {\r\n\t\tthis.password = password;\r\n\t}\r\n\r\n\tpublic static void main(String[] args) {\r\n\t\tObjectMapper mapper = new ObjectMapper();\r\n\r\n\t\tJsonTest json = new JsonTest(\"user\", \"password\");\r\n\r\n\t\ttry {\r\n\t\t\tSystem.out.println(mapper.writeValueAsString(json));\r\n\t\t} catch (JsonProcessingException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\r\n\t\tString jsonString = \"{ \\\"username\\\":\\\"username\\\",\\\"password\\\":\\\"password\\\" }\";\r\n\t\ttry {\r\n\t\t\tjson = mapper.readValue(jsonString, JsonTest.class);\r\n\r\n\t\t\tSystem.out.println(json.getPassword());\r\n\t\t} catch (IOException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\r\n\t}\r\n}\r\n```\r\n\r\nthe version is 2.8.7.\r\nthe password cannot deserialize.\r\nthe output is:\r\n{\"username\":\"user\"}\r\nnull"
            },
            "83": {
                "commit_sha_buggy": "edaa4ad8204dfda985d3c74ffe542c9eb67a201d",
                "commit_sha_fixed": "9a083ad56b20711eab368a7818fb079a870feb93",
                "report_id": "1629",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1629",
                "issue_title": "`FromStringDeserializer` ignores registered `DeserializationProblemHandler` for `java.util.UUID`",
                "issue_description": "Culprit appears to be [lines 155-161 of FromStringDeserializer](https://github.com/FasterXML/jackson-databind/blob/60ae6000d361f910ab0d7d269a5bac1fc66f4cd9/src/main/java/com/fasterxml/jackson/databind/deser/std/FromStringDeserializer.java#L155-L161):\r\n\r\n```\r\n            // 05-May-2016, tatu: Unlike most usage, this seems legit, so...\r\n            JsonMappingException e = ctxt.weirdStringException(text, _valueClass, msg);\r\n            if (cause != null) {\r\n                e.initCause(cause);\r\n            }\r\n            throw e;\r\n            // nothing to do here, yet? We'll fail anyway\r\n```\r\nThe above lines appear to show that the exception will be thrown regardless of any problem handling logic.\r\n\r\nTest Case:\r\n\r\n```\r\nimport com.fasterxml.jackson.databind.DeserializationContext;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport com.fasterxml.jackson.databind.deser.DeserializationProblemHandler;\r\nimport org.junit.Test;\r\n\r\nimport java.io.IOException;\r\nimport java.util.UUID;\r\n\r\npublic class UUIDDeserializerTest {\r\n\r\n\r\n  @Test\r\n  public void itUsesDeserializationProblemHandlerProperly() throws IOException {\r\n    ObjectMapper mapper = new ObjectMapper().addHandler(new DeserializationProblemHandler() {\r\n      @Override\r\n      public Object handleWeirdStringValue(final DeserializationContext ctxt, final Class<?> targetType, final String valueToConvert, final String failureMsg) throws IOException {\r\n        return null;\r\n      }\r\n    });\r\n\r\n    mapper.readValue(\"{\\\"id\\\" : \\\"I am not a UUID\\\"}\", IdBean.class);\r\n\r\n\r\n\r\n  }\r\n\r\n  public static class IdBean {\r\n    private UUID id;\r\n\r\n    public UUID getId() {\r\n      return id;\r\n    }\r\n\r\n    public void setId(final UUID id) {\r\n      this.id = id;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThe handler handles the issue properly; but an exception is thrown anyway:\r\n\r\n```\r\nan not deserialize value of type java.util.UUID from String \"I am not a UUID\": not a valid textual representation\r\n at [Source: (String)\"{\"id\" : \"I am not a UUID\"}\"; line: 1, column: 9] (through reference chain: com.company.test.UUIDDeserializerTest$IdBean[\"id\"])\r\ncom.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type java.util.UUID from String \"I am not a UUID\": not a valid textual representation\r\n at [Source: (String)\"{\"id\" : \"I am not a UUID\"}\"; line: 1, column: 9] (through reference chain: com.company.test.UUIDDeserializerTest$IdBean[\"id\"])\r\n\tat com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.weirdStringException(DeserializationContext.java:1504)\r\n\tat com.fasterxml.jackson.databind.deser.std.FromStringDeserializer.deserialize(FromStringDeserializer.java:156)\r\n\tat com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:127)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:287)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:151)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3999)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2980)\r\n```\r\n"
            },
            "84": {
                "commit_sha_buggy": "9b9e47b889751ed72154bbff11e8181089e88e78",
                "commit_sha_fixed": "1a0326fbc31d3d9f1e5145dc71b937820142d111",
                "report_id": "1647",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1647",
                "issue_title": "Missing properties from base class when recursive types are involved.",
                "issue_description": "When a type hierarchy as follows is constructed and the base class' type is constructed first by the TypeFactory then serializing the sub class fails due to missing properties from the base class.\r\n\r\n```\r\nclass Base implements IFace<Sub> { @JsonProperty int base = 1 }\r\nclass Sub { @JsonProperty int sub = 2 }\r\ninterface IFace<T> {}\r\n```\r\n\r\nSerializes sub as `{\"sub\":2}` where `{\"base\":1,\"sub\":2}` is expected.\r\n\r\nI've created a minimal scenario of this bug here: https://github.com/slobo-showbie/jackson-recursive-type-bug\r\nI've experienced this bug in 2.7.8, 2.8.8, and 2.8.8.1"
            },
            "85": {
                "commit_sha_buggy": "4b00ccc8ae9763c76e363621dc9ee4b8692d30dc",
                "commit_sha_fixed": "93f7e14d096181a251aae3355464d24bcd7677a5",
                "report_id": "1648",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1648",
                "issue_title": "`DateTimeSerializerBase` ignores configured date format when creating contextual ",
                "issue_description": "`DateTimeSerializerBase#createContextual` creates a new serializer with `StdDateFormat.DATE_FORMAT_STR_ISO8601` format instead of re-using the actual format that may have been specified on the configuration. See the following code:\r\n\r\n```\r\nfinal String pattern = format.hasPattern()\r\n                                    ? format.getPattern()\r\n                                    : StdDateFormat.DATE_FORMAT_STR_ISO8601;\r\n```\r\n\r\nUsing the `@JsonFormat` annotation on a field will therefore reset the format to Jackson's default even if the annotation doesn't specify any custom format.\r\n\r\n\r\n`DateBasedDeserializer#createContextual` behaves differently and tries to re-use the configured format:\r\n\r\n```\r\nDateFormat df = ctxt.getConfig().getDateFormat();\r\n// one shortcut: with our custom format, can simplify handling a bit\r\nif (df.getClass() == StdDateFormat.class) {\r\n   ...\r\n   StdDateFormat std = (StdDateFormat) df;\r\n   std = std.withTimeZone(tz);\r\n   ...\r\n} else {\r\n  // otherwise need to clone, re-set timezone:\r\n  df = (DateFormat) df.clone();\r\n  df.setTimeZone(tz);\r\n}\r\n```\r\n\r\nShouldn't the serializer follow the same approach ?\r\n"
            },
            "87": {
                "commit_sha_buggy": "fe80e86551be38fccb1a983854925a78db6e845f",
                "commit_sha_fixed": "5a0ce57b5d3a6d30420267b56b3d2282c76df581",
                "report_id": "1657",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1657",
                "issue_title": "`StdDateFormat` deserializes dates with no tz/offset as UTC instead of configured timezone",
                "issue_description": "Prior to version `2.8.9`, dates without time zone or time offset (eg `1970-01-01T00:00:00.000`) were deserialised in the TimeZone set on the ObjectMapper. \r\nStarting from `2.8.9`, these dates are deserialised in `UTC` - which is a major (breaking) change in behaviour...\r\n\r\nExample:\r\n```\r\nObjectMapper mapper = new ObjectMapper();\r\nmapper.setTimeZone(TimeZone.getTimeZone(\"GMT+2\");\r\nDate date = mapper.readValue(\"\\\"1970-01-01T00:00:00.000\\\"\", java.util.Date.class);\r\n\r\n// date == \"1970-01-01T00:00:00.000+02.00\" with Jackson < 2.8.9\r\n// date == \"1970-01-01T00:00:00.000+00.00\" with Jackson  2.8.9\r\n\r\n``` "
            },
            "88": {
                "commit_sha_buggy": "ce7d1c9abc7a8eb3bd882e700691ccb80491febc",
                "commit_sha_fixed": "f2c445d6d2de988531dcda25da81fda129bc53f2",
                "report_id": "1735",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1735",
                "issue_title": "Missing type checks when using polymorphic type ids",
                "issue_description": "(report by Lukes Euler)\r\n\r\n`JavaType` supports limited amount of generic typing for textual representation, originally just to support typing needed for `EnumMap` (I think). Based on some reports, it appears that some of type compatibility checks are not performed in those cases; if so, they should be made since there is potential for abuse.\r\nThe problem here although actual type assignment will fail later on, ability to trigger some of processing (instantiation of incompatible classes, perhaps assingnment of properties) may itself be vulnerability.\r\n"
            },
            "89": {
                "commit_sha_buggy": "6cd5be98485a5fe8920846bb0b47a0fec87113be",
                "commit_sha_fixed": "ddfddfba6414adbecaff99684ef66eebd3a92e92",
                "report_id": "1737",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1737",
                "issue_title": "Block more JDK types from polymorphic deserialization (CVE 2017-15095)",
                "issue_description": "(note: follow-up for #1599)\r\n\r\nAfter initial set of types blocked new reports have arrived for more black-listing.\r\nAlthough eventual approach is likely to rely separate module (for more timely updates and wider version coverage), at this point addition in databind is needed.\r\n\r\nI will update specific list of additions once complete and release is out. Target versions are `2.8.10` and `2.9.1` -- it is possible to backport in 2.7 and even 2.6, but there is diminishing return on effort with those versions so it will not happen unless specifically requested (I'm happy to merge PRs).\r\n"
            },
            "90": {
                "commit_sha_buggy": "467589680add00ab49108bbbe7db375d81a75837",
                "commit_sha_fixed": "a1404d5684783ccf28dc1b0a2791ce7c0c311907",
                "report_id": "1804",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1804",
                "issue_title": "`ValueInstantiator.canInstantiate()` ignores `canCreateUsingArrayDelegate()`",
                "issue_description": "### Problem\r\n\r\nMethod Javadoc doesn't match behavior. As a result, delegate collection constructors (for abstract types) don't work properly.\r\n\r\n### Tested versions\r\n\r\njackson-databind v2.8.7 and v2.9.2.\r\n\r\n### Location in code\r\n\r\nhttps://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/deser/ValueInstantiator.java#L70\r\n\r\n### Expected Behavior\r\nOutputs `[]`.\r\n\r\n### Observed Behavior\r\n```\r\nException in thread \"main\" com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `ArrayDelegateDeserializationTest$MyType` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information\r\n at [Source: (String)\"[]\"; line: 1, column: 1]\r\n\tat com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1451)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1027)\r\n\tat com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserialize(AbstractDeserializer.java:265)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4001)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2992)\r\n\tat ArrayDelegateDeserializationTest.main(ArrayDelegateDeserializationTest.java:35)\r\n```\r\n\r\n### Test code\r\n```java\r\nimport java.util.List;\r\n\r\nimport com.fasterxml.jackson.annotation.JsonCreator;\r\nimport com.fasterxml.jackson.annotation.JsonValue;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\n\r\npublic class ArrayDelegateDeserializationTest {\r\n\r\n    public static class MyTypeImpl implements MyType {\r\n        private final List<Integer> values;\r\n\r\n        MyTypeImpl(List<Integer> values) {\r\n            this.values = values;\r\n        }\r\n\r\n        @Override\r\n        public List<Integer> getValues() {\r\n            return values;\r\n        }\r\n    }\r\n\r\n    public interface MyType {\r\n        @JsonValue\r\n        List<Integer> getValues();\r\n\r\n        @JsonCreator\r\n        static MyType of(List<Integer> values) {\r\n            return new MyTypeImpl(values);\r\n        }\r\n    }\r\n\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        ObjectMapper mapper = new ObjectMapper();\r\n        MyType thing = mapper.readValue(\"[]\", MyType.class);\r\n        System.out.println(thing.getValues());\r\n    }\r\n\r\n}\r\n```\r\n"
            },
            "91": {
                "commit_sha_buggy": "a1404d5684783ccf28dc1b0a2791ce7c0c311907",
                "commit_sha_fixed": "dfaca81ae7a82b7c3018f265815e98a5138118f7",
                "report_id": "1809",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1809",
                "issue_title": "2.9.2 deserialization regression",
                "issue_description": "There seems to be a regression in the latest 2.9.2 release.\r\n\r\nUsing `org.apache.logging.log4j.core.jackson.Log4jJsonObjectMapper` from `org.apache.logging.log4j:log4j-core:2.9.1` to deserialize the appended JSON object is throwing an exception with 2.9.2 but worked with 2.9.1.\r\n\r\n`org.apache.logging.log4j.core.jackson.Log4jYamlObjectMapper` and `org.apache.logging.log4j.core.jackson.Log4jXmlObjectMapper` fail in similar ways.\r\n\r\n### inputString\r\n```json\r\n{\r\n  \"timeMillis\" : 1493121664118,\r\n  \"thread\" : \"main\",\r\n  \"threadId\" : 1,\r\n  \"threadPriority\" : 5,\r\n  \"level\" : \"INFO\",\r\n  \"loggerName\" : \"HelloWorld\",\r\n  \"marker\" : {\r\n    \"name\" : \"child\",\r\n    \"parents\" : [ {\r\n      \"name\" : \"parent\",\r\n      \"parents\" : [ {\r\n        \"name\" : \"grandparent\"\r\n      } ]\r\n    } ]\r\n  },\r\n  \"message\" : \"Hello, world!\",\r\n  \"thrown\" : {\r\n    \"commonElementCount\" : 0,\r\n    \"message\" : \"error message\",\r\n    \"name\" : \"java.lang.RuntimeException\",\r\n    \"extendedStackTrace\" : [ {\r\n      \"class\" : \"logtest.Main\",\r\n      \"method\" : \"main\",\r\n      \"file\" : \"Main.java\",\r\n      \"line\" : 29,\r\n      \"exact\" : true,\r\n      \"location\" : \"classes/\",\r\n      \"version\" : \"?\"\r\n    } ]\r\n  },\r\n  \"contextStack\" : [ \"one\", \"two\" ],\r\n  \"loggerFqcn\" : \"org.apache.logging.log4j.spi.AbstractLogger\",\r\n  \"endOfBatch\" : false,\r\n  \"contextMap\" : {\r\n    \"bar\" : \"BAR\",\r\n    \"foo\" : \"FOO\"\r\n  },\r\n  \"source\" : {\r\n    \"class\" : \"logtest.Main\",\r\n    \"method\" : \"main\",\r\n    \"file\" : \"Main.java\",\r\n    \"line\" : 29\r\n  }\r\n}\r\n```\r\n\r\n### Exception\r\n```\r\norg.apache.logging.log4j.core.parser.ParseException: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `org.apache.logging.log4j.Level` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('INFO')\r\n at [Source: (byte[])\"{\r\n  \"timeMillis\" : 1493121664118,\r\n  \"thread\" : \"main\",\r\n  \"threadId\" : 1,\r\n  \"threadPriority\" : 5,\r\n  \"level\" : \"INFO\",\r\n  \"loggerName\" : \"HelloWorld\",\r\n  \"marker\" : {\r\n    \"name\" : \"child\",\r\n    \"parents\" : [ {\r\n      \"name\" : \"parent\",\r\n      \"parents\" : [ {\r\n        \"name\" : \"grandparent\"\r\n      } ]\r\n    } ]\r\n  },\r\n  \"message\" : \"Hello, world!\",\r\n  \"thrown\" : {\r\n    \"commonElementCount\" : 0,\r\n    \"message\" : \"error message\",\r\n    \"name\" : \"java.lang.RuntimeException\",\r\n    \"extendedStackTrace\" : [ {\r\n      \"clas\"[truncated 482 bytes]; line: 6, column: 13] (through reference chain: org.apache.logging.log4j.core.impl.Log4jLogEvent[\"level\"])\r\n```\r\n\r\n### parsing pseudo code\r\n```java\r\nimport org.apache.logging.log4j.core.LogEvent;\r\nimport org.apache.logging.log4j.core.parser.LogEventParser;\r\nimport org.apache.logging.log4j.core.parser.JsonLogEventParser;\r\nimport java.nio.charset.StandardCharsets;\r\n\r\nLogEventParser parser = new JsonLogEventParser();\r\nLogEvent result = parser.parseFrom(inputString.getBytes(StandardCharsets.UTF_8));\r\nassert result != null;\r\n```\r\n"
            },
            "92": {
                "commit_sha_buggy": "e8f043d1aac9b82eee907e0f0c3abbdea723a935",
                "commit_sha_fixed": "e865a7a4464da63ded9f4b1a2328ad85c9ded78b",
                "report_id": "1737",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1737",
                "issue_title": "Block more JDK types from polymorphic deserialization (CVE 2017-15095)",
                "issue_description": "(note: follow-up for #1599)\r\n\r\nAfter initial set of types blocked new reports have arrived for more black-listing.\r\nAlthough eventual approach is likely to rely separate module (for more timely updates and wider version coverage), at this point addition in databind is needed.\r\n\r\nI will update specific list of additions once complete and release is out. Target versions are `2.8.10` and `2.9.1` -- it is possible to backport in 2.7 and even 2.6, but there is diminishing return on effort with those versions so it will not happen unless specifically requested (I'm happy to merge PRs).\r\n"
            },
            "93": {
                "commit_sha_buggy": "d9bbae43dd474f51b01899bbd83116ab4e2b33ed",
                "commit_sha_fixed": "755e3bc0cbea30de0102f6a88519a0c34d571bbd",
                "report_id": "1872",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1872",
                "issue_title": "`NullPointerException` in `SubTypeValidator.validateSubType` when validating Spring interface",
                "issue_description": "In jackson-databind-2.8.11 jackson-databind-2.9.3 and  jackson-databind-2.9.4-SNAPSHOT `SubTypeValidator.validateSubType` fails with a `NullPointerException` if the `JavaType.getRawClass()` is an interface that starts with `org.springframework.` For example, the following will fail:\r\n\r\n```java\r\npackage org.springframework.security.core;\r\n\r\nimport java.util.*;\r\n\r\npublic class Authentication {\r\n\tprivate List<GrantedAuthority> authorities = new ArrayList<GrantedAuthority>();\r\n\r\n\tpublic List<GrantedAuthority> getAuthorities() {\r\n\t\treturn this.authorities;\r\n\t}\r\n\r\n\tpublic void setAuthorities(List<GrantedAuthority> authorities) {\r\n\t\tthis.authorities = authorities;\r\n\t}\r\n}\r\n```\r\n\r\n```java\r\npackage org.springframework.security.core;\r\n\r\npublic interface GrantedAuthority {\r\n\tString getAuthority();\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\npublic void validateSubTypeFailsWithNPE() throws Exception {\r\n\tObjectMapper mapper = new ObjectMapper();\r\n\tmapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);\r\n\r\n\tString json = \"{\\\"@class\\\":\\\"org.springframework.security.core.Authentication\\\",\\\"authorities\\\":[\\\"java.util.ArrayList\\\",[]]}\";\r\n\r\n\tAuthentication authentication = mapper.readValue(json, Authentication.class);\r\n}\r\n```\r\n\r\nwith the following stacktrace:\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.SubTypeValidator.validateSubType(SubTypeValidator.java:86)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory._validateSubType(BeanDeserializerFactory.java:916)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:135)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:411)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:349)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:183)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:27)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handlePrimaryContextualization(DeserializationContext.java:651)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:471)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:4178)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3997)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2992)\r\n```\r\nIn prior versions, the test works.   "
            },
            "94": {
                "commit_sha_buggy": "939e332d951822f451d307ac4fc394af659aa0c6",
                "commit_sha_fixed": "6799f8f10cc78e9af6d443ed6982d00a13f2e7d2",
                "report_id": "1931",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1931",
                "issue_title": "Block two more gadgets to exploit default typing issue (c3p0, CVE-2018-7489)",
                "issue_description": "From an email report there are 2 other c3p0 classes (above and beyond ones listed in #1737) need to be blocked.\r\n\r\nEDIT 21-Jun-2021: Fix included in:\r\n\r\n* `2.9.5`\r\n* `2.8.11.1`\r\n* `2.7.9.3`\r\n* `2.6.7.5`\r\n\r\n"
            },
            "95": {
                "commit_sha_buggy": "c5bfb9a191240fac1744d6569d48a52ebd53c3cf",
                "commit_sha_fixed": "18dc249e793b15e40e67753ea5e988bd428b1a92",
                "report_id": "1941",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1941",
                "issue_title": "`TypeFactory.constructFromCanonical()` throws NPE for Unparameterized generic canonical strings",
                "issue_description": "When `TypeFactory.constructFromCanonical(returnType)` is used in `2.6.1`, the `returnType` string for generic types is not expected to have parameterized type information. For example, the following code runs fine on 2.6.1:\r\n\r\n```java\r\nreturnType = \"java.util.List\";\r\nobjectMapper.getTypeFactory().constructFromCanonical(returnType);\r\n```\r\n\r\nBut in version `2.8.7`, the same code gives a `NullPointerException` with the stack trace:\r\n\r\n```\r\njava.rmi.RemoteException: java.lang.NullPointerException:null. \r\n    at com.fasterxml.jackson.databind.type.TypeFactory._fromVariable(TypeFactory.java:1421)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory._fromAny(TypeFactory.java:1182)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory._fromParamType(TypeFactory.java:1404)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory._fromAny(TypeFactory.java:1172)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory._resolveSuperInterfaces(TypeFactory.java:1318)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory._fromClass(TypeFactory.java:1261)\r\n    at com.fasterxml.jackson.databind.type.TypeParser.parseType(TypeParser.java:60)\r\n    at com.fasterxml.jackson.databind.type.TypeParser.parse(TypeParser.java:33)\r\n    at com.fasterxml.jackson.databind.type.TypeFactory.constructFromCanonical(TypeFactory.java:544)\r\n    at foo.company.package.serialize.Serializer.deserialize(Serializer.java:355)\r\n```\r\n\r\nBut if the `returnType` string is passed with the generic type information, even if it is passed as `Object`, ie, `returnType = \"java.util.List<java.lang.Object>\";`, it works fine.\r\n\r\nI have 2 questions, is there a way to make this change backward compatible? If not, how can I work around this? PS: The workaround given by Tatu in the mailing list is not clear to *me*, if someone can give me an example, it'd be great help. Thanks!\r\n\r\n[Link to google groups thread.](https://groups.google.com/forum/#!topic/jackson-user/Ik1oEkUC1E8)"
            },
            "96": {
                "commit_sha_buggy": "31153568b58a29979dd0c416d14833886f9216a9",
                "commit_sha_fixed": "dd57a2dd576a77423553c197df109a5b60c1c669",
                "report_id": "2051",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2051",
                "issue_title": "Implicit constructor property names are not renamed properly with `PropertyNamingStrategy`",
                "issue_description": "(note: spin-off from https://github.com/FasterXML/jackson-modules-java8/issues/67)\r\n\r\nLooks like something with linking of creator properties (constructor arguments for annotated/discovered constructor) to \"regular\" properties does not work when using `PropertyNamingStrategy`. Apparently this was working better until 2.9.1, but broke with 2.9.2.\r\n\r\n"
            },
            "97": {
                "commit_sha_buggy": "dd57a2dd576a77423553c197df109a5b60c1c669",
                "commit_sha_fixed": "0e06d15b5ce1d5f16d8bcd69e2418c18009bc1c8",
                "report_id": "1991",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1991",
                "issue_title": "Context attributes are not passed/available to custom serializer if object is in POJO",
                "issue_description": "Below is a test case where I create a custom serializer and use it to serialize an object 1) in a HashMap and 2) in an ObjectNode. In both cases I pass attribute to the serializer like this:\r\n`mapper.writer().withAttribute(\"myAttr\", \"Hello!\")`\r\nSerializing HashMap works as expected, but during ObjectNode serialization the attribute is null . It seems that in both cases the custom serializer should get access to the passed attribute and so both lines in the output should contain \"Hello!\"\r\n\r\nProduced output from running testCase.test()\r\n```\r\n{\"data\":{\"aStr\":\"The value is: Hello!\"}}\r\n{\"data\":{\"aStr\":\"The value is: NULL\"}}\r\n\r\n```\r\nTest case:\r\n\r\n```\r\nimport com.fasterxml.jackson.core.JsonGenerator;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport com.fasterxml.jackson.databind.SerializerProvider;\r\nimport com.fasterxml.jackson.databind.annotation.JsonSerialize;\r\nimport com.fasterxml.jackson.databind.node.ObjectNode;\r\nimport com.fasterxml.jackson.databind.ser.std.StdSerializer;\r\n\r\nimport java.io.IOException;\r\nimport java.util.HashMap;\r\nimport java.util.Map;\r\n\r\npublic class TestCase {\r\n  public final static ObjectMapper mapper = new ObjectMapper();\r\n\r\n  @JsonSerialize(using = TestCase.CustomSer.class)\r\n  public static class Data {\r\n    public String aStr;\r\n  }\r\n\r\n  public static class CustomSer extends StdSerializer<Data> {\r\n    public CustomSer() {\r\n      super(Data.class);\r\n    }\r\n\r\n    @Override\r\n    public void serialize(Data value, JsonGenerator gen, SerializerProvider provider) throws IOException {\r\n      String attrStr = (String) provider.getAttribute(\"myAttr\");\r\n      gen.writeStartObject();\r\n      gen.writeObjectField(\"aStr\", \"The value is: \" + (attrStr == null ? \"NULL\" : attrStr));\r\n      gen.writeEndObject();\r\n    }\r\n  }\r\n\r\n  public static void test() throws IOException {\r\n    Data data = new Data();\r\n    data.aStr = \"Hello\";\r\n\r\n    Map<String, Object> mapTest = new HashMap<>();\r\n    mapTest.put(\"data\", data);\r\n\r\n    ObjectNode treeTest = mapper.createObjectNode();\r\n    treeTest.putPOJO(\"data\", data);\r\n\r\n    String mapOut = mapper.writer().withAttribute(\"myAttr\", \"Hello!\").writeValueAsString(mapTest);\r\n    System.out.println(mapOut);\r\n\r\n    String treeOut = mapper.writer().withAttribute(\"myAttr\", \"Hello!\").writeValueAsString(treeTest);\r\n    System.out.println(treeOut);\r\n  }\r\n}\r\n\r\n```\r\n"
            },
            "98": {
                "commit_sha_buggy": "bf261d404c2f79fd3406237710d40ebb03c99d84",
                "commit_sha_fixed": "12f82c60782f05015336bb6305fd72c133a410b5",
                "report_id": "1328",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1328",
                "issue_title": "External property polymorphic deserialization does not work with enums",
                "issue_description": "versions: Jackson 2.8.1, Jackson-module-kotlin 2.8.1\r\n\r\nAttempting to deserialize a class using external_property. In my case, the property is an Enum type with values matching the type name. Now that issue #999 is fixed, I thought this would work, but now I'm getting a different error:\r\n\r\n```\r\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of enum.Invite, problem: argument type mismatch\r\n at [Source: {\r\n  \"kind\": \"CONTACT\",\r\n  \"to\": {\r\n    \"name\": \"Foo\"\r\n  }\r\n}; line: 6, column: 1]\r\n    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:268)\r\n    at com.fasterxml.jackson.databind.DeserializationContext.instantiationException(DeserializationContext.java:1405)\r\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.wrapAsJsonMappingException(StdValueInstantiator.java:468)\r\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.rewrapCtorProblem(StdValueInstantiator.java:487)\r\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createFromObjectWith(StdValueInstantiator.java:276)\r\n    at com.fasterxml.jackson.module.kotlin.KotlinValueInstantiator.createFromObjectWith(KotlinValueInstantiator.kt:30)\r\n    at com.fasterxml.jackson.databind.deser.impl.PropertyBasedCreator.build(PropertyBasedCreator.java:135)\r\n    at com.fasterxml.jackson.databind.deser.impl.ExternalTypeHandler.complete(ExternalTypeHandler.java:225)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeUsingPropertyBasedWithExternalTypeId(BeanDeserializer.java:937)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeWithExternalTypeId(BeanDeserializer.java:792)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:312)\r\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:148)\r\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3789)\r\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2852)\r\n    at enum.Reproduction_KindEnumKt.main(Reproduction-KindEnum.kt:49)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke(Method.java:498)\r\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\r\nCaused by: java.lang.IllegalArgumentException: argument type mismatch\r\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n    at com.fasterxml.jackson.databind.introspect.AnnotatedConstructor.call(AnnotatedConstructor.java:124)\r\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createFromObjectWith(StdValueInstantiator.java:274)\r\n    ... 15 more\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nHere is the reproduction recipe: https://github.com/rocketraman/jackson-issue-enum-polymorphism/blob/master/src/main/kotlin/enumtype/Reproduction-KindEnum.kt\r\n"
            },
            "99": {
                "commit_sha_buggy": "bc5e138dfaf572ea519cbfefe36a9bec8b017365",
                "commit_sha_fixed": "bc91126c55dc513735a2a95ace4c00a6021c76f4",
                "report_id": "2109",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2109",
                "issue_title": "Canonical string for reference type is built incorrectly",
                "issue_description": "Canonical string for reference type is built incorrectly. \r\nE.g.:\r\n`new ReferenceType(new TypeFactory(new LRUMap<Object, JavaType>(0, 10000)).constructType(Object.class), new PlaceholderForType(0)).toCanonical()`\r\nyields:\r\n`java.lang.Object<$1`\r\nwhile the expected value is:\r\n`java.lang.Object<$1>`"
            },
            "100": {
                "commit_sha_buggy": "fd522c58b94fa5646f56dabd6ef4e219e939100c",
                "commit_sha_fixed": "d98ae778876cddd5ed3eacab9e5daf55186ff483",
                "report_id": "2096",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2096",
                "issue_title": "`TreeTraversingParser` does not take base64 variant into account",
                "issue_description": "This affects at least 2.6.4 to current versions. In [TreeTraversingParser#getBinaryValue](https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/node/TreeTraversingParser.java#L348), a `Base64Variant` is accepted but ignored. The call to `n.binaryValue()`, when `n` is a `TextNode`, then uses the default Base64 variant instead of what's specified. It seems the correct behavior would be to call `TextNode#getBinaryValue` instead."
            },
            "101": {
                "commit_sha_buggy": "63d48ff05508a5f52ff10035602f079d2f3390fb",
                "commit_sha_fixed": "644831ce403590db4dbeb8ee47adb3c393438fb2",
                "report_id": "2088",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2088",
                "issue_title": "`@JsonUnwrapped` fields are skipped when using `PropertyBasedCreator` if they appear after the last creator property",
                "issue_description": "Example:\r\n\r\n```java\r\n    static class Bean {\r\n        int x;\r\n        int y;\r\n\r\n        @JsonUnwrapped\r\n        UnwrappedBean w;\r\n\r\n        public Bean(@JsonProperty(\"x\") int x, @JsonProperty(\"y\") int y) {\r\n            this.x = x;\r\n            this.y = y;\r\n        }\r\n\r\n        public void setW(UnwrappedBean w) {\r\n            this.w = w;\r\n        }\r\n    }\r\n\r\n    static class UnwrappedBean {\r\n        int a;\r\n        int b;\r\n\r\n        public UnwrappedBean(@JsonProperty(\"a\") int a, @JsonProperty(\"b\") int b) {\r\n            this.a = a;\r\n            this.b = b;\r\n        }\r\n    }\r\n```\r\n\r\n```json\r\n    {\"x\": 1, \"a\": 2, \"y\": 3, \"b\": 4}\r\n```\r\n\r\n`x`, `y`, and `a` are deserialized as expected. `b` is skipped entirely. I think I've found the root cause and the fix doesn't appear to break any tests; opening a PR for further review."
            },
            "102": {
                "commit_sha_buggy": "940ebf42f2dd7aa0376c385fc5dcf0643e758f2e",
                "commit_sha_fixed": "323cd0b309697021f1883de1e53038d2d09fc160",
                "report_id": "2064",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2064",
                "issue_title": "Cannot set custom format for `SqlDateSerializer` globally",
                "issue_description": "Version: 2.9.5\r\n\r\nAfter https://github.com/FasterXML/jackson-databind/issues/219 was fixed, the default format for `java.sql.Date` serialization switched from string to numeric, following the default value of `WRITE_DATES_AS_TIMESTAMPS`.\r\n\r\nIn order to prevent breaks, I want `java.sql.Date` to serialize as a string, without changing behavior for `java.util.Date` (which has always serialized as a number by default).\r\n\r\nAccording to https://github.com/FasterXML/jackson-databind/issues/219#issuecomment-370690333, I should be able to revert the behavior for `java.sql.Date` only with\r\n```\r\nfinal ObjectMapper mapper = new ObjectMapper();\r\nmapper.configOverride(java.sql.Date.class).setFormat(JsonFormat.Value.forPattern(\"yyyy-MM-dd\"));\r\n```\r\n\r\nThis doesn't seem to do anything, though. Looking at the code, it looks like it's because the custom format isn't actually added to `SqlDateSerializer` except in the `createContextual` method (https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/std/DateTimeSerializerBase.java#L59).\r\n\r\nFor now, I've reverted this behavior with \r\n```\r\nmapper.registerModule(new SimpleModule() {\r\n            {\r\n                addSerializer(\r\n                        java.sql.Date.class,\r\n                        new SqlDateSerializer().withFormat(false, new SimpleDateFormat(\"yyyy-MM-dd\"))\r\n                );\r\n            }\r\n        });\r\n```\r\nbut it seems pretty hacky so I'd prefer the other method if possible. \r\n"
            },
            "103": {
                "commit_sha_buggy": "323cd0b309697021f1883de1e53038d2d09fc160",
                "commit_sha_fixed": "f6cf1817509dc5ed61b9730c17abe492cc62b074",
                "report_id": "2128",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2128",
                "issue_title": "Location information included twice for some `JsonMappingException`s",
                "issue_description": "Looks like due to some double-processing, certain kinds of `JsonMappingException` (observed with `InvalidFormatException`) seem to include \" at [source]\" twice. This is probably due to calls to `getMessage()` that add location being used to pass `message` property when wrapping or re-creating exceptions.\r\n"
            },
            "104": {
                "commit_sha_buggy": "54c744c2c2007eb93dd756cc8581573c9bec97ac",
                "commit_sha_fixed": "83c7c4347055c3a70a3115fa106aa69c9cb56456",
                "report_id": "2167",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2167",
                "issue_title": "Large ISO-8601 Dates are formatted/serialized incorrectly",
                "issue_description": "**The problem**\r\n\r\n```\r\njava.text.ParseException: Cannot parse date \"\u75dd055-12-02T16:47:04.192+0000\": not compatible with any of standard forms (\"yyyy-MM-dd'T'HH:mm:ss.SSSZ\", \"yyyy-MM-dd'T'HH:mm:ss.SSS\", \"EEE, dd MMM yyyy HH:mm:ss zzz\", \"yyyy-MM-dd\")\r\n\tat com.fasterxml.jackson.databind.util.StdDateFormat.parse(StdDateFormat.java:372)\r\n```\r\n\r\nYears > 9999 are not rendered as 5 numbers or more, but with a non numerical characters for the thousands digit..\r\n\r\n**The testcase**\r\n\r\n```\r\npublic class MyTestCase{\r\n  public static void main(String[] args) throws JsonProcessingException, ParseException {\r\n    StdDateFormat formatter = new StdDateFormat();\r\n    System.out.println(formatter.format(new Date(Long.MIN_VALUE)));\r\n    System.out.println(formatter.format(new Date(Long.MAX_VALUE)));\r\n    System.out.println(formatter.parse(formatter.format(new Date(Long.MIN_VALUE))));\r\n    System.out.println(formatter.parse(formatter.format(new Date(Long.MAX_VALUE))));\r\n\r\n    assert formatter.parse(formatter.format(new Date(Long.MAX_VALUE))).getTime() == Long.MAX_VALUE;\r\n    // Will fail due to lack of support for negative dates.\r\n    //assert formatter.parse(formatter.format(new Date(Long.MIN_VALUE))).getTime() == Long.MIN_VALUE;\r\n  }\r\n}\r\n```\r\n**Expected**\r\n\r\na) All dates are formatted correctly, meaning, years bigger than 9999.\r\nb) or some sort of exception telling the data is not supported.\r\n\r\n**The location** \r\n`'0' + something`\r\nhttps://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/util/StdDateFormat.java#L442\r\n\r\n**Suggestion**\r\na) Adding '0' with an integer is not a safe operation. But if you are doing it, you need an upper bound check, e.g.:\r\n```\r\n private static void pad2(StringBuffer buffer, int value) {\r\n     int tens = value / 10;\r\n+    if (tens >= 10) {\r\n+        pad2(buffer, tens);\r\n+        buffer.append((char) ('0' + value % 10));\r\n+        return;\r\n+    }\r\n     if (tens == 0) {\r\n         buffer.append('0');\r\n     } else {\r\n         buffer.append((char) ('0' + tens));\r\n         value -= 10 * tens;\r\n     }\r\n     buffer.append((char) ('0' + value));\r\n }\r\n \r\n private static void pad3(StringBuffer buffer, int value) {\r\n     int h = value / 100;\r\n+    if (h >= 100) {\r\n+        pad3(buffer, h);\r\n+        pad2(buffer, value % 100);\r\n+        return;\r\n+    }\r\n     if (h == 0) {\r\n         buffer.append('0');\r\n     } else {\r\n         buffer.append((char) ('0' + h));\r\n         value -= (h * 100);\r\n     }\r\n     pad2(buffer, value);\r\n }\r\n```\r\nb) Or if you do not want to support such high years, then throw some sort of exception. E.g.:\r\n```\r\n     protected void _format(TimeZone tz, Locale loc, Date date,\r\n             StringBuffer buffer)\r\n     {\r\n         Calendar cal = _getCalendar(tz);\r\n         cal.setTime(date);\r\n\r\n+        int year = cal.get(Calendar.YEAR);\r\n+        if (cal.get(Calendar.ERA) == 0) {\r\n+            year = -year + 1;\r\n+        }\r\n+        if (year < 0 || 9999 < year) {\r\n+            throw new IndexOutOfBoundsException(\"Year not within the range [0,9999]: \" + Integer.toString(year))\r\n+        }\r\n \r\n-        pad4(buffer, cal.get(Calendar.YEAR));\r\n+        pad4(buffer, year);\r\n         buffer.append('-');\r\n         pad2(buffer, cal.get(Calendar.MONTH) + 1);\r\n         buffer.append('-');\r\n         pad2(buffer, cal.get(Calendar.DAY_OF_MONTH));\r\n```"
            },
            "105": {
                "commit_sha_buggy": "dccb9bcb3d175a1997921f75fd3ef8fce8989014",
                "commit_sha_fixed": "69903aeb290415809bfaf6a2e18ec6cb2141fc5a",
                "report_id": "2197",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2197",
                "issue_title": "Illegal reflective access operation warning when using `java.lang.Void` as value type",
                "issue_description": "I'm using Jackson (**2.9.7**) through Spring's RestTemplate:\r\n\r\n```java\r\nResponseEntity<Void> response = getRestTemplate().exchange(\r\n\t\trequestUrl,\r\n\t\tHttpMethod.PATCH,\r\n\t\tnew HttpEntity<>(dto, authHeaders),\r\n\t\tVoid.class\r\n);\r\n```\r\n\r\nWhen [`Void`](https://docs.oracle.com/javase/7/docs/api/java/lang/Void.html) is used to indicate that the ResponseEntity has no body, the following warning appears in the console:\r\n\r\n```\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by com.fasterxml.jackson.databind.util.ClassUtil (file:/<snip>repository/com/fasterxml/jackson/core/jackson-databind/2.9.7/jackson-databind-2.9.7.jar) to constructor java.lang.Void()\r\nWARNING: Please consider reporting this to the maintainers of com.fasterxml.jackson.databind.util.ClassUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n```\r\n\r\nThe problem disappears if `String` is used as generic type. "
            },
            "106": {
                "commit_sha_buggy": "1f437f242f6fba6dbd32a1fa78383c55fcc8bdf3",
                "commit_sha_fixed": "6ef86656aa504309ea3d89cf98ce45d11d6ea9c6",
                "report_id": "2189",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2189",
                "issue_title": "`TreeTraversingParser` does not check int bounds",
                "issue_description": "Similar to https://github.com/FasterXML/jackson-databind/issues/1729, [TreeTraversingParser](https://github.com/FasterXML/jackson-databind/blob/2.9/src/main/java/com/fasterxml/jackson/databind/node/TreeTraversingParser.java#L311) does not perform bounds checks on _some_ JSON values bound to ints.\r\n\r\nUsing Jackson version 2.9.7, here are several comparisons generated with the following code:\r\n```java\r\n  public static class IntClass {\r\n    public int x;\r\n\r\n    @Override\r\n    public String toString() {\r\n      return String.valueOf(x);\r\n    }\r\n  }\r\n\r\n  ObjectMapper mapper  = new ObjectMapper();\r\n  void readAndPrint(String _example) {\r\n    String fromTree;\r\n    try {\r\n      JsonNode tree = mapper.readTree(_example);\r\n      fromTree = mapper.readerFor(IntClass.class).readValue(tree).toString();\r\n    } catch (IOException _e) {\r\n      fromTree = _e.getClass().getSimpleName();\r\n    }\r\n\r\n    String fromString;\r\n    try {\r\n      fromString = mapper.readerFor(IntClass.class).readValue(_example).toString();\r\n    } catch (IOException _e) {\r\n      fromString = _e.getClass().getSimpleName();\r\n    }\r\n\r\n    System.out.printf(\"|%30s | %30s | %-30s|\\n\", _example, fromTree, fromString);\r\n  }\r\n\r\n  @Test\r\n  public void compareFromTree() {\r\n    System.out.printf(\"|%30s | %30s | %-30s|\\n\", \"json input\", \"read from tree\", \"read from string\");\r\n    System.out.println(\"|-------------------------------|--------------------------------|-------------------------------|\");\r\n    readAndPrint(\"{\\\"x\\\": 0}\");\r\n    // etc.\r\n  }\r\n```\r\n\r\n|                    json input |                 read from tree | read from string              |\r\n|-------------------------------|--------------------------------|-------------------------------|\r\n|                      {\"x\": 0} |                              0 | 0                             |\r\n|                     {\"x\": 10} |                             10 | 10                            |\r\n|                    {\"x\": 1e4} |                          10000 | 10000                         |\r\n|                   {\"x\": 1e10} |                     2147483647 | JsonMappingException          |\r\n|                   {\"x\": 1e-1} |                              0 | 0                             |\r\n|             {\"x\": 2147483648} |                    -2147483648 | JsonMappingException          |\r\n|             {\"x\": 2147483649} |                    -2147483647 | JsonMappingException          |\r\n|            {\"x\": -2147483649} |                     2147483647 | JsonMappingException          |\r\n|            {\"x\": -4294967295} |                              1 | JsonMappingException          |\r\n|                    {\"x\": 0.1} |                              0 | 0                             |\r\n|                    {\"x\": 1.9} |                              1 | 1                             |\r\n|     {\"x\": 1.9999999999999999} |                              2 | 2                             |\r\n|                   {\"x\": true} |       MismatchedInputException | MismatchedInputException      |\r\n|                     {\"x\": {}} |       MismatchedInputException | MismatchedInputException      |\r\n|                     {\"x\": []} |       MismatchedInputException | MismatchedInputException      |\r\n|                    {\"x\": [0]} |       MismatchedInputException | MismatchedInputException      |\r\n|                    {\"x\": \"0\"} |                              0 | 0                             |\r\n|                   {\"x\": \"10\"} |                             10 | 10                            |\r\n|                  {\"x\": \"1e4\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                 {\"x\": \"1e10\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                 {\"x\": \"1e-1\"} |         InvalidFormatException | InvalidFormatException        |\r\n|           {\"x\": \"2147483648\"} |         InvalidFormatException | InvalidFormatException        |\r\n|           {\"x\": \"2147483649\"} |         InvalidFormatException | InvalidFormatException        |\r\n|          {\"x\": \"-2147483649\"} |         InvalidFormatException | InvalidFormatException        |\r\n|          {\"x\": \"-4294967295\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                  {\"x\": \"0.1\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                  {\"x\": \"1.9\"} |         InvalidFormatException | InvalidFormatException        |\r\n|   {\"x\": \"1.9999999999999999\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                 {\"x\": \"true\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                   {\"x\": \"{}\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                   {\"x\": \"[]\"} |         InvalidFormatException | InvalidFormatException        |\r\n|                  {\"x\": \"[0]\"} |         InvalidFormatException | InvalidFormatException        |\r\n\r\nWithout digging further into the code, it appears if the JSON value is numeric, `TreeTraversingParser` silently overflows. Maybe this is expected behavior, but to me the inconsistency between reading from a non-tree (reader/string/file, etc) versus directly from a tree seems like a bug. At the very least, it makes it less convenient to do manipulations on a JSON document before binding.\r\n\r\nI would expect an exception thrown for the all but the first three examples above, but I do understand there are use-cases for coercing values. Even so, I would expect the coercion logic to be \r\n- consistent between the parsers (or clearly documented otherwise)\r\n- consistent between quoted and unquoted values\r\n\r\nI'm also curious about the expected behavior when converting non-integral values. Why is `true` `MismatchedInput`, but `0.1` is converted? Similarly, why are `0.1`, `1e4`, and `1e-1` acceptable, but not when in quotes, even though `\"10\"` and other quote integers are acceptable? \r\n\r\nThanks for all your hard work on this. I hope this issue doesn't come off as condescending. For our specific use case, we read the value as a tree, validating it against a schema, then using Jackson to bind the tree to an object. While it's true that we can specify type, minimum, and maximum values in the schema, it is prone to mistakes, and there's not necessarily a reason to tie the schema to the language implementation, provided things like overflow consistently result in an exception. Thus, I'm trying to better understand the expectations and limits Jackson has when using the tree parser."
            },
            "107": {
                "commit_sha_buggy": "96ec23b2bb19b4d4b4530fee6ff08cd248d32a33",
                "commit_sha_fixed": "f3a1798076d9dc71883d317c8e97c4e033fcee98",
                "report_id": "2221",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2221",
                "issue_title": "`DeserializationProblemHandler.handleUnknownTypeId()` returning `Void.class`, enableDefaultTyping causing NPE",
                "issue_description": "Returning Void.class from com.fasterxml.jackson.databind.deser.HandleUnknowTypeIdTest.testDeserializationWithDeserializationProblemHandler().new DeserializationProblemHandler() {...}.handleUnknownTypeId(DeserializationContext, JavaType, String, TypeIdResolver, String) is causing a NPE in jackson 2.9. I'll provide a pull request illustrating the issue in a test. "
            },
            "108": {
                "commit_sha_buggy": "6532c755438df3d8c9a17cc06148f1ab70dc38d8",
                "commit_sha_fixed": "e797b2271ab9a00b99694a963728f3835f31d1cf",
                "report_id": "2211",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2211",
                "issue_title": "Change of behavior (2.8 -> 2.9) with `ObjectMapper.readTree(input)` with no content",
                "issue_description": "So, it looks like `readTree()` methods in `ObjectMapper`, `ObjectReader` that take input OTHER than `JsonParser`, and are given \"empty input\" (only white-space available before end), will\r\n\r\n* Return `NullNode` (Jackson 2.x up to and including 2.8)\r\n* Return `null` (Jackson 2.9)\r\n\r\nLatter behavior is what `readTree(JsonParser)` has and will do; but this accidentally changed other methods due to refactoring that unified underlying call handling (and add checking for new `DeserializationFeature.FAIL_ON_TRAILING_TOKENS`). \r\nBehavior for this edge case was not being tested, apparently.\r\n\r\nNow: since behavior has been changed for all 2.9.x patch versions, I am not sure it should be changed for 2.9 branch. But it seems sub-optimal as behavior, and something to definitely change for 3.0... but probably also for 2.10.\r\n\r\nThere are multiple things we could do.\r\n\r\n1. Change it back to 2.8, to return `NullNode`\r\n2. Change to throw exception, as \"not valid\" use case\r\n3. Change it to return `MissingNode`\r\n4. Leave as-is, for rest of 2.x.\r\n\r\nAlthough it might seem best to revert it to (1), that seems somewhat wrong, problematic, as it would now not be possible to distinguish between JSON `null` value and missing content.\r\nAnd although (2) would probably make sense, if designing API from scratch, it is probably too intrusive.\r\n\r\nSo I think (3) is the best way: it avoids returning `null` or throwing Exception (both being likely to break 2.9 code), but still allows distinguishing between all possible input cases.\r\n\r\n\r\n\r\n\r\n"
            },
            "109": {
                "commit_sha_buggy": "a475c0d526ba9b8343e28ad9543a46005b0842b3",
                "commit_sha_fixed": "e287a62cd32832d5a9611d5b8f3bc06ec1310dc0",
                "report_id": "2230",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2230",
                "issue_title": "`WRITE_BIGDECIMAL_AS_PLAIN` is ignored if `@JsonFormat` is used",
                "issue_description": "I am trying to serialize BigDecimal as json string while avoiding scientific notation (kotlin):\r\n```kotlin\r\ndata class Test(\r\n    @JsonFormat(shape= JsonFormat.Shape.STRING)\r\n    val value: BigDecimal\r\n)\r\n\r\nfun main() {\r\n    val mapper = jacksonObjectMapper()\r\n        .configure(JsonGenerator.Feature.WRITE_BIGDECIMAL_AS_PLAIN, true)\r\n    val test = Test(0.0000000005.toBigDecimal())\r\n    println(mapper.writeValueAsString(test))\r\n}\r\n```\r\noutput `{\"value\":\"5.0E-10\"}`\r\nIf  `JsonFormat` is removed, then `WRITE_BIGDECIMAL_AS_PLAIN` works and output is `{\"value\":0.00000000050}` (json number, not string), but trying to make it json string with `JsonFormat` results in `WRITE_BIGDECIMAL_AS_PLAIN` being ignored.\r\n\r\nUsing latest version, jackson-bom:2.9.8"
            },
            "110": {
                "commit_sha_buggy": "3e6524801d689c6875b861897f31411a7c04c6ab",
                "commit_sha_fixed": "83264a7e377bd3399f0b550460077959aaece16d",
                "report_id": "2265",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2265",
                "issue_title": "Inconsistent handling of Collections$UnmodifiableList VS Collections$UnmodifiableRandomAccessList",
                "issue_description": "I'm sorry to bring that one up again, but I'm under the impression that the issue about unmodifiable collections (https://github.com/FasterXML/jackson-databind/issues/1880) is still not solved completely.\r\n\r\nIn fact, the way the `CLASS_UNMODIFIABLE_LIST` is retrieved [here](https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/deser/impl/JavaUtilCollectionsDeserializers.java#L52) yields `Collections$UnmodifiableRandomAccessList`, and therefore only this type is currently supported by Jackson 2.9.8.\r\n\r\nHowever, using `Collections.unmodifiableList()` on a `List` implementation that doesn't implement `RandomAccess` will yield a `Collections$UnmodifiableList` instead, which is not deserialized properly and fails with:\r\n```\r\ncom.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `java.util.Collections$UnmodifiableList` (no Creators, like default constructor, exist): no default no-arguments constructor found\r\n```\r\n\r\nThis can be reproduced by adding the following test case in `TestDefaultForUtilCollections1868`:\r\n```java\r\npublic void testUnmodifiableNonRandomAccessList() throws Exception {\r\n   _verifyCollection(Collections.unmodifiableList(new LinkedList<>(Arrays.asList(\"first\", \"second\"))));\r\n}\r\n```\r\n\r\nOr more generally for outside the project:\r\n```java\r\npublic void testUnmodifiableNonRandomAccessList() throws Exception {\r\n    Collection<?> exp = Collections.unmodifiableList(new LinkedList<>(Arrays.asList(\"first\", \"second\")));\r\n    ObjectMapper mapper = new ObjectMapper();\r\n    mapper.enableDefaultTyping(DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);\r\n    String json = mapper.writeValueAsString(exp);\r\n    Collection<?> act = mapper.readValue(json, Collection.class);\r\n\r\n    assertEquals(exp, act);\r\n    assertEquals(exp.getClass(), act.getClass());\r\n}\r\n```\r\n\r\nCurrently `java.util.Collections.unmodifiableList()` can only return these 2 types of unmodifiable lists, so I believe it is safe for now to just hardcode yet another special case for this class.\r\n\r\nThis can currently be solved on user side by adding a mixin, but since `Collections$UnmodifiableRandomAccessList` is supported, I would find it natural to also support the non-random access variant."
            },
            "111": {
                "commit_sha_buggy": "4b630c6e741782efdf560a0bd3b6b1d0de9da8c3",
                "commit_sha_fixed": "f36222e5c0b318e2b739e2b77b93c5d2c919413f",
                "report_id": "2303",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2303",
                "issue_title": "Deserialize null, when java type is \"TypeRef of TypeRef of T\", does not provide \"Type(Type(null))\"",
                "issue_description": "**Dependency**\r\n\r\n    jackson = '2.9.7'\r\n    compile \"com.fasterxml.jackson.core:jackson-databind:$jackson\"\r\n\r\n**Short explanation**\r\n\r\nIn Kotlin, I got an issue when I deserialize the value in the context of a reference type that include another reference type. I provide here a reproduction scenario in Java based on AtomicReference (I don't think there is a real use-case that use an AR of AR of Integer, but with a kind of DSL, it may happen to have a similar inclusion...)\r\n\r\nSo, when we deserialize an 22, we get an AR of AR of 22 as expected. But when we deserialize the null value, we get an AR of null (instead of AR of AR of null).\r\n\r\nI think there is 2 issues:\r\n\r\n(1) the getNull method of AtomicReference always returns \"new AtomicReference()\". I think it should be smarter and use contextual information such fullType or simply call _valueDeserializer.getNull() -- but _valueDeserializer was null during my tests because of (2).\r\n\r\n(2) the bean propertyCreator has distinct deserializer and nullProvider. In the case of ReferenceTypeDeserializer, a new contextual deserializer is created, which is able to deserialize its content. Then the deserializer of the bean propertyCreator is updated, but not its nullProvider\r\n\r\n**To reproduce**\r\n\r\n    class MyBean {\r\n        private AtomicReference<AtomicReference<Integer>> refRef;\r\n        public AtomicReference<AtomicReference<Integer>> getRefRef() {\r\n            return refRef;\r\n        }\r\n        public void setRefRef(AtomicReference<AtomicReference<Integer>> refRef) {\r\n            this.refRef = refRef;\r\n        }\r\n    }\r\n\r\n    @Test\r\n    void myTest() throws IOException {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        ObjectReader objectReader = objectMapper.readerFor(MyBean.class);\r\n\r\n        MyBean intRef = objectReader.readValue(\" {\\\"refRef\\\": 2 } \");\r\n        Assertions.assertNotNull(intRef.refRef); // succeeds\r\n        Assertions.assertNotNull(intRef.refRef.get()); // succeeds\r\n        Assertions.assertEquals(intRef.refRef.get().get(), new Integer(2)); // succeeds\r\n\r\n        MyBean nullRef = objectReader.readValue(\" {\\\"refRef\\\": null } \");\r\n        Assertions.assertNotNull(intRef.refRef); // succeeds\r\n        Assertions.assertNotNull(intRef.refRef.get()); // fails\r\n        Assertions.assertNull(intRef.refRef.get().get()); // fails\r\n    }\r\n\r\n"
            },
            "112": {
                "commit_sha_buggy": "f36222e5c0b318e2b739e2b77b93c5d2c919413f",
                "commit_sha_fixed": "8bb7c9abca9a2e298a2436cb995ba1721e49de5c",
                "report_id": "2324",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2324",
                "issue_title": "`StringCollectionDeserializer` fails with custom collection",
                "issue_description": "Seeing this with Jackson 2.9.8.\r\n\r\nWe have a custom collection implementation, which is wired to use its \"immutable\" version for deserialization. The rationale is that we don't want accidental modifications to the data structures that come from the wire, so they all are forced to be immutable.\r\n\r\nAfter upgrade from 2.6.3 to 2.9.8, the deserialization started breaking with the message:\r\n\r\n>Cannot construct instance of `XXX` (although at least one Creator exists): no default no-arguments constructor found\r\n\r\n\r\nThis happens ONLY when you deserialize a custom collection of strings as a property of the other object. Deserializing the custom collection of strings directly works fine, and so does the deserialization of custom collection of non-strings. I believe either the `StringCollectionDeserializer` should not be invoked for custom collections, or perhaps it does not handle the delegation as expected.\r\n\r\nPlease see comments for repro and workaround.\r\n\r\nThanks!"
            },
            "121": {
                "commit_sha_buggy": "0a47e54fe4a263351494cb0aa40f6743f382b0fd",
                "commit_sha_fixed": "c7ff8f6974759302037d6ebb815d14ca89ec6549",
                "report_id": "2513",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2513",
                "issue_title": "BigDecimalAsStringSerializer in NumberSerializer throws IllegalStateException in 2.10",
                "issue_description": "Hi,\r\n\r\nI just updated from Jackson (databind) 2.9.7 to 2.10.0 as a part of updating from Spring Boot 2.1.x to 2.2. In my project I depend on [jackson-dataformat-hal](https://github.com/openapi-tools/jackson-dataformat-hal) to generate responses to web requests. After the update to Jackson 2.10 I get the following exception when trying to serialize a field of type `BigDecimal`: \r\n\r\n```\r\nCaused by: java.lang.IllegalStateException: null\r\n\tat com.fasterxml.jackson.databind.ser.std.NumberSerializer$BigDecimalAsStringSerializer.valueToString(NumberSerializer.java:161)\r\n\tat com.fasterxml.jackson.databind.ser.std.NumberSerializer$BigDecimalAsStringSerializer.isEmpty(NumberSerializer.java:132)\r\n\tat com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:711)\r\n\tat io.openapitools.jackson.dataformat.hal.ser.HALBeanSerializer$FilteredProperties.serialize(HALBeanSerializer.java:191)\r\n\t... 120 common frames omitted\r\n```\r\n\r\nIf I have a look at `com.fasterxml.jackson.databind.ser.std.NumberSerializer$BigDecimalAsStringSerializer.valueToString`it looks like this:\r\n\r\n```java\r\n@Override\r\npublic String valueToString(Object value) {\r\n    // should never be called\r\n    throw new IllegalStateException();\r\n}\r\n```\r\n\r\nbut this method seems to be called from `com.fasterxml.jackson.databind.ser.std.NumberSerializer$BigDecimalAsStringSerializer.isEmpty(NumberSerializer.java:132)` just as the exception implies:\r\n\r\n```java\r\n@Override\r\npublic boolean isEmpty(SerializerProvider prov, Object value) {\r\n    return valueToString(value).isEmpty();\r\n}\r\n```\r\n\r\nThe call to `BeanPropertyWriter.serializeAsField(..)` in [jackson-dataformat-hal](https://github.com/openapi-tools/jackson-dataformat-hal) looks like this:\r\n\r\n```java\r\nfor (BeanPropertyWriter prop : state) {\r\n    try {\r\n        prop.serializeAsField(bean, jgen, provider);\r\n    } catch (Exception e) {\r\n        wrapAndThrow(provider, e, bean, prop.getName());\r\n    }\r\n}\r\n```\r\n\r\nwhere `jgen` is a `JsonGenerator ` and `provider` is a `SerializerProvider` from Jackson 2.10. \r\n\r\nCould this be a bug in Jackson Databind or is there something else going on?"
            },
            "122": {
                "commit_sha_buggy": "df8b4b12cf84cd9d23231a089984fb17c8b9ae54",
                "commit_sha_fixed": "6f9a26dc71b2d0ccf7b3a5d754cd5821de259163",
                "report_id": "913",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/913",
                "issue_title": "ObjectMapper.copy does not preserve MappingJsonFactory features",
                "issue_description": "ObjectMapper's copy method does not correctly copy Features if constructed with a MappingJsonFactory, which is the default for the ObjectMapper no-arg constructor.\n\nThis issue was fixed for JsonFactory https://github.com/FasterXML/jackson-core/commit/7b796a8cddab8cf95953bdd4ab44df1d16990dc2 , but not for the default factory of ObjectMapper.\n\nFor example:\n\n```\npublic static void main(String[] args) throws JsonParseException, JsonMappingException, IOException {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.configure(Feature.ALLOW_COMMENTS, true);\n    System.out.println(\"Expecting true: \" + mapper.getFactory().isEnabled(Feature.ALLOW_COMMENTS));\n\n    System.out.println(\"Expecting 9: \" + mapper.readValue(\"//test\\n9\", Integer.class));\n    ObjectMapper copy = mapper.copy();\n    System.out.println(\"Expecting true: \" + copy.isEnabled(Feature.ALLOW_COMMENTS));\n    System.out.println(\"Expecting 9: \" + copy.readValue(\"//test\\n9\", Integer.class));\n}\n```\n\nThis prints out:\nExpecting true: true\nExpecting 9: 9\nExpecting true: false\nException in thread \"main\" com.fasterxml.jackson.core.JsonParseException: Unexpected character ('/' (code 47)): maybe a (non-standard) comment? (not recognized as one since Feature 'ALLOW_COMMENTS' not enabled for parser)\n at [Source: //test\n9; line: 1, column: 2]\n    at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1581)\n    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:533)\n    at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:462)\n    at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipComment(ReaderBasedJsonParser.java:2099)\n    at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipWSOrEnd2(ReaderBasedJsonParser.java:2074)\n    at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipWSOrEnd(ReaderBasedJsonParser.java:2025)\n    at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:577)\n    at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3742)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3687)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2714)\n    at foo.JacksonTest.main(JacksonTest.java:20)\n"
            },
            "123": {
                "commit_sha_buggy": "563470e6ea72eead488e917ed939b4a3d5abded5",
                "commit_sha_fixed": "f89737c46e7adaef5c18874dc68b78adbdd9f2d9",
                "report_id": "978",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/978",
                "issue_title": "ObjectMapper#canSerialize(Object.class) returns false even though FAIL_ON_EMPTY_BEANS is disabled",
                "issue_description": "Version: 2.5.x, 2.6.x\n\nWhen `FAIL_ON_EMPTY_BEANS` is disabled, `ObjectMapper#writeValueAsString(new Object())` succeeds.\nHowever, `ObjectMapper#canSerialize(Object.class)` returns false.\n\n``` java\nObjectMapper mapper = new ObjectMapper();\nmapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);\nSystem.err.println(mapper.canSerialize(Object.class));\nSystem.err.println(mapper.writeValueAsString(new Object()));\n```\n\n```\nfalse\n{}\n```\n\nI suppose https://github.com/FasterXML/jackson-databind/commit/152aabb7399df1d3178418062c7fa580f3533d4e caused this problem.\n"
            },
            "124": {
                "commit_sha_buggy": "19ba37248e23156b7898b198d77ee75e6ec6c06e",
                "commit_sha_fixed": "be1136361aa2eb9ddf65f9af48dda36abc4a4cf0",
                "report_id": "1003",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1003",
                "issue_title": "JsonTypeInfo.As.EXTERNAL_PROPERTY does not work with a Delegate",
                "issue_description": "I am using a library which generates the Jackson deserialization code as a delegate. I have created a class here which simulates this format:\n\n```\npublic class HeroBattle {\n\n    private final Hero hero;\n\n    private HeroBattle(Hero hero) {\n        this.hero = requireNonNull(hero);\n    }\n\n    @JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.EXTERNAL_PROPERTY, property = \"heroType\")\n    public Hero getHero() {\n        return hero;\n    }\n\n    @JsonCreator\n    static HeroBattle fromJson(Delegate json) {\n        return new HeroBattle(json.hero);\n    }\n\n    public class Delegate {\n        @JsonProperty\n        @JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.EXTERNAL_PROPERTY, property = \"heroType\")\n        Hero hero;\n    }\n\n    public static void main(String[] args) throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n\n        final String json = mapper.writeValueAsString(new HeroBattle(new Superman()));\n        final HeroBattle battle = mapper.readValue(json, HeroBattle.class);\n\n        assert battle.getHero() instanceof Superman;\n    }\n\n    public interface Hero {\n    }\n\n    public static class Superman implements Hero {\n        public String getName() {\n            return \"superman\";\n        }\n    }\n}\n```\n\nThis results in the following exception:\n\n```\nException in thread \"main\" java.lang.IllegalStateException: No default constructor for [simple type, class HeroBattle]\n    at com.fasterxml.jackson.databind.deser.std.StdValueInstantiator.createUsingDefault(StdValueInstantiator.java:211)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeWithExternalTypeId(BeanDeserializer.java:652)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:262)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:124)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3066)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2161)\n    at HeroBattle.main(HeroBattle.java:43)\n```\n"
            },
            "125": {
                "commit_sha_buggy": "b9f6c5b1d4e6717ff95e71025d09f6affd5b7150",
                "commit_sha_fixed": "15f96ef28d5412c1d62e51b27da615f213487033",
                "report_id": "1112",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1112",
                "issue_title": "Detailed error message from custom key deserializer is discarded",
                "issue_description": "The PR I'm about to create shows what I'm talking about.\n"
            },
            "126": {
                "commit_sha_buggy": "24de8a202578831c9633c8e86fef2f382cbb77a5",
                "commit_sha_fixed": "f2bb0dfb8d11979d63cbecd18775a3cc25133fbb",
                "report_id": "1194",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1194",
                "issue_title": "Incorrect signature for generic type via `JavaType.getGenericSignature",
                "issue_description": "(see https://github.com/FasterXML/jackson-modules-base/issues/8 for background)\n\nIt looks like generic signature generation is missing one closing `>` character to produce:\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;;\n```\n\ninstead of expected\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;>;\n```\n\nthat is, closing '>' is missing.\n"
            },
            "128": {
                "commit_sha_buggy": "f1f4023763e57d956da89f7094b7692979582c74",
                "commit_sha_fixed": "b254aff593bd021e31c50f8c4d2faf3740e7862b",
                "report_id": "1203",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1203",
                "issue_title": "`@JsonTypeInfo` does not work correctly for ReferenceTypes like AtomicReference",
                "issue_description": "Looks like polymorphic handling for `ReferenceType` types -- such as `AtomicReference` in JDK, and Option/Optional from Guava, Scala and JDK8 -- do not work as expected with polymorphic types, at least when declared using `@JsonTypeInfo` on property. This may be because handling of `JacksonAnnotationIntrospector` has specific behavior for Collection(Like) and Map(Like) types, but not yet necessarily for `ReferenceType`.\n"
            },
            "129": {
                "commit_sha_buggy": "61a829a7c8aefa588437b12cea5001b1899a9e0f",
                "commit_sha_fixed": "d4a2092984c992b269ba75c723eb9092d94bf1f9",
                "report_id": "1315",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1315",
                "issue_title": "Binding numeric values can BigDecimal lose precision",
                "issue_description": "It looks like commit c809c0cbe75fa24a19430867af8c35d78c6663be (intended to fix #1028) introduced an issue where numeric values lose precision prior to being returned as `BigDecimal` instances. (Feature `USE_BIG_DECIMAL_FOR_FLOATS` enables this; given that it's disabled for performance by default, the reason to enable it is when you specifically want to avoid precision loss.)\n\nThis issue is still present in 2.8.1 (which is where I encountered it).\n\nSome initial discussion took place as [comments on the commit](https://github.com/FasterXML/jackson-databind/commit/c809c0cbe75fa24a19430867af8c35d78c6663be#commitcomment-18364729). I don't know enough about the contracts involved in the parsing state, but some things that caught my eye:\n- Retrieving the parser value as a `Double` is where the precision loss occurs.\n- The fix was intended to deal with returning NaN/Inf, which `BigDecimal` doesn't support. However these aren't legal values in JSON, and there's a `ALLOW_NON_NUMERIC_NUMBERS` feature to allow this as extension. (Maybe the feature-check is somewhere else? I haven't looked.)\n"
            },
            "131": {
                "commit_sha_buggy": "e4b261e94933bc9a03345b390b7d5558e7942321",
                "commit_sha_fixed": "19048396c24b84fc3c65b1864cd1d800f477f797",
                "report_id": "1368",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1368",
                "issue_title": "Problem serializing `JsonMappingException` due to addition of non-ignored `processor` property",
                "issue_description": "I notice that, e.g.,  JsonMappingException has several bidirectional links in internal fields like _processor.\n\nWhy not annotate those fields with @JsonIgnore?  You've already got the Java serialization \"transient\" on them.\n\nOne symptom of not eating your own dog food here is that AWS SWF Flow Framework is broken.  If it attempts to deserialize the result of an activity and that attempt fails with a JsonMappingException, the framework then attempts to serialize the resulting DataConverterException via Jackson...which fails with a different JsonMappingException (StackOverflowError) because of the embedded JsonMappingException.\n\nI see no reason why a serde framework should not be able to serde itself.\n"
            },
            "132": {
                "commit_sha_buggy": "a80cef281426ee5480fb5e7472d226217165d2d6",
                "commit_sha_fixed": "bcd616d28c411f30280a86370d50e97469504a98",
                "report_id": "1383",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1383",
                "issue_title": "Problem with `@JsonCreator` with 1-arg factory-method, implicit param names",
                "issue_description": "It appear that auto-detection of `@JsonCreator` mode may not be working as desired for the case where a single-arg constructor has implicit name. This should NOT result in properties-creator, at least in case where there is no matching getter available, but rather should default to delegating-creator; same as if no name was available. Only explicit name, or, possibly, existence of getter with name same as implicit name, should result in properties-creator.\n"
            },
            "133": {
                "commit_sha_buggy": "497e455bed6692cb36caf54f279e40e615e8695e",
                "commit_sha_fixed": "4debd67e053a254b5f42294426340fc91a312f64",
                "report_id": "1550",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1550",
                "issue_title": "Unexpected behavior with `@JsonInclude(JsonInclude.Include.NON_EMPTY)` and `java.util.Date` serialization",
                "issue_description": "(note: moved from https://github.com/FasterXML/jackson-annotations/issues/111 by @ stefan-huettemann )\r\n\r\nIs this really what is intended? I would consider this a bug.\r\n\r\nI see unexpected behavior using `@JsonInclude(JsonInclude.Include.NON_EMPTY)` with `java.util.Date` serialization.\r\n\r\nSetting a `Date` to `1970-01-01` results in an empty JSON object since `NON_EMPTY` seems to consider `1970-01-01` as empty (`0` time stamp value) where as I consider `1970-01-01` a perfectly valid `NON_EMPTY` value ;)\r\n\r\nConsider this code:\r\n```\r\npublic class TestJacksonJsonFormat {\r\n\r\n    public static void main(String[] args) throws JsonProcessingException {\r\n\r\n        final ObjectMapper theObjectMapper = new ObjectMapper();\r\n        final TestDTO theTestDTO = new TestDTO();\r\n\r\n        theTestDTO.setDate(new Date(0));  // set to \"1970-01-01\"\r\n        System.out.printf(\"1970-01-01: %s\\n\", theTestDTO.getDate());\r\n        System.out.printf(\"Serialized: %s\\n\", theObjectMapper.writeValueAsString(theTestDTO));\r\n\r\n        theTestDTO.setDate(new Date(1));  // set to \"1970-01-01T00:00:00.001+0000\"\r\n        System.out.printf(\"1970-01-01 + 1 msec: %s\\n\", theTestDTO.getDate());\r\n        System.out.printf(\"Serialized: %s\\n\", theObjectMapper.writeValueAsString(theTestDTO));\r\n\r\n    }\r\n\r\n    @JsonInclude(JsonInclude.Include.NON_EMPTY) // Note: works with NON_NULL\r\n    private static class TestDTO {\r\n\r\n        @JsonFormat(shape = JsonFormat.Shape.STRING, pattern = \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\", timezone = \"UTC\")\r\n        private Date date;\r\n\r\n        Date getDate() {\r\n            return date;\r\n        }\r\n\r\n        void setDate(final Date aDate) {\r\n            date = aDate;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nNote: setting `disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)` does not change the effect."
            },
            "135": {
                "commit_sha_buggy": "dc2c00358822901b943019a9dbc0c912285998af",
                "commit_sha_fixed": "075319dbf91d6c091c78a3b7c686b579569678e1",
                "report_id": "1658",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1658",
                "issue_title": "Infinite recursion when deserializing a class extending a Map, with a recursive value type.",
                "issue_description": "Hello, I am using jackson-databind 2.8.8, and have a class with an unusual definition (extending a Map, where the values are of the type of the same class). It seems like I am facing an infinite recursion issue.\r\n\r\nTo reproduce you can re-use or inspire from the class defined [here](https://github.com/apache/tinkerpop/blob/master/gremlin-core/src/main/java/org/apache/tinkerpop/gremlin/process/traversal/step/util/Tree.java).\r\n\r\nThen, when executing the following code:\r\n\r\n```java\r\n        Tree t = new Tree(\"hello\", new Tree(\"world\"));\r\n\r\n        ObjectMapper om = new ObjectMapper();\r\n        final TypeResolverBuilder<?> typer = new StdTypeResolverBuilder()\r\n                .init(JsonTypeInfo.Id.CLASS, null)\r\n                .inclusion(JsonTypeInfo.As.PROPERTY)\r\n                .typeProperty(GraphSONTokens.CLASS);\r\n        om.setDefaultTyping(typer);\r\n\r\n        String res = om.writeValueAsString(t);\r\n        Object tRead = om.readValue(res, Tree.class);\r\n```\r\n\r\nWhen calling `readValue()` the mapper throws a `StackOverflowException` , here's the stacktrace:\r\n```\r\njava.lang.StackOverflowError\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.MapLikeType.equals(MapLikeType.java:305)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.ResolvedRecursiveType.equals(ResolvedRecursiveType.java:110)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.MapLikeType.equals(MapLikeType.java:305)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.ResolvedRecursiveType.equals(ResolvedRecursiveType.java:110)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.MapLikeType.equals(MapLikeType.java:305)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.ResolvedRecursiveType.equals(ResolvedRecursiveType.java:110)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.MapLikeType.equals(MapLikeType.java:305)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.ResolvedRecursiveType.equals(ResolvedRecursiveType.java:110)\r\n\tat org.apache.tinkerpop.shaded.jackson.databind.type.MapLikeType.equals(MapLikeType.java:305)\r\n[...]\r\n```\r\n\r\nLooking briefly into the code, it seems like because of the recursive definition of the class, the [equals](https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/type/MapLikeType.java#L305) call in `MapLikeType` may never get out of this loop. Any idea?\r\n\r\nThanks."
            },
            "136": {
                "commit_sha_buggy": "88d12b4baf7b29cdc16171dc293edb38f0046391",
                "commit_sha_fixed": "a2a45b371e19bfc97fa490fa378ee3124498de6a",
                "report_id": "1672",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1672",
                "issue_title": "`@JsonAnySetter` deserialization fails with parameter names module",
                "issue_description": "Starting with Jackson release `2.9.0.pr1` deserialization of `@JsonAnySetter` fails when `ParameterNamesModule` is registered.\r\n\r\nThe following sample demonstrates the problem:\r\n\r\n```gradle\r\napply plugin: 'java'\r\n\r\next {\r\n\tjacksonVersion = '2.9.0.pr4'\r\n}\r\n\r\nrepositories {\r\n\tjcenter()\r\n}\r\n\r\ndependencies {\r\n\tcompile \"com.fasterxml.jackson.core:jackson-databind:$jacksonVersion\"\r\n\tcompile \"com.fasterxml.jackson.module:jackson-module-parameter-names:$jacksonVersion\"\r\n\r\n\ttestCompile 'junit:junit:4.12'\r\n\ttestCompile 'org.assertj:assertj-core:3.8.0'\r\n}\r\n```\r\n\r\n```java\r\npublic class AnySetterRegressionTests {\r\n\r\n\t@Test\r\n\tpublic void deserialization() throws Exception {\r\n\t\tString content = \"{ \\\"info1\\\":\\\"value1\\\", \\\"info2\\\":\\\"value2\\\" }\";\r\n\t\tObjectMapper objectMapper = new ObjectMapper();\r\n\t\tobjectMapper.registerModule(new ParameterNamesModule());\r\n\t\tBaseClientDetails clientDetails = objectMapper.readValue(content, BaseClientDetails.class);\r\n\t\tMap<String, Object> additionalInfo = clientDetails.additionalInformation;\r\n\t\tassertThat(additionalInfo).hasSize(2);\r\n\t\tassertThat(additionalInfo.get(\"info1\")).isEqualTo(\"value1\");\r\n\t\tassertThat(additionalInfo.get(\"info2\")).isEqualTo(\"value2\");\r\n\t}\r\n\r\n\t@JsonInclude(JsonInclude.Include.NON_DEFAULT)\r\n\t@JsonIgnoreProperties(ignoreUnknown = true)\r\n\tstatic class BaseClientDetails {\r\n\r\n\t\tprivate final Map<String, Object> additionalInformation = new HashMap<>();\r\n\r\n\t\t@JsonAnySetter\r\n\t\tpublic void addAdditionalInformation(String key, Object value) {\r\n\t\t\tthis.additionalInformation.put(key, value);\r\n\t\t}\r\n\r\n\t}\r\n\r\n}\r\n```\r\n\r\nThe test passes either when `ParameterNamesModule` is not registered, or when Jackson release `2.8.9` is used.\r\n\r\nThis was originally reported as spring-projects/spring-boot#9553."
            },
            "137": {
                "commit_sha_buggy": "4009fe3a05caaf45ec230fbedc29dbe5d9b7f412",
                "commit_sha_fixed": "e20bcc877a8149a9c4ecd562209b3b3954b6dda2",
                "report_id": "1679",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1679",
                "issue_title": "`StackOverflowError` in Dynamic `StdKeySerializer`",
                "issue_description": "There seem to be a problem (checked and doesn't seem to be fixed in latest version) with the serialize method of the Dynamic static class of the StdKeySerializer. \r\n```\r\n        @Override\r\n        public void serialize(Object value, JsonGenerator g, SerializerProvider provider)\r\n                throws IOException\r\n        {\r\n            Class<?> cls = value.getClass();\r\n            PropertySerializerMap m = _dynamicSerializers;\r\n            JsonSerializer<Object> ser = m.serializerFor(cls);\r\n            if (ser == null) {\r\n                ser = _findAndAddDynamic(m, cls, provider);\r\n            }\r\n            ser.serialize(value, g, provider);\r\n        }\r\n```\r\n\r\nThe problem comes from the fact that when `ser` is `null`, the new `ser` returned by `_findAndAddDynamic` is incorrectly filled.\r\n\r\n```\r\n        protected JsonSerializer<Object> _findAndAddDynamic(PropertySerializerMap map,\r\n                Class<?> type, SerializerProvider provider) throws JsonMappingException\r\n        {\r\n            PropertySerializerMap.SerializerAndMapResult result =\r\n                    // null -> for now we won't keep ref or pass BeanProperty; could change\r\n                    map.findAndAddKeySerializer(type, provider, null);\r\n            // did we get a new map of serializers? If so, start using it\r\n            if (map != result.map) {\r\n                _dynamicSerializers = result.map;\r\n            }\r\n            return result.serializer;\r\n        }\r\n```\r\nSo say we are in `ser#1`, `ser#1._dynamicSerializers` now has the correct `PropertySerializerMap$Single`. However, `result.serializer._dynamicSerializers ` has `PropertySerializerMap$Empty`.\r\nTherefore, a new call with that result `ser#2` is made which ends up creating an infinite loop.\r\n\r\nPossible fix:\r\n- replace `_dynamicSerializers = result.map;` by `result.serializer._dynamicSerializers  = result.map`\r\n\r\nIf I'm mistaken please let me know, but It seems obvious when debugging that something's is not working as intended\r\n"
            },
            "138": {
                "commit_sha_buggy": "c64b5a8b36fef8385e47e865514b51534d3d5795",
                "commit_sha_fixed": "445bd4482ff7e7fb2b222f410a5c9208f2a31c57",
                "report_id": "1690",
                "report_url": "https://github.com/FasterXML/jackson-databind/pull/1690",
                "issue_title": "Prevent use of quoted number (index) for Enum deserialization via `MapperFeature.ALLOW_COERCION_OF_SCALARS`",
                "issue_description": "Just want to make option to restrict default ability to deserialize any number string as enum value if it is in its ordinal range"
            },
            "139": {
                "commit_sha_buggy": "f71ba6f3fc5b686814a02902029cd8703c589f1e",
                "commit_sha_fixed": "424f56c34fa7554b301ab8b1d96c28f067587d6c",
                "report_id": "1730",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1730",
                "issue_title": "`InvalidFormatException` for `JsonToken.VALUE_EMBEDDED_OBJECT`",
                "issue_description": "jackson 2.9.0\r\n\r\nI got InvalidFormatException. It works fine in 2.8\r\n\r\n```\r\nCaused by: com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `org.bson.types.ObjectId` from native value (`JsonToken.VALUE_EMBEDDED_OBJECT`) of type `org.bson.types.ObjectId`: incompatible types\r\n at [Source: org.litote.bson4jackson.io.LittleEndianInputStream@69a2b3b6; pos: 5] (through reference chain: org.litote.kmongo.model.Friend[\"_id\"])\r\n\tat com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.weirdNativeValueException(DeserializationContext.java:1568)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleWeirdNativeValue(DeserializationContext.java:975)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromEmbedded(BeanDeserializerBase.java:1471)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:176)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)\r\n\tat com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:519)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:527)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:416)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1265)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:325)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:159)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4001)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3079)\r\n\r\n```\r\n in BeanDeserializerBase line 1469 I think that instead\r\n`!_beanType.getClass().isInstance(value)`\r\nIt should be` !_beanType.getRawClass().isInstance(value)`"
            },
            "140": {
                "commit_sha_buggy": "49987547ae6294717e4ef63da5c30bde9eaa34d9",
                "commit_sha_fixed": "b06bec8825f9b9a9b269020877866b1e1c67a894",
                "report_id": "1788",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1788",
                "issue_title": "`StdDateFormat._parseAsISO8601()` does not parse \"fractional\" timezone correctly",
                "issue_description": "I think this line: https://github.com/FasterXML/jackson-databind/blob/91a3636eac479761172c102a7708a54c06419fac/src/main/java/com/fasterxml/jackson/databind/util/StdDateFormat.java#L590\r\n\r\nshould be:\r\n\r\n```\r\noffsetSecs += _parse2D(dateStr, end-2) * 60;\r\n```\r\n\r\nAs `StdFormat.parse` currently fails to parse this string \"2017-04-25T13:31:02-0730\":\r\n\r\n```\r\nnew StdDateFormat().parse(\"2017-04-25T13:31:02-0730\") => Tue Apr 25 16:31:32 EDT 2017\r\n```\r\n\r\nbut it should be \"Tue Apr 25 21:01:02 EDT 2017\".\r\n\r\n"
            },
            "141": {
                "commit_sha_buggy": "0ee3f5ccae5aa72d65c2bfda9e912939ad3c2aa4",
                "commit_sha_fixed": "fb2d03c258e2f8a9511248eb7566812ed6591f3a",
                "report_id": "1842",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1842",
                "issue_title": "`null` String for `Exception`s deserialized as String \"null\" instead of `null`",
                "issue_description": "Hi!\r\nI have been trying to solve this problem for over a day now, and what research I did showed that this should work, but it does not in my case, e.g. default behaviour should deserialize null objects to null objects, right?\r\n\r\nThe problem is that while serialization of string object properties with null value is fine, the deserialization is not.\r\n\r\nWhat I want is, if string property value\r\n\r\n- is \"null\" -> deserialize to string \"null\"\r\n- is null -> deserialize to null object\r\n- is \"\" -> deserialize to empty string (\"\")\r\n- is \"ladida\" -> deserialize to string \"ladida\"\r\n\r\nExample code to reproduce the error:\r\n```\r\n        final ObjectMapper mapper = new ObjectMapper();\r\n        // so that the error is visible at the beginning of the output :)\r\n        mapper.configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true);\r\n        final NullPointerException ex = new NullPointerException();\r\n        String json;\r\n        try {\r\n            json = mapper.writeValueAsString(ex);\r\n            System.out.println(\"OK\\t-> \" + json);\r\n            final NullPointerException parsed = mapper.readValue(json, NullPointerException.class);\r\n            json = mapper.writeValueAsString(parsed);\r\n            System.out.println(\"Not OK\\t<- \" + json);\r\n        } catch (final IOException e1) {\r\n            e1.printStackTrace();\r\n        }\r\n```\r\n\r\nOutput:\r\nSee 'localizedMessage' and 'message' strings in serialized and deserialized output. Serialization is OK (null), deserialized is not ok (string containing \"null\")\r\n```\r\nOK\t-> {\"cause\":null,\"localizedMessage\":null,\"message\":null,\"stackTrace\":[{\"className\":\"com.cosylab.tcs.commons.communication.model.Test\",\"fileName\":\"Test.java\",\"lineNumber\":87,\"methodName\":\"main\",\"nativeMethod\":false}],\"suppressed\":[]}\r\nNot OK\t<- {\"cause\":null,\"localizedMessage\":\"null\",\"message\":\"null\",\"stackTrace\":[{\"className\":\"com.cosylab.tcs.commons.communication.model.Test\",\"fileName\":\"Test.java\",\"lineNumber\":87,\"methodName\":\"main\",\"nativeMethod\":false}],\"suppressed\":[]}\r\n```\r\n\r\nVersion: 2.9.1\r\n"
            },
            "142": {
                "commit_sha_buggy": "8a2be69c5e421f64f8367b0d48f0e5ddfb793e07",
                "commit_sha_fixed": "8d2ccf305b32d22f9a0880242051855f3e96dccd",
                "report_id": "1831",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1831",
                "issue_title": "`ObjectReader.readValue(JsonNode)` does not work correctly with polymorphic types, value to update",
                "issue_description": "There seems to be a difference in behavior of `ObjectReader::readValue(JsonNode)` and `ObjectReader::readValue(String)`. In particular I've found a difference in how they treat the combination of `@JsonUnwrapped` and `@JsonSubTypes` and a custom deserializer. I am attaching two minimal test cases. They are identical but one uses `ObjectReader::readValue(JsonNode)` (and fails) and the other one uses `ObjectReader::readValue(String)` and passes.\r\nTested on version 2.9.2.\r\n\r\n[unwrappedSubtypesBug.zip](https://github.com/FasterXML/jackson-databind/files/1483046/unwrappedSubtypesBug.zip)\r\n\r\n\r\n"
            },
            "143": {
                "commit_sha_buggy": "4e71662bbe0e3776dadd4ee76dfeb197be951291",
                "commit_sha_fixed": "4c448eebb26309ff1b991f3c37d73c72bf4bf4ea",
                "report_id": "1895",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1895",
                "issue_title": "Per-type config override \"JsonFormat.Shape.OBJECT\" for Map.Entry not working ",
                "issue_description": "Hi, after updating from a 2.0.x version of jackson to 2.9.2 we faced an issue with the serialization of Map.Entity as reported also here #565. One of the proposed solution to have a backward-compatibility to versions prior to 2.5, as a default, is this one:\r\n\r\n`ObjectMapper mapper = new ObjectMapper();\r\n\t\t\tmapper.configOverride(Map.Entry.class).setFormat(JsonFormat.Value.forShape(JsonFormat.Shape.OBJECT));`\r\n\r\nBut unluckly is not working. Is there a way to fix that or have a similar solution without using annotations?\r\n\r\nThanks.\r\n\r\n\r\n"
            },
            "144": {
                "commit_sha_buggy": "5d4eb514820a7cfc7135e4b515dd9531ebdd523a",
                "commit_sha_fixed": "c803a2658e45b8d1095d2504f943bd4ebaab18e9",
                "report_id": "1872",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1872",
                "issue_title": "`NullPointerException` in `SubTypeValidator.validateSubType` when validating Spring interface",
                "issue_description": "In jackson-databind-2.8.11 jackson-databind-2.9.3 and  jackson-databind-2.9.4-SNAPSHOT `SubTypeValidator.validateSubType` fails with a `NullPointerException` if the `JavaType.getRawClass()` is an interface that starts with `org.springframework.` For example, the following will fail:\r\n\r\n```java\r\npackage org.springframework.security.core;\r\n\r\nimport java.util.*;\r\n\r\npublic class Authentication {\r\n\tprivate List<GrantedAuthority> authorities = new ArrayList<GrantedAuthority>();\r\n\r\n\tpublic List<GrantedAuthority> getAuthorities() {\r\n\t\treturn this.authorities;\r\n\t}\r\n\r\n\tpublic void setAuthorities(List<GrantedAuthority> authorities) {\r\n\t\tthis.authorities = authorities;\r\n\t}\r\n}\r\n```\r\n\r\n```java\r\npackage org.springframework.security.core;\r\n\r\npublic interface GrantedAuthority {\r\n\tString getAuthority();\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\npublic void validateSubTypeFailsWithNPE() throws Exception {\r\n\tObjectMapper mapper = new ObjectMapper();\r\n\tmapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);\r\n\r\n\tString json = \"{\\\"@class\\\":\\\"org.springframework.security.core.Authentication\\\",\\\"authorities\\\":[\\\"java.util.ArrayList\\\",[]]}\";\r\n\r\n\tAuthentication authentication = mapper.readValue(json, Authentication.class);\r\n}\r\n```\r\n\r\nwith the following stacktrace:\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.SubTypeValidator.validateSubType(SubTypeValidator.java:86)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory._validateSubType(BeanDeserializerFactory.java:916)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:135)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:411)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:349)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:444)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:183)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.createContextual(CollectionDeserializer.java:27)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handlePrimaryContextualization(DeserializationContext.java:651)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:471)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:293)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:477)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:4178)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3997)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2992)\r\n```\r\nIn prior versions, the test works.   "
            },
            "145": {
                "commit_sha_buggy": "ff834690c1df3b90c2f89d362d5c77035820bc88",
                "commit_sha_fixed": "8098ff38f696a2b7001d86969c6b98c549458726",
                "report_id": "1912",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1912",
                "issue_title": "`BeanDeserializerModifier.updateBuilder()` not work to set custom deserializer on a property (since 2.9.0)",
                "issue_description": "Since `2.9` use `BeanDeserializerModifier.updateBuilder` not work to set custom deserializer on a property.\r\n\r\nThis is because this method on `BeanDeserializerBase` has bean replace by this : \r\n\r\nold\r\n``` java\r\npublic SettableBeanProperty findProperty(String propertyName)\r\n{\r\n    SettableBeanProperty prop = (_beanProperties == null) ?\r\n            null : _beanProperties.find(propertyName);\r\n    if (prop == null && _propertyBasedCreator != null) {\r\n        prop = _propertyBasedCreator.findCreatorProperty(propertyName);\r\n    }\r\n    return prop;\r\n}\r\n```\r\n\r\nnew \r\n``` java\r\n    public SettableBeanProperty findProperty(String propertyName)\r\n    {\r\n        SettableBeanProperty prop = (_beanProperties == null) ?\r\n                null : _beanProperties.find(propertyName);\r\n        if (_neitherNull(prop, _propertyBasedCreator)) {\r\n            prop = _propertyBasedCreator.findCreatorProperty(propertyName);\r\n        }\r\n        return prop;\r\n    }\r\n\r\n   protected final static boolean _neitherNull(Object a, Object b) {\r\n        return (a != null) && (b != null);\r\n    }\r\n```\r\n\r\n`prop == null` has been replace by `prop != null`.\r\n\r\nSo custom deserializer can not be used and are replaced by default.\r\n"
            },
            "146": {
                "commit_sha_buggy": "bc22f90eb7f896ace9567598a99cb1ff6e0f9d9d",
                "commit_sha_fixed": "9b1b35de0af5aa43d7bb9de21612088d9c4f7496",
                "report_id": "1940",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1940",
                "issue_title": "`Float` values with integer value beyond `int` lose precision if bound to `long`",
                "issue_description": "Jackson version: 2.9.4\r\n\r\nSample code demonstrating the problem:\r\n```\r\nimport com.fasterxml.jackson.annotation.JsonProperty;\r\nimport com.fasterxml.jackson.annotation.JsonTypeInfo;\r\nimport com.fasterxml.jackson.databind.JsonNode;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\n\r\nimport java.io.IOException;\r\n\r\n@JsonTypeInfo(use=JsonTypeInfo.Id.CLASS, include=JsonTypeInfo.As.PROPERTY, property=\"_class\")\r\npublic class LongContainer {\r\n    @JsonProperty\r\n    private Long longObj;\r\n\r\n    public static void main(String[] args) throws IOException {\r\n        ObjectMapper objectMapper = new ObjectMapper();\r\n        JsonNode tree = objectMapper.readTree(\"{\\\"longObj\\\": 1519348261000.0, \\\"_class\\\": \\\"LongContainer\\\"}\");\r\n        LongContainer obj = objectMapper.treeToValue(tree, LongContainer.class);\r\n        System.out.println(obj.longObj);\r\n    }\r\n}\r\n```\r\n\r\nIt's caused by [this line](https://github.com/FasterXML/jackson-databind/commit/6a1152cd446230b192b7d5b056cc1cb3877be684#diff-5c0023d081050275137dd9b6afc1ece9R1692). Curiously enough, it works fine if you deserialize a plain float value into `Long.class` since that uses `TreeTraversingParser` instead of `TokenBuffer`.\r\n"
            },
            "147": {
                "commit_sha_buggy": "881f9209aaa5e604f9749ad0f0345845e32c42bd",
                "commit_sha_fixed": "13a7490da909d3597aad8fda543baa2af6c60e1e",
                "report_id": "1947",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1947",
                "issue_title": "`MapperFeature.AUTO_DETECT_XXX` do not work if all disabled",
                "issue_description": "We use ObjectMapper.disable(MapperFeature.AUTO_DETECT_XXX) to disable autodetection of all kind of property accessors. After updating to jackson 2.9 I noticed that this method doesn't work anymore and visibility is reset to default (ANY for getters/is getters and public for other)\r\n\r\nI've created a repository that shows this issue:\r\nhttps://github.com/saladinkzn/jackson-auto-detect-issue\r\n\r\nIf run without changes it produces following output:\r\n```\r\n{\"shouldBeDetected\":0,\"shouldNotBeDetected\":null}\r\n[Visibility: getter=PUBLIC_ONLY,isGetter=PUBLIC_ONLY,setter=ANY,creator=ANY,field=PUBLIC_ONLY]\r\n```\r\n\r\nBut if I comment out any disable line (e.g. AUTO_DETECT_IS_GETTER) I receive following output:\r\n```\r\n{\"shouldBeDetected\":0}\r\n[Visibility: getter=NONE,isGetter=PUBLIC_ONLY,setter=NONE,creator=NONE,field=NONE]\r\n```\r\n\r\nI guess the reason is that getDefaultVisibilityChecker explicitly skips disabling if none of AUTO_DETECT features is enabled. \r\nhttps://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.9.4/src/main/java/com/fasterxml/jackson/databind/cfg/MapperConfigBase.java#L675\r\n\r\nP.S.\r\nI see that this code is rewritten in master branch already, so I'll try to reproduce my issue on it."
            },
            "148": {
                "commit_sha_buggy": "1074386f74c42ce0abd80a9304bcd77a26e56113",
                "commit_sha_fixed": "ba35c173988104039ea68c46ab85bb1c11f8984f",
                "report_id": "1977",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1977",
                "issue_title": "Serializing an Iterator with multiple sub-types fails after upgrading to 2.9.x",
                "issue_description": "Hello,\r\n\r\nI recently upgraded my jackson version 2.8.7 to 2.9.4 and serialization of an iterator with multiple sub-types seems broken.\r\n\r\n### Code to recreate the issue:\r\n```\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.Iterator;\r\n\r\npublic class JacksonErrorTest {\r\n\r\n    private static Iterator<Number> numbers;\r\n    private static final ObjectMapper MAPPER = new ObjectMapper();\r\n\r\n    public static void main(String[] args) throws Exception {\r\n\r\n        ArrayList<Number> numbersList = new ArrayList<>();\r\n        numbersList.add(1);\r\n        numbersList.add(1.0);\r\n        numbers = numbersList.iterator();\r\n        MAPPER.writeValueAsString(numbers);\r\n    }\r\n}\r\n```\r\n\r\n### The exception stack trace is:\r\n```\r\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: java.lang.Double cannot be cast to java.lang.Integer\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._wrapAsIOE(DefaultSerializerProvider.java:509)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:482)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3893)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:3207)\r\n\tat JacksonErrorTest.main(JacksonErrorTest.java:21)\r\nCaused by: java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Integer\r\n\tat com.fasterxml.jackson.databind.ser.std.NumberSerializers$IntegerSerializer.serialize(NumberSerializers.java:137)\r\n\tat com.fasterxml.jackson.databind.ser.impl.IteratorSerializer._serializeDynamicContents(IteratorSerializer.java:120)\r\n\tat com.fasterxml.jackson.databind.ser.impl.IteratorSerializer.serializeContents(IteratorSerializer.java:80)\r\n\tat com.fasterxml.jackson.databind.ser.impl.IteratorSerializer.serialize(IteratorSerializer.java:67)\r\n\tat com.fasterxml.jackson.databind.ser.impl.IteratorSerializer.serialize(IteratorSerializer.java:13)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480)\r\n\t... 4 more\r\n```\r\n\r\nIt looks like the error is on this line: \r\nhttps://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/impl/IteratorSerializer.java#L109\r\n`serializers.serializerFor(cc);`\r\nshould be\r\n`serializer = serializers.serializerFor(cc);`"
            },
            "149": {
                "commit_sha_buggy": "de6ca2527ed3080802d77a4dd863307c7aaed5b6",
                "commit_sha_fixed": "69f6f52da2204839e0826a1e79ce43781bbcf0d1",
                "report_id": "1999",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/1999",
                "issue_title": "\"Duplicate property\" issue should mention which class it complains about",
                "issue_description": "When Jackson 2.9.5 complains about \"duplicate property\", it does give no reference to the specific class.\r\nIf you have hundreds of generated models, it's quite tedious to find out.\r\n```\r\ncom.fasterxml.jackson.databind.exc.InvalidDefinitionException: \r\nDuplicate creator property \"id\" (index 0 vs 1)\r\n at [Source: (String)\"{\r\n  \"description\": \"patched description\"}\"; line: 1, column: 1]\r\n        at com.fasterxml.jackson.databind.exc.InvalidDefinitionExc\r\n```\r\nI assume it happens with other errors too, at least I found in forums: \"Could not find creator property with name 'id'\" and some more.\r\n\r\nBtw, it started with version 2.9.2 - it did not complain before (I assume that was a bug).\r\n\r\nSource: \r\nhttps://github.com/FasterXML/jackson-databind/blob/f42b0dcf247b3abeab77a785548a4e7e6500909b/src/main/java/com/fasterxml/jackson/databind/deser/impl/CreatorCollector.java\r\n"
            },
            "150": {
                "commit_sha_buggy": "fce83268fad94fbbda58387dc3594055aad1eee5",
                "commit_sha_fixed": "f2d2c313bc2c81aa1e64a5e30abb43d92db2cf13",
                "report_id": "2019",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2019",
                "issue_title": "Abstract Type mapping in 2.9 fails when multiple modules are registered",
                "issue_description": "If multiple modules are used to map abstract types, deserialization might fail in 2.9+:\r\n\r\n> com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `model.Datatype1` (no Creators, like default construct, exist): abstract types either need to be mapped to concrete types, have custom deserializer, or contain additional type information\r\n\r\nThe bug can be reproduced for version 2.9+ in the attached maven project.\r\n\r\nI guess the bug was introduced due to a modification of _mapAbstractType2 in com.fasterxml.jackson.databind.deser.BasicDeserializerFactory:\r\n\r\n2.9:\r\nJavaType concrete = resolver.findTypeMapping(config, type);\r\nif (ClassUtil.rawClass(concrete) != currClass) {\r\n    return concrete;\r\n}\r\n\r\n2.8\r\nif (concrete != null && concrete.getRawClass() != currClass) {\r\n    return concrete;\r\n}\r\n\r\nThe not null check is needed for continuing iterating other modules for abstract type mappings. \r\n\r\n[jackson-error-example.zip](https://github.com/FasterXML/jackson-databind/files/1964903/jackson-error-example.zip)\r\n\r\nBest regards\r\nAsger Christiansen"
            },
            "151": {
                "commit_sha_buggy": "78e78738d69adcb59fdac9fc12d9053ce8809f3d",
                "commit_sha_fixed": "bfeb1fa9dc4c889f8027b80abb2f77996efd9b70",
                "report_id": "2034",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2034",
                "issue_title": "Serialization problem with type specialization of nested generic types",
                "issue_description": "We're facing a problem in our project when updating to the latest Spring Boot version (1.5.12) which upgrades from Jackson 1.8.10 to 1.8.11: Serialization of some of our classes now doesn't work anymore. Going up to 1.9.5 the same problem still persists for us.\r\n\r\nI was able to track this back to a change in issue #1604 where I've commented earlier. I'm opening a new issue as suggested there, but this problem could be connected to #1964.\r\n\r\nI've isolated our problem into a simple maven based project, you can find it here:\r\n\r\nhttps://github.com/dnno/jackson-serialization-problem/\r\n\r\nThe classes we try to serialize make use of generics and Jackson now isn't able to handle them anymore. Type resolution stops here:\r\n\r\nTypeFactory._verifyAndResolvePlaceholders():476\r\n\r\nif (exp.getRawClass() != act.getRawClass()) {  \r\n    return false;  \r\n}\r\n\r\nI don't really understand a lot of what's happening here, but what I do see is, that if I manually set the resulting error String to , the serialization will work fine.\r\n\r\nCould it be, that it's wrong to just compare for the same raw classes, but instead traverse the type hierarchy? In my case it's comparing a List (actual) to an Object (expected). A successful comparison would make sense for me.\r\n\r\n"
            },
            "152": {
                "commit_sha_buggy": "e12eea63573848f5af1350ee09b97ada287e3a33",
                "commit_sha_fixed": "9e2a4a95c4083d9386130aad42b676d92b3bfb43",
                "report_id": "2374",
                "report_url": "https://github.com/FasterXML/jackson-databind/pull/2374",
                "issue_title": "`ObjectMapper. getRegisteredModuleIds()` throws NPE if no modules registered",
                "issue_description": "`#getRegisteredModuleIds()` does not throws `NullPointerException` when there is no registered modules, now it returns a empty unmodifiable set.\r\n\r\n```java\r\nnew ObjectMapper().getRegisteredModuleIds() // throws NPE\r\n```"
            },
            "153": {
                "commit_sha_buggy": "052be02b243bdec8c386e362009aac81700167c7",
                "commit_sha_fixed": "5dfd86f6840becb3210a3886d17885529499301d",
                "report_id": "2309",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2309",
                "issue_title": "READ_ENUMS_USING_TO_STRING doesn't support null values",
                "issue_description": "The test added in EnumDeserializationTest.java fails w/out the fix in EnumResolver.java.\r\n\r\nhttps://github.com/FasterXML/jackson-databind/pull/2307/files\r\n\r\n"
            },
            "154": {
                "commit_sha_buggy": "7904f92ed53cb6243ce42aeb7ff5df7b7bd1295b",
                "commit_sha_fixed": "e3ec9dc5a816ba1107816cd199f9be5e3f41d628",
                "report_id": "2164",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2164",
                "issue_title": "`FactoryBasedEnumDeserializer` does not respect `DeserializationFeature.WRAP_EXCEPTIONS`",
                "issue_description": "We have the following Enum setup with a `@JsonCreator` on `fromString`:\r\n```java\r\npublic enum TestEnum {\r\n    A,\r\n    B;\r\n\r\n    @JsonCreator\r\n    public static TestEnum fromString(String input) {\r\n        // after some check...\r\n        throw new IllegalArgumentException();\r\n    }\r\n}\r\n```\r\nWhen `DeserializationFeature.WRAP_EXCEPTIONS` is disabled\r\n\r\n#### Expected Behavior\r\nThe `IllegalArgumentException` gets propergated. \r\n#### Actual Behavior\r\nAn `InvalidDefinitionException` wrapping the exception was thrown.\r\n\r\n##### Error: \r\n```\r\ncom.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `TestModule$TestEnum`, problem: null\r\n at [Source: (String)\"{\"key\": \"value\"}\"; line: 1, column: 9] (through reference chain: java.util.LinkedHashMap[\"key\"])\r\n\tat com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.instantiationException(DeserializationContext.java:1601)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleInstantiationProblem(DeserializationContext.java:1072)\r\n\tat com.fasterxml.jackson.databind.deser.std.FactoryBasedEnumDeserializer.deserialize(FactoryBasedEnumDeserializer.java:142)\r\n\tat com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:527)\r\n\tat com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:364)\r\n\tat com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:29)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3023)\r\n\tat TestModule.testEnumDeserialization(TestModule.java:34)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\r\nCaused by: java.lang.IllegalArgumentException\r\n\tat TestModule$TestEnum.fromString(TestModule.java:24)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat com.fasterxml.jackson.databind.introspect.AnnotatedMethod.callOnWith(AnnotatedMethod.java:122)\r\n\tat com.fasterxml.jackson.databind.deser.std.FactoryBasedEnumDeserializer.deserialize(FactoryBasedEnumDeserializer.java:134)\r\n\t... 30 more\r\n```\r\n\r\n##### Full Junit Test Case\r\n```java\r\nimport com.fasterxml.jackson.annotation.JsonCreator;\r\nimport com.fasterxml.jackson.core.type.TypeReference;\r\nimport com.fasterxml.jackson.databind.DeserializationFeature;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport org.junit.Rule;\r\nimport org.junit.Test;\r\nimport org.junit.rules.ExpectedException;\r\nimport java.util.Map;\r\n\r\npublic class TestModule {\r\n    private static final ObjectMapper MAPPER = new ObjectMapper();\r\n\r\n    @Rule\r\n    public final ExpectedException expectedException = ExpectedException.none();\r\n\r\n    public enum TestEnum {\r\n        A,\r\n        B;\r\n\r\n        @JsonCreator\r\n        public static TestEnum fromString(String input) {\r\n            throw new IllegalArgumentException();\r\n        }\r\n    }\r\n\r\n    @Test\r\n    public void testEnumDeserialization() throws Exception {\r\n        expectedException.expect(IllegalArgumentException.class);\r\n\r\n        MAPPER.disable(DeserializationFeature.WRAP_EXCEPTIONS);\r\n\r\n        MAPPER.readValue(\"{\\\"key\\\": \\\"value\\\"}\", new TypeReference<Map<String, TestEnum>>() {\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n"
            },
            "155": {
                "commit_sha_buggy": "c71939108f6007d1ef5d907475eac880bd3486b8",
                "commit_sha_fixed": "81b334ce53a512dcf400bbc78f314101d306a45b",
                "report_id": "2472",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2472",
                "issue_title": "DefaultTypeResolverBuilder#_subtypeValidator causes NPE with JsonTypeInfo.Id.CLASS or MINIMAL_CLASS",
                "issue_description": "Hi guys!\r\nI faced with an issue with last update (2.10.0.pr3):\r\nThere was added a DefaultTypeResolverBuilder constructor with PolymorphicTypeValidator, and the @ Deprecated one passes the null reference by default. \r\n```java\r\n    @Deprecated // since 2.10\r\n    public DefaultTypeResolverBuilder(DefaultTyping t) {\r\n        this(t, null);\r\n    }\r\n```\r\nSo, in the cases of deserialization with `JsonTypeInfo.Id.CLASS` there will be NPE. For example the last redisson `JsonJacksonCodec` make the following configuration:\r\n```java\r\nprotected void initTypeInclusion(ObjectMapper mapObjectMapper) {\r\n        TypeResolverBuilder<?> mapTyper = new DefaultTypeResolverBuilder(DefaultTyping.NON_FINAL) {\r\n            public boolean useForType(JavaType t) {\r\n                switch (_appliesFor) {\r\n                case NON_CONCRETE_AND_ARRAYS:\r\n                    while (t.isArrayType()) {\r\n                        t = t.getContentType();\r\n                    }\r\n                    // fall through\r\n                case OBJECT_AND_NON_CONCRETE:\r\n                    return (t.getRawClass() == Object.class) || !t.isConcrete();\r\n                case NON_FINAL:\r\n                    while (t.isArrayType()) {\r\n                        t = t.getContentType();\r\n                    }\r\n                    // to fix problem with wrong long to int conversion\r\n                    if (t.getRawClass() == Long.class) {\r\n                        return true;\r\n                    }\r\n                    if (t.getRawClass() == XMLGregorianCalendar.class) {\r\n                        return false;\r\n                    }\r\n                    return !t.isFinal(); // includes Object.class\r\n                default:\r\n                    // case JAVA_LANG_OBJECT:\r\n                    return t.getRawClass() == Object.class;\r\n                }\r\n            }\r\n        };\r\n        mapTyper.init(JsonTypeInfo.Id.CLASS, null);\r\n        mapTyper.inclusion(JsonTypeInfo.As.PROPERTY);\r\n        mapObjectMapper.setDefaultTyping(mapTyper);\r\n\trest of config...\r\n```\r\nNPE will be thrown in `StdTypeResolverBuilder#verifyBaseTypeValidity`, cause the `ptv` will be null.\r\nSo my question: is it possible (for backward compatibility) to change constructor in `DefaultTypeResolverBuilder` from\r\n```java\r\n    @Deprecated // since 2.10\r\n    public DefaultTypeResolverBuilder(DefaultTyping t) {\r\n        this(t, null);\r\n    }\r\n```\r\nto\r\n```java\r\n    @Deprecated // since 2.10\r\n    public DefaultTypeResolverBuilder(DefaultTyping t) {\r\n        this(t, LaissezFaireSubTypeValidator.instance);\r\n    }\r\n```\r\n?"
            },
            "156": {
                "commit_sha_buggy": "d132efa93d5651b61e7e2ab6276b5cc4bccaa13d",
                "commit_sha_fixed": "d1959f88327a6172a527de201a2134afd9aaf01f",
                "report_id": "2457",
                "report_url": "https://github.com/FasterXML/jackson-databind/issues/2457",
                "issue_title": "Extended enum values are not handled as enums when used as Map keys",
                "issue_description": "Hello, guys!\r\nI've faced with a problem of inconsistent enum serialization:\r\n\r\n``` java\r\nimport com.fasterxml.jackson.core.JsonProcessingException;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\n\r\nimport java.util.Map;\r\n\r\npublic class JacksonEnumTest {\r\n\r\n    public static void main(String[] args) throws JsonProcessingException {\r\n        final ObjectMapper mapper = new ObjectMapper();\r\n        final Map<MyEnum, String> map = Map.of(\r\n            MyEnum.A, \"1\",\r\n            MyEnum.B, \"2\");\r\n        System.out.println(mapper.writeValueAsString(map));\r\n    }\r\n\r\n    enum MyEnum {\r\n        A,\r\n        B() {\r\n            @Override\r\n            public void foo() {\r\n                // also do nothing\r\n            }\r\n        }\r\n\r\n        public void foo() {\r\n            // do nothing\r\n        }\r\n\r\n        @Override\r\n        public String toString() {\r\n            return name() + \" as string\";\r\n        }\r\n    }\r\n}\r\n```\r\n### Expected result:\r\n`{\"A\":\"1\", \"B\":\"2\"}`\r\n### Actial result:\r\n`{\"A\":\"1\", \"B as string\":\"2\"}`\r\n\r\n### Research:\r\nActually `B.getClass()` is not `MyEnum` but `MyEnum$1` which is not enum anymore! \r\n```java\r\nMyEnum.B.getClass().isEnum() == false\r\n```\r\nSo, my proposal is to add this check to `com.fasterxml.jackson.databind.JavaType`:\r\n``` java\r\n @Override\r\n    public final boolean isEnumType() { \r\n    return  _class.isEnum() || Enum.class.isAssignableFrom(_class);\r\n }\r\n```"
            }
        }
    },
    "JacksonXml": {
        "owner_repo": "FasterXML/jackson-dataformat-xml",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "81f38e1985bdfafdbe02e32dfb5ccb200fc64eae",
                "commit_sha_fixed": "2d7683ed820116b77cba9b4b290cd7ce7dfa5cf4",
                "report_id": "180",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/180",
                "issue_title": "Problem with deserialization of nested non-wrapped lists, with empty inner list",
                "issue_description": "Looks like there is a problem, wherein nested structures like say:\n- Definition POJO, with `records`, unwrapped List with `Record`\n- `Record` POJO having property `fields`, another unwrapped list of `Field` POJOs\n\nand case where inner `List` happens to be empty/missing, cause incorrectly \"split\" parts of outermost `List`s (here for property `records`).\n\nI will come up with a full reproduction later on, but observed this in the wild, and I think it occurs with latest 2.7.0-rc code, as well as `2.6.4-1`, so is not just something that has been fixed with a later version.\n"
            },
            "2": {
                "commit_sha_buggy": "a96d27d4c74707965b257b6ecced4d337357545e",
                "commit_sha_fixed": "37eb331acce08142ad027f127c355f9b462fe9e0",
                "report_id": "196",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/196",
                "issue_title": "Mixed content not supported if there are child elements.",
                "issue_description": "@XmlText is only supported if there are no child elements, support could be improved with some changes in XmlTokenStream.\nI successfully made some changes in XmlTokenStream, it's working in my personal case, but it needs more tests.\nIf agreed, I could provide a patch.\n\nExample:\nInput string : `\"<windSpeed units=\\\"kt\\\">27<radius>20</radius></windSpeed>\"`\n \"CxmlWindSpeed\" class :\n\n```\npublic class WindSpeed {\n\n    public static class Radius {\n        @JacksonXmlProperty(isAttribute = true)\n        private String sector;\n        @JacksonXmlProperty(isAttribute = true)\n        private String units;\n        @JacksonXmlText\n        private int value;\n        ..../ Getters and Setters code/....\n    }\n    @JacksonXmlProperty(isAttribute = true)\n    private String units;\n    @JacksonXmlProperty(isAttribute = true)\n    private String source;\n    @JacksonXmlText\n    private int value;\n    @JacksonXmlElementWrapper(useWrapping = false)\n    private List<Radius> radius;\n    ..../ Getters and Setters code/....\n}\n```\n"
            },
            "3": {
                "commit_sha_buggy": "23ab583c46a6a20b0c1232ebb91b16d4058c7502",
                "commit_sha_fixed": "79a4b57f2bbe08ce46e6dabb0a8b76f4a787141c",
                "report_id": "204",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/204",
                "issue_title": "FromXMLParser nextTextValue() incorrect for attributes",
                "issue_description": "As of #129 the Method nextTextValue of FromXMLParser will no longer return a value for attributes. As the _currToken is JsonToken.VALUE_STRING in this case I think it is wrong to return null and it should return _currText.\n"
            },
            "4": {
                "commit_sha_buggy": "4c6a8b996ac608251fa63286d6c322251910ca63",
                "commit_sha_fixed": "2c5f6f4e0f7bbcfa566fbc91ee57baf8dd7a371a",
                "report_id": "213",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/213",
                "issue_title": "`XmlSerializerProvider` does not use `withRootName` config for null",
                "issue_description": "In `jackson-dataformat-xml/src/main/java/com/fasterxml/jackson/dataformat/xml/ser/XmlSerializerProvider.java`\n\nLine 203, I think `_rootNameFromConfig()` should be used if available instead of `ROOT_NAME_FOR_NULL`, so that `withRootName()` config can be used.\n\nI don't know whether/how deser would be affected\n\nhttps://github.com/FasterXML/jackson-dataformat-xml/blob/ca1c671c419e88a18357d497ec3671c73c37452e/src/main/java/com/fasterxml/jackson/dataformat/xml/ser/XmlSerializerProvider.java#L203\n"
            },
            "5": {
                "commit_sha_buggy": "ce61138456e10580c6bf78bc4009de926105c4d6",
                "commit_sha_fixed": "8aa276ba6b2092a562195f9a94eb562686a3352c",
                "report_id": "282",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/282",
                "issue_title": "`@JacksonXmlRootElement` malfunction when using it with multiple `XmlMapper`s and disabling annotations",
                "issue_description": "Found this in version 2.9.4 running some tests that go back and forth serializing with an XML mapper that uses annotations, and another one that ignores them. May be related to issue #171 and the cache of class annotations.\r\n\r\nWhen running this code, the second print statement should use the annotation's localName but it instead uses the class name.\r\n\r\n```\r\n@JacksonXmlRootElement(localName = \"myname\")\r\npublic class XMLTest {\r\n\r\n    public static void main(String[] s) throws Exception {\r\n\r\n        final ObjectMapper xmlMapper = new XmlMapper();\r\n        final ObjectMapper noAnnotationsXmlMapper = xmlMapper.copy()\r\n                .configure(MapperFeature.USE_ANNOTATIONS, false)\r\n                .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);\r\n\r\n        System.out.println(noAnnotationsXmlMapper.writeValueAsString(new XMLTest()));\r\n        System.out.println(xmlMapper.writeValueAsString(new XMLTest()));\r\n\r\n    }\r\n\r\n}\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n<XMLTest/>\r\n<XMLTest/>\r\n```"
            },
            "6": {
                "commit_sha_buggy": "17f39695b24bbf0e8fa1fb86cbb5347d7ddadefc",
                "commit_sha_fixed": "8fd9463dad8d2232c1e947403ead465d6a3e5f73",
                "report_id": "270",
                "report_url": "https://github.com/FasterXML/jackson-dataformat-xml/issues/270",
                "issue_title": "Add support for `writeBinary()` with `InputStream` to `ToXMLGenerator`",
                "issue_description": "The regular `UTF8JSONGenerator` has a method:\r\n\r\n```\r\nwriteBinary(Base64Variant b64variant, InputStream data, int dataLength)\r\n```\r\n\r\nThat supports reading an InputStream, converting the binary stream to Base64, and directly writing to the content output. Thereby saving some memory by not having to load the entire stream's content into memory all at once.\r\n\r\nHowever, `ToXmlGenerator` does not implement this method. It only implements a writeBinary overload that takes an already existing `byte[]`.\r\n\r\nI first [reported this issue](https://groups.google.com/forum/#!topic/jackson-user/rZ8UwvXtArM) on the jackson-user google group, and @cowtowncoder suggested I open an issue on GitHub."
            }
        }
    },
    "Jsoup": {
        "owner_repo": "jhy/jsoup",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "77add7946ea5bca622b1f4f654f97e62f6db1e95",
                "commit_sha_fixed": "27a52f90a25699bebe23ff1ff94d6db361fdb11d",
                "report_id": "23",
                "report_url": "https://github.com/jhy/jsoup/issues/23",
                "issue_title": "Parsing a HTML snippet causes the leading text to be moved to back",
                "issue_description": "Code:\n\n```\nString html = \"foo <b>bar</b> baz\";\nString text = Jsoup.parse(html).text();\nSystem.out.println(text);\n```\n\nResult: \n\n```\nbar baz foo\n```\n\nExpected:\n\n```\nfoo bar baz\n```\n"
            },
            "2": {
                "commit_sha_buggy": "27a52f90a25699bebe23ff1ff94d6db361fdb11d",
                "commit_sha_fixed": "bb4ead7c350695c1ed3c52d028090da4d4cecd1e",
                "report_id": "22",
                "report_url": "https://github.com/jhy/jsoup/issues/22",
                "issue_title": "Unadorned text following data-only tags doesn't parse properly",
                "issue_description": "This HTML, parsed and immediately printed out, results in:\n\n&lt;html&gt;\n&lt;body&gt;\n&lt;script type=&quot;text/javascript&quot;&gt;\n  var inside = true;\n&lt;/script&gt;\nthis should be outside.\n&lt;/body&gt;\n&lt;/html&gt;\n\nResults:\n\n&lt;html&gt; \n&lt;head&gt; \n&lt;/head&gt; \n&lt;body&gt; \n &lt;script type=&quot;text/javascript&quot;&gt; \n  var inside = true;\n\nthis should be outside.\n\n&lt;/script&gt; \n&lt;/body&gt; \n&lt;/html&gt;\n\nNote how \"this should be outside\" ends up inside the &lt;script&gt; tag, instead of following it.  From what I can tell, this only happens to data-only tags.\n"
            },
            "3": {
                "commit_sha_buggy": "5599adfa2bd30d9784c1eed07b24a31f458f0a58",
                "commit_sha_fixed": "0081d162cca8ad23b500b53799195fec644f261b",
                "report_id": "21",
                "report_url": "https://github.com/jhy/jsoup/issues/21",
                "issue_title": "Issue with <tr>",
                "issue_description": "When calling append to add a table row the resulting tr gets wrapped in a table even though I appended to an existing table.\n"
            },
            "4": {
                "commit_sha_buggy": "f548940dd8be5f8c93ef17a8896b2807aa2a08bc",
                "commit_sha_fixed": "5e52f1b266173593fab32fe9d8a4963066b2f2fe",
                "report_id": "31",
                "report_url": "https://github.com/jhy/jsoup/issues/31",
                "issue_title": "uppercase umlauts get replaced by lowercase umlaut entities",
                "issue_description": "The line\n\n```\nSystem.out.println(Jsoup.clean(\"<h1>\u00dcberschrift</h1>\", Whitelist.none()));\n```\n\nshould print\n\n```\n&Uuml;berschrift\n```\n\nbut prints\n\n```\n&uuml;berschrift\n```\n\nThis used to work correctly in v0.3.1, but fails in v1.2.3.\n\nWhile _baseArray_ in _Entities.java_ distinguishes between lowercase and uppercase umlauts, the above call yields the wrong result.\n"
            },
            "5": {
                "commit_sha_buggy": "5e52f1b266173593fab32fe9d8a4963066b2f2fe",
                "commit_sha_fixed": "62afbdf6a85fec75fde38d327928a180bc5bccb3",
                "report_id": "32",
                "report_url": "https://github.com/jhy/jsoup/issues/32",
                "issue_title": "StringIndexOutOfBoundsException when testing whether String content is valid HTML ",
                "issue_description": "If I try to parse a tag with an equals sign (an empty attribute) but without any single or double quotes around an attribute value, then I get a StringIndexOutOfBoundsException.  The stack trace is pasted below.\n\nAn example String would be \"<a =a\"\n\nThe following JUnit test case should not throw a StringIndexOutOfBoundsException:\n\nimport static org.junit.Assert.assertTrue;\nimport org.jsoup.Jsoup;\nimport org.jsoup.safety.Whitelist;\nimport org.junit.Test;\npublic class BadAttributeTest {\n    @Test\n    public void aTagWithABadAttributeIsValid() throws Exception {\n        assertTrue(Jsoup.isValid(\"<a =a\", Whitelist.relaxed()));\n    }\n}\n\njava.lang.StringIndexOutOfBoundsException: String index out of range: 13\n    at java.lang.String.charAt(String.java:686)\n    at org.jsoup.parser.TokenQueue.consume(TokenQueue.java:130)\n    at org.jsoup.parser.Parser.parseAttribute(Parser.java:207)\n    at org.jsoup.parser.Parser.parseStartTag(Parser.java:142)\n    at org.jsoup.parser.Parser.parse(Parser.java:91)\n    at org.jsoup.parser.Parser.parseBodyFragment(Parser.java:64)\n    at org.jsoup.Jsoup.parseBodyFragment(Jsoup.java:99)\n    at org.jsoup.Jsoup.isValid(Jsoup.java:155)\n"
            },
            "6": {
                "commit_sha_buggy": "0b56f3e5e012e689af8dda0e96d6e0c9f31853b6",
                "commit_sha_fixed": "20ed24cefb5df53c48021459af98bef83c55f241",
                "report_id": "34",
                "report_url": "https://github.com/jhy/jsoup/issues/34",
                "issue_title": "StringIndexOutOfBoundsException when parsing link http://news.yahoo.com/s/nm/20100831/bs_nm/us_gm_china",
                "issue_description": "java.lang.StringIndexOutOfBoundsException: String index out of range: 1\n    at java.lang.String.charAt(String.java:686)\n    at java.util.regex.Matcher.appendReplacement(Matcher.java:711)\n    at org.jsoup.nodes.Entities.unescape(Entities.java:69)\n    at org.jsoup.nodes.TextNode.createFromEncoded(TextNode.java:95)\n    at org.jsoup.parser.Parser.parseTextNode(Parser.java:222)\n    at org.jsoup.parser.Parser.parse(Parser.java:94)\n    at org.jsoup.parser.Parser.parse(Parser.java:54)\n    at org.jsoup.Jsoup.parse(Jsoup.java:30)\n"
            },
            "7": {
                "commit_sha_buggy": "08a3d67273f31718acde383a4c5158bed9c506b2",
                "commit_sha_fixed": "82855b07f5336d30c70dc20548ab7ab8adeac05e",
                "report_id": "43",
                "report_url": "https://github.com/jhy/jsoup/issues/43",
                "issue_title": "Page results in malformed tree",
                "issue_description": "The page I will attach results in a Jsoup tree with two body elements, neither if which is a direct child of the html element.\n\nYou will find the page in \"git@github.com:bimargulies/Misc.git\" under the jsoup-tc directory.\n"
            },
            "8": {
                "commit_sha_buggy": "82855b07f5336d30c70dc20548ab7ab8adeac05e",
                "commit_sha_fixed": "da9b977ef99e2595602a964561906a930b4332f3",
                "report_id": "45",
                "report_url": "https://github.com/jhy/jsoup/issues/45",
                "issue_title": "toString NPE for orphans",
                "issue_description": "I'm working on code that frequently calls 'remove' and then re-adds an element. While the element is in a detached string, toString throws something, so Eclipse prints only an 'invocation target exception.' It would be nice if this were not so.\n"
            },
            "9": {
                "commit_sha_buggy": "da9b977ef99e2595602a964561906a930b4332f3",
                "commit_sha_fixed": "2e4969497c5734d90d394103728bb517644f9157",
                "report_id": "46",
                "report_url": "https://github.com/jhy/jsoup/issues/46",
                "issue_title": "Html entities containing digits are not unescaped correctly",
                "issue_description": "Some html entities (such as sup1, sup2) are not unescaped correctly by Entities.unescape because they contain digits.\n\nThe problem is the pattern Entities.unescapePattern. I changed it to '&(#(x|X)?([0-9a-fA-F]+)|[0-9a-zA-Z]+);?', and it worked fine for me. But there might be side effects ...\n\nYou can see my changes here : https://github.com/clementdenis/jsoup/commit/d65387cb6763c4e6e9896917ce02ea623e30b04e\n"
            },
            "10": {
                "commit_sha_buggy": "9dcc488f3c6afb691e49af42755cfd61b0a69d04",
                "commit_sha_fixed": "adce18ec3d06b849886d203fe932205f312cc37f",
                "report_id": "49",
                "report_url": "https://github.com/jhy/jsoup/issues/49",
                "issue_title": "attr(\"abs:href\") , absUrl(\"href\") ",
                "issue_description": "Document doc = Jsoup.parse(new URL(\"http://www.oschina.net/bbs/thread/12975\"), 5*1000);\nElements es = doc.select(\"a[href]\");\nfor(Iterator<Element> it = es.iterator();it.hasNext();){\n    Element e = it.next();\n        System.out.println(e.absUrl(\"href\"));\n}\n\nattr(\"abs:href\")   ------  &lt;a href=\"?p=1\"&gt;1&lt;/a&gt;\nresult: -------------------   http://www.oschina.net/bbs/thread/?p=1\n\nI think it's a wrong result~.\nThe correct results should be \"http://www.oschina.net/bbs/thread/12975?p=1\"\n"
            },
            "11": {
                "commit_sha_buggy": "13c2af3f24fceda5b44776a5257112ac7218d038",
                "commit_sha_fixed": "f462438f2ebfb354c823cd2c0b677b0674f0e80c",
                "report_id": "36",
                "report_url": "https://github.com/jhy/jsoup/issues/36",
                "issue_title": "Implement :not pseudo-selector",
                "issue_description": "In version 1.3.3, the pseudo selector :not is not implemented.\n"
            },
            "12": {
                "commit_sha_buggy": "43a39b308abfbe39ea06729277d0630786b9956d",
                "commit_sha_fixed": "d0a7e3a00350ea9bdca6a1f005ccc75e5b2d19d4",
                "report_id": "52",
                "report_url": "https://github.com/jhy/jsoup/issues/52",
                "issue_title": "tag[attr~=regex] fails if preceded by a combinator",
                "issue_description": "All following selectors fail with a SelectorParseException:\n\n<pre>\ndiv table[class~=x|y]\ndiv > table[class~=x|y]\ndiv + table[class~=x|y]\ndiv ~ table[class~=x|y]\n</pre>\n\n\nNote that <pre>div, table[class~=x|y]</pre> does not fail\n\nUsing: jsoup 1.4.1 and JDK 7 build 116\n"
            },
            "13": {
                "commit_sha_buggy": "71608a8424e1ad5d110a71d93313c370b2923411",
                "commit_sha_fixed": "411c01ff53f56f0b84bee210ad75c8c2114efa55",
                "report_id": "97",
                "report_url": "https://github.com/jhy/jsoup/issues/97",
                "issue_title": "abs: attribute prefix does not work on Elements.attr()",
                "issue_description": "Elements.attr() iterates on its element to look for the first one with the given attrbute.\n\nIf I try to get the attribute abs:href, the test element.hasAttr(\"abs:herf\") fails, and the returned value is an empty string. \n"
            },
            "14": {
                "commit_sha_buggy": "35ba2dd27d69d1d09fed6f7a3c690f2bd121cb0f",
                "commit_sha_fixed": "437d8eca9f51dd0ed7af5b828412ee96ac192f17",
                "report_id": "82",
                "report_url": "https://github.com/jhy/jsoup/issues/82",
                "issue_title": "Unclosed title tag causes JSoup to \"eat up\" rest of document",
                "issue_description": "Hi:\n\nWe've come across an issue with parsing a document with an unclosed title tag. JSoup\nseems to \"eat up\" the rest of the document in its parsing and thus no elements after\nthe unclosed tag are available after the parse.\n\nWhile this is obviously not a valid document Firefox seems to handle it OK by displaying\nthe document and saying \"Untitled document\" in its title bar.\n\nWe come across a lot of badly formed documents in our web crawls so having a fix\nfor this issue would be much appreciated. I've given some sample source below\nwhich demonstrates the bug (tested against JSoup 1.5.2).\n\nMany thanks,\n- Francis.\n\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.select.Elements;\n\npublic class UnclosedTitleTest {\n\n```\npublic static void main(String args[]) throws Exception {\n    String html = \"<html><head><title>First parse</head>\"\n          + \"<body><p>Parsed HTML into a doc.</p></body></html>\";\n    Document doc = Jsoup.parse(html);\n\n    Elements elements = doc.select(\"p\");\n\n    for (Element element : elements) {\n        System.out.println(element.outerHtml());\n    }\n}\n```\n\n}\n"
            },
            "15": {
                "commit_sha_buggy": "7b47828bc2cf749edfb0f75e370f168c6b1be210",
                "commit_sha_fixed": "7fe868089855c33d6345e740bfdbe6f140794598",
                "report_id": "104",
                "report_url": "https://github.com/jhy/jsoup/issues/104",
                "issue_title": "<script> containing tags causes issues",
                "issue_description": "Thanks for the release, using 1.6.0 now, and getting issues with http://techcrunch.com.  html has a script tag containing tags inside of javascript strings.  Seems to be treating those as real tag openers, creating tag elements and causing the close script tag to be ignored and therefore include a ton of other stuff.  I think this was working in 1.5.2.  \n\nSimplified example:\n\n<pre>\n&lt;HTML>\n&lt;body>\n &lt;div class=vsc sig=Uga>\n  &lt;div class=before>&lt;/div>\n  &lt;script type=\"text/javascript\">\n   header = jQuery('#header_features');\n   if(header.length){\n    header\n     .prepend('&lt;a class=\"prevPage browse left \" />')\n     .append('&lt;a class=\"nextPage browse right\" />');\n\n    items\n     .wrapAll('&lt;div class=\"scrollable\"/>')\n     .wrapAll('&lt;ul class=\"items\"/>')\n     .wrap('&lt;li/>');\n   }\n   &lt;/script>\n   &lt;div class=after>&lt;/div>\n &lt;/div>\n&lt;/body>\n&lt;/HTML>\n</pre>\n\n\nResult, notice the script strings become tags and the script tag now subsumes the following div:\n\n<pre>\n&lt;html>\n &lt;body> \n  &lt;div class=\"vsc\" sig=\"Uga\"> \n   &lt;div class=\"before\">&lt;/div> \n   &lt;script type=\"text/javascript\">\n   header = jQuery('#header_features');\n   if(header.length){\n    header\n     .prepend('\n    &lt;a class=\"prevPage browse left \">') .append('&lt;/a>\n    &lt;a class=\"nextPage browse right\">'); items .wrapAll('\n     &lt;div class=\"scrollable\">\n      ') .wrapAll('\n      &lt;ul class=\"items\">\n       ') .wrap('\n       &lt;li>'); }  \n        &lt;div class=\"after\">&lt;/div> &lt;/li>\n      &lt;/ul>\n     &lt;/div>  &lt;/a>\n   &lt;/script>\n  &lt;/div>\n &lt;/body>\n&lt;/html>\n</pre>\n"
            },
            "16": {
                "commit_sha_buggy": "f16c0c17aa38ecff097f5fc50db7cd5e247c8737",
                "commit_sha_fixed": "f36b950de16f6db134bd98969cd8fbe578d37480",
                "report_id": "109",
                "report_url": "https://github.com/jhy/jsoup/issues/109",
                "issue_title": "DocumentType.outerHtmlHead missing quote",
                "issue_description": "There's just a doublequote missing from the append sequence right before the systemId.\n\nFor example:\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n"
            },
            "17": {
                "commit_sha_buggy": "f36b950de16f6db134bd98969cd8fbe578d37480",
                "commit_sha_fixed": "3d6f1e47ccf93d01364ed5f7603fa66d43eae0e2",
                "report_id": "107",
                "report_url": "https://github.com/jhy/jsoup/issues/107",
                "issue_title": "Cleaning a fragment with just \"0\" returns an empty string (1.6.0)",
                "issue_description": "When using JSoup to sanitize some fragments that are inserted into another document, I noticed if a text node contains just the \"0\", it ends up cleaning it as just 0.\n\nThe root of this seems to come from TreeBuilderState's methods, in such places like InBody and InSelect; when it checks for type Character, it seems to cause the \"0\" token to equal the nullstring; this shouldn't be the case, as character 0 is not the same as a \"null\" character.\n"
            },
            "18": {
                "commit_sha_buggy": "3d6f1e47ccf93d01364ed5f7603fa66d43eae0e2",
                "commit_sha_fixed": "128b3f8212e357468cb608546a52da3826903fad",
                "report_id": "110",
                "report_url": "https://github.com/jhy/jsoup/issues/110",
                "issue_title": "outerHtml method returns extra attribute when element definition has new line",
                "issue_description": "I think this is a bug.\n\nVersion: jsoup-1.6.0.jar\n\nSource:\n---------BEGIN\n&lt;img alt=\"\"\n\n```\n         src=\"/imagelibraries/homepagebanners/british_10k_2010.jpg\" />\n```\n\n---------END\nSteps to reproduce: element.outerHtml() ->\n\nExpected result: two attributes alt and src\nObserved result output\n----------BEGIN\n&lt;img alt=\"\" =\"\" src=\"/imagelibraries/homepagebanners/british_10k_2010.jpg\" />\n----------END\n"
            },
            "19": {
                "commit_sha_buggy": "d0418222830f42f4f0c770e406f71454ea50e56d",
                "commit_sha_fixed": "c98349a7fb5598f0cbac88130520171bd6f253c1",
                "report_id": "127",
                "report_url": "https://github.com/jhy/jsoup/issues/127",
                "issue_title": "Cleaning html containing the cid identifier breaks images",
                "issue_description": "Ok, so in mail type HTML the following is common\n\n<img src=\"cid:SDOMSDOFMOSDOMFOSD\">\n\nThe item after CID: can be almost anything (US-ASCII I think) and of any length. It corresponds to an image linked elsewhere in MIME say like this\n\n--mimebounday\nContent-ID:<SDOMSDOFMOSDOMFOSD>\nContent-Type: image/jpeg.....\n(snip)\n\nSo, to mark a long story somewhat shorter, I use Jsoup's sanitizer extensively. However, I need these CID references to be preserved post sanitization. addProtocols does not work because the items are not valid URLs. As a result\nthe above becomes <img />. Which for my purposes is not good :)\n"
            },
            "20": {
                "commit_sha_buggy": "2c257f6482dd7a9583538b7b0d4b3b0bef9417fd",
                "commit_sha_fixed": "1d31086acba06579c4e7d5928dbba9ca8a0128b1",
                "report_id": "134",
                "report_url": "https://github.com/jhy/jsoup/issues/134",
                "issue_title": "Some html file's head element will be empty",
                "issue_description": "Hello, Jonathan\n\nI love Jsoup, and handling many html files. \n\nBut today, I'm under the  problem.\nWhen parse with Jsoup, some html file's head element will be empty.\n\nSample html is here -> http://dl.dropbox.com/u/972460/test.html\n\nPlease help me.\n"
            },
            "21": {
                "commit_sha_buggy": "c744b9afb57beec265226a9416eec4e572adca28",
                "commit_sha_fixed": "249e5a8aae9324cc6c8caf5303a607056b15a9da",
                "report_id": "179",
                "report_url": "https://github.com/jhy/jsoup/issues/179",
                "issue_title": "Selector parsing gets confused by commata in regexes",
                "issue_description": "The selector `div, li:matches([0-9,]+)` causes a java.util.regex.PatternSyntaxException because  [QueryParser (line 63)](https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/select/QueryParser.java#L63) thinks that the comma inside the regex is a combinator and thus extracts `, li:matches([0-9` as the second alternative.\n\nInstead of scanning ahead with `chompTo(\",\"), the parser needs to parse its way through the alternative until it reaches a comma or the end of a string. That way, commata in regular expressions will be correctly interpreted as part of the regex.\n\nNote that there may be many more variations of this bug in the parser. Wherever a construct allows embedding an arbitrary string one should expect this problem. `[attr=a,b]` for example is likely to cause the same issue. In a way, any invocation of chompTo() needs to examined.\n"
            },
            "22": {
                "commit_sha_buggy": "5d56ace149ae3264d2502d49dd85302fc613a27c",
                "commit_sha_fixed": "4b0dde413a3c38a77461ac64ad278a042d6eea68",
                "report_id": "184",
                "report_url": "https://github.com/jhy/jsoup/issues/184",
                "issue_title": "siblingElements in Element throws Null Pointer Exception",
                "issue_description": "Hi,\n\nI have noticed that the sibling methods (nextSibling, previousSibling, siblingElements) rely on an element (underlying node) having a parent. If the node does not have a parent it throws null pointer exception.\n\nWould it be possible to modify the code so that it checks for parent nullness around Node.java:468? \n\nIn the event of nullness return null as in the javadoc?\n\nConfirmed in 1.6.2\n"
            },
            "23": {
                "commit_sha_buggy": "dbc1e34bdeede1cabee58b65bceb02f930ce5d88",
                "commit_sha_fixed": "1d37cef1d8367af963fee4dc99164708f5d3c6f8",
                "report_id": "145",
                "report_url": "https://github.com/jhy/jsoup/issues/145",
                "issue_title": "Entity whose name is made up of letters and digits is not retained",
                "issue_description": "At about line 136 Tokenizer.java, reader.consumeLetterSequence() is called. This is fine until it an entity such as &amp;sup1; is encountered - just the letter part of the entity name will be read causing the Entities.isNamedEntity(nameRef) call at about line 140 to fail.\n\nI have fixed this quickly locally by replacing reader.consumerLetterSequence() with a call to a new consumeLetterDigitSequence() in the CharacterReader.java - there may be a better way of doing this:\n\n```\nString consumeLetterDigitSequence() {\n    String letters = consumeLetterSequence();\n    String digits = consumeDigitSequence();\n    return letters + digits;\n}\n```\n\nThe following is a sample  unit test:\n\n```\n@Test public void letterDigitEntities() {\n    String html = \"<p>&sup1;&sup2;&sup3;&frac14;&frac12;&frac34;</p>\";\n    Whitelist whitelist = Whitelist.none();\n    whitelist\n        .addTags(\"p\");\n    String html = Jsoup.clean(html, whitelist);\n    assertEquals(\"<p>&sup1;&sup2;&sup3;&frac14;&frac12;&frac34;</p>\", html);\n}\n```\n"
            },
            "24": {
                "commit_sha_buggy": "1d37cef1d8367af963fee4dc99164708f5d3c6f8",
                "commit_sha_fixed": "04b8921d4dcab019b02588620d953c4f19d43a58",
                "report_id": "115",
                "report_url": "https://github.com/jhy/jsoup/issues/115",
                "issue_title": "1.6.0 dropping a ' on a particular javascript string",
                "issue_description": "Loses a single quote when the javascript contains a partial tag, exampled pared from ad section of http://scienceblogs.com/pharyngula.  Note in the result that '&lt;/scr is missing closing ' :\n\nInput:\n\n<pre>\n&lt;HTML>\n&lt;body>\n &lt;div>\n  &lt;script language=\"JavaScript1.1\"> \n    document.write('&lt;/scr' + 'ipt>');\n  &lt;/script>\n &lt;/div>\n&lt;/body>\n&lt;/HTML>\n</pre>\n\n\nResult:\n\n<pre>\n&lt;html>\n &lt;body> \n  &lt;div> \n   &lt;script language=\"JavaScript1.1\"> \n    document.write('&lt;/scr + 'ipt>');\n  \n   &lt;/script> \n  &lt;/div>  \n &lt;/body>\n&lt;/html>\n</pre>\n"
            },
            "25": {
                "commit_sha_buggy": "4b763cc86f698d31f59e22e169e7a5a83e696a55",
                "commit_sha_fixed": "94002db5f90395b8927ae69c569e5a0726dd00c4",
                "report_id": "167",
                "report_url": "https://github.com/jhy/jsoup/issues/167",
                "issue_title": "JSoup is not preserving whitespace for <textArea> tags",
                "issue_description": "This tag may have been mistakenly left out of the array of preserveWhitespace tags in the Tag class:\n\nprivate static final String[] preserveWhitespaceTags = {\"pre\", \"plaintext\", \"title\"};\n\nThere is a comment next to the preserveWhitespace  boolean that indicates this should have been added here.\n private boolean preserveWhitespace = false; // for pre, textarea, script etc\n"
            },
            "26": {
                "commit_sha_buggy": "074d9bfd5476d0430e75073fb27001f43435c081",
                "commit_sha_fixed": "d7b5d5b28a6dd7ff198f02e1ee82160220135a74",
                "report_id": "154",
                "report_url": "https://github.com/jhy/jsoup/issues/154",
                "issue_title": "NullpointerException when applying Cleaner to a frameset",
                "issue_description": "To reproduce:\n1. Create/find a html document of a frameset.\n2. Parse the html.\n3. Create a Cleaner instance and call the clean method with the document from step 2.\n4. NullPointerException\n\nCause:\nIn Cleaner.clean(Document) (https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/safety/Cleaner.java#L43) the copySafeNodes is called with the document.body(). However, this is null when handling a frameset document.\n\nExpected:\nAn empty document or perhaps null returned. But not a nullpointerException.\n"
            },
            "27": {
                "commit_sha_buggy": "009013169754d4869f3a55c27a3443fc72d1d1f1",
                "commit_sha_fixed": "8963e2ac79a97e694c388622e935a0471267e9eb",
                "report_id": "215",
                "report_url": "https://github.com/jhy/jsoup/issues/215",
                "issue_title": "Invalid HTTP-Response header leads to exception",
                "issue_description": "In particular case a HTTP-Webpage responses with a invalid HTTP-Charset field (delivered UFT8 instead of UTF8).\nThis leads to an UnsupportedCharsetException in org.jsoup.helper.DataUtil at around Line 93(?) where :\n\n``` Java\n  Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n  docData = Charset.forName(charsetName).decode(byteData).toString();\n```\n\nI fixed it by wrapping a try catch statement around these two lines such that:\n\n``` Java\ntry{\n  Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n  docData = Charset.forName(charsetName).decode(byteData).toString();\n} catch(UnsupportedCharsetException e){\n  return parseByteData(byteData,(String)null,baseUri,parser);\n}\n```\n\nIt now falls back to the none charset argument assigned clause, and tries to detect the character set via HTML.\n"
            },
            "28": {
                "commit_sha_buggy": "398f9cf93414253c216585efdfca3b9f73f90d74",
                "commit_sha_fixed": "a31ec08e102fd3832f3ff4449e9163440f0afb2c",
                "report_id": "224",
                "report_url": "https://github.com/jhy/jsoup/issues/224",
                "issue_title": "Jsoup.parse unescapes query params in plain text URL's",
                "issue_description": "I'm trying to clean the HTML snippet below, but unfortunately the URL parameter names have been mistaken for HTML entities and unescaped to HTML.\n\n``` html\n    <a href=\"http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\">\n        http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n    </a>\n```\n\nCleaned HTML:    http://www.foo.com?a=1#_rooms=1\u03c7ldren=0\u222b=VA&amp;b=2\nExpected HTML: http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n\nUnit tests...\n\n``` java\n    private static final String URL = \"http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\";\n\n    /**\n     * Passes\n     */\n    @Test\n    public void testStringEscapeUtilsUnescapeHtml() throws Exception {\n        // org.apache.commons.lang.StringEscapeUtils;\n        assertEquals(URL, StringEscapeUtils.unescapeHtml(URL));\n    }\n\n    /**\n     * Fails: unescapes &num, &chi, and &int to #, \u03c7, and \u222b respectively\n     * Expected :http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n     * Actual   :http://www.foo.com?a=1#_rooms=1\u03c7ldren=0\u222b=VA&amp;b=2\n     */\n    @Test\n    public void testJsoupClean() throws Exception {\n        String html = \"<a href=\\\"\" + URL + \"\\\">\" + URL + \"</a>\";\n        assertEquals(URL, Jsoup.clean(html, Whitelist.none()));\n    }\n\n    /**\n     * Fails: unescapes &num, &chi, and &int to #, \u03c7, and \u222b respectively\n     * Expected :http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n     * Actual   :http://www.foo.com?a=1#_rooms=1&children=0\u222b=VA&b=2\n     */\n    @Test\n    public void testJsoupTextNodeCreateFromEncoded() throws Exception {\n        assertEquals(URL, TextNode.createFromEncoded(URL, null).text());\n    }\n```\n"
            },
            "29": {
                "commit_sha_buggy": "59fb5117a767ab75fe3baf5c37966c83430b02af",
                "commit_sha_fixed": "05ae97865c84536a6cfe7759ca6c382eb761ecb2",
                "report_id": "168",
                "report_url": "https://github.com/jhy/jsoup/issues/168",
                "issue_title": "'\\n' and redundant space char is not needed from title",
                "issue_description": "We assume that we just need 1 line title string from below uri.\nhttp://docs.oracle.com/javase/tutorial/uiswing/lookandfeel/nimbus.html\n\nwe can see title like as below by viewing page source code in that page (of course, It is real situation.)\n\n<pre>\n<title>Nimbus Look and Feel (The Java&trade; Tutorials &gt;        \n            Creating a GUI With JFC/Swing &gt; Modifying the Look and Feel)\n</title>\n</pre>\n\n\nmaybe some another page has multiline title, but browser will shows ordinarily.\nin the other words, Browser shows one line title without CR/LF and redundant space character\nwhether string has newline character or many redundant space or tab, or not.\n\nBut,\nWhen we execute Jsoup.connect(uri).get().title(); after we assign \n\"http://docs.oracle.com/javase/tutorial/uiswing/lookandfeel/nimbus.html\" into uri variable as String,\nit gives two lines like below,\n\n\"Nimbus Look and Feel (The Java\u2122 Tutorials > &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\n\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creating a GUI With JFC/Swing > Modifying the Look and Feel)\"\n\n\"Nimbus Look and Feel (The Java\u2122 Tutorials > Creating a GUI With JFC/Swing > Modifying the Look and Feel)\"\nis better, I think.\n\nHumm ... do you have another idea?\n"
            },
            "30": {
                "commit_sha_buggy": "381ce3d861251ae35aea636fc29c277a84060276",
                "commit_sha_fixed": "dfac9ce465ff9c988904d05014d2be2715aa1d2b",
                "report_id": "246",
                "report_url": "https://github.com/jhy/jsoup/issues/246",
                "issue_title": "Jsoup.clean sometimes will throw execution exception:java.lang.StackOverflowError",
                "issue_description": " [ ERROR ]  throw execution exception:java.lang.StackOverflowError\njava.util.concurrent.ExecutionException: java.lang.StackOverflowError\nCaused by: java.lang.StackOverflowError\n    at org.jsoup.safety.Whitelist.isSafeTag(Whitelist.java:323)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:115)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n\nclean the url:http://blog.sina.com.cn/s/blog_501a5b1f0102dx6z.html\n\nIt's have to much **wbr** tags,when i search the page source ,found 24205.\n\ni look at  org.jsoup.safety.Cleaner source code and add code like this \n\n``` java\nprivate int num = 1;\n    /**\n     * Iterates the input and copies trusted nodes (tags, attributes, text) into\n     * the destination.\n     * \n     * @param source\n     *            source of HTML\n     * @param dest\n     *            destination element to copy into\n     * @return number of discarded elements (that were considered unsafe)\n     */\n    private int copySafeNodes(Element source, Element dest) {\n        List<Node> sourceChildren = source.childNodes();\n        int numDiscarded = 0;\n\n        for (Node sourceChild : sourceChildren) {\n            num++;\n            logger.info(num);\n            if (num > 2000) {\n                //break this tag.\n                break;\n            }\n            if (sourceChild instanceof Element) {\n                Element sourceEl = (Element) sourceChild;\n\n                if (whitelist.isSafeTag(sourceEl.tagName())) { // safe, clone\n                                                                // and copy safe\n                                                                // attrs\n                    ElementMeta meta = createSafeElement(sourceEl);\n                    Element destChild = meta.el;\n                    dest.appendChild(destChild);\n                    numDiscarded += meta.numAttribsDiscarded;\n                    numDiscarded += copySafeNodes(sourceEl, destChild); // recurs\n                } else { // not a safe tag, but it may have children (els or\n                            // text) that are, so recurse\n                    numDiscarded++;\n                    numDiscarded += copySafeNodes(sourceEl, dest);\n                }\n            } else if (sourceChild instanceof TextNode) {\n                TextNode sourceText = (TextNode) sourceChild;\n                TextNode destText = new TextNode(sourceText.getWholeText(),\n                        sourceChild.baseUri());\n                dest.appendChild(destText);\n            } // else, we don't care about comments, xml proc instructions, etc\n        }\n        return numDiscarded;\n    }\n```\n\nbut the clean result will be wrong and The layout will be chaos.\n\nHow can I solve this problem?\n"
            },
            "31": {
                "commit_sha_buggy": "f9901ab35d61700dd56cc6c1639e00f0aa58e435",
                "commit_sha_fixed": "caf61a4a0778a72ab713f72e9ef749bf373c98ac",
                "report_id": "242",
                "report_url": "https://github.com/jhy/jsoup/issues/242",
                "issue_title": "Xml declaration is parsed as a comment",
                "issue_description": "Using jsoup 1.6.3, the following snippet\n\n``` java\nSystem.out.println(\n  Jsoup.parse(\n    \"<?xml encoding='UTF-8' version='1.0'?>\" +\n    \"<html>\" +\n    \"<head><title></title></head>\" +\n    \"<body>Document content</body>\" +\n    \"</html>\").outerHtml());\n```\n\nprints :\n\n``` html\n<!--?xml encoding='UTF-8' version='1.0'?-->\n<html>\n <head>\n  <title></title>\n </head>\n <body>\n  Document content\n </body>\n</html>\n```\n\nwhile I expect :\n\n``` html\n<?xml encoding='UTF-8' version='1.0'?>\n<html>\n <head>\n  <title></title>\n </head>\n <body>\n  Document content\n </body>\n</html>\n```\n"
            },
            "32": {
                "commit_sha_buggy": "fa87a8fe2838e80ae0eeba6e2978815ef5533e91",
                "commit_sha_fixed": "0e37cba87eea9d89156c144e3d4298c9c9ed04d4",
                "report_id": "278",
                "report_url": "https://github.com/jhy/jsoup/issues/278",
                "issue_title": "Element.clone() wrongly shared a same classNames Set instance",
                "issue_description": "In the clone() method of Node, the Object.clone() is called, if the original element's classNames Set had been initialized before clone, the original classNames Set will be set to the new cloned Element instance due to the JDK's clone mechanism. Thus, the old element and the newly cloned Element will share a same classNames Set instance.\n"
            },
            "33": {
                "commit_sha_buggy": "834d3142304e0927dc659791da6a4521f271d7fd",
                "commit_sha_fixed": "2518e92a052d922d81d11e28b8e5205639fed9a7",
                "report_id": "305",
                "report_url": "https://github.com/jhy/jsoup/issues/305",
                "issue_title": "Self-closing script tag causes remainder of document to be html-escaped.",
                "issue_description": "When a self-closing script block is encountered it appears that the state transitions do not account for the closing tag, so the rest of the document is considered to be in the body of the script tag, and so is escaped.\n\nThe unit test HtmlParserTest.handlesKnownEmptyBlocks() will fail if a self-closing script tag is included in the String h.\n"
            },
            "34": {
                "commit_sha_buggy": "2518e92a052d922d81d11e28b8e5205639fed9a7",
                "commit_sha_fixed": "88730bf9f399aab6a150212faeea012598be9ec6",
                "report_id": "349",
                "report_url": "https://github.com/jhy/jsoup/issues/349",
                "issue_title": "Parser error on commented CDATA",
                "issue_description": "Jsoup gives the following error when trying to parse this HTML: https://gist.github.com/felipehummel/6122799\n\n```\njava.lang.ArrayIndexOutOfBoundsException: 8666\n    at org.jsoup.parser.CharacterReader.nextIndexOf(CharacterReader.java:92)\n    at org.jsoup.parser.CharacterReader.consumeTo(CharacterReader.java:112)\n    at org.jsoup.parser.TokeniserState$67.read(TokeniserState.java:1789)\n    at org.jsoup.parser.Tokeniser.read(Tokeniser.java:42)\n    at org.jsoup.parser.TreeBuilder.runParser(TreeBuilder.java:47)\n    at org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:41)\n    at org.jsoup.parser.HtmlTreeBuilder.parse(HtmlTreeBuilder.java:37)\n    at org.jsoup.parser.Parser.parse(Parser.java:90)\n    at org.jsoup.Jsoup.parse(Jsoup.java:58)\n...\n```\n\nThe HTML is from a entry in a RSS feed. If I remove the line:\n\n```\n// ]]\n```\n\nor just the \n      ]]\n\nThen it parses the HTML nicely.\n\nDoes this syntax error should really throw an exception or it should be silently ignored?\n"
            },
            "35": {
                "commit_sha_buggy": "88730bf9f399aab6a150212faeea012598be9ec6",
                "commit_sha_fixed": "76399e5b273d63d6affeb94597d8dfddce811964",
                "report_id": "313",
                "report_url": "https://github.com/jhy/jsoup/issues/313",
                "issue_title": "JSoup parsing unclosed tags",
                "issue_description": "Using JSoup inclusive the last release 1.7.2 there is a bug parsing HTML with unclosed tags.\n\nExample:\n\n``` java\nString tmp = \"<a href='www.google.com'>Link<p>Error link</a>\";\nJsoup.parse(tmp);\n```\n\nThe Document that generate is:\n\n``` html\n<html>\n <head></head>\n <body>\n  <a href=\"www.google.com\">Link</a>\n  <p><a>Error link</a></p>\n </body>\n</html>\n```\n\nThe browsers would generate something as:\n\n``` html\n<html>\n <head></head>\n <body>\n  <a href=\"www.google.com\">Link</a>\n  <p><a href=\"www.google.com\">Error link</a></p>\n </body>\n</html>\n```\n\nJsoup should works as browsers or as source code.\n\nAlso there is a question on stackoverflow:\nhttp://stackoverflow.com/questions/15813821/jsoup-parsing-unclosed-tags\n"
            },
            "36": {
                "commit_sha_buggy": "b67cc18ba1814d1abdb16f8ee9bb5473aaa42cf8",
                "commit_sha_fixed": "f052908ec90e12bdc6b67915ef2290aa9eefa48b",
                "report_id": "321",
                "report_url": "https://github.com/jhy/jsoup/issues/321",
                "issue_title": "More robust charset detection code",
                "issue_description": "With the following HTML:\n\n```\n<html lang=\"en-US\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"Content-Type\" content=\"text/html; \" />\n</head>\n```\n\njsoup fails to parse the page with a IllegalCharsetNameException. I see that http-equiv=\"Content-Type\" has an invalid content-type but it would be possible to still parse it correctly by using the html5  <meta charset=\"UTF-8\">, i.e. jsoup could be more robust on this one.\n\nother domains which are not working but could be:\n9kuhkep.net\nwww.a-bright.org\n\nI use this code to parse the sites:\n\n```\nJsoup.connect(url).execute()\n```\n"
            },
            "37": {
                "commit_sha_buggy": "be64f746f9f034e524f8d9bfb9748d19054c8772",
                "commit_sha_fixed": "c07ba8a34b6a6d6665928e106fea67bd9144e4e0",
                "report_id": "368",
                "report_url": "https://github.com/jhy/jsoup/issues/368",
                "issue_title": "Whitespaces are discared in Element.html() method",
                "issue_description": "Hi,\nI'm trying to make an exact copy of a document (changing just a couple of attributes and appending a few nodes) and the trim() inside the Element.html() is killing me.\nI'm using Parsers.xml() and no prettyPrint.\n\nI think this trim should be enabled for prettyPrint only.\n"
            },
            "38": {
                "commit_sha_buggy": "c07ba8a34b6a6d6665928e106fea67bd9144e4e0",
                "commit_sha_fixed": "9e9e15856d41f55cee4a215acae3c3866e78d200",
                "report_id": "364",
                "report_url": "https://github.com/jhy/jsoup/issues/364",
                "issue_title": "Jsoup converts \"svg image\" to \"svg img\"",
                "issue_description": "Hi,\nwhen I parse a html page with a svg element, which contains an image element, the \"image\" element is replaced by \"img\". But this is not correct. The \"image\" must be \"image\".\n\nExample:\nInput:\n\n``` html\n<svg width=\"560\" height=\"150\">\n<image xlink:href=\"myimage.jpg\"\n   y=\"5\" x=\"100\"  \n   height=\"140\" width=\"230\" />\n</svg>\n```\n\nOutput:\n\n``` html\n<svg width=\"560\" height=\"150\">\n<img xlink:href=\"myimage.jpg\"\n   y=\"5\" x=\"100\"  \n   height=\"140\" width=\"230\" />\n</svg>\n```\n\nThe problem seems to be in line 457 of HtmlTreeBuilderState.java.\n"
            },
            "39": {
                "commit_sha_buggy": "6c4f16f233cdfd7aedef33374609e9aa4ede255c",
                "commit_sha_fixed": "3f9f33d88355f22aefc7ea402da09fd1950289ce",
                "report_id": "348",
                "report_url": "https://github.com/jhy/jsoup/issues/348",
                "issue_title": "JSoup incorrectly moves content from the <head> section into <body> for sample URL",
                "issue_description": "If you load the following URL:\n\n```\nhttp://jornutzon.sydneyoperahouse.com/home.htm\n```\n\ninto:\n\n```\nhttp://try.jsoup.org/\n```\n\nthen it will move the content from the \"head\" section into the \"body\" section. The URL\nbeing parsed validates using the W3C validator:\n\nhttp://validator.w3.org/check?uri=http%3A%2F%2Fjornutzon.sydneyoperahouse.com%2Fhome.htm&charset=%28detect+automatically%29&doctype=Inline&ss=1&group=0&user-agent=W3C_Validator%2F1.3+http%3A%2F%2Fvalidator.w3.org%2Fservices\n\nWe are using JSoup 1.7.2\n"
            },
            "40": {
                "commit_sha_buggy": "1837ecbcdbafd051fab6a37e2540bda054e52151",
                "commit_sha_fixed": "b033535fe2cf887de8076221a0d614abfcf17d7b",
                "report_id": "460",
                "report_url": "https://github.com/jhy/jsoup/issues/460",
                "issue_title": "\"<!DOCTYPE>\" IllegalArgumentException: String must not be empty",
                "issue_description": "While this may be a contrived example, Jsoup.parse(\"<!DOCTYPE>\") throws an exception, this was unexpected. Possibly related, a proper document with <!DOCTYPE> (no name) is generating corrupt html e.g. \"<!DOCTYPE &lt;html&gt; ...\" (missing right angle bracket on DOCTYPE.)\n\nSpec says \"When a DOCTYPE token is created, its name, public identifier, and system identifier must be marked as missing (which is a distinct state from the empty string), [...]\"\n"
            },
            "41": {
                "commit_sha_buggy": "b8c259cfaf668e4237de09a0327b82080cfd37ba",
                "commit_sha_fixed": "8391b7231a2519557d41209d728acc4f422af381",
                "report_id": "537",
                "report_url": "https://github.com/jhy/jsoup/issues/537",
                "issue_title": "Element.hashCode() ignores the content text of the element.",
                "issue_description": "Found [this question](http://stackoverflow.com/questions/28970732/jsoup-node-hash-code-collision-when-traversing-dom-tree/28971463) on SO, OP was using `Element.hashCode()` and it wasn't woring right.\r\n\r\nThe problem is that when jsoup generates the hashCode of an Element, the content text of the element will be ignored, and the hashCode is generated only based on the attributes, and the hashCode of the parent Element.\r\n\r\n---\r\n\r\nUsing the following HTML:\r\n\r\n```\r\n<html>\r\n    <head>\r\n    </head>\r\n    <body>\r\n        <div style=\"blah\">TODO: write content</div>\r\n        <div style=\"blah\">Nothing here</div>\r\n        <p style=\"test\">Empty</p>\r\n        <p style=\"nothing\">Empty</p>\r\n    </body>\r\n</html>\r\n```\r\n\r\nAnd the following code:\r\n\r\n```\r\nString html = //HTML posted above\r\n\r\nDocument doc = Jsoup.parse(html);\r\n\r\nElements elements = doc.select(\"[style]\");\r\nfor (Element e : elements) {\r\n   System.out.println(e.hashCode());\r\n}\r\n```\r\n\r\nIt gives:\r\n\r\n```\r\n-148184373\r\n-148184373\r\n-1050420242\r\n2013043377\r\n```\r\n\r\nI believe the hashCode should be different for the first two Elements, since the content is text is different. Or is this intended behaviour?\r\n"
            },
            "42": {
                "commit_sha_buggy": "0c10dbffb475febe05ebaf074278e5d5aa81e32c",
                "commit_sha_fixed": "c01fcd338d73dc039e6a3a6cd2c449d9c9d41304",
                "report_id": "489",
                "report_url": "https://github.com/jhy/jsoup/issues/489",
                "issue_title": "FormElement's formData ignores input checkbox checked without value.",
                "issue_description": "When there is input:         \n\n```\n<input type=\"checkbox\" name=\"testCheckBox\" checked=\"checked\" />\n```\n\nThe \"formData()\" of FormElement's ignores that default value which should be \"on\" as submitted by browsers.\n\nHTML fragment:\n\n```\n<html>\n    <head>\n        <title>Test</title>\n    </head>\n\n    <body>\n\n    <form name=\"myForm\" method=\"POST\">\n        <input type=\"checkbox\" name=\"testCheckBox\" checked=\"checked\" /> Something<br/>\n\n        <input type=\"submit\" value=\"Submit\" />\n    </form>\n\n    </body>\n</html>\n```\n\nWhen submiting from Firefox it sends to sever: testCheckBox=on\n\nJava code:\n\n```\n    public static void main(String[] args)\n    {\n        final String html = \"<html>\\n\"\n                            + \"    <head>\\n\"\n                            + \"        <title>Test</title>\\n\"\n                            + \"    </head>\\n\"\n                            + \"    \\n\"\n                            + \"    <body>\\n\"\n                            + \"\\n\"\n                            + \"    <form name=\\\"myForm\\\" method=\\\"POST\\\">\\n\"\n                            + \"        <input type=\\\"checkbox\\\" name=\\\"testCheckBox\\\" checked=\\\"checked\\\" /> Something<br/>\\n\"\n                            + \"\\n\"\n                            + \"        <input type=\\\"submit\\\" value=\\\"Submit\\\" />\\n\"\n                            + \"    </form>\\n\"\n                            + \"\\n\"\n                            + \"    </body>\\n\"\n                            + \"</html>\";\n\n        final Document document = Jsoup.parse(html);\n\n        final FormElement formElement = (FormElement) document.select(\"form[name=myForm]\").first();\n\n        for (Connection.KeyVal keyVal : formElement.formData())\n        {\n            System.out.println(keyVal.key() + \"=\" + keyVal.value());\n        }\n\n    }\n```\n\nOutput: testCheckBox=\n\nExpected output: testCheckBox=on\n\nSeems like Jsoup doesn't add default value which is sent by browsers. The \"submit()\" method from FormElement also uses \"formData()\" method to get form's submission parameters. By sending the empty String for checkbox the server acts as it's not checked when in fact it was checked.\n\nAlso while testing noticed that it doesn't check the checkbox'es at all. If there is checkbox with value, but not checked, it will get the value no matter what, for example:\n\n```\n        <input type=\"checkbox\" name=\"textCheckBox2\" value=\"testVal\" /> \n```\n\nThis affects radio buttons as well. Not selected radion buttons should not be sent to server, but formData() add their values anyway.\n\nI'm not sure if that's done on purpose, but submit() method will get wrong parameters for submission since not checked input value is not sent to server at all.\n\nMoreover type button value and \"disabled\" inputs are not sent to server as well (by browsers). \n\nLooked at the source, one extra else if before the final else in \"formData()\" method could solve this:\n\n```\nelse if (\"input\".equals(el.tagName())) {\n                // Not disabled? Ignore disabled inputs.\n                if(!el.hasAttr(\"disabled\")) {\n\n                    // Deal with checkbox and radio (not checked should not be added to avoid sending to server)\n                    if(\"checkbox\".equals(el.attr(\"type\")) || \"radio\".equals(el.attr(\"type\"))) {\n\n                        // Checked, but no value? Default should be \"on\".\n                        if(el.hasAttr(\"checked\") && !el.hasAttr(\"value\")) {\n                            data.add(HttpConnection.KeyVal.create(name, \"on\"));\n                        } \n                        // Checked? Add it's value\n                        else if(el.hasAttr(\"checked\")) {\n                            data.add(HttpConnection.KeyVal.create(name, el.val()));\n                        }\n                    } \n                    // Buttons should be ignored.\n                    else if(!\"button\".equals(el.attr(\"type\"))){\n                        data.add(HttpConnection.KeyVal.create(name, el.val()));\n                    }\n                }\n            }\n```\n\nOne more thing. If form has multiple type submit inputs, only the clicked input's value should be sent to server, but I have no idea how this could be implemented. Sending all submit input's values can change the server's logic and be bad (result not as expected).\n"
            },
            "43": {
                "commit_sha_buggy": "373ea35b2cb227b56694aa50589c853b68caa03a",
                "commit_sha_fixed": "11f7c1bd7a2d12f0b1150aa246c61afefd11991f",
                "report_id": "554",
                "report_url": "https://github.com/jhy/jsoup/issues/554",
                "issue_title": "Unexpected behavior in elementSiblingIndex",
                "issue_description": "The documentation for elementSiblingIndex states \"Get the list index of this element in its element sibling list. I.e. if this is the first element sibling, returns 0\".\n\nThis would imply that if\n\n```\nn=myElem.elementSiblingIndex();\n```\n\nthen\n\n```\nmyElem.parent().children().get(n)==myElem.  \n```\n\nHowever, this is not how elementSiblingIndex behaves. What is guaranteed is that\n\n```\nmyElem.parent().children().get(n).equals(myElem).  \n```\n\nFor example, if both row 2 and row 5 of a table are\n\n```\n<tr><td>Cell1</td><td>Cell2</td></tr>\n```\n\nthen the Element object associated with both rows will have the same `elementSiblingIndex()`.\n"
            },
            "44": {
                "commit_sha_buggy": "ec608674d877d2e906cab77bb09ecb2494167f0e",
                "commit_sha_fixed": "3a7f39c507ed2b6809dc3a8bcc0a28ad19aab2f3",
                "report_id": "552",
                "report_url": "https://github.com/jhy/jsoup/issues/552",
                "issue_title": "Unexpected elements inside table are moved to wrong location",
                "issue_description": "This commit https://github.com/jhy/jsoup/commit/e99193605b688e923d20054c13db897cff751607 introduced a bug where handling of unexpected elements inside a table element changed, resulting in the unexpected elements being pushed further up the document than before.\n\nI have constructed a minimal repro. Before the commit in question, the unexpected p tag would continue to be positioned after the comment (with some elements being closed early etc. to support this). After the commit, the p tag and its contents are moved up more than one table level, and now appear after the comment tag.\n\nObviously this input HTML is very broken and bad, but it seems that the change in behaviour was unintended. \n\ncopying @jaredstehler  \n\n```\n@Test\npublic void testInvalidTableContents() throws IOException {\n    File in = getFile(\"/htmltests/table-invalid-elements.html\");\n    Document doc = Jsoup.parse(in, \"UTF-8\");\n    doc.outputSettings().prettyPrint(true);\n    String rendered = doc.toString();\n    int endOfEmail = rendered.indexOf(\"Comment\");\n    int guarantee = rendered.indexOf(\"Why am I here?\");\n    assertTrue(\"Comment not found\", endOfEmail > -1);\n    assertTrue(\"Search text not found\", guarantee > -1);\n    assertTrue(\"Search text did not come after comment\", guarantee > endOfEmail);\n}\n```\n\nUses the following fixture:\n\n```\n<html>\n    <body>\n        <table>\n            <tr>\n                <td>\n                    <table>\n                        <tr>\n                            <!--Comment-->\n                            <table>\n                                <p>Why am I here?</p>\n                        </tr>\n                    </table>\n                </td>\n            </tr>\n        </table>\n    </body>\n</html>\n```\n"
            },
            "45": {
                "commit_sha_buggy": "5be8b081ce931865d46b49ed44e19d3eafde748d",
                "commit_sha_fixed": "3b4f9dfa91b6f1852c35baf79c4a13eacc6112c3",
                "report_id": "575",
                "report_url": "https://github.com/jhy/jsoup/issues/575",
                "issue_title": "Test for redirects in form of ./file.html\n\nNo repro on #585",
                "issue_description": "Test for redirects in form of ./file.html\n\nNo repro on #585"
            },
            "46": {
                "commit_sha_buggy": "ddf4c1bcae69ad48c01eea207e3f3c24d2eda208",
                "commit_sha_fixed": "3ba88d8c2ab500c07f9e2ddbc07a4bd01fadbd78",
                "report_id": "523",
                "report_url": "https://github.com/jhy/jsoup/issues/523",
                "issue_title": "EscapeMode.xhtml no longer falls back to numeric escapes - Can cause '?' replacement in output",
                "issue_description": "I've been using EscapeMode.xhtml with JSoup to avoid encoding things which don't (from my perspective) need to be encoded, like egrave in a UTF-8 document for example.\n\nWhile upgrading from JSoup 1.7.2 to 1.8.1 however, I've noticed a problem with a shift-jis related test I have. Here's a simplified/reduced version.\n\n```\npackage test;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\n\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Entities.EscapeMode;\nimport org.junit.Assert;\nimport org.junit.Test;\n\npublic class ShiftJisTest {\n\n    @Test\n    public void testShiftJisRoundtrip() throws Exception {\n        String input = \n            \"<html>\"\n          +   \"<head>\"\n          +     \"<meta http-equiv=\\\"content-type\\\" content=\\\"text/html; charset=Shift_JIS\\\" />\"\n          +   \"</head>\"\n          +   \"<body>\"\n          +     \"before&nbsp;after\"\n          +   \"</body>\"\n          + \"</html>\";\n        InputStream is = new ByteArrayInputStream(input.getBytes(Charset.forName(\"ASCII\")));\n\n        Document doc = Jsoup.parse(is, null, \"http://example.com\");\n        doc.outputSettings().escapeMode(EscapeMode.xhtml);\n\n        String output = new String(doc.html().getBytes(doc.outputSettings().charset()), doc.outputSettings().charset());\n\n        System.out.println(output);\n\n        Assert.assertFalse(\"Should not have contained a '?'.\", output.contains(\"?\"));\n        Assert.assertTrue(\"Should have contained a '&#xa0;' or a '&nbsp;'.\", \n            output.contains(\"&#xa0;\") || output.contains(\"&nbsp;\"));\n    }\n\n}\n```\n\nUnder JSoup 1.7.2, the body of the output in this test is \"before&#xa0;after\" (which looks as expected when rendered in Firefox), where as under 1.8.1 it is \"before?after\".\n\nI assume the issue here is that I've asked JSoup to escape only XHTML characters (i.e. not nbsp), and it's producing a charset where (I assume) there's no character to represent 'non-breaking space'.\n\nThe upshot of this is that, as a result of upgrading JSoup, I end up with '?' replaced in for what used to be shown as a non breaking space.\n\nIt seems like the old behaviour was to fall back to providing an escaped numeric character (odd if there's no valid character for that in Shift_JIS, but it still rendered correctly). From my perspective, the old behaviour was better - Is there any way it can be reinstated (or an escape mode provided for it)?\n\nObviously using EscapeMode.base instead of EscapeMode.xhtml is a possible workaround, however I would really prefer not to have characters unnecessarily escaped if possible.\n"
            },
            "47": {
                "commit_sha_buggy": "1e09df66f0302958d547037e7258913b3069f2b6",
                "commit_sha_fixed": "a025d87deb9cc4cda49ae1b77feb0f29805dd7c5",
                "report_id": "528",
                "report_url": "https://github.com/jhy/jsoup/issues/528",
                "issue_title": "Jsoup not retaining &lt in data attributes",
                "issue_description": "Jsoup not retaining &lt in data attributes value if there is &lt;\n\nIn the example below &amp;lt; is converted to < in the output after parsing. \nPlease let me know how to retain it. \nExample:\nhttp://notes.io/Gww\n@uggedal \n@krystiangor \n@tc \n@bbeck \n"
            },
            "48": {
                "commit_sha_buggy": "73b52d0d995b8c6091c0e92f8ada03a2753b576a",
                "commit_sha_fixed": "65553582d184e18de10e496b0eaa53fbe206ba17",
                "report_id": "618",
                "report_url": "https://github.com/jhy/jsoup/issues/618",
                "issue_title": "A small bug for duplicate tuple in response header",
                "issue_description": "for response headers have duplicate tuple\uff0c\nin this case\nX-Powered-By:PHP/5.2.8\nX-Powered-By:ASP.NET\n\nJsoup can only get the second one\nif I run header\uff08\u201cX-powered-by\u201d\uff09 \nI got Asp.NET\n\nURL\uff1ahttp://01pt.com/\n\nCache-Control:no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nContent-Encoding:gzip\nContent-Length:16224\nContent-Type:text/html;charset=gb2312\nDate:Thu, 27 Aug 2015 09:22:40 GMT\nExpires:Thu, 19 Nov 1981 08:52:00 GMT\nPragma:no-cache\nServer:Microsoft-IIS/7.5\nVary:Accept-Encoding\nX-Powered-By:PHP/5.2.8\nX-Powered-By:ASP.NET\n\nThe bug is because \nif (!values.isEmpty()) header(name, values.get(0));\n\nI change it to\n                 if (!values.isEmpty()) {\n                        String val = \"\";\n                        for(String str: values) {\n                          val = val.concat(str).concat(\" \");\n\n```\n                    }\n                    header(name, val);\n              }\n```\n\nthen I am able to get \u201cPHP/5.2.8 ASP.NET\u201d when I run header\uff08\u201cX-powered-by\u201d\uff09\n\n void processResponseHeaders(Map<String, List<String>> resHeaders) {\n            for (Map.Entry<String, List<String>> entry : resHeaders.entrySet()) {\n                String name = entry.getKey();\n                if (name == null)\n                    continue; // http/1.1 line\n\n```\n            List<String> values = entry.getValue();\n            if (name.equalsIgnoreCase(\"Set-Cookie\")) {\n                for (String value : values) {\n                    if (value == null)\n                        continue;\n                    TokenQueue cd = new TokenQueue(value);\n                    String cookieName = cd.chompTo(\"=\").trim();\n                    String cookieVal = cd.consumeTo(\";\").trim();\n                    // ignores path, date, domain, validateTLSCertificates et al. req'd?\n                    // name not blank, value not null\n                    if (cookieName.length() > 0)\n                        cookie(cookieName, cookieVal);\n                }\n            } else { // only take the first instance of each header\n                if (!values.isEmpty())\n                    header(name, values.get(0));\n            }\n        }\n    }\n```\n"
            },
            "49": {
                "commit_sha_buggy": "941f69bfe96753ef30dbb3bb1bdffb72ee8944e0",
                "commit_sha_fixed": "b2e37fca64877104cfdad3f56cdc2c8b98cb6be1",
                "report_id": "689",
                "report_url": "https://github.com/jhy/jsoup/issues/689",
                "issue_title": "Bug in Element.insertChildren()",
                "issue_description": "When using org.jsoup.nodes.Element.insertChildren(int, Collection<? extends Node>) to move (more than one!) child-elements from one parent-element to the same parent, but different index then it produces wrong results.\n\nThe problem is that the first Element's 'move' leaves the siblingIndex unchanged and then the second 'move' removes a wrong element and produces some crap. Maybe calling reindexChildren() inside the loop in addChildren() fixes this.\nVersion 1.8.3.\nWorkaround: call remove() on the elements before passing them to insertChildren()\n\nEasy Test Case:\n\n```\n    @Test\n    public void mustCorrectlyMoveChildrenInsideOneParentElement() {\n\n        Document doc = new Document( \"\" );\n        Element body = doc.appendElement( \"body\" );\n        body.appendElement( \"div1\" );\n        body.appendElement( \"div2\" );\n        Element div3 = body.appendElement( \"div3\" );\n        Element div4 = body.appendElement( \"div4\" );\n\n        ArrayList<Element> toMove = new ArrayList<Element>() {\n            {\n                add( div3 );\n                add( div4 );\n            }\n        };\n\n        body.insertChildren( 0, toMove );\n\n        String result = doc.toString().replaceAll( \"\\\\s+\", \"\" );\n        assertEquals( \"<body><div3></div3><div4></div4><div1></div1><div2></div2></body>\", result );\n\n    }\n```\n"
            },
            "50": {
                "commit_sha_buggy": "cc19d3029ab0db137da0e95cc55c20b131241cf1",
                "commit_sha_fixed": "c3cbe1b64e7f66ff9f9b53f1388eb135e6693187",
                "report_id": "695",
                "report_url": "https://github.com/jhy/jsoup/issues/695",
                "issue_title": "UTF16 streams with BOM are processed as UTF-8",
                "issue_description": "The handling of the character encoding in org.jsoup.helper.DataUtil.parseByteData(...) is bugged when the input is an UTF16 stream with unicode BOM. This method does a check for presence of a BOM and, if it finds one, incorrectly assumes that this was a UTF-8 BOM. To fix this, the code would have to check the raw BOM bytes as the distinction between the various BOMs is lost after conversion to characters. See also: http://unicode.org/faq/utf_bom.html#bom4\n"
            },
            "51": {
                "commit_sha_buggy": "8b38cd812802397dfcbaddb34cde9ac27f0fde22",
                "commit_sha_fixed": "25e0e1e9ffca9a350d060db7d2179c5c9e459055",
                "report_id": "667",
                "report_url": "https://github.com/jhy/jsoup/issues/667",
                "issue_title": "Problem in reading XML file containing Japanese tag names",
                "issue_description": "Hello,\nI have XML file containing Japanese tag names and values.\nJSOUP is not parsing this Japanese tags.\nI am using JSOUP library (version: 1.8.3).\nPlease help me to solve this issue.\n\n---\n\ne.g. ( XML File to reproduce problem )\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<\u9032\u6357\u63a8\u79fb\u30b0\u30e9\u30d5>\n    <\u958b\u59cb\u4e88\u5b9a\u51e1\u4f8b\u540d \u8868\u793a\u72b6\u614b=\"0\" \u7dda\u8272=\"00CED1\">&amp;#9312;&amp;#35373;&amp;#35336; &amp;#38283;&amp;#22987;&amp;#20104;&amp;#23450;</\u958b\u59cb\u4e88\u5b9a\u51e1\u4f8b\u540d>\n## </\u9032\u6357\u63a8\u79fb\u30b0\u30e9\u30d5>\n\n//// ***\\*  Source Code  ******\nDocument doc = Jsoup.parse(XMLString.toString(),\"UTF-8\",Parser.xmlParser());\nElements objElementCollection = doc.getAllElements();\n\nint iElementsSize=objElementCollection.size();\n\nfor(Element objCurrent : objElementCollection)\n{\n        String szTag=objCurrent.tagName();\n\n```\n    for (TextNode tnTextNode : objCurrent.textNodes()) \n    {\n        String szVal=tnTextNode.text();\n    }\n```\n\n}\n"
            },
            "52": {
                "commit_sha_buggy": "2bca40cf59bfda485f2fbf43b8bd66509a8f98ab",
                "commit_sha_fixed": "4eb4f2b2e88a2f9e6c5c1e8d0477060954f24218",
                "report_id": "701",
                "report_url": "https://github.com/jhy/jsoup/issues/701",
                "issue_title": "Should detect ?xml encoding charset",
                "issue_description": "Hi,\n\nFor example this is target URL: http://www.elacontecer.com.uy/rss/hoy.xml, its charset is `ISO-8859-1`.\n\nI use Jsoup like this:\n\n``` java\nfinal Document doc = Jsoup.connect(\"http://...\").parser(Parser.xmlParser()).get();\nSystem.out.println(\"charset=\" + doc.charset());\n```\n\nThe result is: `java.nio.charset.CharsetICU[UTF-8]`\n\nWould you please check to see if it's a bug?\n\nThanks,\n"
            },
            "53": {
                "commit_sha_buggy": "c090381c55b6d275eebe60053d36f198ffe793ca",
                "commit_sha_fixed": "a229d7354da5210a728ce5d43158d5cd780772db",
                "report_id": "611",
                "report_url": "https://github.com/jhy/jsoup/issues/611",
                "issue_title": "Parse failed with org.jsoup.select.Selector$SelectorParseException when selector has unbalanced '(' or '[' or ')' or ']' ",
                "issue_description": "Selector I am having as following div.card-content2:has(a.subtitle[title= MySubTitle:)]) OR a.title[title=MyTitle :] ]\n"
            },
            "54": {
                "commit_sha_buggy": "9e8ba01343f2b39185846821407e93ca5240bdb1",
                "commit_sha_fixed": "f148f88de365c50eea28d3e14093e13c33104483",
                "report_id": "721",
                "report_url": "https://github.com/jhy/jsoup/issues/721",
                "issue_title": "INVALID_CHARACTER_ERR when converting Document to W3C",
                "issue_description": "A recent ClearQuest version has an HTML generation bug, which is ignored by both Chrome and Internet Explorer. Jsoup.parse is also successful:\n\n`org.jsoup.nodes.Document doc = Jsoup.parse(\"<html><head></head><body style=\\\"color: red\\\" \\\"></body></html>\");`\n\n(Please note the single quotation mark at the end of the body start tag.)\n\nBut trying to convert this to a W3C document fails:\n\n`new W3CDom().fromJsoup(doc);`\n\n```\nException in thread \"main\" org.w3c.dom.DOMException: INVALID_CHARACTER_ERR: An invalid or illegal XML character is specified. \n    at org.apache.xerces.dom.CoreDocumentImpl.createAttribute(Unknown Source)\n    at org.apache.xerces.dom.ElementImpl.setAttribute(Unknown Source)\n    at org.jsoup.helper.W3CDom$W3CBuilder.copyAttributes(W3CDom.java:124)\n    at org.jsoup.helper.W3CDom$W3CBuilder.head(W3CDom.java:92)\n    at org.jsoup.select.NodeTraversor.traverse(NodeTraversor.java:31)\n    at org.jsoup.helper.W3CDom.convert(W3CDom.java:66)\n    at org.jsoup.helper.W3CDom.fromJsoup(W3CDom.java:46)\n```\n\nPerhaps copyAttributes() should ignore invalid attributes, or catch exactly this error, and ignore it, or W3CDom could have flags to ignore such errors...\n"
            },
            "55": {
                "commit_sha_buggy": "aa81e10c34f48a3c4ac7160aa90ee18af4f5c0c2",
                "commit_sha_fixed": "f0f0e41e6c581de43dfaa98f5c2af52e43e42e62",
                "report_id": "746",
                "report_url": "https://github.com/jhy/jsoup/issues/746",
                "issue_title": "Parse slash in attibutes",
                "issue_description": "Hello,\nI don't know if it is a bug or not, but when I'm parsing:\n`<img /onerror=\"a()\"/>`\n\nThe result of the parsers is: \n`<img nerror=\"a()\"/>`\nIs it OK? can I change the parser behavior for those types of tags? \n"
            },
            "56": {
                "commit_sha_buggy": "fa929d4f4b1576f3f2c4020892b74bc3518575e7",
                "commit_sha_fixed": "c28e5bf53a9ce9e32ab84ce2e6eba87ec747d1a0",
                "report_id": "408",
                "report_url": "https://github.com/jhy/jsoup/issues/408",
                "issue_title": "Jsoup.parse seems to remove system identifier in DOCTYPE",
                "issue_description": "Specifically when I call:\r\n```\r\nDocument doc = Jsoup.parse(xhtml, \"\", Parser.xmlParser());\r\n```\r\non a xhtml document that has the following doctype:\r\n\r\n```\r\n<!DOCTYPE html SYSTEM \"exampledtdfile.dtd\">\r\n```\r\nI end up with the following result in the document (SYSTEM is now missing):\r\n\r\n```\r\n<!DOCTYPE html \"exampledtdfile.dtd\"> \r\n```\r\n\r\nBut this works fine on a document with:\r\n\r\n```\r\n <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"> \r\n```\r\n\r\nSince SYSTEM is a proper way of declaring a DTD, I believe this is an issue with Jsoup.\r\n"
            },
            "57": {
                "commit_sha_buggy": "c28e5bf53a9ce9e32ab84ce2e6eba87ec747d1a0",
                "commit_sha_fixed": "2c58e975ab00eb369ee3dfbba07a4a78a1ef9e19",
                "report_id": "759",
                "report_url": "https://github.com/jhy/jsoup/issues/759",
                "issue_title": "removeIgnoreCase ConcurrentModificationException",
                "issue_description": "When testing out the removeIgnoreCase method, I'm now seeing a ConcurrentModificationException with code like: element.select(\"abc\").first().removeAttr(\"attr1\").removeAttr(\"attr2\");\n\nIt appears to be due to using a foreach loop over the LinkedHashMap to do the removal. Changing to do the removal directly with an iterator fixes this issue.\nLike so:\n\n```\nfor (Iterator<Map.Entry<String, Attribute>> iter = attributes.entrySet().iterator(); iter.hasNext();) {\n            Map.Entry<String, Attribute> entry = iter.next();\n            if (entry.getKey().equalsIgnoreCase(\"key1\")) {\n                iter.remove();\n            }\n        }\n```\n"
            },
            "58": {
                "commit_sha_buggy": "b919f01e4719631f2621c523d78777ba237be7dd",
                "commit_sha_fixed": "f44d6e64ac97d4a5c119e3e22f22f4d87c94b7e1",
                "report_id": "245",
                "report_url": "https://github.com/jhy/jsoup/issues/245",
                "issue_title": "Jsoup.isValid returns true even when htmlFragment includes tags not on whitelist",
                "issue_description": "Caused by Jsoup.isValid performing a destructive parse before testing for validity.  The html returned from parseBodyFragment is not what was passed in.\n\nAccording to documentation, html, head tags etc. should be specifically added to whitelist if they should be allowed.\n\nTest cases below.\n\n```\npackage jsoup;\n\nimport junit.framework.Assert;\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.safety.Cleaner;\nimport org.jsoup.safety.Whitelist;\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.junit.runners.Parameterized;\n\nimport java.util.Arrays;\nimport java.util.Collection;\n\n@RunWith(Parameterized.class)\npublic class JsoupTest\n{\n    private String htmlFragment;\n\n    public JsoupTest(String htmlFragment)\n    {\n        this.htmlFragment = htmlFragment;\n    }\n\n    @Parameterized.Parameters\n    public static Collection<String[]> dirtyHtml()\n    {\n        String[][] htmlFragments = new String[][] { {\"<html></html>\"},\n                                                    {\"<head></head>\"},\n                                                    {\"<body></body>\"}\n        };\n\n        return Arrays.asList(htmlFragments);\n    }\n\n    @Test\n    public void emptyWhitelistReturnsFalseForAllTags()\n    {\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, new Whitelist()));\n    }\n\n    @Test\n    public void whitelistNoneReturnsFalseForAllTags()\n    {\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, Whitelist.none()));\n    }\n\n    @Test\n    public void typicalWhitelistReturnsFalseForNonIncludedTags()\n    {\n        Whitelist whitelist = new Whitelist();\n        whitelist.addTags(\"p\");\n\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, whitelist));\n    }\n\n    @Test\n    public void codeFromSource()\n    {\n        Document dirty = Parser.parseBodyFragment(htmlFragment, \"\");\n        Cleaner cleaner = new Cleaner(Whitelist.none());\n\n        Assert.assertEquals(false, cleaner.isValid(dirty));\n    }\n\n}\n```\n"
            },
            "59": {
                "commit_sha_buggy": "d8eb9bd63c861132e5307a65e8f2f234fab2416b",
                "commit_sha_fixed": "a623db776696c0e03f68e849147f6a0c57063c02",
                "report_id": "793",
                "report_url": "https://github.com/jhy/jsoup/issues/793",
                "issue_title": "Jsoup.clean control characters throws: IllegalArgumentException: String must not be empty",
                "issue_description": "I found that when running Jsoup.clean() on a string that contains the format below, Jsoup throws: `IllegalArgumentException: String must not be empty`.\r\nThe problematic string format:\r\n`'<a/*>'`, (where * is a control char).\r\ni.e. `<` char followed by a letter (a-z), then any chars, `/` and any control char (ASCII 0-31) except 0, 9-10, 12-13, any chars, and a `>` char.\r\n"
            },
            "60": {
                "commit_sha_buggy": "c221cc8ab03fe7a88982cdddb9e66cff546d29df",
                "commit_sha_fixed": "8fecf72da0c9d1d6da7ec1aab0214ff68588da88",
                "report_id": "803",
                "report_url": "https://github.com/jhy/jsoup/issues/803",
                "issue_title": "1.10.1 failed a test while 1.8.3 passed for a contains query",
                "issue_description": "Today I tried to upgrade jsoup from 1.8.3 to 1.10.1, however, one of my unit test failed like this:\r\n\r\n\"div.a-row.a-spacing-medium span.a-size-base:contains(I'll Ship & Pay)\"\r\n\"div.a-row.a-spacing-medium span.a-size-base:contains(I'll Send & Pay)\"\r\n\"div.a-row.a-spacing-medium span.a-color-price:contains(Varies)\"\r\n\r\nAbove are 3 css selectors and in a webpage that no such element exists, Jsoup selector find 9 elements, which broke my unit test. It seems like that the **contains** logic broke. I'm not sure whether **'** or **&** processing changed in newer version.\r\n\r\nCan you have a look at this? For your reference I've attached the html page as a zip file.\r\n\r\n[AmazonReturn.zip](https://github.com/jhy/jsoup/files/676839/AmazonReturn.zip)\r\n"
            },
            "61": {
                "commit_sha_buggy": "b6dda00bc19f6d3bc4009a6b9a4a932de9640bd4",
                "commit_sha_fixed": "83f01fd864e59fa69c894da06f4a15489222d401",
                "report_id": "814",
                "report_url": "https://github.com/jhy/jsoup/issues/814",
                "issue_title": "Unexpected case sensitivity for CSS class selector",
                "issue_description": "Hi,\r\ni use JSoup version 1.10.2 and noticed an unexpected case sensitivity for a CSS class selector. I tried to parse the following HTML document with capitalized class attributes:\r\n\r\n```html\r\n<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'>\r\n<HTML>\r\n  <HEAD>\r\n    <FORM Method='POST' name='Form' Action='Action'>\r\n      <TABLE Class='Lst'>\r\n        <TR Class='Lst'>\r\n          <TH Class='Lst'>Header 1</TH>\r\n          <TH Class='Lst'>Header 2</TH>\r\n          <TH Class='Lst'>Header 3</TH>\r\n        </TR>\r\n        <TR Class='Lst1'>\r\n          <TD Class='Lst'>Cell 1</TD>\r\n          <TD Class='Lst'>Cell 2</TD>\r\n          <TD Class='Lst'>Cell 3</TD>\r\n        </TR>\r\n      </TABLE>\r\n    </FORM>\r\n  </BODY>\r\n</HTML>\r\n```\r\n\r\nI wanted to select the table using the selector _\"html > body > form table.Lst\"_ because I expected it to choose the table with the class attribute \"Lst\", but that did not work. The selector _\"html > body > form table[class=Lst]\"_ works. Is this a bug?\r\n\r\nHere is the parser code:\r\n\r\n```java\r\ntry {\r\n  final String htmlStr = \"<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'>\\n\"\r\n      + \"<HTML>\\n\"\r\n      + \"  <HEAD>\\n\"\r\n      + \"    <FORM Method='POST' name='Form' Action='Action'>\\n\"\r\n      + \"      <TABLE Class='Lst'>\\n\"\r\n      + \"        <TR Class='Lst'>\\n\"\r\n      + \"          <TH Class='Lst'>Header 1</TH>\\n\"\r\n      + \"          <TH Class='Lst'>Header 2</TH>\\n\"\r\n      + \"          <TH Class='Lst'>Header 3</TH>\\n\"\r\n      + \"        </TR>\\n\"\r\n      + \"        <TR Class='Lst1'>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 1</TD>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 2</TD>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 3</TD>\\n\"\r\n      + \"        </TR>\\n\"\r\n      + \"      </TABLE>\\n\"\r\n      + \"    </FORM>\\n\"\r\n      + \"  </BODY>\\n\"\r\n      + \"</HTML>\";\r\n  final Document htmlDoc = Jsoup.parse(htmlStr,\r\n      \"\");\r\n\r\n  final Element tableNotOk = htmlDoc.select(\"html > body > form table.Lst\")\r\n      .first();\r\n  final Element tableOk = htmlDoc.select(\"html > body > form table[class=Lst]\")\r\n      .first();\r\n\r\n  Logger.getLogger(this.getClass().getName())\r\n      .log(Level.INFO,\r\n          \"tableNotOk found: ''{0}'', tableOk found: ''{1}''\",\r\n          new Object[]{(tableNotOk != null), (tableOk != null)});\r\n\r\n} catch (UnsupportedCharsetException | ParseException | Selector.SelectorParseException ex) {\r\n  Logger.getLogger(this.getClass().getName())\r\n      .log(Level.SEVERE,\r\n          null,\r\n          ex);\r\n}\r\n```\r\n"
            },
            "62": {
                "commit_sha_buggy": "2f6eabc9f0999421acf032c79f3106215c013580",
                "commit_sha_fixed": "b934c5d3e30917de86796c89fcb7cd000f642a80",
                "report_id": "819",
                "report_url": "https://github.com/jhy/jsoup/issues/819",
                "issue_title": "Wrong parsing of case sensitive HTML ",
                "issue_description": "Executing : \r\n\r\n            String xml=\"<r><X>A</X><y>B</y></r>\";\r\n\t\tParser parser = Parser.htmlParser();\r\n\t\tparser.settings(ParseSettings.preserveCase);\r\n\t\torg.jsoup.nodes.Document _doc = parser.parseInput(xml, \"/\");\r\n\r\n\r\nResults in : \r\n&lt;html&gt;\r\n &lt;head&gt;&lt;/head&gt;\r\n &lt;body&gt;\r\n  &lt;r&gt;\r\n   &lt;X&gt;\r\n    A\r\n    &lt;y&gt;\r\n     B\r\n    &lt;/y&gt;\r\n   &lt;/X&gt;\r\n  &lt;/r&gt;\r\n &lt;/body&gt;\r\n&lt;/html&gt;\r\n\r\nManual hacking : remove all .toLowerCase() invocations from Token.java (normalName=...)\r\n\r\n\r\n"
            },
            "63": {
                "commit_sha_buggy": "d51f6539c6245847f4296230077faade0e5d6973",
                "commit_sha_fixed": "35bceca331e07938a9c4cd62d68e08740cd39575",
                "report_id": "868",
                "report_url": "https://github.com/jhy/jsoup/issues/868",
                "issue_title": "Error: \"Self closing flag not acknowledged\" for self closing break",
                "issue_description": "This code snippet returns invalid html with the message: \"Self closing flag not acknowledged\"\r\n```java\r\nJsoup.isValid(\"<p>test<br/>test</p>\")\r\n```\r\nWhy breaks could not be self closing?\r\n"
            },
            "64": {
                "commit_sha_buggy": "c4f6a622ef63687c23a21e795d7a3e32de222d2f",
                "commit_sha_fixed": "195566fa6d4092c6983fbf497c37ae53a188fa90",
                "report_id": "906",
                "report_url": "https://github.com/jhy/jsoup/issues/906",
                "issue_title": "Incorrect handling of self-closing tags noframes, style and title cause remainder of document to be html-escaped",
                "issue_description": "Given the input:\r\n\r\n```html\r\n<html>\r\n<head>\r\n\t<style />   <!-- < - - this is the culprit -->\r\n</head>\r\n<body>\r\n\t<p>Whatever</p>\r\n</body>\r\n</html>\r\n```\r\n\r\nJSoup 1.8.2 and also http://try.jsoup.org/~lJwWpjXYUSTBeBZhdEnS3Mt56g4 will produce:\r\n```html\r\n    <html>\r\n     <head> \r\n      <style></style>\r\n     </head>\r\n     <body>\r\n       &lt;/head&gt; &lt;body&gt; &lt;p&gt;Whatever&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;\r\n     </body>\r\n    </html>\r\n```\r\n\r\nWith `<title/>` instead of `<style/>`, the result is different but still wrong (http://try.jsoup.org/~BZ3uoMki-r904fZxUOWJgLJO7r8 ):\r\n```html\r\n<html>\r\n <head> \r\n  <title></title>\r\n </head>\r\n <body>\r\n   &lt;/head&gt;  \r\n  <p>Whatever</p>  \r\n </body>\r\n</html>\r\n```\r\n\r\nThat weirdness was fixed for `<script>` with Issue #305: http://try.jsoup.org/~3Ms6TQCrrdaA_uPgxgURYYvwFAg\r\n```html\r\n<html>\r\n <head> \r\n  <script></script> \r\n </head> \r\n <body> \r\n  <p>Whatever</p>  \r\n </body>\r\n</html>\r\n```\r\n\r\nLooking [at the source](https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/parser/HtmlTreeBuilderState.java#L106), it seems only the HtmlTreeBuilderState handling for `<noframes>`, `<style>` and `<title>` in the methods `handleRawText` and `handleRcData` doesn't get along with the self-closing tags.\r\nAny other tagname I've checked (and I tried to cover all branches of that `case StartTag` switch) results in a good parse similar to the `<script>` case, which is what I'd expect.\r\n\r\nThanks for looking into this!\r\n"
            },
            "65": {
                "commit_sha_buggy": "32af6ba9f1b15f89660645a7a27f89517a0890c6",
                "commit_sha_fixed": "4fa93397353a7cd3cf15f9c29c40f8a18fc051e5",
                "report_id": "807",
                "report_url": "https://github.com/jhy/jsoup/issues/807",
                "issue_title": "Parser error on <template> inside <tr>",
                "issue_description": "I've been experimenting with jsoup as a validator for TensorBoard code and I encountered a bug.\r\n\r\nIf I have code like this:\r\n\r\n```html\r\n          <tr>\r\n            <th></th>\r\n            <th>Name</th>\r\n            <template is=\"dom-if\" if=\"{{smoothingEnabled}}\">\r\n              <th>Smoothed</th>\r\n            </template>   \r\n            <th>Value</th>\r\n            <th>Step</th>\r\n            <th>Time</th>\r\n            <th>Relative</th>\r\n          </tr>\r\n```\r\n\r\nI get errors like this:\r\n\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1282): Unexpected token [StartTag] when in state [InTable]\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1338): Unexpected token [EndTag] when in state [InTable]\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1338): Unexpected token [EndTag] when in state [InBody]\r\n\r\nPlease note that those offset numbers point to the `<template>` tags.\r\n\r\nTemplate tag is legal here because https://www.w3.org/TR/html5/tabular-data.html#the-tr-element says content model for `tr` is \"Zero or more td, th, and script-supporting elements\" and `template` is a script supporting element."
            },
            "66": {
                "commit_sha_buggy": "22a17d24279450e7e214b57beb4c0bda5f3698e5",
                "commit_sha_fixed": "c324fabe86c0a59eb635610dc85d8d7a7be25c74",
                "report_id": "951",
                "report_url": "https://github.com/jhy/jsoup/issues/951",
                "issue_title": "Method nextElementSibling() returns null after adding an element to a document that was cloned",
                "issue_description": "If I clone a document, and add an element by the method `after()`, and try to get the new element by the method `nextElementSibling()` I get null. In the same time the method `nextSibling()` successfully returns this element.\r\nIf I do the same with the original document everything is fine.\r\n\r\nCode:\r\n\r\n    String html = \"<!DOCTYPE html><html lang=\\\"en\\\"><head></head><body><div>Initial element</div></body></html>\";\r\n    Document original = Jsoup.parse(html);\r\n    Document clone = original.clone();\r\n\r\n    Element originalElement = original.body().child(0);\r\n    originalElement.after(\"<div>New element</div>\");\r\n    Element originalNextElementSibling = originalElement.nextElementSibling();\r\n    Element originalNextSibling = (Element) originalElement.nextSibling();\r\n    System.out.println(\"originalNextElementSibling:\\n\" + originalNextElementSibling);\r\n    System.out.println(\"originalNextSibling:\\n\" + originalNextSibling);\r\n    System.out.println();\r\n\r\n    Element cloneElement = clone.body().child(0);\r\n    cloneElement.after(\"<div>New element</div>\");\r\n    Element cloneNextElementSibling = cloneElement.nextElementSibling();\r\n    Element cloneNextSibling = (Element) cloneElement.nextSibling();\r\n    System.out.println(\"cloneNextElementSibling:\\n\" + cloneNextElementSibling);\r\n    System.out.println(\"cloneNextSibling:\\n\" + cloneNextSibling);\r\n\r\nOutput:\r\n\r\n    originalNextElementSibling:\r\n    <div>\r\n     New element\r\n    </div>\r\n    originalNextSibling:\r\n    <div>\r\n     New element\r\n    </div>\r\n\r\n    cloneNextElementSibling:\r\n    null\r\n    cloneNextSibling:\r\n    <div>\r\n    New element\r\n    </div>\r\n"
            },
            "67": {
                "commit_sha_buggy": "2412188026aa32491e769d6221c16a3bda6e897b",
                "commit_sha_fixed": "fb8b60b4d3d202c6fa708f60b8b4a5a53836af24",
                "report_id": "955",
                "report_url": "https://github.com/jhy/jsoup/issues/955",
                "issue_title": "Quadratic behaviour on deeply nested pages",
                "issue_description": "On pages with very deep sequence of elements (like this one sv.stargate.wikia.com/wiki/M2J), Jsoup gets very slow and spends too much time in this function:\r\nhttps://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/parser/HtmlTreeBuilder.java#L462\r\n\r\nIs there any way to remove this quadratic behaviour? Either by using better data structures or by having option to limit stack size (and throw exception when it is too deep)."
            },
            "68": {
                "commit_sha_buggy": "1b38f80d623310e84c87b2d708ed0ab648dfafc5",
                "commit_sha_fixed": "adb7a15a1e2dd6742a25592602a6e8ee77b518b6",
                "report_id": "966",
                "report_url": "https://github.com/jhy/jsoup/issues/966",
                "issue_title": "version 1.11.1 java.lang.StackOverflowError",
                "issue_description": "version 1.10.3 no problem\r\nversion 1.11.1 java.lang.StackOverflowError\r\nExample URL\uff1a\r\nhttp://szshb.nxszs.gov.cn/\r\nhttp://www.lnfsfda.gov.cn/\r\nhttp://www.beihai.gov.cn/\r\nhttp://www.fsepb.gov.cn/\r\nhttp://www.bhem.gov.cn\r\n"
            },
            "69": {
                "commit_sha_buggy": "4d78e0316e1eae331bc0b460f367ce878688d6d2",
                "commit_sha_fixed": "f75f47397836ba2127f06c8390a87eada369f7cc",
                "report_id": "429",
                "report_url": "https://github.com/jhy/jsoup/issues/429",
                "issue_title": "Removing nodes from forms using jsoup",
                "issue_description": "I'm having a problem removing nodes from forms using jsoup v1.7.3. The following code works as expected:\n\n```\nConnection.Response response = Jsoup.connect(\"myURL\").execute();\n\nDocument doc = response.parse();\n\n//prints HTML including \"input[name=alpha]\"\nSystem.out.println(doc.toString());\n\ndoc.select(\"input[name=alpha]\").first().remove();\n\n//prints HTML excluding \"input[name=alpha]\"\nSystem.out.println(doc.toString());\n\nFormElement form = (FormElement)doc.select(\"form\").first();\n\n//prints HTML excluding \"input[name=alpha]\"\nSystem.out.println(form.toString());\n```\n\nHowever, the following code appears to highlight a bug:\n\n```\nList<Connection.KeyVal> data = form.formData();\n\n//prints a list including \"alpha\"\nSystem.out.println(data.toString());\n```\n\nI would expect \"alpha\" to have been removed from the form data, but it hasn't. Is this a bug? Or am I doing something wrong?\n\n[Previously reported on [Stack Overflow](http://stackoverflow.com/questions/24104910/removing-nodes-from-forms-using-jsoup/24110967)]\n"
            },
            "70": {
                "commit_sha_buggy": "4d78e0316e1eae331bc0b460f367ce878688d6d2",
                "commit_sha_fixed": "aeaf3c1a03fe4d5bfda4d63824a1f97dcec42e74",
                "report_id": "722",
                "report_url": "https://github.com/jhy/jsoup/issues/722",
                "issue_title": "Whitespaces not properly handled in <pre> tag",
                "issue_description": "If a \"pre\" tag contains deep nested tags, whitespaces in nested tags are not preserved.\n## Example:\n\n```\nString s = \"<pre><code>\\n\"\n        + \"  message <span style=\\\"color:red\\\"> other   \\n    message  with \\n\"\n        + \"   whitespaces      </span>\\n\"\n        + \"</code></pre>\";\n    Document doc = Jsoup.parse(s);\n    System.out.println(doc.select(\"pre\").first().outerHtml());\n```\n\nWill output:\n&lt;pre&gt;&lt;code&gt;\n  &nbsp;&nbsp;message &lt;span style=\"color:red\"&gt; other message with whiptespaces &lt;/span&gt;\n&lt;/pre&gt;&lt;/code&gt;\n\n---\n\nOutput is OK if we omit the \"code\" tag\n"
            },
            "71": {
                "commit_sha_buggy": "5fa76800671ff1d5477a383a0c3516d6fcc0a55a",
                "commit_sha_fixed": "1d7e6fa1c5fb974bdae7abeabbb1e5a48dc00967",
                "report_id": "550",
                "report_url": "https://github.com/jhy/jsoup/issues/550",
                "issue_title": "Please support text node selector",
                "issue_description": "Please support some kind of text node selectors. Currently it's not possible to select a sibling text node of an element without coding Java. A possible expression would be:\nELEM + :text\n"
            },
            "72": {
                "commit_sha_buggy": "5f0714329e2763d330460efee8ccd7f69acc8e7c",
                "commit_sha_fixed": "b8411990753314ed3b746d3402dec5a65ff6d603",
                "report_id": "972",
                "report_url": "https://github.com/jhy/jsoup/issues/972",
                "issue_title": "StringIndexOutOfBoundsException as of jsoup 1.11.1",
                "issue_description": "Example:\r\n\r\n    Jsoup.parse(new URL(\"https://gist.githubusercontent.com/valodzka/91ed27043628e9023009e503d41f1aad/raw/a15f68671e6f0517e48fdac812983b85fea27c16/test.html\"), 10_000);\r\n"
            },
            "73": {
                "commit_sha_buggy": "8c7414da71bc7c156f44638f44718c5f70b70460",
                "commit_sha_fixed": "3475dc846d78e56422b3e6fdf36dfd4416f359f5",
                "report_id": "977",
                "report_url": "https://github.com/jhy/jsoup/issues/977",
                "issue_title": "In w3c dom, siblings are incorrectly inheriting namespaces",
                "issue_description": "I am not sure if this is a bug or I am missing something that is defined in specification.\r\n\r\nWhen I am parsing (W3C DOM)  html file without namespace that have some element(s) with defined namespace, elements that are following will inherit that namespace.\r\n\r\nSmall test case and test html are included.\r\n\r\n[test.zip](https://github.com/jhy/jsoup/files/1478508/test.zip)\r\n\r\n"
            },
            "74": {
                "commit_sha_buggy": "3475dc846d78e56422b3e6fdf36dfd4416f359f5",
                "commit_sha_fixed": "c3f8caa7c16c08b803b0f34bfffdf9777c7e382c",
                "report_id": "978",
                "report_url": "https://github.com/jhy/jsoup/issues/978",
                "issue_title": "&shy; renders as '-' when Node.text() is called",
                "issue_description": "Consider the following JUnit4 test \r\n```java\r\n@Test\r\npublic void testIfShyIsStripped(){\r\n        String htmlwithSHY = \"<html><body>quite&shy;a&shy;long&shy;word</body></html>\";\r\n        Document parse = Jsoup.parse(htmlwithSHY);\r\n        String text = parse.body().text();\r\n        assertEquals(\"quitealongword\", text);\r\n}\r\n```\r\nThis test fails as text is parsed as `quite-a-long-word` rather then it's actual textual representation that would have been `quitealongword` in any browser.\r\n\r\nPerhaps this is working as intended, but it would be interesting to understand the reasoning behind it.\r\n"
            },
            "75": {
                "commit_sha_buggy": "64eef180f610d0dad97873f6786b103700ddb8b2",
                "commit_sha_fixed": "f627193ce0950f0d55ed1b4f6a2fe9973447853a",
                "report_id": "985",
                "report_url": "https://github.com/jhy/jsoup/issues/985",
                "issue_title": "Regression - Boolean attributes not collapsed when using HTML syntax",
                "issue_description": "Hello,\r\n\r\nFirst off, thanks for a really useful library.\r\n\r\nSo, upgrading from 1.10.2 to 1.11.2 we see that boolean attributes are no longer collapsed when using html syntax. Example test case:\r\n\r\n```\r\n    @Test\r\n    public void test() {\r\n        Document document = Jsoup.parse(\r\n                \"<html><head></head><body><hr size=\\\"1\\\" noshade=\\\"\\\"></body></html>\");\r\n        assertEquals(\"<html>\\n\" +\r\n                     \" <head></head>\\n\" +\r\n                     \" <body>\\n\" +\r\n                     \"  <hr size=\\\"1\\\" noshade>\\n\" +\r\n                     \" </body>\\n\" +\r\n                     \"</html>\",\r\n                     document.outerHtml());\r\n    }\r\n```\r\n\r\nTracked it down to commit \"Refactored Attributes to be an array pair vs LinkedHashSet \" ea1fb65. The `Attibutes.html(final Appendable accum, final Document.OutputSettings out)` method no longer uses `Attribute` and **fails** to check the value of the attribute for an _empty string_(line 320). \r\n\r\nIf I may also suggest to use `Attribute.shouldCollapseAttribute(String key, String val, Document.OutputSettings out)` instead as a single source of truth as the boolean expression is complex enough and easy to make a mistake. Not sure if this would have an impact in performance though but I am guessing that optimizer will inline the call at some point anyways? "
            },
            "76": {
                "commit_sha_buggy": "f9307ec96a894191e5d3782601ddb49fbfc53ea6",
                "commit_sha_fixed": "02668f757c59f0c1a7ad8f3169faf061b4b787c1",
                "report_id": "825",
                "report_url": "https://github.com/jhy/jsoup/issues/825",
                "issue_title": "Newline after pre and textarea not handled properly",
                "issue_description": "The WHATWG spec for HTML syntax indicates that if there is a newline directly after an opening `<pre>` or `<textarea>`, it should be removed.\r\n\r\nhttps://html.spec.whatwg.org/multipage/syntax.html#element-restrictions\r\n\r\njsoup currently does not do this:\r\n\r\n```\r\nJsoup.parse(\"<pre>\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).text();\r\n// Outputs  \" abc def\"\r\n// Expected \"abc def\"\r\n```\r\n\r\nArguably, jsoup is also wrong for the value of `getWholeText()`, although I guess this depends on one's interpretation of what `getWholeText()` is supposed to do. I am hoping that it intends to correspond to the value of [Node.nodeValue](https://developer.mozilla.org/en-US/docs/Web/API/Node/nodeValue), in which case:\r\n\r\n```\r\nJsoup.parse(\"<pre>\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).getWholeText();\r\n// Outputs  \"\\nabc  def\"\r\n// Expected \"abc  def\" \r\n\r\nJsoup.parse(\"<pre>\\n\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).getWholeText();\r\n// Outputs  \"\\n\\nabc  def\"\r\n// Expected \"\\nabc  def\"\r\n```"
            },
            "77": {
                "commit_sha_buggy": "bf4f99c72ba3d59486e0decb59a2b87edee4f1ff",
                "commit_sha_fixed": "df272b77c2cf89e9cbe2512bbddf8a3bc28a704b",
                "report_id": "998",
                "report_url": "https://github.com/jhy/jsoup/issues/998",
                "issue_title": "xmlParser() with ParseSettings.htmlDefault does not put end tag to lower case",
                "issue_description": "```java\r\n@Test public void test() {\r\n    Parser parser = Parser.xmlParser().settings(ParseSettings.htmlDefault);\r\n    Document document = Jsoup.parse(\"<div>test</DIV><p></p>\", \"\", parser);\r\n    assertEquals(\"<div>\\n test\\n</div>\\n<p></p>\", document.toString()); // fail -> toString() = \"<div>\\n test\\n <p></p>\\n</div>\"\r\n}\r\n\r\n@Test public void test1() {\r\n    Parser parser = Parser.xmlParser().settings(ParseSettings.htmlDefault);\r\n    Document document = Jsoup.parse(\"<DIV>test</div><p></p>\", \"\", parser);\r\n    assertEquals(\"<div>\\n test\\n</div>\\n<p></p>\", document.toString()); // pass\r\n}\r\n```"
            },
            "78": {
                "commit_sha_buggy": "71561e09e0f29ec5fd1bb918206f3d8e42876518",
                "commit_sha_fixed": "2c4e79b104c0ff32566ce247617d47c0b39cc2c7",
                "report_id": "980",
                "report_url": "https://github.com/jhy/jsoup/issues/980",
                "issue_title": "Underlying input stream returned zero bytes",
                "issue_description": "```\r\nCaused by org.jsoup.c: java.io.IOException: Underlying input stream returned zero bytes\r\n       at org.jsoup.parser.CharacterReader.bufferUp(CharacterReader.java:60)\r\n       at org.jsoup.parser.CharacterReader.(CharacterReader.java)\r\n       at org.jsoup.parser.CharacterReader.(CharacterReader.java)\r\n       at org.jsoup.parser.TreeBuilder.defaultSettings(TreeBuilder.java:35)\r\n       at org.jsoup.parser.HtmlTreeBuilder.initialiseParse(HtmlTreeBuilder.java:66)\r\n       at org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:44)\r\n       at org.jsoup.parser.Parser.parseInput(Parser.java:39)\r\n       at org.jsoup.helper.DataUtil.parseInputStream(DataUtil.java:151)\r\n       at org.jsoup.helper.HttpConnection$Response.parse(HttpConnection.java:832)\r\n       at org.jsoup.helper.HttpConnection.get(HttpConnection.java:289)\r\n```\r\n\r\nThere isn't much information I can offer here.\r\nThis is with JSoup 1.11.1, with an attempt of parsing for a user's name.\r\n\r\nMy assumption is that the call is executing the following:\r\n\r\n```kotlin\r\nvar result = \"\"\r\ntry {\r\n\tresult = frostJsoup(cookie, FbItem.PROFILE.url).title()\r\n\tL.d(\"Fetch username found\", result)\r\n} catch (e: Exception) {\r\n\tif (e !is UnknownHostException)\r\n\t\te.logFrostAnswers(\"Fetch username failed\")\r\n} finally {\r\n\tif (result.isBlank() && (name?.isNotBlank() == true)) {\r\n\t\tcallback(name!!)\r\n\t\treturn@subscribe\r\n\t}\r\n\tif (name != result) {\r\n\t\tname = result\r\n\t\tsaveFbCookie(this@fetchUsername)\r\n\t}\r\n\tcallback(result)\r\n}\r\n```\r\n\r\nwhere cookie is the user's cooke, and the url is touch.facebook.com/me\r\n\r\nI'm not sure why this is a seemlingly fatal error though.\r\n\r\nAs usual, the full log and thread info can be found [here](http://crashes.to/s/92e0e5d0b69)"
            },
            "79": {
                "commit_sha_buggy": "2c4e79b104c0ff32566ce247617d47c0b39cc2c7",
                "commit_sha_fixed": "1028b37a1dfbc5dda7b18cbe692ab168c54fb505",
                "report_id": "1032",
                "report_url": "https://github.com/jhy/jsoup/issues/1032",
                "issue_title": "LeafNode.childNodes() throws UnsupportedOperationException.",
                "issue_description": "`LeafNode.childNodes()` throws `UnsupportedOperationException` since this commit:\r\nhttps://github.com/jhy/jsoup/commit/f71712ba5d28df09c9a5b6e3c8a37f05f5e3372d#diff-605d28890f72a0f43298f842d0a3414f\r\n\r\nThe javadoc of `Node.childNodes()` says this:\r\n  `@return list of children. If no children, returns an empty list.`\r\n\r\nBut in the case of a LeafNode, which has no children, it throws `UnsupportedOperationException`. This is because `childNodes()` calls `ensureChildNodes()`, which throws an exception when called on a `LeafNode`.\r\n\r\nThe result is that the calling application needs to guard against this case. But the application should not need to know if the `Node` it has is a `LeafNode` or not.\r\n\r\n`LeafNode.childNodes()` should simply return an empty list as it used to do, and as per the javadoc.\r\n\r\n"
            },
            "80": {
                "commit_sha_buggy": "47a7f5ab2a22a2ce526f96e0cf9f2c46511c56d9",
                "commit_sha_fixed": "e9feec90dbd3e428dc1930c3b5efbd9271160d01",
                "report_id": "1015",
                "report_url": "https://github.com/jhy/jsoup/issues/1015",
                "issue_title": "Faulty Xml Causes IndexOutOfBoundsException",
                "issue_description": "\r\n```java\r\n@Test\r\npublic void parseFaultyXml() {\r\n    String xml = \"<?xml version='1.0'><val>One</val>\";\r\n    Document doc = Jsoup.parse(xml, \"\", Parser.xmlParser());\r\n}\r\n```\r\n\r\nResults in:\r\n\r\n```\r\njava.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n\r\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:657)\r\n\tat java.util.ArrayList.get(ArrayList.java:433)\r\n\tat org.jsoup.nodes.Element.child(Element.java:254)\r\n\tat org.jsoup.parser.XmlTreeBuilder.insert(XmlTreeBuilder.java:91)\r\n\tat org.jsoup.parser.XmlTreeBuilder.process(XmlTreeBuilder.java:49)\r\n\tat org.jsoup.parser.TreeBuilder.runParser(TreeBuilder.java:52)\r\n\tat org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:45)\r\n\tat org.jsoup.parser.Parser.parseInput(Parser.java:34)\r\n\tat org.jsoup.Jsoup.parse(Jsoup.java:45)\r\n```\r\n"
            },
            "81": {
                "commit_sha_buggy": "850a9cc02fb72cc450d1a9dc41912fa80fee9020",
                "commit_sha_fixed": "e38dfd44829e13ee83fd62bfe937580f5a998c11",
                "report_id": "1009",
                "report_url": "https://github.com/jhy/jsoup/issues/1009",
                "issue_title": "Failure to guess correct XHTML encoding even when explicitly declared",
                "issue_description": "```\r\nString encoding = \"iso-8859-1\";\r\nInputStream soup = new ByteArrayInputStream((\r\n    \"<?xml version=\\\"1.0\\\" encoding=\\\"\" + encoding + \"\\\"?>\" +\r\n    \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Strict//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\">\" +\r\n    \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\" xml:lang=\\\"en\\\">Hell\u00f6 W\u00f6rld!</html>\"\r\n    ).getBytes(encoding));\r\n\r\nSystem.out.println(Jsoup.parse(soup, null, \"\"));\r\n```\r\nprints:\r\n\r\n```\r\n<!--?xml version=\"1.0\" encoding=\"iso-8859-1\"?--><!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\">\r\n <head></head>\r\n <body>\r\n  Hell\ufffd W\ufffdrld!\r\n </body>\r\n</html>\r\n```\r\n\r\ninstead of expected output:\r\n\r\n```\r\n<!--?xml version=\"1.0\" encoding=\"iso-8859-1\"?--><!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\">\r\n <head></head>\r\n <body>\r\n  Hell\u00f6 W\u00f6rld!\r\n </body>\r\n</html>\r\n```\r\n"
            },
            "82": {
                "commit_sha_buggy": "77966f79996f3fc4c7828b4d02a926c071faf040",
                "commit_sha_fixed": "6be19a6fa26e6e5e3d716283bad4b5de0348a8b7",
                "report_id": "1007",
                "report_url": "https://github.com/jhy/jsoup/issues/1007",
                "issue_title": "UnsupportedOperationException thrown for charsets that don't support encoding",
                "issue_description": "```\r\npublic static void main(String[] args) throws IOException {\r\n\r\n    String html = \"<html><meta charset=\\\"ISO-2022-CN\\\"/></html>\";\r\n\r\n    System.out.println(\r\n        Jsoup.parse(new ByteArrayInputStream(html.getBytes()), null, \"\")\r\n    );  \r\n\r\n}\r\n```\r\n\r\nthrows\r\n\r\n<pre>\r\nException in thread \"main\" java.lang.UnsupportedOperationException\r\n\tat sun.nio.cs.ext.ISO2022_CN.newEncoder(ISO2022_CN.java:76)\r\n\tat org.jsoup.nodes.Document$OutputSettings.prepareEncoder(Document.java:443)\r\n\tat org.jsoup.nodes.Node$OuterHtmlVisitor.<init>(Node.java:704)\r\n\tat org.jsoup.nodes.Node.outerHtml(Node.java:573)\r\n\tat org.jsoup.nodes.Element.html(Element.java:1395)\r\n\tat org.jsoup.nodes.Element.html(Element.java:1389)\r\n\tat org.jsoup.nodes.Document.outerHtml(Document.java:195)\r\n\tat org.jsoup.nodes.Element.toString(Element.java:1422)\r\n\tat java.lang.String.valueOf(String.java:2982)\r\n\tat java.io.PrintStream.println(PrintStream.java:821)\r\n</pre>\r\n"
            },
            "83": {
                "commit_sha_buggy": "39e90ee38c3ce7aa254bb89740282c12eb149162",
                "commit_sha_fixed": "bdf1df7eb3ca76cdcdaca38f7df5d941bbb1c664",
                "report_id": "797",
                "report_url": "https://github.com/jhy/jsoup/issues/797",
                "issue_title": "Could handle missing tag ends (>) better",
                "issue_description": "We are using Jsoup to parse HTML documents from some external websites, which are not under our control. A few days ago, one of these sites updated their website, and introduced a bug, causing our crawling to fail spectacularly. The HTML which was broken looked a bit like this:\r\n\r\n```\r\n<td class=\"my-cell\"\r\n   <div class=\"great-formatting\">100</div>\r\n</td>\r\n```\r\n\r\nAs you can see, the TD is missing a closing `>`, while we did a `document.select(\"div.great-formatting\")`. This failed, because Jsoup couldn't parse the document correctly anymore. \r\n\r\nI understand it's a very edge case, and maybe very hard to fix. However, for us it was a production issue, and caused us quite a few headaches. Right now, we have a sort of preprocessor running over the HTML to close all elements which should be closed, but it would be much nicer if Jsoup would handle this out of the box. \r\n"
            },
            "84": {
                "commit_sha_buggy": "bdf1df7eb3ca76cdcdaca38f7df5d941bbb1c664",
                "commit_sha_fixed": "a810d2e3615da9a37ad74a7db2ca8bc6945ab9a8",
                "report_id": "848",
                "report_url": "https://github.com/jhy/jsoup/issues/848",
                "issue_title": "W3CDom Helper fails to convert whenever some namespace declarations are missing",
                "issue_description": "Hello\r\n\r\nI've been running into an issue where if I convert my Jsoup parsed document into a org.w3c.dom.Document with the W3CDom helper and that document happens to be missing namespace declarations we get the following exception:\r\n\r\n```\r\nNAMESPACE_ERR: An attempt is made to create or change an object in a way which is incorrect with regard to namespaces.\r\n```\r\n\r\nI've looked into this a bit and first thing I tried was using a locally forked version of the W3CDom helper that simply turned this flag off:\r\n\r\n```\r\nfactory.setNamespaceAware(false);\r\n```\r\n\r\nHowever the issue continued, so instead I simply hacked the code to completely ignore namespaces\r\n\r\n```\r\n// (csueiras): We purposely remove any namespace because we get malformed HTML that might not be\r\n// declaring all of it's namespaces!\r\nElement el = doc.createElementNS(\"\", sourceEl.tagName());\r\n```\r\n\r\nI am not completely sure if this will have any side effects, but it resolved the issues with the document I'm interacting with. I would be glad to provide a pull request if I have some guidance regarding how to properly handle this issue if it can be handled by Jsoup.\r\n\r\nThe document I'm having issues is simply making use of the Facebook like buttons using tags like this:\r\n\r\n```\r\n<fb:like ...\r\n```\r\n\r\nBut there's no namespace declaration for \"fb\"."
            },
            "85": {
                "commit_sha_buggy": "49c4a148b7817ed424e8cf823ae601863fec31ce",
                "commit_sha_fixed": "25ba713e1d1a97ebfee38c0df3e7e6d4d9615f97",
                "report_id": "1159",
                "report_url": "https://github.com/jhy/jsoup/issues/1159",
                "issue_title": "Attribute.java line 45 variable key scope error, it seems should be \"this.key\"",
                "issue_description": "![image](https://user-images.githubusercontent.com/41705526/49982508-ca65db80-ff11-11e8-9833-1775ddcc8871.png)\r\n\r\nAttribute.java Line 45, it should be:\r\n```java\r\nValidate.notEmpty(this.key);\r\n```\r\nrather than\r\n```java\r\nValidate.notEmpty(key);\r\n```\r\n\r\nThis issue only happens when **key** is blank or empty, in reality this would rarely happen, but in the syntax context it is still an issue, so better fix this.\r\n"
            },
            "86": {
                "commit_sha_buggy": "973234bc842b0de2febea195f7819236b57fd992",
                "commit_sha_fixed": "38c13b5ae97c294afb859c49ded903beb7b9b100",
                "report_id": "1139",
                "report_url": "https://github.com/jhy/jsoup/issues/1139",
                "issue_title": "Jsoup 1.11.3: IndexOutOfBoundsException",
                "issue_description": "Hi, I am using Jsoup 1.11.3. While trying to parse HTML content, I'm getting IndexOutOfBoundsException.\r\n\r\nI am using such Jsoup call as this is the only way to parse iframe content.\r\n\r\nJsoup call:\r\n\r\n`Jsoup.parse(html, \"\", Parser.xmlParser())`\r\n\r\nHTML is here:  https://files.fm/u/v43yemgb. I can't add it to the body as it's huge."
            },
            "87": {
                "commit_sha_buggy": "38c13b5ae97c294afb859c49ded903beb7b9b100",
                "commit_sha_fixed": "7ff7c43e9fbf4bbaf2b4517b3d4f8a429d87d3bb",
                "report_id": "1149",
                "report_url": "https://github.com/jhy/jsoup/issues/1149",
                "issue_title": "wrong parsing with ParseSettings.preserveCase",
                "issue_description": "jsoup version:1.11.3\r\nwhen using case sensitive settings,  parse wrong \r\n```java \r\npublic class TestJsoupParser {\r\n\r\n    public static void main(String[] args) {\r\n        Parser parser = Parser.htmlParser();\r\n        parser.settings(ParseSettings.preserveCase); // this line\r\n        String html = \"<div class=\\\"bdsharebuttonbox\\\">\"\r\n                + \"<A class=bds_more href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"more\\\">\u5206\u4eab\u5230\uff1a</A>\"\r\n                + \"<A title=\u5206\u4eab\u5230QQ\u7a7a\u95f4 class=bds_qzone href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"qzone\\\">\"\r\n                + \"</A><A title=\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a class=bds_tsina href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"tsina\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a class=bds_tqq href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"tqq\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u4eba\u4eba\u7f51 class=bds_renren href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"renren\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u5fae\u4fe1 class=bds_weixin href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"weixin\\\"></A>\"\r\n                + \"</div>\\r\\n\";\r\n        Document doc = Jsoup.parse(html, \"\", parser);\r\n        System.out.println(doc.html());\r\n    }\r\n    \r\n\r\n}\r\n```\r\n\r\nthe result is:\r\n\r\n```\r\n<html>\r\n <head></head>\r\n <body>\r\n  <div class=\"bdsharebuttonbox\">\r\n   <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n    \u5206\u4eab\u5230\uff1a\r\n   </A>\r\n   <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n    <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\"></A>\r\n    <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\">\r\n     <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\"></A>\r\n     <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\">\r\n      <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\"></A>\r\n      <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\">\r\n       <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\"></A>\r\n       <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\">\r\n        <A title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"></A>\r\n       </A>\r\n      </A>\r\n     </A>\r\n    </A>\r\n   </A>\r\n  </div>\r\n  <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n   <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\">\r\n    <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\">\r\n     <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\">\r\n      <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\">\r\n       <A title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"> \r\n       </A>\r\n      </A>\r\n     </A>\r\n    </A>\r\n   </A>\r\n  </A>\r\n </body>\r\n</html>\r\n```\r\n\r\nhowever, when not use preserveCase , result is right\r\n```\r\n<html>\r\n <head></head>\r\n <body>\r\n  <div class=\"bdsharebuttonbox\">\r\n   <a class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\u5206\u4eab\u5230\uff1a</a>\r\n   <a title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"></a>\r\n  </div> \r\n </body>\r\n</html>\r\n```"
            },
            "88": {
                "commit_sha_buggy": "8adcd55d8abe4c84ae2dcffb9a882abc4143bb93",
                "commit_sha_fixed": "8b837a43cbe2c12624ab2088dc4ff9a725af5f4d",
                "report_id": "1065",
                "report_url": "https://github.com/jhy/jsoup/issues/1065",
                "issue_title": "Attribute.getValue() broken for empty attributes since 1.11.1",
                "issue_description": "```\r\n        Document doc = Jsoup.parse(\"<div hidden>\");\r\n        Attributes attributes = doc.body().child(0).attributes();\r\n        System.out.println(String.format(\"Attr: '%s', value: '%s'\", \"hidden\",\r\n                attributes.get(\"hidden\")));\r\n\r\n        Attribute first = attributes.iterator().next();\r\n        System.out.println(String.format(\"Attr: '%s', value: '%s'\",\r\n                first.getKey(), first.getValue()));\r\n```\r\n\r\nExpected output, as in 1.10.x\r\n```\r\nAttr: 'hidden', value: ''\r\nAttr: 'hidden', value: ''\r\n```\r\n\r\nOutput in 1.11.1-1.11.3:\r\n```\r\nAttr: 'hidden', value: ''\r\nAttr: 'hidden', value: 'null'\r\n```\r\n"
            },
            "89": {
                "commit_sha_buggy": "8b837a43cbe2c12624ab2088dc4ff9a725af5f4d",
                "commit_sha_fixed": "1d663eeb1c0d1c08bcfe5d30f05170768bb0438e",
                "report_id": "1107",
                "report_url": "https://github.com/jhy/jsoup/issues/1107",
                "issue_title": "NPE in Attribute.setValue() for attribute without parent",
                "issue_description": "```\r\n    public String setValue(String val) {\r\n        String oldVal = parent.get(this.key);\r\n        if (parent != null) {\r\n            int i = parent.indexOfKey(this.key);\r\n            if (i != Attributes.NotFound)\r\n                parent.vals[i] = val;\r\n        }\r\n        this.val = val;\r\n        return oldVal;\r\n    }\r\n```\r\nIts useless to check `parent` for `null` after it has been dereferenced. I guess this is a copy-paste-bug:\r\n```\r\n    public void setKey(String key) {\r\n        Validate.notNull(key);\r\n        key = key.trim();\r\n        Validate.notEmpty(key); // trimming could potentially make empty, so validate here\r\n        if (parent != null) {\r\n            int i = parent.indexOfKey(this.key);\r\n            if (i != Attributes.NotFound)\r\n                parent.keys[i] = key;\r\n        }\r\n        this.key = key;\r\n    }\r\n```"
            },
            "90": {
                "commit_sha_buggy": "315655cc11c9d49bb821dd800d45580696b02185",
                "commit_sha_fixed": "7de614ffd01161d8718d7458bab9d9690ad2334f",
                "report_id": "1172",
                "report_url": "https://github.com/jhy/jsoup/issues/1172",
                "issue_title": "ArrayIndexOutOfBoundsException when parsing with some URL",
                "issue_description": "### error\r\n```\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 11\r\n\tat org.jsoup.helper.HttpConnection$Base.looksLikeUtf8(HttpConnection.java:437)\r\n\tat org.jsoup.helper.HttpConnection$Base.fixHeaderEncoding(HttpConnection.java:400)\r\n\tat org.jsoup.helper.HttpConnection$Base.addHeader(HttpConnection.java:386)\r\n\tat org.jsoup.helper.HttpConnection$Response.processResponseHeaders(HttpConnection.java:1075)\r\n\tat org.jsoup.helper.HttpConnection$Response.setupFromConnection(HttpConnection.java:1019)\r\n\tat org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:752)\r\n\tat org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:722)\r\n\tat org.jsoup.helper.HttpConnection.execute(HttpConnection.java:306)\r\n```\r\n\r\n### code\r\n```\r\ntry {\r\n            String url = \"https://www.colisprive.com/moncolis/pages/detailColis.aspx?numColis=P4000000037777930\";\r\n            Connection connection = Jsoup.connect(url).referrer(url).\r\n                    userAgent(\"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36\")\r\n                    .ignoreContentType(true).timeout(20000);\r\n           \r\n            connection.method(Method.GET);\r\n            return connection.execute().parse();\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n```"
            },
            "91": {
                "commit_sha_buggy": "7de614ffd01161d8718d7458bab9d9690ad2334f",
                "commit_sha_fixed": "247c5d05f4529e55aa1fdbd333f99e323809b5e0",
                "report_id": "1192",
                "report_url": "https://github.com/jhy/jsoup/issues/1192",
                "issue_title": "Jsoup.parse method hangs for certain bogus input text",
                "issue_description": "We are indexing the [ClueWeb12](https://lemurproject.org/clueweb12/) dataset using [lucene-clueweb-retrieval](https://github.com/iorixxx/lucene-clueweb-retrieval) library. We are using JSoup to parse Web pages. After a (drop-in) upgrade to JSoup version 1.11.3, our indexing processes hanged. Note than this was not the issue for earlier version of JSoup. Using jstack we spot document(s) that cause this problem crated a failing test case using it. We understand that the input is bogus (not a html code, but a binary file), but we expect JSoup to throw an exception or return an empty string. But the program hangs and never ends. We would like to report this to the community in the hope for obtaining a fix for the issue."
            },
            "92": {
                "commit_sha_buggy": "27a445b029b02bced263a0686f40a4f373827953",
                "commit_sha_fixed": "0fc3d6728ae270fb38f9778ad7fa2663060b50c7",
                "report_id": "1219",
                "report_url": "https://github.com/jhy/jsoup/issues/1219",
                "issue_title": "Duplicated attribute parsing problem ",
                "issue_description": "In case there is duplicated tag attribute Jsoup parses the last one, but Chrome browser takes the first one.\r\n\r\n"
            },
            "93": {
                "commit_sha_buggy": "e9e613706443fd1cd3458d1e5116c0498afd8b09",
                "commit_sha_fixed": "a9439f0c503ac8e0f009a0ec39f8bff1a6271d51",
                "report_id": "1231",
                "report_url": "https://github.com/jhy/jsoup/issues/1231",
                "issue_title": "<input type=\"image\"> is not special cased in formData method",
                "issue_description": "The following code:\r\n\r\n```java\r\nimport org.jsoup.Jsoup;\r\nimport org.jsoup.nodes.FormElement;\r\n\r\nclass Scratch {\r\n    public static void main(String[] args) {\r\n        System.out.println(((FormElement) Jsoup.parse(\"<form id=f><input type=image name=x></form>\").getElementById(\"f\")).formData());\r\n    }\r\n}\r\n```\r\n\r\nReturns the following output:\r\n\r\n```\r\n[x=]\r\n```\r\n\r\nWhen either `[]` or `[x.x=0, x.y=0]` is expected (not sure which, but `[x=]` is definitely wrong)."
            }
        }
    },
    "JxPath": {
        "owner_repo": "apache/commons-jxpath",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "932131e698e669cd7e0743a6999eab455f9de6b0",
                "commit_sha_fixed": "fab38abb27f2f92b9340cfc232eb5517434bf138",
                "report_id": "JXPATH-12",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-12",
                "issue_title": "[JXPATH-12] Descendant or self axis does not work correctly at root node - ASF JIRA",
                "issue_description": "\nGiven the following XML document: <root id=\"1234\"/>\nand the XPath: //root/@id/text().\nJXPath returns null instead of \"1234\".\nJXPathContext context = JXPathContext.newContext(doc);\nassertEquals(value, context.selectSingleNode(\"//root/@id/text()\"));\nThe attached JUnit test highlights the problem. It seems that JXPath does not\nfind the root node if it is accessed with the axis descendant-or-self.\n"
            },
            "2": {
                "commit_sha_buggy": "5eb29ba7901ab88e8388095a8696c4ae13a2c163",
                "commit_sha_fixed": "716c03b3b12ec106974898451b149f6eb79c65da",
                "report_id": "JXPATH-50",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-50",
                "issue_title": "[JXPATH-50] does not properly handle NodeSet returned by extension function - ASF JIRA",
                "issue_description": "\nPer the documentation, my function is returning a BasicNodeSet containing zero\nor more pointers:\n  public static NodeSet observations(ExpressionContext context) {\n    // the cast below shouldn't break, as this is the only pointer type that\n    // makes sense in this context\n    List<NodePointer> ptrs = extractObservations(\n                                  (NodePointer)context.getContextNodePointer(), \n                                  new ArrayList<NodePointer>());\n    BasicNodeSet result = new BasicNodeSet();\n    for (NodePointer ptr : ptrs) \n{\n      result.add(ptr);\n    }\n    return result;\n  }\nHowever, if I call JXPathContext.selectNodes(\"ems:observations()\"), I'm getting\na single node containing the BasicNodeSet. I notice that there is a testcase for\nfunctions that return NodeSets, but that it uses expressions that actually\nreturn the children of the NodeSet (\"test:nodeSet()/name\").\nThere appear to be two problems. First, Expression.iterate() and\nExpression.iteratePointers() do not correctly recognize a NodeSet as something\niterable. I've resolved this by reaching into the NodeSet and getting an\niterator over its pointers.\nSecond, Expression.PointerIterator doesn't recognize when it already has a\npointer, and instead tries to wrap it in a new pointer. This ends up treating\nthe pointer as a bean.\nI've made these changes, and written a testcase that uses an unadorned NodeSet\nfunction. I also found a class that used a variable named \"enum\", and changed\nthis so that it would compile under 1.5.\nThe patch is attached. It's relative to \"commons-jxpath-1.2\" (root of extract\ndirectory).\n"
            },
            "3": {
                "commit_sha_buggy": "34e73b6483b08da2d793eb613520e23c3d6afeb1",
                "commit_sha_fixed": "984778f3c264df5d608eb9697df2a268122ac66f",
                "report_id": "JXPATH-68",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-68",
                "issue_title": "[JXPATH-68] StackOverflow error on a call to 'JXPathContext.createPath()' - ASF JIRA",
                "issue_description": "\nI'm running into a StackOverflow error on a call to\n'JXPathContext.createPath()' whenever I have a path that looks like\n'a/b[1]/c'.  I took a quick look at the code and it appears JXPath, when\ntrying to create its parent pointer, simply recreates an equivalent\npointer(???).\nHere is code to reproduce the problem.\n    Map map = new HashMap();\n    map.put(\"a\", null);\n    JXPathContext pathContext = JXPathContext.newContext(map);\n    pathContext.setFactory(new AbstractFactory() {\n      public boolean createObject(\n          JXPathContext context, Pointer pointer, Object parent, String\nname, int index) {\n        Map parentMap = (Map)parent;\n        System.out.println(parent + \":\" + name + \":\" + index);\n        if (index > -1) {\n          List list = (List)parentMap.get(name);\n          if (list == null) \n{\n            list = new ArrayList();\n          }\n          int size = list.size();\n          for (int i = size; i <= index; i++) {\n            list.add(i, null);\n          }\n          parentMap.put(name, list);\n        } else {\n          parentMap.put(name, new HashMap());\n        }\n        return true;\n      }\n\n    });\n    pathContext.createPath(\"a/b[1]/c\");\n\n***************\n\nI have continued looking into this, and found that the problem is that, if\nthe List is created with a 'null' element, JXPath gets stuck in infinite\nrecursion.\n\nTo discover this, I changed my Factory to implement the following method:\n\n      public boolean createObject(\n          JXPathContext context, Pointer pointer, Object parent, \n          String name, int index) {\n\n        if (pointer instanceof NodePointer) {\n          index = ((NodePointer)pointer).getIndex();\n        }\n        System.out.println(parent + \":\" + name + \":\" + index);\n        Map parentMap = (Map)parent;\n        if (index > -1) {\n          List list = (List)parentMap.get(name);\n          if (list == null) {            list = new ArrayList();          }\n          int size = list.size();\n          for (int i = size; i <= index; i++) \n{\n            list.add(i, new HashMap());  // !!!!!!  Don't set to 'null'\n          }\n          parentMap.put(name, list);\n        } else \n{\n          parentMap.put(name, new HashMap());\n        }\n        return true;\n      }\nThen I ran the following code:\n    pathContext.createPath(\"a/b[1]/c\");\n    pathContext.createPath(\"a/b[2]/c\");  // STACK OVERFLOW HERE\nHere is the stack trace at the beginning, where\n'ValueUtils.expandCollection()' is called.  It puts 'null' into the list,\nthus causing the stack overflow as we cycle between createPath() &\ncreateChild().\nThread [main] (Suspended (breakpoint at line 227 in DynamicPropertyPointer))\n\tDynamicPropertyPointer.createPath(JXPathContext) line: 227\n\tDynamicPropertyPointer(PropertyPointer).createChild(JXPathContext,\nQName, int) line: 188\n\tNullElementPointer.createPath(JXPathContext) line: 82\n\tNullPointer.createPath(JXPathContext) line: 86\n\tNullPropertyPointer.createPath(JXPathContext) line: 103\n\tNullPointer.createPath(JXPathContext) line: 86\n\tNullPropertyPointer.createPath(JXPathContext) line: 103\n\tJXPathContextReferenceImpl.createPath(String, Expression) line: 447\n\tJXPathContextReferenceImpl.createPath(String) line: 427\n\tTest.test4() line: 75\n\tTest.main(String[]) line: 38\n"
            },
            "4": {
                "commit_sha_buggy": "2bb50b71c9169033d917213ec753ff5af309965b",
                "commit_sha_fixed": "9f912437a14392f8d4c98aa811e9134fbf7b5a52",
                "report_id": "JXPATH-83",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-83",
                "issue_title": "[JXPATH-83] JXpath automatically trims string values - ASF JIRA",
                "issue_description": "\nWhen an xml contains a value with leading or trailing spaces, JXPath trims this value.\nexample: <value>     12324 56</value> is retrieved by JXPath as : '1234 56' while I expect '     1234 56'.\n"
            },
            "5": {
                "commit_sha_buggy": "458f562cdbe13b42ae325ac88a082047fe05ab89",
                "commit_sha_fixed": "2a01dfaf8d6abbabc7e4cd5cfd05d2e0b4886708",
                "report_id": "JXPATH-89",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-89",
                "issue_title": "[JXPATH-89] Cannot compare pointers that do not belong to the same tree - ASF JIRA",
                "issue_description": "\nFor XPath \"$var | /MAIN/A\" exception is thrown:\norg.apache.commons.jxpath.JXPathException: Cannot compare pointers that do not belong to the same tree: '$var' and ''\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:665)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:649)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:649)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareTo(NodePointer.java:639)\n\tat java.util.Arrays.mergeSort(Arrays.java:1152)\n\tat java.util.Arrays.sort(Arrays.java:1079)\n\tat java.util.Collections.sort(Collections.java:113)\n\tat org.apache.commons.jxpath.ri.EvalContext.constructIterator(EvalContext.java:176)\n\tat org.apache.commons.jxpath.ri.EvalContext.hasNext(EvalContext.java:100)\n\tat org.apache.commons.jxpath.JXPathContext.selectNodes(JXPathContext.java:648)\n\tat org.apache.commons.jxpath.ri.model.VariablePointerTestCase.testUnionOfVariableAndNode(VariablePointerTestCase.java:76)\n"
            },
            "6": {
                "commit_sha_buggy": "5e277f495715b7552d8eb9d8493b6450c071a990",
                "commit_sha_fixed": "9b6406bf37af48e843b02fa8fd53dc673f3cbd1e",
                "report_id": "JXPATH-94",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-94",
                "issue_title": "[JXPATH-94] equality test for multi-valued variables does not conform to spec - ASF JIRA",
                "issue_description": "\ngiven e.g. variable d=\n{\"a\", \"b\"}\n, the spec implies that \"$d = 'a'\" and that \"$d = 'b'\".  Instead of iterating the variable's components its immediate content (here, the String[]) is compared, causing the aforementioned assertions to fail.\n"
            },
            "7": {
                "commit_sha_buggy": "9b6406bf37af48e843b02fa8fd53dc673f3cbd1e",
                "commit_sha_fixed": "58fac658aba985ba77f8bd0156c6d01bec8d991b",
                "report_id": "JXPATH-93",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-93",
                "issue_title": "[JXPATH-93] Binary operators behaviour involving node-sets is incorrect - ASF JIRA",
                "issue_description": "\nAccording to XPath specification:\n\"If both objects to be compared are node-sets, then the comparison will be true if and only if there is a node in the first node-set and a node in the second node-set such that the result of performing the comparison on the string-values of the two nodes is true. If one object to be compared is a node-set and the other is a number, then the comparison will be true if and only if there is a node in the node-set such that the result of performing the comparison on the number to be compared and on the result of converting the string-value of that node to a number using the number function is true.\"\nBut following example illustrates, that this is not a JXPath behaviour:\n        JXPathContext pathContext = JXPathContext\n                .newContext(DocumentBuilderFactory.newInstance()\n                        .newDocumentBuilder().parse(\n                                new InputSource(new StringReader(\n                                        \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\r\\n\"\n                                                + \"<doc/>\"))));\n        Boolean result = (Boolean) pathContext.getValue(\"2.0 > child1\",\n                Boolean.class);\n        assertFalse(result.booleanValue());\n\"child1\" is not found - right operand node set is empty, but result is TRUE, instead of FALSE.\nPlease, check greaterThan(), lesserThan(), etc methods of org.apache.xpath.objects.XObject for possible solution \n"
            },
            "8": {
                "commit_sha_buggy": "bb12c5b5ec5ce80c8148749ffef72956c01571a0",
                "commit_sha_fixed": "1befe1b93eec887971e729b89dd4d900319a06b0",
                "report_id": "JXPATH-95",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-95",
                "issue_title": "[JXPATH-95] Comparing with NaN is incorrect - ASF JIRA",
                "issue_description": "\n'NaN' > 'NaN' is true, but should be FALSE\n"
            },
            "9": {
                "commit_sha_buggy": "b546d575e5b626929a3649794f4e47bccc4fd3e3",
                "commit_sha_fixed": "40689aa2f3e6e601b51f6c590dbaf079325da772",
                "report_id": "JXPATH-95",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-95",
                "issue_title": "[JXPATH-95] Comparing with NaN is incorrect - ASF JIRA",
                "issue_description": "\n'NaN' > 'NaN' is true, but should be FALSE\n"
            },
            "10": {
                "commit_sha_buggy": "1860d750670f46e64c276bae92d93f545dfb5bd5",
                "commit_sha_fixed": "3b3e58d3d35aaa7e8e35c0856611f4bfc3f291c7",
                "report_id": "JXPATH-93",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-93",
                "issue_title": "[JXPATH-93] Binary operators behaviour involving node-sets is incorrect - ASF JIRA",
                "issue_description": "\nAccording to XPath specification:\n\"If both objects to be compared are node-sets, then the comparison will be true if and only if there is a node in the first node-set and a node in the second node-set such that the result of performing the comparison on the string-values of the two nodes is true. If one object to be compared is a node-set and the other is a number, then the comparison will be true if and only if there is a node in the node-set such that the result of performing the comparison on the number to be compared and on the result of converting the string-value of that node to a number using the number function is true.\"\nBut following example illustrates, that this is not a JXPath behaviour:\n        JXPathContext pathContext = JXPathContext\n                .newContext(DocumentBuilderFactory.newInstance()\n                        .newDocumentBuilder().parse(\n                                new InputSource(new StringReader(\n                                        \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\r\\n\"\n                                                + \"<doc/>\"))));\n        Boolean result = (Boolean) pathContext.getValue(\"2.0 > child1\",\n                Boolean.class);\n        assertFalse(result.booleanValue());\n\"child1\" is not found - right operand node set is empty, but result is TRUE, instead of FALSE.\nPlease, check greaterThan(), lesserThan(), etc methods of org.apache.xpath.objects.XObject for possible solution \n"
            },
            "11": {
                "commit_sha_buggy": "626e5e5994a651085e9d2ccb1ca99c701f88bc68",
                "commit_sha_fixed": "52d73022820d163104c6419f25ca955f86464f63",
                "report_id": "JXPATH-97",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-97",
                "issue_title": "[JXPATH-97] Incomplete handling of undefined namespaces - ASF JIRA",
                "issue_description": "\nMcduffey, Joe <jdmcduf@nsa.gov>\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.\n"
            },
            "12": {
                "commit_sha_buggy": "52d73022820d163104c6419f25ca955f86464f63",
                "commit_sha_fixed": "d52074012200f55cbd3635591b914e2c1b19674f",
                "report_id": "JXPATH-97",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-97",
                "issue_title": "[JXPATH-97] Incomplete handling of undefined namespaces - ASF JIRA",
                "issue_description": "\nMcduffey, Joe <jdmcduf@nsa.gov>\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.\n"
            },
            "13": {
                "commit_sha_buggy": "d52074012200f55cbd3635591b914e2c1b19674f",
                "commit_sha_fixed": "15a67164cbefb9f9ae03b334888947d5fe5dccb4",
                "report_id": "JXPATH-97",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-97",
                "issue_title": "[JXPATH-97] Incomplete handling of undefined namespaces - ASF JIRA",
                "issue_description": "\nMcduffey, Joe <jdmcduf@nsa.gov>\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.\n"
            },
            "14": {
                "commit_sha_buggy": "2c5243995eceb0de0a71271ce2ea7c02c38649fb",
                "commit_sha_fixed": "8a04f62fa755ec165152a03a516c186d20e8cd46",
                "report_id": "JXPATH-102",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-102",
                "issue_title": "[JXPATH-102] Core rounding functions don't handle NaN or infinite values correctly - ASF JIRA",
                "issue_description": "\n        assertXPathValue(context, \"floor('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"floor(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"floor(2 div 0)\", new Double(Double.POSITIVE_INFINITY));\n        assertXPathValue(context, \"ceiling('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"ceiling(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"ceiling(2 div 0)\", new Double(Double.POSITIVE_INFINITY));\n        assertXPathValue(context, \"round('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"round(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"round(2 div 0)\", new Double(Double.POSITIVE_INFINITY));\n"
            },
            "15": {
                "commit_sha_buggy": "33cabe52b5ab65bcbb67a2b725b3d97d09749f18",
                "commit_sha_fixed": "497ed5f8b0bb95ad7a97ea5f0cc517a0420e422f",
                "report_id": "JXPATH-100",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-100",
                "issue_title": "[JXPATH-100] Core union operation does not sort result nodes according to document order - ASF JIRA",
                "issue_description": "\nSource document:\n<MAIN><A>avalue</A><B>bvalue</B></MAIN>\nAccording to string() function defintion:\n\"A node-set is converted to a string by returning the string-value of the node in the node-set that is first in document order. If the node-set is empty, an empty string is returned.\"\nFollowing XPath calculated incorrectly:\n string(/MAIN/B | /MAIN/A)\nExpected result: \"avalue\"\nActual value: \"bvalue\"\nReason:\nsorting of result nodes is missing from CoreOperationUnion\n"
            },
            "16": {
                "commit_sha_buggy": "e2c9d22b8dc59c707e32ef7fb05a3282792ce92b",
                "commit_sha_fixed": "6cf7092809515b6add5f0e83fd837b8e013c5256",
                "report_id": "JXPATH-114",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-114",
                "issue_title": "[JXPATH-114] node() implementation in DOM and JDOM model - ASF JIRA",
                "issue_description": "\nI think that the code in DOMNodePointer.java, line 120 is wrong because considers only element and document to be matched by node().\nwhile instead it matches any node that pass from there.\ncase Compiler.NODE_TYPE_NODE :\n                    return nodeType == Node.ELEMENT_NODE\n\n\n\n nodeType == Node.DOCUMENT_NODE;\n\n\n\nshould be changed to \ncase Compiler.NODE_TYPE_NODE :\n                    return true;\nSame in JDOMNodePointer, line 391\n                  return true;//(node instanceof Element) || (node instanceof Document);\n"
            },
            "17": {
                "commit_sha_buggy": "1a292f1cd08ec2272c3565e0197ec11772db28c0",
                "commit_sha_fixed": "a1bc20f2af31730caa12faa116e14a964354f28d",
                "report_id": "JXPATH-109",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-109",
                "issue_title": "[JXPATH-109] Namespaced attribute not selected with wildcard - ASF JIRA",
                "issue_description": "\nWith expression:\nxml/@*\nOn xml:\n<xml xmlns:x='foo' x:pop='a'/>\nselectSingleNode returns null, @x:* works fine.\nPossible Fix:\nIn DOMAttributeIterator, line 84\nif (equalStrings(testPrefix, nodePrefix)) \n{\n                return true;\n            }\n\nshould probably be changed to\n\nif (testPrefix==null || equalStrings(testPrefix, nodePrefix)) {                return true;            }\n            "
            },
            "18": {
                "commit_sha_buggy": "a1bc20f2af31730caa12faa116e14a964354f28d",
                "commit_sha_fixed": "4882e4423ae7bfb80c65da4aa547ef5aed16a007",
                "report_id": "JXPATH-115",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-115",
                "issue_title": "[JXPATH-115] Issue with attribute:: - ASF JIRA",
                "issue_description": "\nChecking test (Issue172_CountAttributeNode) I came with the following fix for the code in AttributeContext  line 72\nfrom \n\nif (!(nodeTest instanceof NodeNameTest)) \n{\n                return false;\n            }\n            QName name = ((NodeNameTest) nodeTest).getNodeName();\n------\n'\nto \n\u2014 (outside method)\nprivate static final QName WILDCARD = new QName(\"\", \"*\");\n\u2014 (in method)\nfinal QName name ;\nif (nodeTest instanceof NodeTypeTest)\n{\n\t if (((NodeTypeTest) nodeTest).getNodeType() == Compiler.NODE_TYPE_NODE)\n\t\t name = WILDCARD;\n\t else return false;\n}\nelse if (nodeTest instanceof NodeNameTest) {\n\tname = ((NodeNameTest) nodeTest).getNodeName();\n}\nelse\n{\n\treturn false;\n}\n"
            },
            "19": {
                "commit_sha_buggy": "b67345afa4817cc8bc7f14137ed1ef90ab299062",
                "commit_sha_fixed": "7b2847e882a9e4216dcf0f35d27101e363611532",
                "report_id": "JXPATH-125",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-125",
                "issue_title": "[JXPATH-125] JXPathContext.iteratePointers() does not work with multiple prefixes for a single namespace URI - ASF JIRA",
                "issue_description": "\nHave a look at the following document:\n<a:doc xmlns:a=\"ns\">\n  <a:elem />\n  <b:elem xmlns:b=\"ns\" />\n</a:doc>\nWe have two elements 'elem' in the same namespace 'ns'.\nThey have a different prefix, however.\nWhen we use JXPathContext.iteratePointers() to iterate over them, the first element is returned two times. The second element is not returned.\nThis is because\nin class org.apache.commons.jxpath.ri.model.dom.DOMNodePointer\nin method getRelativePositionByName() (line 546)\nwe have:\nif (nm.equals(node.getNodeName()))\nIn the example, we have\nnm  == \"a:elem\" and node == \"b:elem\"\nThus, equals() returns false. But since 'a' and 'b' are just different prefixes for the same namespace URI, we should have 'true'.\nI attached a testcase which reproduces the bug.\n"
            },
            "20": {
                "commit_sha_buggy": "a48b10d2a39eab2eb5a6a7309edc98803ceffe81",
                "commit_sha_fixed": "820a69d81b3b5d33f4a2b2cd9f153450f7535452",
                "report_id": "JXPATH-149",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-149",
                "issue_title": "[JXPATH-149] relational operations do not function properly when comparing a non-Iterator LHS to an Iterator RHS - ASF JIRA",
                "issue_description": "\nI have a simple JXpathContext, with the following variables: var1=0, var2=0, var3=1. When I try to evaluate the following expression - \"$var1 + $var2 <= $var3\", it returns false.\n"
            },
            "21": {
                "commit_sha_buggy": "820a69d81b3b5d33f4a2b2cd9f153450f7535452",
                "commit_sha_fixed": "99a20785daf2bfc018552e2eabed1067bf225013",
                "report_id": "JXPATH-151",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-151",
                "issue_title": "[JXPATH-151] null handling is inconsistent - ASF JIRA",
                "issue_description": "\nComparing a vaule to null using unequals (!=) yields false!\n\n        Map<String, Integer> m = new HashMap<String, Integer>();\n        m.put(\"a\", 1);\n        m.put(\"b\", null);\n        m.put(\"c\", 1);\n        JXPathContext c = JXPathContext.newContext(m);\n        System.out.println(c.getValue(\"a != b\") + \" should be true\");\n        System.out.println(c.getValue(\"a != c\") + \" should be false\");\n        System.out.println(c.getValue(\"a = b\") + \" should be false\");\n        System.out.println(c.getValue(\"a = c\") + \" should be true\");\n        System.out.println(c.getValue(\"not(a = b)\") + \" should be true\");\n        System.out.println(c.getValue(\"not(a = c)\") + \" should be false\");\n\n\nOutput using 1.3:\n false should be true\nfalse should be false\nfalse should be false\ntrue should be true\ntrue should be true\nfalse should be false\nIn 1.2 it works correctly!\n"
            },
            "22": {
                "commit_sha_buggy": "5c538c4e51c6c5ebb43182d0c6e99ee8f7b3590c",
                "commit_sha_fixed": "afa2deca94436837e785b89362cfaaf84a8ca1bd",
                "report_id": "JXPATH-154",
                "report_url": "https://issues.apache.org/jira/browse/JXPATH-154",
                "issue_title": "[JXPATH-154] Resetting the default namespace causes a serious endless loop when requesting .asPath() on a node. - ASF JIRA",
                "issue_description": "\nsample smaller case:\n\n<...>\n <b:foo xmlns:b=\"bla\" xmlns=\"test111\">    <!--  No nodes are placed in the tree within ns \"test111\" but the attribute is still there.-->\n  <b:bar>a</b:bar>                         <!-- is in ns 'bla' -->\n  <test xmlns=\"\"></test>                   <!-- does not have a namespace -->\n </b:foo>\n</...>\n\n\nwhen requesting .asPath() on the 'test' node, it loops in org.apache.commons.jxpath.ri.NamespaceResolver.getPrefix(NodePointer, String), \nand if it didn't loop it would create a wrong xpath '//b:fo/null:test' DOMNodePointer.asPath().\nSo I think that the fix should be in org.apache.commons.jxpath.ri.model.dom.DOMNodePointer.asPath()\n\n....\n                    String ln = DOMNodePointer.getLocalName(node);\n                    String nsURI = getNamespaceURI();\n                    if (nsURI == null) {\n                        buffer.append(ln);\n                        buffer.append('[');\n                        buffer.append(getRelativePositionByName()).append(']');\n                    }\n                    else {\n                        String prefix = getNamespaceResolver().getPrefix(nsURI);\n                        if (prefix != null) {\n...\n\n\nshould become\n\n...\n                    String ln = DOMNodePointer.getLocalName(node);\n                    String nsURI = getNamespaceURI();\n                    if (nsURI == null || nsURI.length() == 0) { // check for empty string which means that the node doesn't have a namespace.\n                        buffer.append(ln);\n                        buffer.append('[');\n                        buffer.append(getRelativePositionByName()).append(']');\n                    }\n                    else {\n                        String prefix = getNamespaceResolver().getPrefix(nsURI);\n                        if (prefix != null) {\n...\n\n\n"
            }
        }
    },
    "Lang": {
        "owner_repo": "apache/commons-lang",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2c454a4ce3fe771098746879b166ede2284b94f4",
                "commit_sha_fixed": "687b2e62b7c6e81cd9d5c872b7fa9cc8fd3f1509",
                "report_id": "LANG-747",
                "report_url": "https://issues.apache.org/jira/browse/LANG-747",
                "issue_title": "[LANG-747] NumberUtils does not handle Long Hex numbers - ASF JIRA",
                "issue_description": "\nNumberUtils.createLong() does not handle hex numbers, but createInteger() handles hex and octal.\nThis seems odd.\nNumberUtils.createNumber() assumes that hex numbers can only be Integer.\nAgain, why not handle bigger Hex numbers?\n==\nIt is trivial to fix createLong() - just use Long.decode() instead of valueOf().\nIt's not clear why this was not done originally - the decode() method was added to both Integer and Long in Java 1.2.\nFixing createNumber() is also fairly easy - if the hex string has more than 8 digits, use Long.\nShould we allow for leading zeros in an Integer? \nIf not, the length check is trivial.\n"
            },
            "3": {
                "commit_sha_buggy": "1f001d06a2bde5ee4e3204ab38c4b1db8e95db0b",
                "commit_sha_fixed": "2c9c8753165dc7ce5dd1d5a6d741b445b33302c2",
                "report_id": "LANG-693",
                "report_url": "https://issues.apache.org/jira/browse/LANG-693",
                "issue_title": "[LANG-693] Method createNumber from NumberUtils doesn't work for floating point numbers other than Float - ASF JIRA",
                "issue_description": "\nMethod createNumber from NumberUtils is trying to parse a string with a floating point number always first as a Float, that will cause that if we send a string with a number that will need a Double or even a BigDecimal the number will be truncate to accommodate into the Float without an exception to be thrown, so in fact we will no be returning ever neither a Double nor a BigDecimal.\n"
            },
            "4": {
                "commit_sha_buggy": "4ddbd99c5805781bd3c2287ab7920fecc23dab53",
                "commit_sha_fixed": "fb47b96ab635d7cc6e9edefdddc46f1baf63b117",
                "report_id": "LANG-882",
                "report_url": "https://issues.apache.org/jira/browse/LANG-882",
                "issue_title": "[LANG-882] LookupTranslator accepts CharSequence as input, but fails to work with implementations other than String - ASF JIRA",
                "issue_description": "\nThe core of org.apache.commons.lang3.text.translate is a HashMap<CharSequence, CharSequence> lookupMap.\nFrom the Javadoc of CharSequence (emphasis mine):\n\nThis interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore, in general, undefined. Each object may be implemented by a different class, and there is no guarantee that each class will be capable of testing its instances for equality with those of the other. It is therefore inappropriate to use arbitrary CharSequence instances as elements in a set or as keys in a map.\nThe current implementation causes code such as the following to not work as expected:\n\nCharSequence cs1 = \"1 < 2\";\nCharSequence cs2 = CharBuffer.wrap(\"1 < 2\".toCharArray());\n\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs1));\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2));\n\n\n... which gives the following results (but should be identical):\n\n1 &lt; 2\n1 < 2\n\n\nThe problem, at a minimum, is that CharBuffer.equals is even documented in the Javadoc that:\n\nA char buffer is not equal to any other type of object.\n... so a lookup on a CharBuffer in the Map will always fail when compared against the String implementations that it contains.\nAn obvious work-around is to instead use something along the lines of either of the following:\n\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2.toString()));\nSystem.out.println(StringEscapeUtils.escapeHtml4(cs2.toString()));\n\n\n... which forces everything back to a String.  However, this is not practical when working with large sets of data, which would require significant heap allocations and garbage collection concerns.  (As such, I was actually trying to use the translate method that outputs to a Writer - but simplified the above examples to omit this.)\nAnother option that I'm considering is to use a custom CharSequence wrapper around a char[] that implements hashCode() and equals() to work with those implemented on String.  (However, this will be interesting due to the symmetric assumption - which is further interesting that String.equals is currently implemented using instanceof - even though String is final...)\n"
            },
            "5": {
                "commit_sha_buggy": "379151bad9c5402c335db67f9494351b99298732",
                "commit_sha_fixed": "75944e541d358d5b06ebbba3098a919fbf2539d4",
                "report_id": "LANG-865",
                "report_url": "https://issues.apache.org/jira/browse/LANG-865",
                "issue_title": "[LANG-865] LocaleUtils.toLocale does not parse strings starting with an underscore - ASF JIRA",
                "issue_description": "\nHi,\nJavadocs of Locale.toString() states that \"If the language is missing, the string will begin with an underbar.\". This is not handled in the LocaleUtils.toLocale method if it is meant to be the inversion method of Locale.toString().\nThe fix for the ticket 328 does not handle well the case \"fr__P\", which I found out during fixing the first bug.\nI am attaching the patch for both problems.\n"
            },
            "6": {
                "commit_sha_buggy": "6823c3742ee16f5b28e550a6afb685553befc0c2",
                "commit_sha_fixed": "cff0f1ae37bb2b7ab2dcdb10dec1f3cad7532e1c",
                "report_id": "LANG-857",
                "report_url": "https://issues.apache.org/jira/browse/LANG-857",
                "issue_title": "[LANG-857] StringIndexOutOfBoundsException in CharSequenceTranslator - ASF JIRA",
                "issue_description": "\nI found that there is bad surrogate pair handling in the CharSequenceTranslator\nThis is a simple test case for this problem.\n\\uD83D\\uDE30 is a surrogate pair.\n\n@Test\npublic void testEscapeSurrogatePairs() throws Exception {\n    assertEquals(\"\\uD83D\\uDE30\", StringEscapeUtils.escapeCsv(\"\\uD83D\\uDE30\"));\n}\n\n\nYou'll get the exception as shown below.\n\njava.lang.StringIndexOutOfBoundsException: String index out of range: 2\n\tat java.lang.String.charAt(String.java:658)\n\tat java.lang.Character.codePointAt(Character.java:4668)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59)\n\tat org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)\n\n\nPatch attached, the method affected:\n\npublic final void translate(CharSequence input, Writer out) throws IOException\n\n"
            },
            "7": {
                "commit_sha_buggy": "f0c7e60bbaf975b64ab5bf1b75ba6b7dbc256300",
                "commit_sha_fixed": "e71f6dd3f2f70c640ae73d28b432b3a69ffcab4b",
                "report_id": "LANG-822",
                "report_url": "https://issues.apache.org/jira/browse/LANG-822",
                "issue_title": "[LANG-822] NumberUtils#createNumber - bad behaviour for leading \"--\" - ASF JIRA",
                "issue_description": "\nNumberUtils#createNumber checks for a leading \"--\" in the string, and returns null if found. This is documented as a work round for a bug in BigDecimal.\nReturning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException.\nIt's not clear whether the BigDecimal problem still exists with recent versions of Java. However, if it does exist, then the check needs to be done for all invocations of BigDecimal, i.e. needs to be moved to createBigDecimal.\n"
            },
            "8": {
                "commit_sha_buggy": "8d192d7063cc747a3c6226122ea83c7348e199e7",
                "commit_sha_fixed": "a4a455053e7e4a77320efd6db0814f4de82d754d",
                "report_id": "LANG-818",
                "report_url": "https://issues.apache.org/jira/browse/LANG-818",
                "issue_title": "[LANG-818] FastDateFormat's \"z\" pattern does not respect timezone of Calendar instances passed to format() - ASF JIRA",
                "issue_description": "\nThe work on LANG-462 has introduced a time zone formatting bug in FastDateFormat in commons-lang3.\nThe problem can be seen by this snippet:\n\n// Always prints timezone name of machine's default timezone, ignoring TZ\n// set on calendar, even though the printed time itself respects calendar's TZ.\nCalendar myCal = Calendar.getInstance(TimeZone.getTimeZone(\"US/Central\"));\nSystem.out.println(FastDateFormat.getInstance(\"h:mma z\").format(myCal));\n\n\nIf you happen to be in US/Central, this will print the right thing, but just try it with US/Eastern, US/Pacific, etc.  It will print the time in the correct timezone, but the timezone name at the end (the \"z\" pattern) will always be the system default timezone.  This is a regression against commons-lang 2.x.\nBasically, when the \"forced time zone\" code was removed, the TimeZoneNameRule class stopped respecting the Calendar instance's timezone, and instead now always uses the mTimeZone of the FastDateFormat instance itself (which is only supposed to be used when formatting timezone-less objects such as Date or long).\nThe removal of the forced time zone stuff is surely the right thing to do (it was a mess).  I think the fix is to change the TimeZoneNameRule inner class to not take a TimeZone instance, but rather to use the TimeZone on the Calendar instance passed into appendTo(), just like TimeZoneNumberRule does.  Presumably then for efficiency, one would use the getTimeZoneDisplay() package-static method to quickly retrieve the required timezone's display name.\n"
            },
            "9": {
                "commit_sha_buggy": "afe5dff79fc23d222ba1f1481fbbf55e09d2e6da",
                "commit_sha_fixed": "c45d5bff75edfef6387d40e681f9dc7c9b517bbb",
                "report_id": "LANG-832",
                "report_url": "https://issues.apache.org/jira/browse/LANG-832",
                "issue_title": "[LANG-832] FastDateParser does not handle unterminated quotes correctly - ASF JIRA",
                "issue_description": "\nFDP does not handled unterminated quotes the same way as SimpleDateFormat\nFor example:\nFormat: 'd'd'\nDate: d3\nThis should fail to parse the format and date but it actually works.\nThe format is parsed as:\nPattern: d(\\p\n{IsNd}\n++)\n"
            },
            "10": {
                "commit_sha_buggy": "0afcd15e183205a85a45a2775f1fb75a162a1389",
                "commit_sha_fixed": "afe5dff79fc23d222ba1f1481fbbf55e09d2e6da",
                "report_id": "LANG-831",
                "report_url": "https://issues.apache.org/jira/browse/LANG-831",
                "issue_title": "[LANG-831] FastDateParser does not handle white-space properly - ASF JIRA",
                "issue_description": "\nThe SimpleDateFormat Javadoc does not treat white-space specially, however FastDateParser treats a single white-space as being any number of white-space characters.\nThis means that FDP will parse dates that fail when parsed by SDP.\n"
            },
            "11": {
                "commit_sha_buggy": "c9d786a4fe2639581047d878a64bab6fb24f1ab3",
                "commit_sha_fixed": "c821fafce06adefc040e8983fb12d49399a48627",
                "report_id": "LANG-807",
                "report_url": "https://issues.apache.org/jira/browse/LANG-807",
                "issue_title": "[LANG-807] RandomStringUtils throws confusing IAE when end <= start - ASF JIRA",
                "issue_description": "\nRandomUtils invokes Random#nextInt where n = end - start.\nIf end <= start, then Random throws:\njava.lang.IllegalArgumentException: n must be positive\nThis is confusing, and does not identify the source of the problem.\n"
            },
            "12": {
                "commit_sha_buggy": "9351ed93365de2d1c316b8f419566820e88839e3",
                "commit_sha_fixed": "c9d786a4fe2639581047d878a64bab6fb24f1ab3",
                "report_id": "LANG-805",
                "report_url": "https://issues.apache.org/jira/browse/LANG-805",
                "issue_title": "[LANG-805] RandomStringUtils.random(count, 0, 0, false, false, universe, random) always throws java.lang.ArrayIndexOutOfBoundsException - ASF JIRA",
                "issue_description": "\nIn commons-lang 2.6 line 250 :\n\nch = chars[random.nextInt(gap) + start];\n\nThis line of code takes a random int to fetch a char in the chars array regardless of its size.\n(Besides start is useless here)\nFixed version would be :\n\n//ch = chars[random.nextInt(gap)%chars.length];\n\nWhen user pass 0 as end or when the array is not null but empty this line ends up with an exception\n"
            },
            "13": {
                "commit_sha_buggy": "d0cf0fdd4ff2329f9584c4f663f1af177c1994f6",
                "commit_sha_fixed": "bd59a1908a1df3364918be7b07782500616b15ac",
                "report_id": "LANG-788",
                "report_url": "https://issues.apache.org/jira/browse/LANG-788",
                "issue_title": "[LANG-788] SerializationUtils throws ClassNotFoundException when cloning primitive classes - ASF JIRA",
                "issue_description": "\nIf a serializable object contains a reference to a primitive class, e.g. int.class or int[].class, the SerializationUtils throw a ClassNotFoundException when trying to clone that object.\n\nimport org.apache.commons.lang3.SerializationUtils;\nimport org.junit.Test;\n\n\npublic class SerializationUtilsTest {\n\n\t\n\t@Test\n\tpublic void primitiveTypeClassSerialization(){\n\t\tClass<?> primitiveType = int.class;\n\t\t\n\t\tClass<?> clone = SerializationUtils.clone(primitiveType);\n\t\tassertEquals(primitiveType, clone);\n\t}\n}\n\n\nThe problem was already reported as a java bug http://bugs.sun.com/view_bug.do?bug_id=4171142 and ObjectInputStream is fixed since java version 1.4.\nThe SerializationUtils problem arises because the SerializationUtils internally use the ClassLoaderAwareObjectInputStream that overrides the ObjectInputStream's\nresoleClass method without delegating to the super method in case of a ClassNotFoundException.\nI understand the intention of the ClassLoaderAwareObjectInputStream, but this implementation should also implement a fallback to the original implementation.\nFor example:\n\n        protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException {\n            String name = desc.getName();\n            try {\n                return Class.forName(name, false, classLoader);\n            } catch (ClassNotFoundException ex) {\n            \ttry {\n            \t     return Class.forName(name, false, Thread.currentThread().getContextClassLoader());\n            \t} catch (Exception e) {\n\t\t     return super.resolveClass(desc);\n\t\t}\n            }\n        }\n\n\nHere is the code in ObjectInputStream that fixed the java bug.\n\n    protected Class<?> resolveClass(ObjectStreamClass desc)\n\tthrows IOException, ClassNotFoundException\n    {\n\tString name = desc.getName();\n\ttry {\n\t    return Class.forName(name, false, latestUserDefinedLoader());\n\t} catch (ClassNotFoundException ex) {\n\t    Class cl = (Class) primClasses.get(name);\n\t    if (cl != null) {\n\t\treturn cl;\n\t    } else {\n\t\tthrow ex;\n\t    }\n\t}\n    }\n\n\n"
            },
            "14": {
                "commit_sha_buggy": "c8afaa3e869cc8c25577641553e0d0b5bdac78b5",
                "commit_sha_fixed": "cf7211f9d7d70d56501d8c4c827bf9ce3cac5f0b",
                "report_id": "LANG-786",
                "report_url": "https://issues.apache.org/jira/browse/LANG-786",
                "issue_title": "[LANG-786] StringUtils equals() relies on undefined behavior - ASF JIRA",
                "issue_description": "\nSince the java.lang.CharSequence class was first introduced in 1.4, the JavaDoc block has contained the following note:\n\nThis interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore, in general, undefined. Each object may be implemented by a different class, and there is no guarantee that each class will be capable of testing its instances for equality with those of the other.\nWhen the signature of the StringUtils equals() method was changed from equals(String, String) to equals(CharSequence, CharSequence) in R920543, the implementation still relied on calling CharSequence#equals(Object) even though, in general, the result is undefined.\nOne example where equals(Object) returns false even though, as CharSequences, two objects represent equal sequences is when one object is an instance of javax.lang.model.element.Name and the other object is a String.\n"
            },
            "15": {
                "commit_sha_buggy": "76912e0d8aed581ee4bc6b8635d0512ac2695f5d",
                "commit_sha_fixed": "8185a9e681d6de5f40b0ed07b40730c9761bad37",
                "report_id": "LANG-775",
                "report_url": "https://issues.apache.org/jira/browse/LANG-775",
                "issue_title": "[LANG-775] TypeUtils.getTypeArguments() misses type arguments for partially-assigned classes - ASF JIRA",
                "issue_description": "\nfailing test code to add to TypeUtilsTest.testGetTypeArguments():\n\ntypeVarAssigns = TypeUtils.getTypeArguments(Other.class, This.class);\nAssert.assertEquals(2, typeVarAssigns.size());\nAssert.assertEquals(String.class, typeVarAssigns.get(This.class.getTypeParameters()[0]));\nAssert.assertEquals(Other.class.getTypeParameters()[0], typeVarAssigns.get(This.class.getTypeParameters()[1]));\n\n\nThese should pass based on:\n\n\npublic interface This<K, V> {\n}\n\npublic class Other<T> implements This<String, T> {\n}\n\n\nThis case fails because the current code ignores the Other class due to its specifying its own type variables, which is obviously incorrect.  This report is extrapolated from an offline report received by Hen.\n"
            },
            "16": {
                "commit_sha_buggy": "a145b6d838914e38ee1027a1497de41140549080",
                "commit_sha_fixed": "13c7f19a5ad506340a7c8d8601ef4bf2426ab325",
                "report_id": "LANG-746",
                "report_url": "https://issues.apache.org/jira/browse/LANG-746",
                "issue_title": "[LANG-746] NumberUtils does not handle upper-case hex: 0X and -0X - ASF JIRA",
                "issue_description": "\nNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException\nInteger.decode() handles both upper and lower case hex.\n"
            },
            "17": {
                "commit_sha_buggy": "a7e90b2ffa23ab60c7022e2f94a12651b4fb8ec0",
                "commit_sha_fixed": "b4255e6d071dc8d48bfc51037cecb29097b9a49d",
                "report_id": "LANG-720",
                "report_url": "https://issues.apache.org/jira/browse/LANG-720",
                "issue_title": "[LANG-720] StringEscapeUtils.escapeXml(input) outputs wrong results when an input contains characters in Supplementary Planes. - ASF JIRA",
                "issue_description": "\nHello.\nI use StringEscapeUtils.escapeXml(input) to escape special characters for XML.\nThis method outputs wrong results when input contains characters in Supplementary Planes.\nString str1 = \"\\uD842\\uDFB7\" + \"A\";\nString str2 = StringEscapeUtils.escapeXml(str1);\n// The value of str2 must be equal to the one of str1,\n// because str1 does not contain characters to be escaped.\n// However, str2 is diffrent from str1.\nSystem.out.println(URLEncoder.encode(str1, \"UTF-16BE\")); //%D8%42%DF%B7A\nSystem.out.println(URLEncoder.encode(str2, \"UTF-16BE\")); //%D8%42%DF%B7%FF%FD\nThe cause of this problem is that the loop to translate input character by character is wrong.\nIn CharSequenceTranslator.translate(CharSequence input, Writer out),\nloop counter \"i\" moves from 0 to Character.codePointCount(input, 0, input.length()),\nbut it should move from 0 to input.length().\n"
            },
            "18": {
                "commit_sha_buggy": "aefe0749b2f2e63f9d13393694e7d20173bc032a",
                "commit_sha_fixed": "2aa9dca994b006ccbfcb528de5ff0da6a5578411",
                "report_id": "LANG-719",
                "report_url": "https://issues.apache.org/jira/browse/LANG-719",
                "issue_title": "[LANG-719] FastDateFormat formats year differently than SimpleDateFormat in Java 7 - ASF JIRA",
                "issue_description": "\nStarting with Java 7 does SimpleDateFormat format a year pattern of 'Y' or 'YYY' as '2003' instead of '03' as in former Java releases. According Javadoc this pattern should have been always been formatted as number, therefore the new behavior seems to be a bug fix in the JDK. FastDateFormat is adjusted to behave the same.\n"
            },
            "19": {
                "commit_sha_buggy": "85481c8f87075c88a97e793d9a6fcfd8d3c6946f",
                "commit_sha_fixed": "0b3a8a3128890f710700d04e38df48b883d11d91",
                "report_id": "LANG-710",
                "report_url": "https://issues.apache.org/jira/browse/LANG-710",
                "issue_title": "[LANG-710] StringIndexOutOfBoundsException when calling unescapeHtml4(\"&#03\") - ASF JIRA",
                "issue_description": "\nWhen calling unescapeHtml4() on the String \"&#03\" (or any String that contains these characters) an Exception is thrown:\nException in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 4\n\tat java.lang.String.charAt(String.java:686)\n\tat org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)\n\tat org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)\n\tat org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)\n"
            },
            "20": {
                "commit_sha_buggy": "0c01b4c48bc886a7e53b517efeb2192d1caaffe2",
                "commit_sha_fixed": "f08213cc4c35fd71e98aa5233fcb2db3333793a2",
                "report_id": "LANG-703",
                "report_url": "https://issues.apache.org/jira/browse/LANG-703",
                "issue_title": "[LANG-703] StringUtils.join throws NPE when toString returns null for one of objects in collection - ASF JIRA",
                "issue_description": "\nTry\n\n \nStringUtils.join(new Object[]{\n        new Object() {\n          @Override\n          public String toString() {\n            return null;\n          }\n        }\n    }, ',');\n\n\nToString should probably never return null, but it does in javax.mail.internet.InternetAddress\n"
            },
            "21": {
                "commit_sha_buggy": "a473984ef081ac1c55ce263345c5a54049275935",
                "commit_sha_fixed": "55f642725742513824975af0e5e91cb1920b6d72",
                "report_id": "LANG-677",
                "report_url": "https://issues.apache.org/jira/browse/LANG-677",
                "issue_title": "[LANG-677] DateUtils.isSameLocalTime does not work correct - ASF JIRA",
                "issue_description": "\nHi, I think I found a bug in the DateUtils class in the method isSameLocalTime.\nExample: \nCalendar a = Calendar.getInstance();\na.setTimeInMillis(1297364400000L);\nCalendar b = Calendar.getInstance();\nb.setTimeInMillis(1297321200000L);\nAssert.assertFalse(DateUtils.isSameLocalTime(a, b));\nThis is because the method compares \ncal1.get(Calendar.HOUR) == cal2.get(Calendar.HOUR) \nbut I think it has to be \ncal1.get(Calendar.HOUR_OF_DAY) == cal2.get(Calendar.HOUR_OF_DAY)\n"
            },
            "22": {
                "commit_sha_buggy": "1b708e343781255f50e17bf10b363cca303120af",
                "commit_sha_fixed": "0b2b82ad923b0455cde93286e3f504a1abd0863b",
                "report_id": "LANG-662",
                "report_url": "https://issues.apache.org/jira/browse/LANG-662",
                "issue_title": "[LANG-662] org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE, 2^k) - ASF JIRA",
                "issue_description": "\nThe greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k, and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method.\nFractionTest.java\n\t// additional test cases\n\tpublic void testReducedFactory_int_int() {\n\t\t// ...\n\t\tf = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);\n\t\tassertEquals(Integer.MIN_VALUE / 2, f.getNumerator());\n\t\tassertEquals(1, f.getDenominator());\n\n\tpublic void testReduce() {\n\t\t// ...\n\t\tf = Fraction.getFraction(Integer.MIN_VALUE, 2);\n\t\tresult = f.reduce();\n\t\tassertEquals(Integer.MIN_VALUE / 2, result.getNumerator());\n\t\tassertEquals(1, result.getDenominator());\n\n\n"
            },
            "23": {
                "commit_sha_buggy": "458597c6dcc23b01284930521f1cb80e986b442d",
                "commit_sha_fixed": "46356183872f2cba5e340993c6d85597a4f3cdbb",
                "report_id": "LANG-636",
                "report_url": "https://issues.apache.org/jira/browse/LANG-636",
                "issue_title": "[LANG-636] text.ExtendedMessageFormat doesn't override java.text.MessageFormat.equals(Object) - ASF JIRA",
                "issue_description": "\nFindbugs:\nBug: org.apache.commons.lang3.text.ExtendedMessageFormat doesn't override java.text.MessageFormat.equals(Object)\nPattern id: EQ_DOESNT_OVERRIDE_EQUALS, type: Eq, category: STYLE\nThis class extends a class that defines an equals method and adds fields, but doesn't define an equals method itself. Thus, equality on instances of this class will ignore the identity of the subclass and the added fields. Be sure this is what is intended, and that you don't need to override the equals method. Even if you don't need to override the equals method, consider overriding it anyway to document the fact that the equals method for the subclass just return the result of invoking super.equals(o). \n"
            },
            "24": {
                "commit_sha_buggy": "d61f50a3986b983ba0bfc6d2ec2abc26892c6ed2",
                "commit_sha_fixed": "81903abbb25ff92597d5f1e3acc648d12bdee444",
                "report_id": "LANG-664",
                "report_url": "https://issues.apache.org/jira/browse/LANG-664",
                "issue_title": "[LANG-664] NumberUtils.isNumber(String)  is not right when the String is \"1.1L\" - ASF JIRA",
                "issue_description": "\n\"1.1L\"  is not a Java Number . but NumberUtils.isNumber(String) return true.\nperhaps change:\n\n            if (chars[i] == 'l'\n                || chars[i] == 'L') {\n                // not allowing L with an exponent\n                return foundDigit && !hasExp;\n            }\n\n\nto:\n\n            if (chars[i] == 'l'\n                || chars[i] == 'L') {\n                // not allowing L with an exponent\n                return foundDigit && !hasExp && !hasDecPoint;\n            }\n\n\n"
            },
            "25": {
                "commit_sha_buggy": "eb94e61a64105bcdd6afd0f6377de7b4fa7fa105",
                "commit_sha_fixed": "2bae68787d15c3d3540380164e62759485078ec1",
                "report_id": "LANG-658",
                "report_url": "https://issues.apache.org/jira/browse/LANG-658",
                "issue_title": "[LANG-658] Some Entitys like &Ouml; are not matched properly against its ISO8859-1 representation - ASF JIRA",
                "issue_description": "\nIn EntityArrays \nIn\n private static final String[][] ISO8859_1_ESCAPE \nsome matching is wrong, for example\n\n \n        {\"\\u00D7\", \"&Ouml;\"}, // \u00d6 - uppercase O, umlaut\n        {\"\\u00D8\", \"&times;\"}, // multiplication sign\n\n\nbut this must be   \n\n \n       {\"\\u00D6\", \"&Ouml;\"}, // \u00d6 - uppercase O, umlaut\n        {\"\\u00D7\", \"&times;\"}, // multiplication sign\n\n\naccording to http://www.fileformat.info/info/unicode/block/latin_supplement/list.htm\nFirst look:\nu00CA is missing in the array and all following entries are matched wrong by an offset of 1.\nFound on http://stackoverflow.com/questions/4172784/bug-in-apache-commons-stringescapeutil/4172915#4172915\n"
            },
            "26": {
                "commit_sha_buggy": "e67792f82e7eaccb39007c0fa65f3217f24be10d",
                "commit_sha_fixed": "75d5b74a1a7ef68c5169f4b44cdf972c1ab07ee0",
                "report_id": "LANG-645",
                "report_url": "https://issues.apache.org/jira/browse/LANG-645",
                "issue_title": "[LANG-645] FastDateFormat.format() outputs incorrect week of year because locale isn't respected - ASF JIRA",
                "issue_description": "\nFastDateFormat apparently doesn't respect the locale it was sent on creation when outputting week in year (e.g. \"ww\") in format(). It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek, which (depending on the year) may result in the incorrect week number being output.\nHere is a simple test program to demonstrate the problem by comparing with SimpleDateFormat, which gets the week number right:\n\nimport java.util.Calendar;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.text.SimpleDateFormat;\n\nimport org.apache.commons.lang.time.FastDateFormat;\n\npublic class FastDateFormatWeekBugDemo {\n    public static void main(String[] args) {\n        Locale.setDefault(new Locale(\"en\", \"US\"));\n        Locale locale = new Locale(\"sv\", \"SE\");\n\n        Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome\n        cal.set(2010, 0, 1, 12, 0, 0);\n        Date d = cal.getTime();\n        System.out.println(\"Target date: \" + d);\n\n        FastDateFormat fdf = FastDateFormat.getInstance(\"EEEE', week 'ww\", locale);\n        SimpleDateFormat sdf = new SimpleDateFormat(\"EEEE', week 'ww\", locale);\n        System.out.println(\"FastDateFormat:   \" + fdf.format(d)); // will output \"FastDateFormat:   fredag, week 01\"\n        System.out.println(\"SimpleDateFormat: \" + sdf.format(d)); // will output \"SimpleDateFormat: fredag, week 53\"\n    }\n}\n\n\nIf sv/SE is passed to Locale.setDefault() instead of en/US, both FastDateFormat and SimpleDateFormat output the correct week number.\n"
            },
            "27": {
                "commit_sha_buggy": "7c915333685392f7cfc913b2085471709e6d6227",
                "commit_sha_fixed": "c2560c028173c3bc0a4627d4ce5ce221bcc9be66",
                "report_id": "LANG-638",
                "report_url": "https://issues.apache.org/jira/browse/LANG-638",
                "issue_title": "[LANG-638] NumberUtils createNumber throws a StringIndexOutOfBoundsException when argument containing \"e\" and \"E\" is passed in - ASF JIRA",
                "issue_description": "\nNumberUtils createNumber throws a StringIndexOutOfBoundsException instead of NumberFormatException when a String containing both possible exponent indicators is passed in.\nOne example of such a String is \"1eE\".\n"
            },
            "28": {
                "commit_sha_buggy": "8da5fb28a764eee26c76a5018c293f224017887b",
                "commit_sha_fixed": "3e1afecc200d7e3be9537c95b7cf52a7c5031300",
                "report_id": "LANG-617",
                "report_url": "https://issues.apache.org/jira/browse/LANG-617",
                "issue_title": "[LANG-617] StringEscapeUtils.escapeXML() can't process UTF-16 supplementary characters - ASF JIRA",
                "issue_description": "\nSupplementary characters in UTF-16 are those whose code points are above 0xffff, that is, require more than 1 Java char to be encoded, as explained here: http://java.sun.com/developer/technicalArticles/Intl/Supplementary/\nCurrently, StringEscapeUtils.escapeXML() isn't aware of this coding scheme and treats each char as one character, which is not always right.\nA possible solution in class Entities would be:\n    public void escape(Writer writer, String str) throws IOException {\n        int len = str.length();\n        for (int i = 0; i < len; i++) {\n            int code = str.codePointAt;\n            String entityName = this.entityName(code);\n            if (entityName != null) \n{\n                writer.write('&');\n                writer.write(entityName);\n                writer.write(';');\n            }\n else if (code > 0x7F) \n{\n                    writer.write(\"&#\");\n                    writer.write(code);\n                    writer.write(';');\n            }\n else \n{\n                    writer.write((char) code);\n            }\n\n            if (code > 0xffff) \n{\n                    i++;\n            }\n        }\n    }\nBesides fixing escapeXML(), this will also affect HTML escaping functions. I guess that's a good thing, but please remember I have only tested escapeXML().\n"
            },
            "29": {
                "commit_sha_buggy": "cbf8e4eb017a99af9a8f24eb8429e8a12b62af8b",
                "commit_sha_fixed": "982e295053663787bb0396b81a8956c3c87dc25b",
                "report_id": "LANG-624",
                "report_url": "https://issues.apache.org/jira/browse/LANG-624",
                "issue_title": "[LANG-624] SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VM - ASF JIRA",
                "issue_description": "\nCan be replicated in the Android emulator quite easily.\nStack trace:\n\n\nat org.apache.commons.lang.builder.ToStringBuilder.<clinit>(ToStringBuilder.java:98)\nE/AndroidRuntime( 1681): \t... 17 more\nE/AndroidRuntime( 1681): Caused by: java.lang.ExceptionInInitializerError\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.builder.ToStringStyle$MultiLineToStringStyle.<init>(ToStringStyle.java:2276)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.builder.ToStringStyle.<clinit>(ToStringStyle.java:94)\nE/AndroidRuntime( 1681): \t... 18 more\nE/AndroidRuntime( 1681): Caused by: java.lang.StringIndexOutOfBoundsException\nE/AndroidRuntime( 1681): \tat java.lang.String.substring(String.java:1571)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.SystemUtils.getJavaVersionAsFloat(SystemUtils.java:1153)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.SystemUtils.<clinit>(SystemUtils.java:818)\n\n\n"
            },
            "30": {
                "commit_sha_buggy": "24f6517c9d5c1293f0c1209b7b44b6eeaa6ebee2",
                "commit_sha_fixed": "19b6372018c6b800f8e2bf1b85e15ef4cbd500da",
                "report_id": "LANG-607",
                "report_url": "https://issues.apache.org/jira/browse/LANG-607",
                "issue_title": "[LANG-607] StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly. - ASF JIRA",
                "issue_description": "\nStringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters.\nFor example, define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as \"\\uD840\\uDC00\"\n\tprivate static final String CharU20000 = \"\\uD840\\uDC00\";\n\tprivate static final String CharU20001 = \"\\uD840\\uDC01\";\nYou can see Unicode supplementary characters correctly implemented in the JRE call:\n\tassertEquals(-1, CharU20000.indexOf(CharU20001));\nBut this is broken:\n\tassertEquals(false, StringUtils.containsAny(CharU20000, CharU20001));\n\tassertEquals(false, StringUtils.containsAny(CharU20001, CharU20000));\nThis is fine:\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20000));\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20001));\n\tassertEquals(true, StringUtils.contains(CharU20000, CharU20000));\n\tassertEquals(false, StringUtils.contains(CharU20000, CharU20001));\nbecause the method calls the JRE to perform the match.\nMore than you want to know:\n\nhttp://java.sun.com/developer/technicalArticles/Intl/Supplementary/\n\n"
            },
            "31": {
                "commit_sha_buggy": "0cc451d5e5cb565eb7311308466f487bc534ebaf",
                "commit_sha_fixed": "38bf7048571f3bc8dd34d14691906426444e4381",
                "report_id": "LANG-607",
                "report_url": "https://issues.apache.org/jira/browse/LANG-607",
                "issue_title": "[LANG-607] StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly. - ASF JIRA",
                "issue_description": "\nStringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters.\nFor example, define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as \"\\uD840\\uDC00\"\n\tprivate static final String CharU20000 = \"\\uD840\\uDC00\";\n\tprivate static final String CharU20001 = \"\\uD840\\uDC01\";\nYou can see Unicode supplementary characters correctly implemented in the JRE call:\n\tassertEquals(-1, CharU20000.indexOf(CharU20001));\nBut this is broken:\n\tassertEquals(false, StringUtils.containsAny(CharU20000, CharU20001));\n\tassertEquals(false, StringUtils.containsAny(CharU20001, CharU20000));\nThis is fine:\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20000));\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20001));\n\tassertEquals(true, StringUtils.contains(CharU20000, CharU20000));\n\tassertEquals(false, StringUtils.contains(CharU20000, CharU20001));\nbecause the method calls the JRE to perform the match.\nMore than you want to know:\n\nhttp://java.sun.com/developer/technicalArticles/Intl/Supplementary/\n\n"
            },
            "32": {
                "commit_sha_buggy": "1c606c3d96838e595a0664cbafdd60caae34aa0e",
                "commit_sha_fixed": "006fca88e86bd6f650d4d021d2ff3573a572827d",
                "report_id": "LANG-586",
                "report_url": "https://issues.apache.org/jira/browse/LANG-586",
                "issue_title": "[LANG-586] Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environments - ASF JIRA",
                "issue_description": "\nThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapp's use of LANG triggers the loading of this class, a reference chain will be created that will cause a memory leak on web application reload.\nSee http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.\n"
            },
            "33": {
                "commit_sha_buggy": "575be16474e8e8246d4bbde6f243fdf38c34ad5b",
                "commit_sha_fixed": "0603aef594fa60126c2d45f2ab164eee39f7b44c",
                "report_id": "LANG-587",
                "report_url": "https://issues.apache.org/jira/browse/LANG-587",
                "issue_title": "[LANG-587] ClassUtils.toClass(Object[]) throws NPE on null array element - ASF JIRA",
                "issue_description": "\nsee summary\n"
            },
            "35": {
                "commit_sha_buggy": "48bf241d4149919e0928e39616bee2e3783e2987",
                "commit_sha_fixed": "80bd78ea0685d28ddec9b8162d652db9dec949ce",
                "report_id": "LANG-571",
                "report_url": "https://issues.apache.org/jira/browse/LANG-571",
                "issue_title": "[LANG-571] ArrayUtils.add(T[] array, T element) can create unexpected ClassCastException - ASF JIRA",
                "issue_description": "\nArrayUtils.add(T[] array, T element) can create an unexpected ClassCastException.\nFor example, the following code compiles without a warning:\n\nString[] sa = ArrayUtils.add(stringArray, aString);\n\n\nand works fine, provided at least one of the parameters is non-null. However, if both parameters are null, the add() method returns an Object[] array, hence the Exception.\nIf both parameters are null, it's not possible to determine the correct array type to return, so it seems to me this should be disallowed.\nI think the method ought to be changed to throw IllegalParameterException when both parameters are null.\n"
            },
            "36": {
                "commit_sha_buggy": "ec0c4e5508dbd8af83253f7c50f8b728a1003388",
                "commit_sha_fixed": "da0612b348fcfa7679b92a5e9b8e1603e8e2da3a",
                "report_id": "LANG-521",
                "report_url": "https://issues.apache.org/jira/browse/LANG-521",
                "issue_title": "[LANG-521] NumberUtils.isNumber() Should Return True for Valid Number with a Trailing Decimal Place - ASF JIRA",
                "issue_description": "\nNumberUtils.isNumber() should return true for a valid number ending in a trailing decimal place; e.g., \"2.\" should be considered a number because new BigDecimal(\"2.\") works fine.  This could be done by adding the code below after line 1444, which is the if (chars[i] == 'e' || chars[i] == 'E') block.\nif (chars[i] == '.') {\n    if (hasDecPoint || hasExp) \n{\n        // two decimal points or dec in exponent   \n        return false;\n    }\n    return foundDigit; // single trailing decimal point after non-exponent is ok\n}\n"
            },
            "37": {
                "commit_sha_buggy": "b5906d3f325ca3a1147d5fa68912975e2e6c347e",
                "commit_sha_fixed": "ea140fb5c327e2b58f6c5bf1057c7dede909a50c",
                "report_id": "LANG-567",
                "report_url": "https://issues.apache.org/jira/browse/LANG-567",
                "issue_title": "[LANG-567] ArrayUtils.addAll(T[] array1, T... array2) does not handle mixed types very well - ASF JIRA",
                "issue_description": "\nArrayUtils.addAll(T[] array1, T... array2) does not handle mixed array types very well.\nThe stack trace for \nNumber[] st = ArrayUtils.addAll(new Integer[]\n{1}\n, new Long[]\n{2L}\n);\nstarts:\njava.lang.ArrayStoreException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang3.ArrayUtils.addAll(ArrayUtils.java:2962)\nwhich is not all that obvious.\nIt would be a lot clearer if the method threw an IlegalArgumentException or similar.\n"
            },
            "38": {
                "commit_sha_buggy": "e28c95ac2ce95852add84bdf3d2d9c00ac98f5de",
                "commit_sha_fixed": "a95e76eefb91bdd9cf1c22734874a3d3c95ed327",
                "report_id": "LANG-538",
                "report_url": "https://issues.apache.org/jira/browse/LANG-538",
                "issue_title": "[LANG-538] DateFormatUtils.format does not correctly change Calendar TimeZone in certain situations - ASF JIRA",
                "issue_description": "\nIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK, it would be nice if DateFormatUtils was smart enough to detect/resolve this problem.\nFor example, the following unit test fails:\n\n  public void testFormat_CalendarIsoMsZulu() {\n    final String dateTime = \"2009-10-16T16:42:16.000Z\";\n\n    // more commonly constructed with: cal = new GregorianCalendar(2009, 9, 16, 8, 42, 16)\n    // for the unit test to work in any time zone, constructing with GMT-8 rather than default locale time zone\n    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(\"GMT-8\"));\n    cal.clear();\n    cal.set(2009, 9, 16, 8, 42, 16);\n\n\n    FastDateFormat format = FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\", TimeZone.getTimeZone(\"GMT\"));\n    assertEquals(\"dateTime\", dateTime, format.format(cal));\n  }\n\n\nHowever, this unit test passes:\n\n  public void testFormat_CalendarIsoMsZulu() {\n    final String dateTime = \"2009-10-16T16:42:16.000Z\";\n    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(\"GMT-8\"));\n    cal.clear();\n    cal.set(2009, 9, 16, 8, 42, 16);\n    cal.getTime();\n\n    FastDateFormat format = FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\", TimeZone.getTimeZone(\"GMT\"));\n    assertEquals(\"dateTime\", dateTime, format.format(cal));\n  }\n\n\n"
            },
            "39": {
                "commit_sha_buggy": "0aa57f04ede369a4f813bbb86d3eac1ed20b084c",
                "commit_sha_fixed": "cb40e35f5e0990fad4c5278964fcc24e112dde8c",
                "report_id": "LANG-552",
                "report_url": "https://issues.apache.org/jira/browse/LANG-552",
                "issue_title": "[LANG-552] StringUtils replaceEach - Bug or Missing Documentation  - ASF JIRA",
                "issue_description": "\nThe following Test Case for replaceEach fails with a null pointer exception.\nI have expected that all StringUtils methods are \"null-friendly\"\nThe use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null.\nI admit the use case is not perfect, because it is unclear what happens on the replace.\nI outlined three expectations in the test case, of course only one should be met.\nIf it is decided that none of them should be possible, I propose to update the documentation with what happens when null is passed as replacement string\n\nimport static org.junit.Assert.assertEquals;\n\nimport org.apache.commons.lang.StringUtils;\nimport org.junit.Test;\n\n\npublic class StringUtilsTest {\n\n\t@Test\n\tpublic void replaceEach(){\n\t\tString original = \"Hello World!\";\n\t\tString[] searchList = {\"Hello\", \"World\"};\n\t\tString[] replacementList = {\"Greetings\", null};\n\t\tString result = StringUtils.replaceEach(original, searchList, replacementList);\n\t\tassertEquals(\"Greetings !\", result);\n\t\t//perhaps this is ok as well\n                //assertEquals(\"Greetings World!\", result);\n                //or even\n\t\t//assertEquals(\"Greetings null!\", result);\n\t}\n\n\t\n}\n\n\n"
            },
            "40": {
                "commit_sha_buggy": "c72adf1b7592f302b8abefdb3b2f95782cc75aa2",
                "commit_sha_fixed": "8b1a8e178abb46cc048a3982636b8ec4e6ffc8dc",
                "report_id": "LANG-432",
                "report_url": "https://issues.apache.org/jira/browse/LANG-432",
                "issue_title": "[LANG-432] Fix case-insensitive string handling - ASF JIRA",
                "issue_description": "\nString.to*Case() is locale-sensitive, this is usually not intended for case-insensitive comparisions. Please see Common Bug #3 for details.\n"
            },
            "41": {
                "commit_sha_buggy": "ac58807ede6d9a0625b489cdca6fd37bad9cacfe",
                "commit_sha_fixed": "4d3629f310e84cc24c0e5f09d97f5126692d0128",
                "report_id": "LANG-535",
                "report_url": "https://issues.apache.org/jira/browse/LANG-535",
                "issue_title": "[LANG-535] ClassUtils.getShortClassName() will not work with an array;  it seems to add a semicolon to the end. - ASF JIRA",
                "issue_description": "\nA semicolon is introduced into the class name at the end for all arrays...\nString sArray[] = new String[2];\nsArray[0] = \"mark\";\nsArray[1] = \"is cool\";\nString simpleString = \"chris\";\nassertEquals(\"String\", ClassUtils.getShortClassName(simpleString, null));\nassertEquals(\"String;\", ClassUtils.getShortClassName(sArray, null));\n"
            },
            "42": {
                "commit_sha_buggy": "68217617c54467c7c6098168e714a2fb6a48847d",
                "commit_sha_fixed": "dd2ae757d12554f290931f0b3c05e33ad993ecd1",
                "report_id": "LANG-480",
                "report_url": "https://issues.apache.org/jira/browse/LANG-480",
                "issue_title": "[LANG-480] StringEscapeUtils.escapeHtml incorrectly converts unicode characters above U+00FFFF into 2 characters - ASF JIRA",
                "issue_description": "\nCharacters that are represented as a 2 characters internaly by java are incorrectly converted by the function. The following test displays the problem quite nicely:\nimport org.apache.commons.lang.*;\npublic class J2 {\n    public static void main(String[] args) throws Exception {\n        // this is the utf8 representation of the character:\n        // COUNTING ROD UNIT DIGIT THREE\n        // in unicode\n        // codepoint: U+1D362\n        byte[] data = new byte[] \n{ (byte)0xF0, (byte)0x9D, (byte)0x8D, (byte)0xA2 }\n;\n        //output is: &#55348;&#57186;\n        // should be: &#119650;\n        System.out.println(\"'\" + StringEscapeUtils.escapeHtml(new String(data, \"UTF8\")) + \"'\");\n    }\n}\nShould be very quick to fix, feel free to drop me an email if you want a patch.\n"
            },
            "43": {
                "commit_sha_buggy": "ac2a39e92a71d5f9eb3ca7c6cc789b6341c582a4",
                "commit_sha_fixed": "eb3e2ae1f3734986a9f0225c661888baac3cb13b",
                "report_id": "LANG-477",
                "report_url": "https://issues.apache.org/jira/browse/LANG-477",
                "issue_title": "[LANG-477] ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotes - ASF JIRA",
                "issue_description": "\nWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes, an OutOfMemoryError will occur.\nExample that will cause error:\nExtendedMessageFormatTest.java\n\nprivate static Map<String, Object> formatRegistry = new HashMap<String, Object>();    \n    static {\n        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());\n    }\n    \n    public static void main(String[] args) {\n        ExtendedMessageFormat mf = new ExtendedMessageFormat(\"it''s a {dummy} 'test'!\", formatRegistry);\n        String formattedPattern = mf.format(new String[] {\"great\"});\n        System.out.println(formattedPattern);\n    }\n}\n\n\n\nThe following change starting at line 421 on the 2.4 release seems to fix the problem:\nExtendedMessageFormat.java\nCURRENT (Broken):\nif (escapingOn && c[start] == QUOTE) {\n        return appendTo == null ? null : appendTo.append(QUOTE);\n}\n\nWORKING:\nif (escapingOn && c[start] == QUOTE) {\n        next(pos);\n        return appendTo == null ? null : appendTo.append(QUOTE);\n}\n\n\n"
            },
            "44": {
                "commit_sha_buggy": "cf28c89dcf72d27573c478eb91e3b470de060edd",
                "commit_sha_fixed": "81f10d7f1ef52d44f43b38d81ac3dc1c83d45134",
                "report_id": "LANG-457",
                "report_url": "https://issues.apache.org/jira/browse/LANG-457",
                "issue_title": "[LANG-457] NumberUtils createNumber thows a StringIndexOutOfBoundsException when only an \"l\" is passed in. - ASF JIRA",
                "issue_description": "\nSeems to be similar to LANG-300, except that if you don't place a digit in front of the \"l\" or \"L\" it throws a StringIndexOutOfBoundsException instead.\n"
            },
            "45": {
                "commit_sha_buggy": "cfff06bead88e2c1bb164285f89503a919e0e27f",
                "commit_sha_fixed": "d95fcd8e24568b4f9d3cb9da922a4029e293c793",
                "report_id": "LANG-419",
                "report_url": "https://issues.apache.org/jira/browse/LANG-419",
                "issue_title": "[LANG-419] WordUtils.abbreviate bug when lower is greater than str.length - ASF JIRA",
                "issue_description": "\nIn WordUtils.abbreviate, upper is adjusted to the length of the string, then to lower.\nBut lower is never adjusted to the length of the string, so if lower is greater than str.lengt(), upper will be too...\nThen, str.substring(0, upper) throw a StringIndexOutOfBoundsException\nThe fix is to adjust lower to the length of the string\n"
            },
            "46": {
                "commit_sha_buggy": "229151ec41339450e4d4f857bf92ed080d3e2430",
                "commit_sha_fixed": "916639bda234a8e5a030361c4068667764b34cb7",
                "report_id": "LANG-421",
                "report_url": "https://issues.apache.org/jira/browse/LANG-421",
                "issue_title": "[LANG-421] StringEscapeUtils.escapeJava(String) escapes '/' characters - ASF JIRA",
                "issue_description": "\nCommons Lang 2.4 StringEscapeUtils.escapeJava(String) now escapes '/' characters, which is not a valid \"escapable\" character in Java strings.  I haven't tried the other Java escape/unescape methods to see if they have a similar problem, or that only Java \"escapable\" characters are escaped by escapeJava(String).\nThis bug may have appeared as an unintended side-effect of the fix for LANG-363.\nAlso the javadoc for escapeJava is now a little off, in that '/' should now be included in the sentence describing the differences between Java and Javascript strings, with respect to escaping rules.\nThe following is a JUnit3 test demonstrating the bug.\nimport junit.framework.TestCase;\nimport org.apache.commons.lang.StringEscapeUtils;\npublic class StringEscapeUtilsTest extends TestCase {\n    public void testEscapeJavaWithSlash() \n{\n        final String input = \"String with a slash (/) in it\";\n        \n        final String expected = input;\n        final String actual   = StringEscapeUtils.escapeJava( input );\n\n        /**\n         * In 2.4 StringEscapeUtils.escapeJava(String) escapes '/' characters,\n         * which are not a valid character to escape in a Java string.  \n         */\n        assertEquals( expected, actual );\n    }\n}\n"
            },
            "47": {
                "commit_sha_buggy": "19f33e4e0d824e732d07f06a08567c27b3c808f3",
                "commit_sha_fixed": "d5e343049c2610c31ddacb24f0d173942f6d5ac9",
                "report_id": "LANG-412",
                "report_url": "https://issues.apache.org/jira/browse/LANG-412",
                "issue_title": "[LANG-412] StrBuilder appendFixedWidth does not handle nulls - ASF JIRA",
                "issue_description": "\nAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.\n"
            },
            "48": {
                "commit_sha_buggy": "3cea4b2af3f9caf6aa72fa56d647c513d320e073",
                "commit_sha_fixed": "eb8f74efb75e71fc91e515a38becc2aac203e339",
                "report_id": "LANG-393",
                "report_url": "https://issues.apache.org/jira/browse/LANG-393",
                "issue_title": "[LANG-393] EqualsBuilder don't compare BigDecimals correctly  - ASF JIRA",
                "issue_description": "\nWhen comparing a BigDecimal, the comparing is made using equals, not compareTo, which is more appropriate in the case of BigDecimal.  \n"
            },
            "49": {
                "commit_sha_buggy": "3905071819a14403d1cdb9437d2e005adf18fc70",
                "commit_sha_fixed": "0ac772a4e3b07287c435fdc3c812f67277c85cc8",
                "report_id": "LANG-380",
                "report_url": "https://issues.apache.org/jira/browse/LANG-380",
                "issue_title": "[LANG-380] infinite loop in Fraction.reduce when numerator == 0 - ASF JIRA",
                "issue_description": "\nSummary pretty much says it all.\n"
            },
            "50": {
                "commit_sha_buggy": "b2f1757bf9ec1632a940b9a2e65a1a022ba54af8",
                "commit_sha_fixed": "659ef247b1452b6d5b9f92271357381fa59fea50",
                "report_id": "LANG-368",
                "report_url": "https://issues.apache.org/jira/browse/LANG-368",
                "issue_title": "[LANG-368] FastDateFormat getDateInstance() and getDateTimeInstance() assume Locale.getDefault() won't change - ASF JIRA",
                "issue_description": "\nThe FastDateFormat getDateInstance() and getDateTimeInstance()  methods create the HashMap key from various items including the locale.\nIf the locale is null, then it is not made part of the key, but the stored object is created using the current default locale.\nIf the Locale is changed subsequently, then the wrong locale is applied.\nPatch for test case to follow.\n"
            },
            "51": {
                "commit_sha_buggy": "3b46d611b2d595131ce0bce9bdb3209c55391be7",
                "commit_sha_fixed": "a5589b39e985e64861bd920aa7b13ab32c215b06",
                "report_id": "LANG-365",
                "report_url": "https://issues.apache.org/jira/browse/LANG-365",
                "issue_title": "[LANG-365] BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsException - ASF JIRA",
                "issue_description": "\nThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException, for example with the test:\nassertEquals(false, BooleanUtils.toBoolean(\"tru\"));\nThe end of case 3 should return false.\nPatch to follow for source and unit test.\n"
            },
            "52": {
                "commit_sha_buggy": "5209cefa81c9c48a34e5472fdcf2a308a4da2589",
                "commit_sha_fixed": "868f6976aea222e96259843f56df9aed8e48584b",
                "report_id": "LANG-363",
                "report_url": "https://issues.apache.org/jira/browse/LANG-363",
                "issue_title": "[LANG-363] StringEscapeUtils.escapeJavaScript() method did not escape '/' into '\\/', it will make IE render page uncorrectly - ASF JIRA",
                "issue_description": "\nIf Javascripts including'/', IE will parse the scripts uncorrectly, actually '/' should be escaped to '\\/'.\nFor example, document.getElementById(\"test\").value = '<script>alert(\\'aaa\\');</script>';this expression will make IE render page uncorrect, it should be document.getElementById(\"test\").value = '<script>alert(\\'aaa\\');<\\/script>';\nBtw, Spring's JavascriptEscape behavor is correct.\nTry  to run below codes, you will find the difference:\n  String s = \"<script>alert('aaa');</script>\";\n  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);\n  System.out.println(\"Spring JS Escape : \"+str);\n  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);\n  System.out.println(\"Apache Common Lang JS Escape : \"+ str);\n"
            },
            "53": {
                "commit_sha_buggy": "b6f7a8a8be57c9525c59e9f21e958e76cee0dbaf",
                "commit_sha_fixed": "d3b1163073c7aeb6011a5b65bfadad15bfc0f108",
                "report_id": "LANG-346",
                "report_url": "https://issues.apache.org/jira/browse/LANG-346",
                "issue_title": "[LANG-346] Dates.round() behaves incorrectly for minutes and seconds - ASF JIRA",
                "issue_description": "\nGet unexpected output for rounding by minutes or seconds.\npublic void testRound()\n{\n    Calendar testCalendar = Calendar.getInstance(TimeZone.getTimeZone(\"GMT\"));\n    testCalendar.set(2007, 6, 2, 8, 9, 50);\n    Date date = testCalendar.getTime();\n    System.out.println(\"Before round() \" + date);\n    System.out.println(\"After round()  \" + DateUtils.round(date, Calendar.MINUTE));\n}\n--2.1 produces\nBefore round() Mon Jul 02 03:09:50 CDT 2007\nAfter round()  Mon Jul 02 03:10:00 CDT 2007 \u2013 this is what I would expect\n--2.2 and 2.3 produces\nBefore round() Mon Jul 02 03:09:50 CDT 2007\nAfter round()  Mon Jul 02 03:01:00 CDT 2007 \u2013 this appears to be wrong\n"
            },
            "54": {
                "commit_sha_buggy": "5ccddb3ff7c65882ad6bbf95cbdac9debc76a871",
                "commit_sha_fixed": "e89e8d62b911340cc5b293465cdae909f3dfd640",
                "report_id": "LANG-328",
                "report_url": "https://issues.apache.org/jira/browse/LANG-328",
                "issue_title": "[LANG-328] LocaleUtils.toLocale() rejects strings with only language+variant - ASF JIRA",
                "issue_description": "\nLocaleUtils.toLocale() throws an exception on strings containing a language and a variant but no country code. For example : fr__POSIX\nThis string can be produced with the JDK by instanciating a Locale with an empty string for the country : new Locale(\"fr\", \"\", \"POSIX\").toString(). According to the javadoc for the Locale class a variant is allowed with just a language code or just a country code.\nCommons Configuration handles this case in its PropertyConverter.toLocale() method. I'd like to replace our implementation by the one provided by LocaleUtils, but our tests fail due to this case.\n"
            },
            "55": {
                "commit_sha_buggy": "d8c22b8e1c8592bc8c6f6169a5b090082969acd4",
                "commit_sha_fixed": "3ef8a796b5ddf87e3e9afec9ba94aac62681b394",
                "report_id": "LANG-315",
                "report_url": "https://issues.apache.org/jira/browse/LANG-315",
                "issue_title": "[LANG-315] StopWatch: suspend() acts as split(), if followed by stop() - ASF JIRA",
                "issue_description": "\nIn my opinion, it is a bug that suspend() acts as split(), if followed by stop(); see below:\n        StopWatch sw = new StopWatch();\n        sw.start();\n        Thread.sleep(1000);\n        sw.suspend();\n        // Time 1 (ok)\n        System.out.println(sw.getTime());\n        Thread.sleep(2000);\n        // Time 1 (again, ok)\n        System.out.println(sw.getTime());\n        sw.resume();\n        Thread.sleep(3000);\n        sw.suspend();\n        // Time 2 (ok)\n        System.out.println(sw.getTime());\n        Thread.sleep(4000);\n        // Time 2 (again, ok)\n        System.out.println(sw.getTime());\n        Thread.sleep(5000);\n        sw.stop();\n        // Time 2 (should be, but is Time 3 => NOT ok)\n        System.out.println(sw.getTime());\nsuspend/resume is like a pause, where time counter doesn't continue. So a following stop()-call shouldn't increase the time counter, should it?\n"
            },
            "56": {
                "commit_sha_buggy": "7d1b54b33b07a570060824a703222a77c35b1fa0",
                "commit_sha_fixed": "672e3a8ead2970181c32cf5fc70a3ea3d020c1fc",
                "report_id": "LANG-303",
                "report_url": "https://issues.apache.org/jira/browse/LANG-303",
                "issue_title": "[LANG-303] FastDateFormat.mRules is not transient or serializable - ASF JIRA",
                "issue_description": "\nReported by FindBugs.\nEither we need to make the Rule interface Serializable, or make mRules transient and add deserializing code to kick off init().\n"
            },
            "57": {
                "commit_sha_buggy": "c71373047dc2172b0f06cebf61da284323d6ff99",
                "commit_sha_fixed": "bbd990b81fd7f8ab9dde75c8070b973b9ce500fc",
                "report_id": "LANG-304",
                "report_url": "https://issues.apache.org/jira/browse/LANG-304",
                "issue_title": "[LANG-304] NullPointerException in isAvailableLocale(Locale) - ASF JIRA",
                "issue_description": "\nFindBugs pointed out:\n   UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet\ncAvailableSet is used directly once in the source - and if availableLocaleSet() hasn't been called it will cause a NullPointerException.\n"
            },
            "58": {
                "commit_sha_buggy": "8185a5f63e23be852d600a80daa5b848fa836a65",
                "commit_sha_fixed": "1fd45a4f68ea497dfbdf1a67b8b8805a4a9b1166",
                "report_id": "LANG-300",
                "report_url": "https://issues.apache.org/jira/browse/LANG-300",
                "issue_title": "[LANG-300] NumberUtils.createNumber throws NumberFormatException for one digit long - ASF JIRA",
                "issue_description": "\nNumberUtils.createNumber throws a NumberFormatException when parsing \"1l\", \"2l\" .. etc...\nIt works fine if you try to parse \"01l\" or \"02l\".  The condition isDigits(numeric.substring(1)), line 455 return false as numeric.substring(1) is an empty string for \"1l\"\n"
            },
            "59": {
                "commit_sha_buggy": "38f8bcc60b90295f0a697f32e760a0082571bc09",
                "commit_sha_fixed": "c04cd2337786ce7d54ed1fb757192fb8bc8c5e41",
                "report_id": "LANG-299",
                "report_url": "https://issues.apache.org/jira/browse/LANG-299",
                "issue_title": "[LANG-299] Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsException - ASF JIRA",
                "issue_description": "\nThere's a bug in method appendFixedWidthPadRight of class StrBuilder:\npublic StrBuilder appendFixedWidthPadRight(Object obj, int width, char padChar) {\n        if (width > 0) {\n            ensureCapacity(size + width);\n            String str = (obj == null ? getNullText() : obj.toString());\n            int strLen = str.length();\n            if (strLen >= width) \n{\n ==>            str.getChars(0, strLen, buffer, size);   <==== BUG: it should be str.getChars(0, width, buffer, size);\n            }\n else {\n                int padLen = width - strLen;\n                str.getChars(0, strLen, buffer, size);\n                for (int i = 0; i < padLen; i++) \n{\n                    buffer[size + strLen + i] = padChar;\n                }\n            }\n            size += width;\n        }\n        return this;\n    }\nThis is causing an ArrayIndexOutOfBoundsException, so this method is unusable when strLen > width.\nIt's counterpart method appendFixedWidthPadLeft seems to be ok.\n"
            },
            "60": {
                "commit_sha_buggy": "88c76d207f642831ca899e144159424aaa60cf8e",
                "commit_sha_fixed": "a8203b65261110c4a30ff69fe0da7a2390d82757",
                "report_id": "LANG-295",
                "report_url": "https://issues.apache.org/jira/browse/LANG-295",
                "issue_title": "[LANG-295] StrBuilder contains usages of thisBuf.length when they should use size - ASF JIRA",
                "issue_description": "\nWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless I'm mistaken they shouldn't.\n"
            },
            "61": {
                "commit_sha_buggy": "1313a65c11dea54f1baf492d4185fb2d673b6716",
                "commit_sha_fixed": "88c76d207f642831ca899e144159424aaa60cf8e",
                "report_id": "LANG-294",
                "report_url": "https://issues.apache.org/jira/browse/LANG-294",
                "issue_title": "[LANG-294] StrBuilder.replaceAll and StrBuilder.deleteAll can throw ArrayIndexOutOfBoundsException. - ASF JIRA",
                "issue_description": "\nStrBuilder.replaceAll and StrBuilder.deleteAll can thrown ArrayIndexOutOfBoundsException's. Here are a couple of additions to the StrBuilderTest class that demonstrate this problem:\nStrBuilder.deleteAll() - added to testDeleteAll_String():\n        sb = new StrBuilder(\"\\n%BLAH%\\nDo more stuff\\neven more stuff\\n%BLAH%\\n\");\n        sb.deleteAll(\"\\n%BLAH%\");\n        assertEquals(\"\\nDo more stuff\\neven more stuff\\n\", sb.toString());\nthis causes the following error:\njava.lang.ArrayIndexOutOfBoundsException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang.text.StrBuilder.deleteImpl(StrBuilder.java:1114)\n\tat org.apache.commons.lang.text.StrBuilder.deleteAll(StrBuilder.java:1188)\n\tat org.apache.commons.lang.text.StrBuilderTest.testDeleteAll_String(StrBuilderTest.java:606)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\nStrBuilder.replaceAll() - added to testReplaceAll_String_String():\n        sb = new StrBuilder(\"\\n%BLAH%\\nDo more stuff\\neven more stuff\\n%BLAH%\\n\");\n        sb.replaceAll(\"\\n%BLAH%\", \"\");\n        assertEquals(\"\\nDo more stuff\\neven more stuff\\n\", sb.toString());\nthis causes the exception:\njava.lang.ArrayIndexOutOfBoundsException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang.text.StrBuilder.replaceImpl(StrBuilder.java:1256)\n\tat org.apache.commons.lang.text.StrBuilder.replaceAll(StrBuilder.java:1339)\n\tat org.apache.commons.lang.text.StrBuilderTest.testReplaceAll_String_String(StrBuilderTest.java:763)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\n"
            },
            "62": {
                "commit_sha_buggy": "cb7bfbc06d5d289be61733824d7f3e81321b2b3a",
                "commit_sha_fixed": "1313a65c11dea54f1baf492d4185fb2d673b6716",
                "report_id": "LANG-292",
                "report_url": "https://issues.apache.org/jira/browse/LANG-292",
                "issue_title": "[LANG-292] unescapeXml(\"&12345678;\") should be \"&12345678;\" - ASF JIRA",
                "issue_description": "\nFollowing test (in EntitiesTest.java) fails:\n    public void testNumberOverflow() throws Exception \n{\n        doTestUnescapeEntity(\"&#12345678;\", \"&#12345678;\");\n        doTestUnescapeEntity(\"x&#12345678;y\", \"x&#12345678;y\");\n        doTestUnescapeEntity(\"&#x12345678;\", \"&#x12345678;\");\n        doTestUnescapeEntity(\"x&#x12345678;y\", \"x&#x12345678;y\");\n    }\n\nMaximim value for char is 0xFFFF, so &#12345678; is invalid entity reference, and so should be left as is.\n"
            },
            "63": {
                "commit_sha_buggy": "3333dcc11f2d65ee99043945502102dcf3bca50c",
                "commit_sha_fixed": "0695c3f71e3fc5abe29d8b9b33eed7faac7e73bf",
                "report_id": "LANG-281",
                "report_url": "https://issues.apache.org/jira/browse/LANG-281",
                "issue_title": "[LANG-281] DurationFormatUtils returns wrong result - ASF JIRA",
                "issue_description": "\nDurationFormatUtils returns wrong result.  oddly, it is only when Date is set to Dec 31, 2005\nThe following code will result in a String of -2 which is way off.\nI've tested against 2.1 and 2.2.\n        Calendar cal = Calendar.getInstance();\n        cal.set(Calendar.MONTH, Calendar.DECEMBER);\n        cal.set(Calendar.DAY_OF_MONTH, 31);\n        cal.set(Calendar.YEAR, 2005);\n        cal.set(Calendar.HOUR_OF_DAY, 0);\n        cal.set(Calendar.MINUTE, 0);\n        cal.set(Calendar.SECOND, 0);\n        cal.set(Calendar.MILLISECOND, 0);\n        String result = DurationFormatUtils.formatPeriod(cal.getTimeInMillis(), System.currentTimeMillis(), \"MM\");\n        System.out.println(result);\n"
            },
            "64": {
                "commit_sha_buggy": "df1653a8490feba4a21ad8aade5c960b402c3c7a",
                "commit_sha_fixed": "8de71ae52958ae70fe651b7327319c9beecd9b84",
                "report_id": "LANG-259",
                "report_url": "https://issues.apache.org/jira/browse/LANG-259",
                "issue_title": "[LANG-259] ValuedEnum.compareTo(Object other) not typesafe - it easily could be... - ASF JIRA",
                "issue_description": "\nint org.apache.commons.lang.enums.ValuedEnum.compareTo(Object other)\n is not typesafe - if the int-values are the same, it will return \"0\" even for two totally different sub-classes of ValuedEnum\n"
            },
            "65": {
                "commit_sha_buggy": "c8fc5f3dff9491b076a1f76ed5a2584908b1db4f",
                "commit_sha_fixed": "bb1671667d9085fb76bd06af7f7ad91d2c1c8389",
                "report_id": "LANG-59",
                "report_url": "https://issues.apache.org/jira/browse/LANG-59",
                "issue_title": "[LANG-59] [lang] DateUtils.truncate method is buggy when dealing with DST switching hours - ASF JIRA",
                "issue_description": "\nTry to truncate 2004-10-31 01:00:00 MDT by hour and you'll actually get 2004-10-\n31 01:00:00 MST, which is one hour after the input hour.\n    // truncate 2004-10-31 01:00:00 MDT\n    Date oct31_01MDT = new Date(1099206000000L);    \n    Date result = DateUtils.truncate(oct31_01MDT, Calendar.HOUR_OF_DAY);\n    assertEquals(oct31_01MDT, result);\n"
            },
            "69": {
                "commit_sha_buggy": "458cf9df78758efa231c0c242dc7a9a34e92fef7",
                "commit_sha_fixed": "d70baf13700b6cbe664249322559b64dc44303c2",
                "report_id": "LANG-710",
                "report_url": "https://issues.apache.org/jira/browse/LANG-710",
                "issue_title": "[LANG-710] StringIndexOutOfBoundsException when calling unescapeHtml4(\"&#03\") - ASF JIRA",
                "issue_description": "\nWhen calling unescapeHtml4() on the String \"&#03\" (or any String that contains these characters) an Exception is thrown:\nException in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 4\n\tat java.lang.String.charAt(String.java:686)\n\tat org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)\n\tat org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)\n\tat org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)\n"
            },
            "71": {
                "commit_sha_buggy": "a93703d002bc4850e7adcdfc9b51664fca7b8836",
                "commit_sha_fixed": "be370cd0ef134bb44fde733e4ee91661a012dae5",
                "report_id": "LANG-917",
                "report_url": "https://issues.apache.org/jira/browse/LANG-917",
                "issue_title": "[LANG-917] Exception when combining custom and choice format in ExtendedMessageFormat - ASF JIRA",
                "issue_description": "\nWhen using a custom format registered and a choice format with an inner format is used in the same message format, an IndexOutOfBoundsException occurs in the custructor of ExtendedMessageFormat:\n\nnew ExtendedMessageFormat(\"Hi {0,test,any}, got {1,choice,0#none|1#one|1<{1,number}}\", Collections.singletonMap(\"test\", new TestFormatFactory()));\n\n\njava.lang.IndexOutOfBoundsException: Index: 2, Size: 2\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:604)\n\tat java.util.ArrayList.get(ArrayList.java:382)\n\tat org.apache.commons.lang.text.ExtendedMessageFormat.insertFormats(ExtendedMessageFormat.java:364)\n\tat org.apache.commons.lang.text.ExtendedMessageFormat.applyPattern(ExtendedMessageFormat.java:192)\n\tat org.apache.commons.lang.text.ExtendedMessageFormat.<init>(ExtendedMessageFormat.java:127)\n\n\nThe problem occurs at the start of {1,number}.\nAs a workaround i registered the TestFormatFactory also for \"choice\" and then returning new ChoiceFormat(arguments), but that is not the idea.\nI also checked the change logs, but there seems no change on this problem. I have not tester, but I think the bug still is present in the current release.\n"
            },
            "73": {
                "commit_sha_buggy": "38f8b88528487efc4e53ac6c91f08fbaaa2a82d6",
                "commit_sha_fixed": "6ea7f2f7afcd6d60d62a5cd1392feda3471fc666",
                "report_id": "LANG-928",
                "report_url": "https://issues.apache.org/jira/browse/LANG-928",
                "issue_title": "[LANG-928] Issue with OctalUnescaper - ASF JIRA",
                "issue_description": "\nSee this GitHub pull request:\nhttps://github.com/apache/commons-lang/pull/5\n"
            },
            "76": {
                "commit_sha_buggy": "3a8595f1a57759044be301fc76a2300b7f2efe66",
                "commit_sha_fixed": "8cd2339a9788cf2c6e44b6761d3a19259fbe1df3",
                "report_id": "LANG-936",
                "report_url": "https://issues.apache.org/jira/browse/LANG-936",
                "issue_title": "[LANG-936] StringUtils.getLevenshteinDistance with too big of a threshold returns wrong result - ASF JIRA",
                "issue_description": "\nStringUtils.getLevenshteinDistance(CharSequence s, CharSequence t, int threshold) specifies:\n\nFind the Levenshtein distance between two Strings if it's less than or equal to a given threshold.\nWhen passing a threshold > Integer.MAX_VALUE - max(s.length(), t.length()) the method always returns -1.\nThe simplest use case is passing Integer.MAX_VALUE (a common practice if one would want to find the min/max LD of a string to several other strings in an iterative fashion.\nThe code should be fixed to consider the threshold in relation to the source/target lengths, or alternatively the javadoc should be fixed to pronounce the current limit.\n"
            },
            "80": {
                "commit_sha_buggy": "8d360ae70732ae26d961f76da5a98c44ac5931c6",
                "commit_sha_fixed": "aadd8e172eb22fb593fbaa454075677656fad111",
                "report_id": "LANG-981",
                "report_url": "https://issues.apache.org/jira/browse/LANG-981",
                "issue_title": "[LANG-981] DurationFormatUtils#lexx does not detect unmatched quote char - ASF JIRA",
                "issue_description": "\nThe method DurationFormatUtils#lexx does not detect if the format string contains an unmatched single-quote character.\nFor example \"yMd'test\" should really be rejected, as the literal string \"test\" is not properly terminated.\n"
            },
            "81": {
                "commit_sha_buggy": "66a37174a0398d76ff95904c22e77bc65890eec0",
                "commit_sha_fixed": "80bd3fdb42a5d816ded9d9111c7dac3ce57c3101",
                "report_id": "LANG-987",
                "report_url": "https://issues.apache.org/jira/browse/LANG-987",
                "issue_title": "[LANG-987] DateUtils.getFragmentInDays(Date, Calendar.MONTH) returns wrong days - ASF JIRA",
                "issue_description": "\nCommons lang3 screwed up my system after upgraded to 3.3 last night!\nWe use DateUtils.getFragmentInDays(Date, Calendar.MONTH) to extract days for later use. Basically (in 3.2), 'today' (Mar. 13) returns 13, but, it returns 12 in 3.3!\nI compared the underlying method org.apache.commons.lang3.time.DateUtils.getFragment(Calendar, int, int) between 3.2 and 3.3:\n3.2\n\n        // Fragments bigger than a day require a breakdown to days\n        switch (fragment) {\n            case Calendar.YEAR:\n                result += (calendar.get(Calendar.DAY_OF_YEAR) * MILLIS_PER_DAY) / millisPerUnit;\n                break;\n            case Calendar.MONTH:\n                result += (calendar.get(Calendar.DAY_OF_MONTH) * MILLIS_PER_DAY) / millisPerUnit;\n                break;\n        }\n\n\n3.3\n\n        // Fragments bigger than a day require a breakdown to days\n        switch (fragment) {\n            case Calendar.YEAR:\n                result += ((calendar.get(Calendar.DAY_OF_YEAR) -1) * MILLIS_PER_DAY) / millisPerUnit;\n                break;\n            case Calendar.MONTH:\n                result += ((calendar.get(Calendar.DAY_OF_MONTH) -1) * MILLIS_PER_DAY) / millisPerUnit;\n                break;\n            default:\n                break;\n        }\n\n\nIs there ANY ANY reason for adding '-1' in 3.3?! Plus, do you have any unit test for this method?\n"
            },
            "82": {
                "commit_sha_buggy": "d99f581745097c9562f1d701a6da66cd81a550f2",
                "commit_sha_fixed": "fbb0f7f88c84001e0a92dae6a71b7e43bda65a56",
                "report_id": "LANG-995",
                "report_url": "https://issues.apache.org/jira/browse/LANG-995",
                "issue_title": "[LANG-995] Fix bug with stripping spaces on last line in WordUtils.wrap()  - ASF JIRA",
                "issue_description": "\nVia github: https://github.com/apache/commons-lang/pull/18\n"
            },
            "83": {
                "commit_sha_buggy": "358f139d1316df2b8efd7610afa3aa68d165334f",
                "commit_sha_fixed": "64ef8a80224443c81dfb198cbc567e1b2b9356a2",
                "report_id": "LANG-1003",
                "report_url": "https://issues.apache.org/jira/browse/LANG-1003",
                "issue_title": "[LANG-1003] DurationFormatUtils are not able to handle negative durations/periods - ASF JIRA",
                "issue_description": "\nIt spits out complete garbage.\n\nSystem.out.println(DurationFormatUtils.formatDurationHMS(-3454));\nSystem.out.println(DurationFormatUtils.formatPeriodISO(4000, 3000));\n\n\n\n0:00:-3.-454\nP-1Y11M30DT23H59M59.000S\n\n\nIt should throw an IllegalArgumentException if duration is < 0 or period diff is < 0.\n"
            },
            "84": {
                "commit_sha_buggy": "00dc479f6a1d204d557f4cb1d981ba236fe09565",
                "commit_sha_fixed": "fd54d42f78ae17a96fc005d2fcd080807343aad7",
                "report_id": "LANG-1004",
                "report_url": "https://issues.apache.org/jira/browse/LANG-1004",
                "issue_title": "[LANG-1004] DurationFormatUtils#formatDurationHMS implementation does not correspond to Javadoc and vice versa - ASF JIRA",
                "issue_description": "\nThis method has several flaws:\n1. Javadoc says: \"The format used is ISO8601-like: H:m:s.S.\" but the method call supplies \"H:mm:ss.SSS\"\n2. ISO time never omits leading zeros, so the proper pattern must be \"HH:mm:ss.SSS\"\n3. The method name says: \"HMS\" but includes the second fraction.\nSince the use of fractions is optional, the method should use \"HH:mm:ss\" and update the Javadoc as well.\n"
            }
        }
    },
    "Math_4j": {
        "owner_repo": "haidaros/defects4j-math",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1780da711d88f669e29e0517f83d692fb80099db",
                "commit_sha_fixed": "0da657a65c92b086a301a6ffe9e34ec272f8889c",
                "report_id": "MATH-996",
                "report_url": "https://issues.apache.org/jira/browse/MATH-996",
                "issue_title": "[MATH-996] Fraction specified with maxDenominator and a value very close to a simple fraction should not throw an overflow exception - ASF JIRA",
                "issue_description": "\nAn overflow exception is thrown when a Fraction is initialized with a maxDenominator from a double that is very close to a simple\nfraction.  For example:\ndouble d = 0.5000000001;\nFraction f = new Fraction(d, 10);\nPatch with unit test on way.\n"
            },
            "2": {
                "commit_sha_buggy": "ad5c90bbabdbce834068bc79d3eb00c823e97008",
                "commit_sha_fixed": "c0b655ace5665c0cd32e3f5e5b46edad4d223125",
                "report_id": "MATH-1021",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1021",
                "issue_title": "[MATH-1021] HypergeometricDistribution.sample suffers from integer overflow - ASF JIRA",
                "issue_description": "\nHi, I have an application which broke when ported from commons math 2.2 to 3.2. It looks like the HypergeometricDistribution.sample() method doesn't work as well as it used to with large integer values \u2013 the example code below should return a sample between 0 and 50, but usually returns -50.\n\nimport org.apache.commons.math3.distribution.HypergeometricDistribution;\n\npublic class Foo {\n  public static void main(String[] args) {\n    HypergeometricDistribution a = new HypergeometricDistribution(\n        43130568, 42976365, 50);\n    System.out.printf(\"%d %d%n\", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints \"0 50\"\n    System.out.printf(\"%d%n\",a.sample());                                             // Prints \"-50\"\n  }\n}\n\n\nIn the debugger, I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() \u2013 instead of doing\n\nreturn (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();\n\n\nit could do:\n\nreturn getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());\n\n\nThis seemed to fix it, based on a quick test.\n"
            },
            "3": {
                "commit_sha_buggy": "de4209544270def43e39db0d214d1564939f8e40",
                "commit_sha_fixed": "92c4697300e8ddf06152bc0838c738d50673c1d2",
                "report_id": "MATH-1005",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1005",
                "issue_title": "[MATH-1005] ArrayIndexOutOfBoundsException in MathArrays.linearCombination - ASF JIRA",
                "issue_description": "\nWhen MathArrays.linearCombination is passed arguments with length 1, it throws an ArrayOutOfBoundsException. This is caused by this line:\ndouble prodHighNext = prodHigh[1];\nlinearCombination should check the length of the arguments and fall back to simple multiplication if length == 1.\n"
            },
            "4": {
                "commit_sha_buggy": "d609e65f7bfb38c66e2a8670242e72108b3d0e98",
                "commit_sha_fixed": "277e61721f34be16a20da663fd597edf6b51939b",
                "report_id": "MATH-988",
                "report_url": "https://issues.apache.org/jira/browse/MATH-988",
                "issue_title": "[MATH-988] NPE when calling SubLine.intersection() with non-intersecting lines - ASF JIRA",
                "issue_description": "\nWhen calling SubLine.intersection() with two lines that not intersect, then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations.\nThe attached patch fixes both implementations and adds the required test cases.\n"
            },
            "5": {
                "commit_sha_buggy": "f5bcba812fb8bc59ff5e4bc055811039b610aa2b",
                "commit_sha_fixed": "e54a1c92302f3167b06bc04859b87ac0681bcdf3",
                "report_id": "MATH-934",
                "report_url": "https://issues.apache.org/jira/browse/MATH-934",
                "issue_title": "[MATH-934] Complex.ZERO.reciprocal() returns NaN but should return INF. - ASF JIRA",
                "issue_description": "\nComplex.ZERO.reciprocal() returns NaN but should return INF.\nClass: org.apache.commons.math3.complex.Complex;\nMethod: reciprocal()\n@version $Id: Complex.java 1416643 2012-12-03 19:37:14Z tn $\n"
            },
            "6": {
                "commit_sha_buggy": "6c9d06a658d87c01fb02d1efce15bf6b74eb7aab",
                "commit_sha_fixed": "419a052c6842192e78f747d9f5af619c2ca56e78",
                "report_id": "MATH-949",
                "report_url": "https://issues.apache.org/jira/browse/MATH-949",
                "issue_title": "[MATH-949] LevenbergMarquardtOptimizer reports 0 iterations - ASF JIRA",
                "issue_description": "\nThe method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0. A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()\nI've put a test case below. Notice how the evaluations count is correctly incremented, but the iterations count is not.\n\n    @Test\n    public void testGetIterations() {\n        // setup\n        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();\n\n        // action\n        otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),\n                new Weight(new double[] { 1 }), new InitialGuess(\n                        new double[] { 3 }), new ModelFunction(\n                        new MultivariateVectorFunction() {\n                            @Override\n                            public double[] value(double[] point)\n                                    throws IllegalArgumentException {\n                                return new double[] { FastMath.pow(point[0], 4) };\n                            }\n                        }), new ModelFunctionJacobian(\n                        new MultivariateMatrixFunction() {\n                            @Override\n                            public double[][] value(double[] point)\n                                    throws IllegalArgumentException {\n                                return new double[][] { { 0.25 * FastMath.pow(\n                                        point[0], 3) } };\n                            }\n                        }));\n\n        // verify\n        assertThat(otim.getEvaluations(), greaterThan(1));\n        assertThat(otim.getIterations(), greaterThan(1));\n    }\n\n\n\n"
            },
            "7": {
                "commit_sha_buggy": "96cd02e82c219349086092cdc2c5a450efc8be13",
                "commit_sha_fixed": "1cd68eed57febf806c385bf04a596b922f4c1964",
                "report_id": "MATH-950",
                "report_url": "https://issues.apache.org/jira/browse/MATH-950",
                "issue_title": "[MATH-950] event state not updated if an unrelated event triggers a RESET_STATE during ODE integration - ASF JIRA",
                "issue_description": "\nWhen an ODE solver manages several different event types, there are some unwanted side effects.\nIf one event handler asks for a RESET_STATE (for integration state) when its eventOccurred method is called, the other event handlers that did not trigger an event in the same step are not updated correctly, due to an early return.\nAs a result, when the next step is processed with a reset integration state, the forgotten event still refer to the start date of the previous state. This implies that when these event handlers will be checked for In some cases, the function defining an event g(double t, double[] y) is called with state parameters y that are completely wrong. In one case when the y array should have contained values between -1 and +1, one function call got values up to 1.0e20.\nThe attached file reproduces the problem.\n"
            },
            "8": {
                "commit_sha_buggy": "55046479fe33e47a002ab4f4949bd944ba70d37d",
                "commit_sha_fixed": "196e63174afdb3df1529c1b97bb8437b16831cc3",
                "report_id": "MATH-942",
                "report_url": "https://issues.apache.org/jira/browse/MATH-942",
                "issue_title": "[MATH-942] DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class type - ASF JIRA",
                "issue_description": "\nCreating an array with Array.newInstance(singletons.get(0).getClass(), sampleSize) in DiscreteDistribution.sample(int) is risky. An exception will be thrown if:\n\nsingleons.get(0) is of type T1, an sub-class of T, and\nDiscreteDistribution.sample() returns an object which is of type T, but not of type T1.\n\nTo reproduce:\n\nList<Pair<Object,Double>> list = new ArrayList<Pair<Object, Double>>();\nlist.add(new Pair<Object, Double>(new Object() {}, new Double(0)));\nlist.add(new Pair<Object, Double>(new Object() {}, new Double(1)));\nnew DiscreteDistribution<Object>(list).sample(1);\n\n\nAttaching a patch.\n"
            },
            "9": {
                "commit_sha_buggy": "c929aee12a2b777152371fc061e4b79f088fa039",
                "commit_sha_fixed": "de98c0f0a566060ac143c39036f06a03f141dc52",
                "report_id": "MATH-938",
                "report_url": "https://issues.apache.org/jira/browse/MATH-938",
                "issue_title": "[MATH-938] Line.revert() is imprecise - ASF JIRA",
                "issue_description": "\nLine.revert() only maintains ~10 digits for the direction. This becomes an issue when the line's position is evaluated far from the origin. A simple fix would be to use Vector3D.negate() for the direction.\nAlso, is there a reason why Line is not immutable? It is just comprised of two vectors.\n"
            },
            "10": {
                "commit_sha_buggy": "d2a916e325a1c47f12137ea902aaac100ed1f5db",
                "commit_sha_fixed": "7e2ffcc9034de41d7787f0b33b5670474f7a10de",
                "report_id": "MATH-935",
                "report_url": "https://issues.apache.org/jira/browse/MATH-935",
                "issue_title": "[MATH-935] DerivativeStructure.atan2(y,x) does not handle special cases properly - ASF JIRA",
                "issue_description": "\nThe four special cases +/-0 for both x and y should give the same values as Math.atan2 and FastMath.atan2. However, they give NaN for the value in all cases.\n"
            },
            "11": {
                "commit_sha_buggy": "02f64e7355618ef222c2320bd6731cce8c244fc5",
                "commit_sha_fixed": "aa2bd1d0656b0001192aa2b2ef779cfd1f3b7e4d",
                "report_id": "MATH-929",
                "report_url": "https://issues.apache.org/jira/browse/MATH-929",
                "issue_title": "[MATH-929] MultivariateNormalDistribution.density(double[]) returns wrong value when the dimension is odd - ASF JIRA",
                "issue_description": "\nTo reproduce:\n\nAssert.assertEquals(0.398942280401433, new MultivariateNormalDistribution(new double[]{0}, new double[][]{{1}}).density(new double[]{0}), 1e-15);\n\n\n"
            },
            "12": {
                "commit_sha_buggy": "67fc870987c8da66ae719764a6ce2e1a9d3bfc76",
                "commit_sha_fixed": "cc82d38aaf6ec24758a0a6df9535b8204e22ef12",
                "report_id": "MATH-927",
                "report_url": "https://issues.apache.org/jira/browse/MATH-927",
                "issue_title": "[MATH-927] GammaDistribution cloning broken - ASF JIRA",
                "issue_description": "\nSerializing a GammaDistribution and deserializing it, does not result in a cloned distribution that produces the same samples.\nCause: GammaDistribution inherits from AbstractRealDistribution, which implements Serializable. AbstractRealDistribution has random, in which we have a Well19937c instance, which inherits from AbstractWell. AbstractWell implements Serializable. AbstractWell inherits from BitsStreamGenerator, which is not Serializable, but does have a private field 'nextGaussian'.\nSolution: Make BitStreamGenerator implement Serializable as well.\nThis probably affects other distributions as well.\n"
            },
            "13": {
                "commit_sha_buggy": "a6b2e992e17cee0d4cb5a2da8242a20b8e5a8fc3",
                "commit_sha_fixed": "8079ea5b8d1366445da532906e43afa9291473cf",
                "report_id": "MATH-924",
                "report_url": "https://issues.apache.org/jira/browse/MATH-924",
                "issue_title": "[MATH-924] new multivariate vector optimizers cannot be used with large number of weights - ASF JIRA",
                "issue_description": "\nWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers, an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.\nThis happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points, which created a matrix with 1.7 billion elements.\n"
            },
            "14": {
                "commit_sha_buggy": "0f37f87216b67d12b722d706f3e313b731ee31ab",
                "commit_sha_fixed": "a6b2e992e17cee0d4cb5a2da8242a20b8e5a8fc3",
                "report_id": "MATH-924",
                "report_url": "https://issues.apache.org/jira/browse/MATH-924",
                "issue_title": "[MATH-924] new multivariate vector optimizers cannot be used with large number of weights - ASF JIRA",
                "issue_description": "\nWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers, an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.\nThis happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points, which created a matrix with 1.7 billion elements.\n"
            },
            "15": {
                "commit_sha_buggy": "efcf91bce70116ab1f628dee5c9ed1c2f18d2db9",
                "commit_sha_fixed": "b221a7342856a2a548f5d9817055defc0ec4dea6",
                "report_id": "MATH-904",
                "report_url": "https://issues.apache.org/jira/browse/MATH-904",
                "issue_title": "[MATH-904] FastMath.pow deviates from Math.pow for negative, finite base values with an exponent 2^52 < y < 2^53  - ASF JIRA",
                "issue_description": "\nAs reported by Jeff Hain:\npow(double,double):\nMath.pow(-1.0,5.000000000000001E15) = -1.0\nFastMath.pow(-1.0,5.000000000000001E15) = 1.0\n===> This is due to considering that power is an even\ninteger if it is >= 2^52, while you need to test\nthat it is >= 2^53 for it.\n===> replace\n\"if (y >= TWO_POWER_52 || y <= -TWO_POWER_52)\"\nwith\n\"if (y >= 2*TWO_POWER_52 || y <= -2*TWO_POWER_52)\"\nand that solves it.\n"
            },
            "16": {
                "commit_sha_buggy": "87324e56a31c110a1653955cdd715e9e88a54ed7",
                "commit_sha_fixed": "875ed1f4d90d1457c0ab40dafc79be5a0c6f9bf6",
                "report_id": "MATH-905",
                "report_url": "https://issues.apache.org/jira/browse/MATH-905",
                "issue_title": "[MATH-905] FastMath.[cosh, sinh] do not support the same range of values as the Math counterparts - ASF JIRA",
                "issue_description": "\nAs reported by Jeff Hain:\ncosh(double) and sinh(double):\nMath.cosh(709.783) = 8.991046692770538E307\nFastMath.cosh(709.783) = Infinity\nMath.sinh(709.783) = 8.991046692770538E307\nFastMath.sinh(709.783) = Infinity\n===> This is due to using exp( x )/2 for values of |x|\nabove 20: the result sometimes should not overflow,\nbut exp( x ) does, so we end up with some infinity.\n===> for values of |x| >= StrictMath.log(Double.MAX_VALUE),\nexp will overflow, so you need to use that instead:\nfor x positive:\ndouble t = exp(x*0.5);\nreturn (0.5*t)*t;\nfor x negative:\ndouble t = exp(-x*0.5);\nreturn (-0.5*t)*t;\n"
            },
            "17": {
                "commit_sha_buggy": "07611165b6176b6e3e6d5ac6ca052a102f10e3c4",
                "commit_sha_fixed": "621806b796bc416f00341feca894ebae07be5ed0",
                "report_id": "MATH-778",
                "report_url": "https://issues.apache.org/jira/browse/MATH-778",
                "issue_title": "[MATH-778] Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n) - ASF JIRA",
                "issue_description": "\nIn class org.apache.commons.math3.Dfp,  the method multiply(int n) is limited to 0 <= n <= 9999. This is not consistent with the general contract of FieldElement.multiply(int n), where there should be no limitation on the values of n.\n"
            },
            "18": {
                "commit_sha_buggy": "6e62aefca7aefe26a2ebc43fcdcd6cd58953f7de",
                "commit_sha_fixed": "7c7d7e8f103582e753c39a2baf14a483e991fefb",
                "report_id": "MATH-867",
                "report_url": "https://issues.apache.org/jira/browse/MATH-867",
                "issue_title": "[MATH-867] CMAESOptimizer with bounds fits finely near lower bound and coarsely near upper bound.  - ASF JIRA",
                "issue_description": "\nWhen fitting with bounds, the CMAESOptimizer fits finely near the lower bound and coarsely near the upper bound.  This is because it internally maps the fitted parameter range into the interval [0,1].  The unit of least precision (ulp) between floating point numbers is much smaller near zero than near one.  Thus, fits have much better resolution near the lower bound (which is mapped to zero) than the upper bound (which is mapped to one).  I will attach a example program to demonstrate.\n"
            },
            "19": {
                "commit_sha_buggy": "efa9de05114492ca38cf4739a07339f5ad6faddc",
                "commit_sha_fixed": "c73fad0a0d42103b5e13a68317ea95b1090263ba",
                "report_id": "MATH-865",
                "report_url": "https://issues.apache.org/jira/browse/MATH-865",
                "issue_title": "[MATH-865] Wide bounds to CMAESOptimizer result in NaN parameters passed to fitness function - ASF JIRA",
                "issue_description": "\nIf you give large values as lower/upper bounds (for example -Double.MAX_VALUE as a lower bound), the optimizer can call the fitness function with parameters set to NaN.  My guess is this is due to FitnessFunction.encode/decode generating NaN when normalizing/denormalizing parameters.  For example, if the difference between the lower and upper bound is greater than Double.MAX_VALUE, encode could divide infinity by infinity.\n"
            },
            "20": {
                "commit_sha_buggy": "5a50073d07ca309d78cfc4e071f4bbe051bdbd40",
                "commit_sha_fixed": "efa9de05114492ca38cf4739a07339f5ad6faddc",
                "report_id": "MATH-864",
                "report_url": "https://issues.apache.org/jira/browse/MATH-864",
                "issue_title": "[MATH-864] CMAESOptimizer does not enforce bounds - ASF JIRA",
                "issue_description": "\nThe CMAESOptimizer can exceed the bounds passed to optimize.  Looking at the generationLoop in doOptimize(), it does a bounds check by calling isFeasible() but if checkFeasableCount is zero (the default) then isFeasible() is never even called.  Also, even with non-zero checkFeasableCount it may give up before finding an in-bounds offspring and go forward with an out-of-bounds offspring.  This is against svn revision 1387637.  I can provide an example program where the optimizer ends up with a fit outside the prescribed bounds if that would help.\n"
            },
            "21": {
                "commit_sha_buggy": "dbb408e860279d92b7502474328bb5385c2d9243",
                "commit_sha_fixed": "468ed8550b7759858a4dc59d694859a8ae7d35f0",
                "report_id": "MATH-789",
                "report_url": "https://issues.apache.org/jira/browse/MATH-789",
                "issue_title": "[MATH-789] Correlated random vector generator fails (silently) when faced with zero rows in covariance matrix - ASF JIRA",
                "issue_description": "\nThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R, based on 10,000 samples):\nArray2DRowRealMatrix\n{\n{0.0,0.0,0.0,0.0,0.0}\n,\n{0.0,0.013445532,0.01039469,0.009881156,0.010499559}\n,\n{0.0,0.01039469,0.023006616,0.008196856,0.010732709}\n,\n{0.0,0.009881156,0.008196856,0.019023866,0.009210099}\n,\n{0.0,0.010499559,0.010732709,0.009210099,0.019107243}}\n> cov(data1)\n   V1 V2 V3 V4 V5\nV1 0 0.000000000 0.00000000 0.000000000 0.000000000\nV2 0 0.013383931 0.01034401 0.009913271 0.010506733\nV3 0 0.010344006 0.02309479 0.008374730 0.010759306\nV4 0 0.009913271 0.00837473 0.019005488 0.009187287\nV5 0 0.010506733 0.01075931 0.009187287 0.019021483\nArray2DRowRealMatrix\n{\n{0.013445532,0.01039469,0.0,0.009881156,0.010499559}\n,\n{0.01039469,0.023006616,0.0,0.008196856,0.010732709}\n,\n{0.0,0.0,0.0,0.0,0.0},\n{0.009881156,0.008196856,0.0,0.019023866,0.009210099},\n{0.010499559,0.010732709,0.0,0.009210099,0.019107243}}\n\n> cov(data2)\n            V1 V2 V3 V4 V5\nV1 0.006922905 0.010507692 0 0.005817399 0.010330529\nV2 0.010507692 0.023428918 0 0.008273152 0.010735568\nV3 0.000000000 0.000000000 0 0.000000000 0.000000000\nV4 0.005817399 0.008273152 0 0.004929843 0.009048759\nV5 0.010330529 0.010735568 0 0.009048759 0.018683544 \n\nArray2DRowRealMatrix{\n{0.013445532,0.01039469,0.009881156,0.010499559},\n{0.01039469,0.023006616,0.008196856,0.010732709},\n{0.009881156,0.008196856,0.019023866,0.009210099},\n{0.010499559,0.010732709,0.009210099,0.019107243}}\n\n> cov(data3)\n            V1          V2          V3          V4\nV1 0.013445047 0.010478862 0.009955904 0.010529542\nV2 0.010478862 0.022910522 0.008610113 0.011046353\nV3 0.009955904 0.008610113 0.019250975 0.009464442\nV4 0.010529542 0.011046353 0.009464442 0.019260317\n\n\nI've traced this back to the RectangularCholeskyDecomposition, which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):\n\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0,0.0,0.0,0.0,0.0}\n,\n{0.0759577418122063,0.0876125188474239,0.0,0.0,0.0}\n,\n{0.07764443622513505,0.05132821221460752,0.11976381821791235,0.0,0.0}\n,\n{0.06662930527909404,0.05501661744114585,0.0016662506519307997,0.10749324207653632,0.0}\n,{0.13822895138139477,0.0,0.0,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 5\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0759577418122063,0.034512751379448724,0.0},\n{0.07764443622513505,0.13029949164628746,0.0}\n,\n{0.0,0.0,0.0}\n,\n{0.06662930527909404,0.023203936694855674,0.0}\n,{0.13822895138139477,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 3\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0759577418122063,0.034512751379448724,0.033913748226348225,0.07303890149947785},\n{0.07764443622513505,0.13029949164628746,0.0,0.0}\n,\n{0.06662930527909404,0.023203936694855674,0.11851573313229945,0.0}\n,{0.13822895138139477,0.0,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 4\nClearly, the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results, but the second one does. Unfortunately, I don't know enough about the Cholesky decomposition to find the flaw in the implementation, and I could not find documentation for the \"rectangular\" variant (also not at the links provided in the javadoc).\n"
            },
            "22": {
                "commit_sha_buggy": "51461f1c9ce91953ed3e6dbd01b0e2c8bbd75da2",
                "commit_sha_fixed": "b0cba9a79ee99b09958dec8e40c75bed47b7f780",
                "report_id": "MATH-859",
                "report_url": "https://issues.apache.org/jira/browse/MATH-859",
                "issue_title": "[MATH-859] Fix and then deprecate isSupportXxxInclusive in RealDistribution interface - ASF JIRA",
                "issue_description": "\nThe conclusion from [1] was never implemented. We should deprecate these\nproperties from the RealDistribution interface, but since removal\nwill have to wait until 4.0, we should agree on a precise\ndefinition and fix the code to match it in the mean time.\nThe definition that I propose is that isSupportXxxInclusive means\nthat when the density function is applied to the upper or lower\nbound of support returned by getSupportXxxBound, a finite (i.e. not\ninfinite), not NaN value is returned.\n[1] http://markmail.org/message/dxuxh7eybl7xejde\n"
            },
            "23": {
                "commit_sha_buggy": "2b4c1f87a73448323d21cd459f967013a41870ca",
                "commit_sha_fixed": "f1b04e990f4fc86544b6230fab1aa8ecfb74fbb1",
                "report_id": "MATH-855",
                "report_url": "https://issues.apache.org/jira/browse/MATH-855",
                "issue_title": "[MATH-855] \"BrentOptimizer\" not always reporting the best point - ASF JIRA",
                "issue_description": "\nBrentOptimizer (package \"o.a.c.m.optimization.univariate\") does not check that the point it is going to return is indeed the best one it has encountered. Indeed, the last evaluated point might be slightly worse than the one before last.\n"
            },
            "24": {
                "commit_sha_buggy": "4e21bb6f6c4bc7380dc58bd8d23c99ea8f4ef5bd",
                "commit_sha_fixed": "d5ff460ba69e4261f066d7856e2f90b886924513",
                "report_id": "MATH-855",
                "report_url": "https://issues.apache.org/jira/browse/MATH-855",
                "issue_title": "[MATH-855] \"BrentOptimizer\" not always reporting the best point - ASF JIRA",
                "issue_description": "\nBrentOptimizer (package \"o.a.c.m.optimization.univariate\") does not check that the point it is going to return is indeed the best one it has encountered. Indeed, the last evaluated point might be slightly worse than the one before last.\n"
            },
            "25": {
                "commit_sha_buggy": "33201599dd578318ce0b87b1cd15c29a7d046097",
                "commit_sha_fixed": "996dd998e3081e4a842017b8ebcdae9b6059b530",
                "report_id": "MATH-844",
                "report_url": "https://issues.apache.org/jira/browse/MATH-844",
                "issue_title": "[MATH-844] \"HarmonicFitter.ParameterGuesser\" sometimes fails to return sensible values - ASF JIRA",
                "issue_description": "\nThe inner class \"ParameterGuesser\" in \"HarmonicFitter\" (package \"o.a.c.m.optimization.fitting\") fails to compute a usable guess for the \"amplitude\" parameter.\n"
            },
            "26": {
                "commit_sha_buggy": "5f2077bb774d283e7984a2d5dc0c2759f2954963",
                "commit_sha_fixed": "1566dd339f6efc2347b0962fac7fce22adbc31ff",
                "report_id": "MATH-836",
                "report_url": "https://issues.apache.org/jira/browse/MATH-836",
                "issue_title": "[MATH-836] Fraction(double, int) constructor strange behaviour - ASF JIRA",
                "issue_description": "\nThe Fraction constructor Fraction(double, int) takes a double value and a int maximal denominator, and approximates a fraction. When the double value is a large, negative number with many digits in the fractional part, and the maximal denominator is a big, positive integer (in the 100'000s), two distinct bugs can manifest:\n1: the constructor returns a positive Fraction. Calling Fraction(-33655.1677817278, 371880) returns the fraction 410517235/243036, which both has the wrong sign, and is far away from the absolute value of the given value\n2: the constructor does not manage to reduce the Fraction properly. Calling Fraction(-43979.60679604749, 366081) returns the fraction -1651878166/256677, which should have* been reduced to -24654898/3831.\nI have, as of yet, not found a solution. The constructor looks like this:\npublic Fraction(double value, int maxDenominator)\n        throws FractionConversionException\n    {\n       this(value, 0, maxDenominator, 100);\n    }\n\nIncreasing the 100 value (max iterations) does not fix the problem for all cases. Changing the 0-value (the epsilon, maximum allowed error) to something small does not work either, as this breaks the tests in FractionTest. \nThe problem is not neccissarily that the algorithm is unable to approximate a fraction correctly. A solution where a FractionConversionException had been thrown in each of these examples would probably be the best solution if an improvement on the approximation algorithm turns out to be hard to find.\nThis bug has been found when trying to explore the idea of axiom-based testing (http://bldl.ii.uib.no/testing.html). Attached is a java test class FractionTestByAxiom (junit, goes into org.apache.commons.math3.fraction) which shows these bugs through a simplified approach to this kind of testing, and a text file describing some of the value/maxDenominator combinations which causes one of these failures.\n\nIt is never specified in the documentation that the Fraction class guarantees that completely reduced rational numbers are constructed, but a comment inside the equals method claims that \"since fractions are always in lowest terms, numerators and can be compared directly for equality\", so it seems like this is the intention.\n\n"
            },
            "27": {
                "commit_sha_buggy": "d3fc5af31eb696af03cfbe2e18584c7e1d307d54",
                "commit_sha_fixed": "5f2077bb774d283e7984a2d5dc0c2759f2954963",
                "report_id": "MATH-835",
                "report_url": "https://issues.apache.org/jira/browse/MATH-835",
                "issue_title": "[MATH-835] Fraction percentageValue rare overflow - ASF JIRA",
                "issue_description": "\nThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100, then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100, even when the value of the fraction is far below this value.\nThe patch changes the method to first convert to a double value, and then multiply this value by 100 - the result should be the same, but with less overflows. An addition to the test for the method that covers this bug is also included.\n"
            },
            "28": {
                "commit_sha_buggy": "a55c951a3d573464e3905de7328fcdc487eebfb4",
                "commit_sha_fixed": "d3fc5af31eb696af03cfbe2e18584c7e1d307d54",
                "report_id": "MATH-828",
                "report_url": "https://issues.apache.org/jira/browse/MATH-828",
                "issue_title": "[MATH-828] Not expected UnboundedSolutionException - ASF JIRA",
                "issue_description": "\nSimplexSolver throws UnboundedSolutionException when trying to solve minimization linear programming problem. The number of exception thrown depends on the number of variables.\nIn order to see that behavior of SimplexSolver first try to run JUnit test setting a final variable ENTITIES_COUNT = 2 and that will give almost good result and then set it to 15 and you'll get a massive of unbounded exceptions.\nFirst iteration is runned with predefined set of input data with which the Solver gives back an appropriate result.\nThe problem itself is well tested by it's authors (mathematicians who I believe know what they developed) using Matlab 10 with no unbounded solutions on the same rules of creatnig random variables values.\nWhat is strange to me is the dependence of the number of UnboundedSolutionException exceptions on the number of variables in the problem.\nThe problem is formulated as\nmin(1*t + 0*L) (for every r-th subject)\ns.t.\n-q(r) + QL >= 0\nx(r)t - XL >= 0\nL >= 0\nwhere \nr = 1..R, \nL = \n{l(1), l(2), ..., l(R)}\n (vector of R rows and 1 column),\nQ - coefficients matrix MxR\nX - coefficients matrix NxR \n"
            },
            "29": {
                "commit_sha_buggy": "350b2b1aa1ed5d7df05a77bf13f701ac1712dbc0",
                "commit_sha_fixed": "7bbddc2203bed78fafe7739a97df1f53e767341a",
                "report_id": "MATH-803",
                "report_url": "https://issues.apache.org/jira/browse/MATH-803",
                "issue_title": "[MATH-803] Bugs in RealVector.ebeMultiply(RealVector) and ebeDivide(RealVector) - ASF JIRA",
                "issue_description": "\nOpenMapRealVector.ebeMultiply(RealVector) and OpenMapRealVector.ebeDivide(RealVector) return wrong values when one entry of the specified RealVector is nan or infinity. The bug is easy to understand. Here is the current implementation of ebeMultiply\n\n    public OpenMapRealVector ebeMultiply(RealVector v) {\n        checkVectorDimensions(v.getDimension());\n        OpenMapRealVector res = new OpenMapRealVector(this);\n        Iterator iter = entries.iterator();\n        while (iter.hasNext()) {\n            iter.advance();\n            res.setEntry(iter.key(), iter.value() * v.getEntry(iter.key()));\n        }\n        return res;\n    }\n\n\nThe assumption is that for any double x, x * 0d == 0d holds, which is not true. The bug is easy enough to identify, but more complex to solve. The only solution I can come up with is to loop through all entries of v (instead of those entries which correspond to non-zero entries of this). I'm afraid about performance losses.\n"
            },
            "30": {
                "commit_sha_buggy": "631c5bcbb2d8d46eed1091031310ed24fcd866ed",
                "commit_sha_fixed": "a25e7f7abe7f6b3f4147febee4a917ce92241aab",
                "report_id": "MATH-790",
                "report_url": "https://issues.apache.org/jira/browse/MATH-790",
                "issue_title": "[MATH-790] Mann-Whitney U Test Suffers From Integer Overflow With Large Data Sets - ASF JIRA",
                "issue_description": "\nWhen performing a Mann-Whitney U Test on large data sets (the attached test uses two 1500 element sets), intermediate integer values used in calculateAsymptoticPValue can overflow, leading to invalid results, such as p-values of NaN, or incorrect calculations.\nAttached is a patch, including a test, and a fix, which modifies the affected code to use doubles\n"
            },
            "31": {
                "commit_sha_buggy": "6a5ef0149e123d9de19910d59e45d0e66bfd665c",
                "commit_sha_fixed": "2d846db3aec18dd081e680be05f6e0faad1cb186",
                "report_id": "MATH-718",
                "report_url": "https://issues.apache.org/jira/browse/MATH-718",
                "issue_title": "[MATH-718] inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials. - ASF JIRA",
                "issue_description": "\nThe inverseCumulativeProbability method of the BinomialDistributionImpl class returns wrong value for large trials.  Following code will be reproduce the problem.\nSystem.out.println(new BinomialDistributionImpl(1000000, 0.5).inverseCumulativeProbability(0.5));\nThis returns 499525, though it should be 499999.\nI'm not sure how it should be fixed, but the cause is that the cumulativeProbability method returns Infinity, not NaN.  As the result the checkedCumulativeProbability method doesn't work as expected.\n"
            },
            "32": {
                "commit_sha_buggy": "8d6478346e45d728656ccac760adc8126b3d225c",
                "commit_sha_fixed": "f81847d8079753ce45b049813730055188a22efb",
                "report_id": "MATH-780",
                "report_url": "https://issues.apache.org/jira/browse/MATH-780",
                "issue_title": "[MATH-780] BSPTree class and recovery of a Euclidean 3D BRep - ASF JIRA",
                "issue_description": "\nNew to the work here. Thanks for your efforts on this code.\nI create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(x,y,z) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem.\nAny ideas?\n"
            },
            "33": {
                "commit_sha_buggy": "e5c7e4055ab2a40cb107a7ebd33766867325d5cc",
                "commit_sha_fixed": "3ef79313597d7d49067c48d65a09042d8d94822d",
                "report_id": "MATH-781",
                "report_url": "https://issues.apache.org/jira/browse/MATH-781",
                "issue_title": "[MATH-781] SimplexSolver gives bad results - ASF JIRA",
                "issue_description": "\nMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0\nin a simple test problem. It works well in commons-math-2.2. \n"
            },
            "34": {
                "commit_sha_buggy": "b91b3efb3854c0fd0f270bdba6cdfa8058c0515a",
                "commit_sha_fixed": "520f36b43a13681db338a07ac6c251cbe1a7a6e5",
                "report_id": "MATH-779",
                "report_url": "https://issues.apache.org/jira/browse/MATH-779",
                "issue_title": "[MATH-779] ListPopulation Iterator allows you to remove chromosomes from the population. - ASF JIRA",
                "issue_description": "\nCalling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.\n"
            },
            "35": {
                "commit_sha_buggy": "88f944e1aada536e9a70b041387bb328d61490cd",
                "commit_sha_fixed": "a5d8d115cb85149c62059a23e8f4d318cac0e903",
                "report_id": "MATH-776",
                "report_url": "https://issues.apache.org/jira/browse/MATH-776",
                "issue_title": "[MATH-776] Need range checks for elitismRate in ElitisticListPopulation constructors. - ASF JIRA",
                "issue_description": "\nThere is a range check for setting the elitismRate via ElitisticListPopulation's setElitismRate method, but not via the constructors.\n"
            },
            "36": {
                "commit_sha_buggy": "966d2eeef17b0b9bc7c07822be8da337bffedf97",
                "commit_sha_fixed": "1a15d5f4c13eca0435b0ed7e6a624064e7f7e07f",
                "report_id": "MATH-744",
                "report_url": "https://issues.apache.org/jira/browse/MATH-744",
                "issue_title": "[MATH-744] BigFraction.doubleValue() returns Double.NaN for large numerators or denominators - ASF JIRA",
                "issue_description": "\nThe current implementation of doubleValue() divides numerator.doubleValue() / denominator.doubleValue().  BigInteger.doubleValue() fails for any number greater than Double.MAX_VALUE.  So if the user has 308-digit numerator or denominator, the resulting quotient fails, even in cases where the result would be well inside Double's range.\nI have a patch to fix it, if I can figure out how to attach it here I will.\n"
            },
            "37": {
                "commit_sha_buggy": "de147e5cc14f8dac6da785289421a55b11d21aa6",
                "commit_sha_fixed": "65ed08e15af15617e967d3ea9d635dc55a0ef866",
                "report_id": "MATH-722",
                "report_url": "https://issues.apache.org/jira/browse/MATH-722",
                "issue_title": "[MATH-722] [math] Complex Tanh for \"big\" numbers - ASF JIRA",
                "issue_description": "\nHi,\nIn Complex.java the tanh is computed with the following formula:\ntanh(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + [sin(2b)/(cosh(2a)+cos(2b))]i\nThe problem that I'm finding is that as soon as \"a\" is a \"big\" number,\nboth sinh(2a) and cosh(2a) are infinity and then the method tanh returns in\nthe real part NaN (infinity/infinity) when it should return 1.0.\nWouldn't it be appropiate to add something as in the FastMath library??:\nif (real>20.0){\n      return createComplex(1.0, 0.0);\n}\nif (real<-20.0){\n      return createComplex(-1.0, 0.0);\n}\nBest regards,\nJBB\n"
            },
            "38": {
                "commit_sha_buggy": "74e00296574dc3ac0bc064fc3258faabaf732d6c",
                "commit_sha_fixed": "91cc42ba0493938aa53585720b315b62c5784a96",
                "report_id": "MATH-728",
                "report_url": "https://issues.apache.org/jira/browse/MATH-728",
                "issue_title": "[MATH-728] Errors in BOBYQAOptimizer when numberOfInterpolationPoints is greater than 2*dim+1 - ASF JIRA",
                "issue_description": "\nI've been having trouble getting BOBYQA to minimize a function (actually a non-linear least squares fit) so as one change I increased the number of interpolation points.  It seems that anything larger than 2*dim+1 causes an error (typically at\nline 1662\n                   interpolationPoints.setEntry(nfm, ipt, interpolationPoints.getEntry(ipt, ipt));\nI'm guessing there is an off by one error in the translation from FORTRAN.  Changing the BOBYQAOptimizerTest as follows (increasing number of interpolation points by one) will cause failures.\nBruce\nIndex: src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\n===================================================================\n\u2014 src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\t(revision 1221065)\n+++ src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\t(working copy)\n@@ -258,7 +258,7 @@\n //        RealPointValuePair result = optim.optimize(100000, func, goal, startPoint);\n         final double[] lB = boundaries == null ? null : boundaries[0];\n         final double[] uB = boundaries == null ? null : boundaries[1];\n\nBOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 1);\n+        BOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 2);\n         RealPointValuePair result = optim.optimize(maxEvaluations, func, goal, startPoint, lB, uB);\n //        System.out.println(func.getClass().getName() + \" = \" \n //              + optim.getEvaluations() + \" f(\");\n\n"
            },
            "39": {
                "commit_sha_buggy": "c23859f0172edba1ff75577d0ad98e3fb41aa6d4",
                "commit_sha_fixed": "74e00296574dc3ac0bc064fc3258faabaf732d6c",
                "report_id": "MATH-727",
                "report_url": "https://issues.apache.org/jira/browse/MATH-727",
                "issue_title": "[MATH-727] too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(5,3) ...) - ASF JIRA",
                "issue_description": "\nAdaptive step size integrators compute the first step size by themselves if it is not provided.\nFor embedded Runge-Kutta type, this step size is not checked against the integration range, so if the integration range is extremely short, this step size may evaluate the function out of the range (and in fact it tries afterward to go back, and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem, the step size is checked and truncated if needed.\n"
            },
            "40": {
                "commit_sha_buggy": "efa7825880d8c1c7411e51c5e21df6a004b78a3b",
                "commit_sha_fixed": "c8becc7c47963bcdc1578298846ad6fbf08f64ef",
                "report_id": "MATH-716",
                "report_url": "https://issues.apache.org/jira/browse/MATH-716",
                "issue_title": "[MATH-716] BracketingNthOrderBrentSolver exceeds maxIterationCount while updating always the same boundary - ASF JIRA",
                "issue_description": "\nIn some cases, the aging feature in BracketingNthOrderBrentSolver fails.\nIt attempts to balance the bracketing points by targeting a non-zero value instead of the real root. However, the chosen target is too close too zero, and the inverse polynomial approximation is always on the same side, thus always updates the same bracket.\nIn the real used case for a large program, I had a bracket point xA = 12500.0, yA = 3.7e-16, agingA = 0, which is the (really good) estimate of the zero on one side of the root and xB = 12500.03, yB = -7.0e-5, agingB = 97. This shows that the bracketing interval is completely unbalanced, and we never succeed to rebalance it as we always updates (xA, yA) and never updates (xB, yB).\n"
            },
            "41": {
                "commit_sha_buggy": "91e6ac584320681913de4a71a4e8d9f837e099b4",
                "commit_sha_fixed": "882556eabbeb2f62939aee29afdec2a01ce4bbe1",
                "report_id": "MATH-704",
                "report_url": "https://issues.apache.org/jira/browse/MATH-704",
                "issue_title": "[MATH-704] One of Variance.evaluate() methods does not work correctly - ASF JIRA",
                "issue_description": "\nThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double[] values, double[] weights, double mean, int begin, int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset.\nSimilar method in Mean class seems to work.\nI did not check other methods taking the part of the array; they may have the same problem.\nWorkaround: I had to shrink my arrays and use the method without the length.\n"
            },
            "42": {
                "commit_sha_buggy": "800943ecf2e3ecf9258d8fdf8052e9273b816a97",
                "commit_sha_fixed": "e98a5000cd211539bf4ba65f62cc7f81395e1726",
                "report_id": "MATH-713",
                "report_url": "https://issues.apache.org/jira/browse/MATH-713",
                "issue_title": "[MATH-713] Negative value with restrictNonNegative - ASF JIRA",
                "issue_description": "\nProblem: commons-math-2.2 SimplexSolver.\nA variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call:\nSimplexSolver.optimize(function, constraints, GoalType.MINIMIZE, true);\nFunction\n1 * x + 1 * y + 0\nConstraints:\n1 * x + 0 * y = 1\nResult:\nx = 1; y = -1;\nProbably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.\n"
            },
            "43": {
                "commit_sha_buggy": "c282a044d713d78cbf7ff86694c2c224fb47e14f",
                "commit_sha_fixed": "dcae84b2e8f025e93340307d8bc04d406202c323",
                "report_id": "MATH-691",
                "report_url": "https://issues.apache.org/jira/browse/MATH-691",
                "issue_title": "[MATH-691] Statistics.setVarianceImpl makes getStandardDeviation produce NaN - ASF JIRA",
                "issue_description": "\nInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:\n\nint[] scores = {1, 2, 3, 4};\nSummaryStatistics stats = new SummaryStatistics();\nstats.setVarianceImpl(new Variance(false)); //use \"population variance\"\nfor(int i : scores) {\n  stats.addValue(i);\n}\ndouble sd = stats.getStandardDeviation();\nSystem.out.println(sd);\n\n\nA workaround suggested by Mikkel is:\n\n  double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());\n\n\n"
            },
            "44": {
                "commit_sha_buggy": "4d994702cb50c8ad80f4f977292063a118cff724",
                "commit_sha_fixed": "53c8cec5ceb4cd81e3f9b8858814accac83a324e",
                "report_id": "MATH-695",
                "report_url": "https://issues.apache.org/jira/browse/MATH-695",
                "issue_title": "[MATH-695] Incomplete reinitialization with some events handling - ASF JIRA",
                "issue_description": "\nI get a bug with event handling: I track 2 events that occur in the same step, when the first one is accepted, it resets the state but the reinitialization is not complete and the second one becomes unable to find its way.\nI can't give my context, which is rather large, but I tried a patch that works for me, unfortunately it breaks the unit tests.\n"
            },
            "45": {
                "commit_sha_buggy": "4a702dbf7e2264c0b9757178f3afbde38e07fe41",
                "commit_sha_fixed": "bc4e9db01c2a03062965fa4bac65782376ab2287",
                "report_id": "MATH-679",
                "report_url": "https://issues.apache.org/jira/browse/MATH-679",
                "issue_title": "[MATH-679] Integer overflow in OpenMapRealMatrix - ASF JIRA",
                "issue_description": "\ncomputeKey() has an integer overflow. Since it is a sparse matrix, this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem, which could potentially be a security vulnerability (for example, if one was to use this matrix to store access control information).\nWorkaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.\n"
            },
            "46": {
                "commit_sha_buggy": "330f3fe17d132bd4e2a91ff812ccf489e77f390f",
                "commit_sha_fixed": "e6f27ebcb9ee0a344308382b99a3894bb61b225d",
                "report_id": "MATH-657",
                "report_url": "https://issues.apache.org/jira/browse/MATH-657",
                "issue_title": "[MATH-657] Division by zero - ASF JIRA",
                "issue_description": "\nIn class Complex, division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO, otherwise the result should be INF. See here.\n"
            },
            "47": {
                "commit_sha_buggy": "bbb5e1e198f995eddb393f820ed059aa774871c3",
                "commit_sha_fixed": "330f3fe17d132bd4e2a91ff812ccf489e77f390f",
                "report_id": "MATH-657",
                "report_url": "https://issues.apache.org/jira/browse/MATH-657",
                "issue_title": "[MATH-657] Division by zero - ASF JIRA",
                "issue_description": "\nIn class Complex, division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO, otherwise the result should be INF. See here.\n"
            },
            "48": {
                "commit_sha_buggy": "2af72281fcb919dac92b0c4e464f847adda23be1",
                "commit_sha_fixed": "13d22f45624470ce5c07c085cf8b1ec0251eaee6",
                "report_id": "MATH-631",
                "report_url": "https://issues.apache.org/jira/browse/MATH-631",
                "issue_title": "[MATH-631] \"RegulaFalsiSolver\" failure - ASF JIRA",
                "issue_description": "\nThe following unit test:\n\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n\n\nfails with\n\nillegal state: maximal count (100) exceeded: evaluations\n\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n"
            },
            "49": {
                "commit_sha_buggy": "0b78d9accafadffe00697c2c56706043cdba5e64",
                "commit_sha_fixed": "09e35881f1ad74335707e70aa78fd347e37d1066",
                "report_id": "MATH-645",
                "report_url": "https://issues.apache.org/jira/browse/MATH-645",
                "issue_title": "[MATH-645] MathRuntimeException with simple ebeMultiply on OpenMapRealVector - ASF JIRA",
                "issue_description": "\nThe following piece of code\n\nimport org.apache.commons.math.linear.OpenMapRealVector;\nimport org.apache.commons.math.linear.RealVector;\n\npublic class DemoBugOpenMapRealVector {\n    public static void main(String[] args) {\n        final RealVector u = new OpenMapRealVector(3, 1E-6);\n        u.setEntry(0, 1.);\n        u.setEntry(1, 0.);\n        u.setEntry(2, 2.);\n        final RealVector v = new OpenMapRealVector(3, 1E-6);\n        v.setEntry(0, 0.);\n        v.setEntry(1, 3.);\n        v.setEntry(2, 0.);\n        System.out.println(u);\n        System.out.println(v);\n        System.out.println(u.ebeMultiply(v));\n    }\n}\n\n\nraises an exception\n\norg.apache.commons.math.linear.OpenMapRealVector@7170a9b6\nException in thread \"main\" org.apache.commons.math.MathRuntimeException$6: map has been modified while iterating\n\tat org.apache.commons.math.MathRuntimeException.createConcurrentModificationException(MathRuntimeException.java:373)\n\tat org.apache.commons.math.util.OpenIntToDoubleHashMap$Iterator.advance(OpenIntToDoubleHashMap.java:564)\n\tat org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:372)\n\tat org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:1)\n\tat DemoBugOpenMapRealVector.main(DemoBugOpenMapRealVector.java:17)\n\n\n"
            },
            "50": {
                "commit_sha_buggy": "ef028845113aca7e1159b1725edd7c39ed686faf",
                "commit_sha_fixed": "39cf5e69259d7560d50553caf028f9229b721013",
                "report_id": "MATH-631",
                "report_url": "https://issues.apache.org/jira/browse/MATH-631",
                "issue_title": "[MATH-631] \"RegulaFalsiSolver\" failure - ASF JIRA",
                "issue_description": "\nThe following unit test:\n\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n\n\nfails with\n\nillegal state: maximal count (100) exceeded: evaluations\n\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n"
            },
            "51": {
                "commit_sha_buggy": "34fef656d03a5ba75047a55a894f6f72cbe59f2e",
                "commit_sha_fixed": "2f066a5b2d2fe8a00a251a3220b0d52446fe392d",
                "report_id": "MATH-631",
                "report_url": "https://issues.apache.org/jira/browse/MATH-631",
                "issue_title": "[MATH-631] \"RegulaFalsiSolver\" failure - ASF JIRA",
                "issue_description": "\nThe following unit test:\n\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n\n\nfails with\n\nillegal state: maximal count (100) exceeded: evaluations\n\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n"
            },
            "52": {
                "commit_sha_buggy": "def9fbf8701afa6937fe582c7572c7be011c319f",
                "commit_sha_fixed": "3c319db494928e9d51ea6091b301302c65f4eceb",
                "report_id": "MATH-639",
                "report_url": "https://issues.apache.org/jira/browse/MATH-639",
                "issue_title": "[MATH-639] numerical problems in rotation creation - ASF JIRA",
                "issue_description": "\nbuilding a rotation from the following vector pairs leads to NaN:\nu1 = -4921140.837095533, -2.1512094250440013E7, -890093.279426377\nu2 = -2.7238580938724895E9, -2.169664921341876E9, 6.749688708885301E10\nv1 = 1, 0, 0\nv2 = 0, 0, 1\nThe constructor first changes the (v1, v2) pair into (v1', v2') ensuring the following scalar products hold:\n <v1'|v1'> == <u1|u1>\n <v2'|v2'> == <u2|u2>\n <u1 |u2>  == <v1'|v2'>\nOnce the (v1', v2') pair has been computed, we compute the cross product:\n  k = (v1' - u1)^(v2' - u2)\nand the scalar product:\n  c = <k | (u1^u2)>\nBy construction, c is positive or null and the quaternion axis we want to build is q = k/[2*sqrt(c)].\nc should be null only if some of the vectors are aligned, and this is dealt with later in the algorithm.\nHowever, there are numerical problems with the vector above with the way these computations are done, as shown\nby the following comparisons, showing the result we get from our Java code and the result we get from manual\ncomputation with the same formulas but with enhanced precision:\ncommons math:   k = 38514476.5,            -84.,                           -1168590144\nhigh precision: k = 38514410.36093388...,  -0.374075245201180409222711..., -1168590152.10599715208...\nand it becomes worse when computing c because the vectors are almost orthogonal to each other, hence inducing additional cancellations. We get:\ncommons math    c = -1.2397173627587605E20\nhigh precision: c =  558382746168463196.7079627...\nWe have lost ALL significant digits in cancellations, and even the sign is wrong!\n"
            },
            "53": {
                "commit_sha_buggy": "3eb3573c62df5b89cb02a4ea67f08d85d2ceefba",
                "commit_sha_fixed": "7707b0bb80be05bbf6533a36bb0c646cbfd1026d",
                "report_id": "MATH-618",
                "report_url": "https://issues.apache.org/jira/browse/MATH-618",
                "issue_title": "[MATH-618] Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same - ASF JIRA",
                "issue_description": "\nFor both Complex add and subtract, the javadoc states that\n\n     * If either this or <code>rhs</code> has a NaN value in either part,\n     * {@link #NaN} is returned; otherwise Inifinite and NaN values are\n     * returned in the parts of the result according to the rules for\n     * {@link java.lang.Double} arithmetic\n\n\nSubtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).\n"
            },
            "54": {
                "commit_sha_buggy": "804309e5c5726ad22b0c74dfccdb1ed318f0a108",
                "commit_sha_fixed": "c00ac8120a4215125e49775cd9351e689586b467",
                "report_id": "MATH-567",
                "report_url": "https://issues.apache.org/jira/browse/MATH-567",
                "issue_title": "[MATH-567] class Dfp toDouble method return -inf whan Dfp value is 0 \"zero\" - ASF JIRA",
                "issue_description": "\nI found a bug in the toDouble() method of the Dfp class.\nIf the Dfp's value is 0 \"zero\", the toDouble() method returns a  negative infini.\nThis is because the double value returned has an exposant equal to 0xFFF \nand a significand is equal to 0.\nIn the IEEE754 this is a -inf.\nTo be equal to zero, the exposant and the significand must be equal to zero.\nA simple test case is :\n----------------------------------------------\nimport org.apache.commons.math.dfp.DfpField;\npublic class test {\n\t/**\n\n@param args\n\t */\n\tpublic static void main(String[] args) \n{\n\t\tDfpField field = new DfpField(100);\n\t\tSystem.out.println(\"toDouble value of getZero() =\"+field.getZero().toDouble()+\n\t\t\t\t\"\\ntoDouble value of newDfp(0.0) =\"+\n\t\t\t\tfield.newDfp(0.0).toDouble());\n\t}\n}\n\nMay be the simplest way to fix it is to test the zero equality at the begin of the toDouble() method, to be able to return the correctly signed zero ?\n"
            },
            "55": {
                "commit_sha_buggy": "3114d4ed4654f54fc1ee8e3c3da5b6cd1cd2cc87",
                "commit_sha_fixed": "0c38504ffa3ef520ce78e260538d7b8742c895e8",
                "report_id": "MATH-554",
                "report_url": "https://issues.apache.org/jira/browse/MATH-554",
                "issue_title": "[MATH-554] Vector3D.crossProduct is sensitive to numerical cancellation - ASF JIRA",
                "issue_description": "\nCross product implementation uses the naive formulas (y1 z2 - y2 z1, ...). These formulas fail when vectors are almost colinear, like in the following example:\n\nVector3D v1 = new Vector3D(9070467121.0, 4535233560.0, 1);\nVector3D v2 = new Vector3D(9070467123.0, 4535233561.0, 1);\nSystem.out.println(Vector3D.crossProduct(v1, v2));\n\n\nThe previous code displays \n{ -1, 2, 0 }\n instead of the correct answer \n{ -1, 2, 1 }\n            "
            },
            "56": {
                "commit_sha_buggy": "d773adb1228299c05ae9abbacf2f3616e9a170e0",
                "commit_sha_fixed": "e06fe05e2dd68936e770ba67caa7b9924568170d",
                "report_id": "MATH-552",
                "report_url": "https://issues.apache.org/jira/browse/MATH-552",
                "issue_title": "[MATH-552] MultidimensionalCounter.getCounts(int) returns wrong array of indices - ASF JIRA",
                "issue_description": "\nMultidimensionalCounter counter = new MultidimensionalCounter(2, 4);\nfor (Integer i : counter) {\n    int[] x = counter.getCounts;\n    System.out.println(i + \" \" + Arrays.toString);\n}\nOutput is:\n0 [0, 0]\n1 [0, 1]\n2 [0, 2]\n3 [0, 2]   <=== should be [0, 3]\n4 [1, 0]\n5 [1, 1]\n6 [1, 2]\n7 [1, 2]   <=== should be [1, 3]\n"
            },
            "57": {
                "commit_sha_buggy": "d3892cb85f3eb8ccadada228b791170e3e0a9124",
                "commit_sha_fixed": "00fea9d8078d487e31cec8292dbd9bd69bc9c216",
                "report_id": "MATH-546",
                "report_url": "https://issues.apache.org/jira/browse/MATH-546",
                "issue_title": "[MATH-546] Truncation issue in KMeansPlusPlusClusterer - ASF JIRA",
                "issue_description": "\nThe for loop inside KMeansPlusPlusClusterer.chooseInitialClusters defines a variable\n  int sum = 0;\nThis variable should have type double, rather than int.  Using an int causes the method to truncate the distances between points to (square roots of) integers.  It's especially bad when the distances between points are typically less than 1.\nAs an aside, in version 2.2, this bug manifested itself by making the clusterer return empty clusters.  I wonder if the EmptyClusterStrategy would still be necessary if this bug were fixed.\n"
            },
            "58": {
                "commit_sha_buggy": "b1392325d1255f7e3a1b04a12859a8bb75e4d14c",
                "commit_sha_fixed": "45add3a0e7e2e94bfc29e85c9ef0856e2e473a33",
                "report_id": "MATH-519",
                "report_url": "https://issues.apache.org/jira/browse/MATH-519",
                "issue_title": "[MATH-519] GaussianFitter Unexpectedly Throws NotStrictlyPositiveException - ASF JIRA",
                "issue_description": "\nRunning the following:\n    \tdouble[] observations = \n\n{ \n    \t\t\t1.1143831578403364E-29, \n    \t\t\t 4.95281403484594E-28, \n    \t\t\t 1.1171347211930288E-26, \n    \t\t\t 1.7044813962636277E-25, \n    \t\t\t 1.9784716574832164E-24, \n    \t\t\t 1.8630236407866774E-23, \n    \t\t\t 1.4820532905097742E-22, \n    \t\t\t 1.0241963854632831E-21, \n    \t\t\t 6.275077366673128E-21, \n    \t\t\t 3.461808994532493E-20, \n    \t\t\t 1.7407124684715706E-19, \n    \t\t\t 8.056687953553974E-19, \n    \t\t\t 3.460193945992071E-18, \n    \t\t\t 1.3883326374011525E-17, \n    \t\t\t 5.233894983671116E-17, \n    \t\t\t 1.8630791465263745E-16, \n    \t\t\t 6.288759227922111E-16, \n    \t\t\t 2.0204433920597856E-15, \n    \t\t\t 6.198768938576155E-15, \n    \t\t\t 1.821419346860626E-14, \n    \t\t\t 5.139176445538471E-14, \n    \t\t\t 1.3956427429045787E-13, \n    \t\t\t 3.655705706448139E-13, \n    \t\t\t 9.253753324779779E-13, \n    \t\t\t 2.267636001476696E-12, \n    \t\t\t 5.3880460095836855E-12, \n    \t\t\t 1.2431632654852931E-11 \n    \t}\n;\n    \tGaussianFitter g = \n    \t\tnew GaussianFitter(new LevenbergMarquardtOptimizer());\n    \tfor (int index = 0; index < 27; index++)\n    \t{\n    \t\tg.addObservedPoint(index, observations[index]);\n    \t}\n       \tg.fit();\nResults in:\norg.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than, or equal to, the minimum (0)\n\tat org.apache.commons.math.analysis.function.Gaussian$Parametric.validateParameters(Gaussian.java:184)\n\tat org.apache.commons.math.analysis.function.Gaussian$Parametric.value(Gaussian.java:129)\nI'm guessing the initial guess for sigma is off.  \n"
            },
            "59": {
                "commit_sha_buggy": "ffcaeb072fe0789bb9a64f8488ce9df742ba7da9",
                "commit_sha_fixed": "5dcca48038fb6274cc155251d09db12746ccce71",
                "report_id": "MATH-482",
                "report_url": "https://issues.apache.org/jira/browse/MATH-482",
                "issue_title": "[MATH-482] FastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f - ASF JIRA",
                "issue_description": "\nFastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f.\nThis is because the wrong variable is returned.\nThe bug was not detected by the test case \"testMinMaxFloat()\" because that has a bug too - it tests doubles, not floats.\n"
            },
            "60": {
                "commit_sha_buggy": "87430634d19f8f3af1e0019f733afb578c80d669",
                "commit_sha_fixed": "9054aac4b948117b838d6a5b15be1f50965d805a",
                "report_id": "MATH-414",
                "report_url": "https://issues.apache.org/jira/browse/MATH-414",
                "issue_title": "[MATH-414] ConvergenceException in NormalDistributionImpl.cumulativeProbability() - ASF JIRA",
                "issue_description": "\nI get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.\nFor instance in the following code:\n\t@Test\n\tpublic void testCumulative() {\n\t\tfinal NormalDistribution nd = new NormalDistributionImpl();\n\t\tfor (int i = 0; i < 500; i++) {\n\t\t\tfinal double val = Math.exp;\n\t\t\ttry \n{\n\t\t\t\tSystem.out.println(\"val = \" + val + \" cumulative = \" + nd.cumulativeProbability(val));\n\t\t\t}\n catch (MathException e) \n{\n\t\t\t\te.printStackTrace();\n\t\t\t\tfail();\n\t\t\t}\n\t\t}\n\t}\nIn version 2.0, I get no exception. \nMy suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.\n"
            },
            "61": {
                "commit_sha_buggy": "30bacfbe14e57ec64d08baae52efa91877e8dd9b",
                "commit_sha_fixed": "f76efe5f4ef36fadc677c94269927076f2f42eb9",
                "report_id": "MATH-349",
                "report_url": "https://issues.apache.org/jira/browse/MATH-349",
                "issue_title": "[MATH-349] Dangerous code in \"PoissonDistributionImpl\" - ASF JIRA",
                "issue_description": "\nIn the following excerpt from class \"PoissonDistributionImpl\":\nPoissonDistributionImpl.java\n    public PoissonDistributionImpl(double p, NormalDistribution z) {\n        super();\n        setNormal(z);\n        setMean(p);\n    }\n\n\n(1) Overridable methods are called within the constructor.\n(2) The reference \"z\" is stored and modified within the class.\nI've encountered problem (1) in several classes while working on issue 348. In those cases, in order to remove potential problems, I copied/pasted the body of the \"setter\" methods inside the constructor but I think that a more elegant solution would be to remove the \"setters\" altogether (i.e. make the classes immutable).\nProblem (2) can also create unexpected behaviour. Is it really necessary to pass the \"NormalDistribution\" object; can't it be always created within the class?\n"
            },
            "62": {
                "commit_sha_buggy": "6a07726a825da09003d153e52ea30005b1a4c013",
                "commit_sha_fixed": "8de3eb542b2be80ba309b2c91ae1dba75bdb5063",
                "report_id": "MATH-413",
                "report_url": "https://issues.apache.org/jira/browse/MATH-413",
                "issue_title": "[MATH-413] Miscellaneous issues concerning the \"optimization\" package - ASF JIRA",
                "issue_description": "\nRevision 990792 contains changes triggered the following issues:\n\nMATH-394\nMATH-397\nMATH-404\n\nThis issue collects the currently still unsatisfactory code (not necessarily sorted in order of annoyance):\n\n\"BrentOptimizer\": a specific convergence checker must be used. \"LevenbergMarquardtOptimizer\" also has specific convergence checks.\nTrying to make convergence checking independent of the optimization algorithm creates problems (conceptual and practical):\n\t\nSee \"BrentOptimizer\" and \"LevenbergMarquardtOptimizer\", the algorithm passes \"points\" to the convergence checker, but the actual meaning of the points can very well be different in the caller (optimization algorithm) and the callee (convergence checker).\nIn \"PowellOptimizer\" the line search (\"BrentOptimizer\") tolerances depend on the tolerances within the main algorithm. Since tolerances come with \"ConvergenceChecker\" and so can be changed at any time, it is awkward to adapt the values within the line search optimizer without exposing its internals (\"BrentOptimizer\" field) to the enclosing class (\"PowellOptimizer\").\n\n\nGiven the numerous changes, some Javadoc comments might be out-of-sync, although I did try to update them all.\nClass \"DirectSearchOptimizer\" (in package \"optimization.direct\") inherits from class \"AbstractScalarOptimizer\" (in package \"optimization.general\").\nSome interfaces are defined in package \"optimization\" but their base implementations (abstract class that contain the boiler-plate code) are in package \"optimization.general\" (e.g. \"DifferentiableMultivariateVectorialOptimizer\" and \"BaseAbstractVectorialOptimizer\").\nNo check is performed to ensure the the convergence checker has been set (see e.g. \"BrentOptimizer\" and \"PowellOptimizer\"); if it hasn't there will be a NPE. The alternative is to initialize a default checker that will never be used in case the user had intended to explicitly sets the checker.\n\"NonLinearConjugateGradientOptimizer\": Ugly workaround for the checked \"ConvergenceException\".\nEverywhere, we trail the checked \"FunctionEvaluationException\" although it is never used.\nThere remains some duplicate code (such as the \"multi-start loop\" in the various \"MultiStart...\" implementations).\nThe \"ConvergenceChecker\" interface is very general (the \"converged\" method can take any number of \"...PointValuePair\"). However there remains a \"semantic\" problem: One cannot be sure that the list of points means the same thing for the caller of \"converged\" and within the implementation of the \"ConvergenceChecker\" that was independently set.\nIt is not clear whether it is wise to aggregate the counter of gradient evaluations to the function evaluation counter. In \"LevenbergMarquartdOptimizer\" for example, it would be unfair to do so. Currently I had to remove all tests referring to gradient and Jacobian evaluations.\nIn \"AbstractLeastSquaresOptimizer\" and \"LevenbergMarquardtOptimizer\", occurences of \"OptimizationException\" were replaced by the unchecked \"ConvergenceException\" but in some cases it might not be the most appropriate one.\n\"MultiStartUnivariateRealOptimizer\": in the other classes (\"MultiStartMultivariate...\") similar to this one, the randomization is on the firts-guess value while in this class, it is on the search interval. I think that here also we should randomly choose the start value (within the user-selected interval).\nThe Javadoc utility raises warnings (see output of \"mvn site\") which I couldn't figure out how to correct.\nSome previously existing classes and interfaces have become no more than a specialisation of new \"generics\" classes; it might be interesting to remove them in order to reduce the number of classes and thus limit the potential for confusion.\n\n"
            },
            "63": {
                "commit_sha_buggy": "91b44a1ef7563f54e8acdf29906bd872985a2a6e",
                "commit_sha_fixed": "d2a5bc02c002acfa220ce8bad23b9e8af137f47d",
                "report_id": "MATH-370",
                "report_url": "https://issues.apache.org/jira/browse/MATH-370",
                "issue_title": "[MATH-370] NaN in \"equals\" methods - ASF JIRA",
                "issue_description": "\nIn \"MathUtils\", some \"equals\" methods will return true if both argument are NaN.\nUnless I'm mistaken, this contradicts the IEEE standard.\nIf nobody objects, I'm going to make the changes.\n"
            },
            "64": {
                "commit_sha_buggy": "1909dbe0ca1fc678d9baf1388f8efcf4c65b2a54",
                "commit_sha_fixed": "7dadc2ab019f066a7a287376ad4c63193e8a0a9a",
                "report_id": "MATH-405",
                "report_url": "https://issues.apache.org/jira/browse/MATH-405",
                "issue_title": "[MATH-405] Inconsistent result from Levenberg-Marquardt - ASF JIRA",
                "issue_description": "\nLevenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost\n"
            },
            "65": {
                "commit_sha_buggy": "d4e5f1ce10a4ca8c13625bd03c00a156238655cc",
                "commit_sha_fixed": "a4f9188a55e6935d4d38ae97806af4d59e671588",
                "report_id": "MATH-377",
                "report_url": "https://issues.apache.org/jira/browse/MATH-377",
                "issue_title": "[MATH-377] weight versus sigma in AbstractLeastSquares - ASF JIRA",
                "issue_description": "\nIn AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.\n Once corrected, getRMS() can even reduce\n public double getRMS() \n{return Math.sqrt(getChiSquare()/rows);}\n            "
            },
            "66": {
                "commit_sha_buggy": "7bbad398dd4da51c933414be9a17b07179dee5e4",
                "commit_sha_fixed": "76fcbc838c0f27d9b029c1f283390cb4f47f8895",
                "report_id": "MATH-395",
                "report_url": "https://issues.apache.org/jira/browse/MATH-395",
                "issue_title": "[MATH-395] Bugs in \"BrentOptimizer\" - ASF JIRA",
                "issue_description": "\nI apologize for having provided a buggy implementation of Brent's optimization algorithm (class \"BrentOptimizer\" in package \"optimization.univariate\").\nThe unit tests didn't show that there was something wrong, although (from the \"changes.xml\" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.\nComparing with an implementation in Python, I could figure out the fixes. I'll modify \"BrentOptimizer\" and add a test. I also propose to change the name of the unit test class from \"BrentMinimizerTest\" to \"BrentOptimizerTest\".\n"
            },
            "67": {
                "commit_sha_buggy": "28f28f18ae42f154e9c43de8c3b78f85adf9b318",
                "commit_sha_fixed": "fc505bba569dede0d29a401798fa9f55df9e27f1",
                "report_id": "MATH-393",
                "report_url": "https://issues.apache.org/jira/browse/MATH-393",
                "issue_title": "[MATH-393] Method \"getResult()\" in \"MultiStartUnivariateRealOptimizer\" - ASF JIRA",
                "issue_description": "\nIn \"MultiStartUnivariateRealOptimizer\" (package \"optimization\"), the method \"getResult\" returns the result of the last run of the \"underlying\" optimizer; this last result might not be the best one, in which case it will not correspond to the value returned by the \"optimize\" method. This is confusing and does not seem very useful. I think that \"getResult\" should be defined as\n\n \npublic double getResult() {\n    return optima[0];\n}\n\n\nand similarly\n\npublic double getFunctionValue() {\n    return optimaValues[0];\n}\n\n\n"
            },
            "68": {
                "commit_sha_buggy": "103f12391b89112f030b921a7c4969f00ff23b44",
                "commit_sha_fixed": "615ca9a000c253575e6f62bed87db6110b750834",
                "report_id": "MATH-362",
                "report_url": "https://issues.apache.org/jira/browse/MATH-362",
                "issue_title": "[MATH-362] LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it - ASF JIRA",
                "issue_description": "\nLevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.\n"
            },
            "69": {
                "commit_sha_buggy": "7272826424a28e22d96b86a8e320a37b9e006e71",
                "commit_sha_fixed": "a2711c189d9754c22e3aba2de1c6c125e52626aa",
                "report_id": "MATH-371",
                "report_url": "https://issues.apache.org/jira/browse/MATH-371",
                "issue_title": "[MATH-371] PearsonsCorrelation.getCorrelationPValues() precision limited by machine epsilon - ASF JIRA",
                "issue_description": "\nSimilar to the issue described in MATH-201, using PearsonsCorrelation.getCorrelationPValues() with many treatments results in p-values that are continuous down to 2.2e-16 but that drop to 0 after that.\nIn MATH-201, the problem was described as such:\n> So in essence, the p-value returned by TTestImpl.tTest() is:\n> \n> 1.0 - (cumulativeProbability(t) - cumulativeProbabily(-t))\n> \n> For large-ish t-statistics, cumulativeProbabilty(-t) can get quite small, and cumulativeProbabilty(t) can get very close to 1.0. When \n> cumulativeProbability(-t) is less than the machine epsilon, we get p-values equal to zero because:\n> \n> 1.0 - 1.0 + 0.0 = 0.0\nThe solution in MATH-201 was to modify the p-value calculation to this:\n> p = 2.0 * cumulativeProbability(-t)\nHere, the problem is similar.  From PearsonsCorrelation.getCorrelationPValues():\n  p = 2 * (1 - tDistribution.cumulativeProbability(t));\nDirectly calculating the p-value using identical code as PearsonsCorrelation.getCorrelationPValues(), but with the following change seems to solve the problem:\n  p = 2 * (tDistribution.cumulativeProbability(-t));\n"
            },
            "70": {
                "commit_sha_buggy": "f184aeb7810bed8c89b2c8cca4f8164aef535e56",
                "commit_sha_fixed": "f41fcd85ca62a2109a6e550be0353d292d351213",
                "report_id": "MATH-369",
                "report_url": "https://issues.apache.org/jira/browse/MATH-369",
                "issue_title": "[MATH-369] BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException - ASF JIRA",
                "issue_description": "\nMethod \n    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  \ninvokes \n    BisectionSolver.solve(double min, double max) \nwhich throws NullPointerException, as member variable\n    UnivariateRealSolverImpl.f \nis null.\nInstead the method:\n    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)\nshould be called.\nSteps to reproduce:\ninvoke:\n     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);\nNullPointerException will be thrown.\n"
            },
            "71": {
                "commit_sha_buggy": "fa959ca8c89133c3a2f024a020ec80948ee31926",
                "commit_sha_fixed": "6537e18ad189603e19615226e6aa1a9cdd154b8f",
                "report_id": "MATH-358",
                "report_url": "https://issues.apache.org/jira/browse/MATH-358",
                "issue_title": "[MATH-358] ODE integrator goes past specified end of integration range - ASF JIRA",
                "issue_description": "\nEnd of integration range in ODE solving is handled as an event.\nIn some cases, numerical accuracy in events detection leads to error in events location.\nThe following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range, more than twice the specified range.\n\n  public void testMissedEvent() throws IntegratorException, DerivativeException {\n          final double t0 = 1878250320.0000029;\n          final double t =  1878250379.9999986;\n          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {\n            \n            public int getDimension() {\n                return 1;\n            }\n            \n            public void computeDerivatives(double t, double[] y, double[] yDot)\n                throws DerivativeException {\n                yDot[0] = y[0] * 1.0e-6;\n            }\n        };\n\n        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,\n                                                                               1.0e-10, 1.0e-10);\n\n        double[] y = { 1.0 };\n        integrator.setInitialStepSize(60.0);\n        double finalT = integrator.integrate(ode, t0, y, t, y);\n        Assert.assertEquals(t, finalT, 1.0e-6);\n    }\n\n\n\n"
            },
            "72": {
                "commit_sha_buggy": "29c3b75e2d5120771ca85ffcbffc9b7cb5d45c58",
                "commit_sha_fixed": "aa09ac7ca6e01a2ba41470ca590f07f2ada8af6f",
                "report_id": "MATH-344",
                "report_url": "https://issues.apache.org/jira/browse/MATH-344",
                "issue_title": "[MATH-344] Brent solver returns the wrong value if either bracket endpoint is root - ASF JIRA",
                "issue_description": "\nThe solve(final UnivariateRealFunction f, final double min, final double max, final double initial) function returns yMin or yMax if min or max are deemed to be roots, respectively, instead of min or max.\n"
            },
            "73": {
                "commit_sha_buggy": "1687372e34828dff42e1482ed6575bb982b81b00",
                "commit_sha_fixed": "29c3b75e2d5120771ca85ffcbffc9b7cb5d45c58",
                "report_id": "MATH-343",
                "report_url": "https://issues.apache.org/jira/browse/MATH-343",
                "issue_title": "[MATH-343] Brent solver doesn't throw IllegalArgumentException when initial guess has the wrong sign - ASF JIRA",
                "issue_description": "\nJavadoc for \"public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial)\" claims that \"if the values of the function at the three points have the same sign\" an IllegalArgumentException is thrown. This case isn't even checked.\n"
            },
            "74": {
                "commit_sha_buggy": "034b4d68157defc3199f618fdd2d3a487306dbc2",
                "commit_sha_fixed": "d06e7b7c8e646ff489a5dfba47dfcb283a194e9b",
                "report_id": "MATH-338",
                "report_url": "https://issues.apache.org/jira/browse/MATH-338",
                "issue_title": "[MATH-338] Wrong parameter for first step size guess for Embedded Runge Kutta methods - ASF JIRA",
                "issue_description": "\nIn a space application using DOP853 i detected what seems to be a bad parameter in the call to the method  initializeStep of class AdaptiveStepsizeIntegrator.\nHere, DormandPrince853Integrator is a subclass for EmbeddedRungeKuttaIntegrator which perform the call to initializeStep at the beginning of its method integrate(...)\nThe problem comes from the array \"scale\" that is used as a parameter in the call off initializeStep(..)\nFollowing the theory described by Hairer in his book \"Solving Ordinary Differential Equations 1 : Nonstiff Problems\", the scaling should be :\nsci = Atol i + |y0i| * Rtoli\nWhereas EmbeddedRungeKuttaIntegrator uses :  sci = Atoli\nNote that the Gragg-Bulirsch-Stoer integrator uses the good implementation \"sci = Atol i + |y0i| * Rtoli  \" when he performs the call to the same method initializeStep(..)\nIn the method initializeStep, the error leads to a wrong step size h used to perform an  Euler step. Most of the time it is unvisible for the user.\nBut in my space application the Euler step with this wrong step size h (much bigger than it should be)  makes an exception occur (my satellite hits the ground...)\nTo fix the bug, one should use the same algorithm as in the rescale method in GraggBulirschStoerIntegrator\nFor exemple :\n final double[] scale= new double[y0.length];;\n          if (vecAbsoluteTolerance == null) {\n              for (int i = 0; i < scale.length; ++i) \n{\n                final double yi = Math.max(Math.abs(y0[i]), Math.abs(y0[i]));\n                scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * yi;\n              }\n            } else {\n              for (int i = 0; i < scale.length; ++i) \n{\n                final double yi = Math.max(Math.abs(y0[i]), Math.abs(y0[i]));\n                scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * yi;\n              }\n            }\n          hNew = initializeStep(equations, forward, getOrder(), scale,\n                           stepStart, y, yDotK[0], yTmp, yDotK[1]);\nSorry for the length of this message, looking forward to hearing from you soon\nVincent Morand\n"
            },
            "75": {
                "commit_sha_buggy": "39e2ad8af8fdedac51144158061cb31e7863c3a1",
                "commit_sha_fixed": "523df0c13719150b1397a6094f410274bfaf1475",
                "report_id": "MATH-329",
                "report_url": "https://issues.apache.org/jira/browse/MATH-329",
                "issue_title": "[MATH-329] In stat.Frequency, getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)  - ASF JIRA",
                "issue_description": "\nDrop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change\nFrequency.java\n   /**\n\nReturns the percentage of values that are equal to v\n@deprecated replaced by \n{@link #getPct(Comparable)}\n as of 2.0\n     */\n    @Deprecated\n    public double getPct(Object v) \n{\n        return getCumPct((Comparable<?>) v);\n    }\n\n"
            },
            "76": {
                "commit_sha_buggy": "d607614a8827a1a5fab587b6e692601d5673833e",
                "commit_sha_fixed": "39e2ad8af8fdedac51144158061cb31e7863c3a1",
                "report_id": "MATH-320",
                "report_url": "https://issues.apache.org/jira/browse/MATH-320",
                "issue_title": "[MATH-320] NaN singular value from SVD - ASF JIRA",
                "issue_description": "\nThe following jython code\nStart code\nfrom org.apache.commons.math.linear import *\nAlist = [[1.0, 2.0, 3.0],[2.0,3.0,4.0],[3.0,5.0,7.0]]\nA = Array2DRowRealMatrix(Alist)\ndecomp = SingularValueDecompositionImpl(A)\nprint decomp.getSingularValues()\nEnd code\nprints\narray('d', [11.218599757513008, 0.3781791648535976, nan])\nThe last singular value should be something very close to 0 since the matrix\nis rank deficient.  When i use the result from getSolver() to solve a system, i end \nup with a bunch of NaNs in the solution.  I assumed i would get back a least squares solution.\nDoes this SVD implementation require that the matrix be full rank?  If so, then i would expect\nan exception to be thrown from the constructor or one of the methods.\n"
            },
            "77": {
                "commit_sha_buggy": "b30bff0126e1a0301a8b86b40a0b532f1d0ae28f",
                "commit_sha_fixed": "d6555de715889237b7be11639d164e7098862003",
                "report_id": "MATH-326",
                "report_url": "https://issues.apache.org/jira/browse/MATH-326",
                "issue_title": "[MATH-326] getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways) - ASF JIRA",
                "issue_description": "\nthe L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries.\nThe current implementation in ArrayRealVector has a typo:\n\n    public double getLInfNorm() {\n        double max = 0;\n        for (double a : data) {\n            max += Math.max(max, Math.abs(a));\n        }\n        return max;\n    }\n\n\nthe += should just be an =.\nThere is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test, not a test for correctness).\nWorse, the implementation in OpenMapRealVector is not even positive semi-definite:\n\n   \n    public double getLInfNorm() {\n        double max = 0;\n        Iterator iter = entries.iterator();\n        while (iter.hasNext()) {\n            iter.advance();\n            max += iter.value();\n        }\n        return max;\n    }\n\n\nI would suggest that this method be moved up to the AbstractRealVector superclass and implemented using the sparseIterator():\n\n  public double getLInfNorm() {\n    double norm = 0;\n    Iterator<Entry> it = sparseIterator();\n    Entry e;\n    while(it.hasNext() && (e = it.next()) != null) {\n      norm = Math.max(norm, Math.abs(e.getValue()));\n    }\n    return norm;\n  }\n\n\nUnit tests with negative valued vectors would be helpful to check for this kind of thing in the future.\n"
            },
            "78": {
                "commit_sha_buggy": "cc7e3e7fe46844f068c622cf439ef4b654d971ec",
                "commit_sha_fixed": "b3ed2415fc58b34667d99f077bae6c8e38b7aced",
                "report_id": "MATH-322",
                "report_url": "https://issues.apache.org/jira/browse/MATH-322",
                "issue_title": "[MATH-322] during ODE integration, the last event in a pair of very close event may not be detected - ASF JIRA",
                "issue_description": "\nWhen an events follows a previous one very closely, it may be ignored. The occurrence of the bug depends on the side of the bracketing interval that was selected. For example consider a switching function that is increasing around first event around t = 90, reaches its maximum and is decreasing around the second event around t = 135. If an integration step spans from 67.5 and 112.5, the switching function values at start and end of step will  have opposite signs, so the first event will be detected. The solver will find the event really occurs at 90.0 and will therefore truncate the step at 90.0. The next step will start from where the first step ends, i.e. it will start at 90.0. Let's say this step spans from 90.0 to 153.0. The switching function switches once again in this step.\nIf the solver for the first event converged to a value slightly before 90.0 (say 89.9999999), then the switch will not be detected because g(89.9999999) and g(153.0) are both negative.\nThis bug was introduced as of r781157 (2009-06-02) when special handling of events very close to step start was added.\n"
            },
            "79": {
                "commit_sha_buggy": "ca1ca9250b99dd49434468aa5530eb00b2f0680d",
                "commit_sha_fixed": "138baec1c778c2ea1dc1a6efe6d5e76a3b072b1d",
                "report_id": "MATH-305",
                "report_url": "https://issues.apache.org/jira/browse/MATH-305",
                "issue_title": "[MATH-305] NPE in  KMeansPlusPlusClusterer unittest - ASF JIRA",
                "issue_description": "\nWhen running this unittest, I am facing this NPE:\njava.lang.NullPointerException\n\tat org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91)\nThis is the unittest:\npackage org.fao.fisheries.chronicles.calcuation.cluster;\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertTrue;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Random;\nimport org.apache.commons.math.stat.clustering.Cluster;\nimport org.apache.commons.math.stat.clustering.EuclideanIntegerPoint;\nimport org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer;\nimport org.fao.fisheries.chronicles.input.CsvImportProcess;\nimport org.fao.fisheries.chronicles.input.Top200Csv;\nimport org.junit.Test;\npublic class ClusterAnalysisTest {\n\t@Test\n\tpublic void testPerformClusterAnalysis2() {\n\t\tKMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>(\n\t\t\t\tnew Random(1746432956321l));\n\t\tEuclideanIntegerPoint[] points = new EuclideanIntegerPoint[] {\n\t\t\t\tnew EuclideanIntegerPoint(new int[] \n{ 1959, 325100 }\n),\n\t\t\t\tnew EuclideanIntegerPoint(new int[] \n{ 1960, 373200 }\n), };\n\t\tList<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points), 1, 1);\n\t\tassertEquals(1, clusters.size());\n\t}\n}\n"
            },
            "80": {
                "commit_sha_buggy": "7d903ca533833e5db8d2fe150f1e31b54ddda700",
                "commit_sha_fixed": "3ced4f2a4e2546f0d7c309bd8f6305edee0dee8f",
                "report_id": "MATH-318",
                "report_url": "https://issues.apache.org/jira/browse/MATH-318",
                "issue_title": "[MATH-318] wrong result in eigen decomposition - ASF JIRA",
                "issue_description": "\nSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0\n\n    public void testMathpbx02() {\n\n        double[] mainTridiagonal = {\n        \t  7484.860960227216, 18405.28129035345, 13855.225609560746,\n        \t 10016.708722343366, 559.8117399576674, 6750.190788301587, \n        \t    71.21428769782159\n        };\n        double[] secondaryTridiagonal = {\n        \t -4175.088570476366,1975.7955858241994,5193.178422374075, \n        \t  1995.286659169179,75.34535882933804,-234.0808002076056\n        };\n\n        // the reference values have been computed using routine DSTEMR\n        // from the fortran library LAPACK version 3.2.1\n        double[] refEigenValues = {\n        \t\t20654.744890306974412,16828.208208485466457,\n        \t\t6893.155912634994820,6757.083016675340332,\n        \t\t5887.799885688558788,64.309089923240379,\n        \t\t57.992628792736340\n        };\n        RealVector[] refEigenVectors = {\n        \t\tnew ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),\n        \t\tnew ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),\n        \t\tnew ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),\n        \t\tnew ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),\n        \t\tnew ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),\n        \t\tnew ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),\n        \t\tnew ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})\n        };\n\n        // the following line triggers the exception\n        EigenDecomposition decomposition =\n            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);\n\n        double[] eigenValues = decomposition.getRealEigenvalues();\n        for (int i = 0; i < refEigenValues.length; ++i) {\n            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);\n            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {\n                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);\n            } else {\n                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);\n            }\n        }\n\n    }\n\n\n"
            },
            "81": {
                "commit_sha_buggy": "6e3ea6857dce8b7a586c3af555e21ba35a59ea54",
                "commit_sha_fixed": "7d903ca533833e5db8d2fe150f1e31b54ddda700",
                "report_id": "MATH-308",
                "report_url": "https://issues.apache.org/jira/browse/MATH-308",
                "issue_title": "[MATH-308] ArrayIndexOutOfBoundException in EigenDecompositionImpl - ASF JIRA",
                "issue_description": "\nThe following test triggers an ArrayIndexOutOfBoundException:\n\n    public void testMath308() {\n\n        double[] mainTridiagonal = {\n            22.330154644539597, 46.65485522478641, 17.393672330044705, 54.46687435351116, 80.17800767709437\n        };\n        double[] secondaryTridiagonal = {\n            13.04450406501361, -5.977590941539671, 2.9040909856707517, 7.1570352792841225\n        };\n\n        // the reference values have been computed using routine DSTEMR\n        // from the fortran library LAPACK version 3.2.1\n        double[] refEigenValues = {\n            14.138204224043099, 18.847969733754262, 52.536278520113882, 53.456697699894512, 82.044413207204002\n        };\n        RealVector[] refEigenVectors = {\n            new ArrayRealVector(new double[] {  0.584677060845929, -0.367177264979103, -0.721453187784497,  0.052971054621812, -0.005740715188257 }),\n            new ArrayRealVector(new double[] {  0.713933751051495, -0.190582113553930,  0.671410443368332, -0.056056055955050,  0.006541576993581 }),\n            new ArrayRealVector(new double[] {  0.222368839324646,  0.514921891363332, -0.021377019336614,  0.801196801016305, -0.207446991247740 }),\n            new ArrayRealVector(new double[] {  0.314647769490148,  0.750806415553905, -0.167700312025760, -0.537092972407375,  0.143854968127780 }),\n            new ArrayRealVector(new double[] { -0.000462690386766, -0.002118073109055,  0.011530080757413,  0.252322434584915,  0.967572088232592 })\n        };\n\n        // the following line triggers the exception\n        EigenDecomposition decomposition =\n            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);\n\n        double[] eigenValues = decomposition.getRealEigenvalues();\n        for (int i = 0; i < refEigenValues.length; ++i) {\n            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-6);\n            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {\n                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-6);\n            } else {\n                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-6);\n            }\n        }\n\n    }\n\n\nRunning the previous method as a Junit test triggers the exception when the EigenDecompositionImpl instance is built. The first few lines of the stack trace are:\n\njava.lang.ArrayIndexOutOfBoundsException: -1\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.computeShiftIncrement(EigenDecompositionImpl.java:1545)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.goodStep(EigenDecompositionImpl.java:1072)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.processGeneralBlock(EigenDecompositionImpl.java:894)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.findEigenvalues(EigenDecompositionImpl.java:658)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.decompose(EigenDecompositionImpl.java:246)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.<init>(EigenDecompositionImpl.java:205)\n\tat org.apache.commons.math.linear.EigenDecompositionImplTest.testMath308(EigenDecompositionImplTest.java:136)\n\n\nI'm currently investigating this bug. It is not a simple index translation error between the original fortran (Lapack) and commons-math implementation.\n"
            },
            "82": {
                "commit_sha_buggy": "f36be8e8b7371fb8814456b6c095866aa802de78",
                "commit_sha_fixed": "4ece1884cc408e15c8f1db9010fec5cac43937b9",
                "report_id": "MATH-288",
                "report_url": "https://issues.apache.org/jira/browse/MATH-288",
                "issue_title": "[MATH-288] SimplexSolver not working as expected 2 - ASF JIRA",
                "issue_description": "\nSimplexSolver didn't find the optimal solution.\nProgram for Lpsolve:\n=====================\n/* Objective function */\nmax: 7 a 3 b;\n/* Constraints */\nR1: +3 a -5 c <= 0;\nR2: +2 a -5 d <= 0;\nR3: +2 b -5 c <= 0;\nR4: +3 b -5 d <= 0;\nR5: +3 a +2 b <= 5;\nR6: +2 a +3 b <= 5;\n/* Variable bounds */\na <= 1;\nb <= 1;\n=====================\nResults(correct): a = 1, b = 1, value = 10\nProgram for SimplexSolve:\n=====================\nLinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]\n{7, 3, 0, 0}\n, 0);\nCollection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>();\npodmienky.add(new LinearConstraint(new double[]\n{1, 0, 0, 0}\n, Relationship.LEQ, 1));\npodmienky.add(new LinearConstraint(new double[]\n{0, 1, 0, 0}\n, Relationship.LEQ, 1));\npodmienky.add(new LinearConstraint(new double[]\n{3, 0, -5, 0}\n, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]\n{2, 0, 0, -5}\n, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]\n{0, 2, -5, 0}\n, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]\n{0, 3, 0, -5}\n, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]\n{3, 2, 0, 0}\n, Relationship.LEQ, 5));\npodmienky.add(new LinearConstraint(new double[]\n{2, 3, 0, 0}\n, Relationship.LEQ, 5));\nSimplexSolver solver = new SimplexSolver();\nRealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);\n=====================\nResults(incorrect): a = 1, b = 0.5, value = 8.5\nP.S. I used the latest software from the repository (including MATH-286 fix).\n"
            },
            "83": {
                "commit_sha_buggy": "0878ad4bc8e4ac345a2c27449a0686b0877013d4",
                "commit_sha_fixed": "f36be8e8b7371fb8814456b6c095866aa802de78",
                "report_id": "MATH-286",
                "report_url": "https://issues.apache.org/jira/browse/MATH-286",
                "issue_title": "[MATH-286] SimplexSolver not working as expected? - ASF JIRA",
                "issue_description": "\nI guess (but I could be wrong) that SimplexSolver does not always return the optimal solution, nor satisfies all the constraints...\nConsider this LP:\nmax: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5;\nr1: x0 + x2 + x4 = 23.0;\nr2: x1 + x3 + x5 = 23.0;\nr3: x0 >= 10.0;\nr4: x2 >= 8.0;\nr5: x4 >= 5.0;\nLPSolve returns 25.8, with x0 = 10.0, x1 = 0.0, x2 = 8.0, x3 = 0.0, x4 = 5.0, x5 = 23.0;\nThe same LP expressed in Apache commons math is:\nLinearObjectiveFunction f = new LinearObjectiveFunction(new double[] \n{ 0.8, 0.2, 0.7, 0.3, 0.6, 0.4 }\n, 0 );\nCollection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\nconstraints.add(new LinearConstraint(new double[] \n{ 1, 0, 1, 0, 1, 0 }\n, Relationship.EQ, 23.0));\nconstraints.add(new LinearConstraint(new double[] \n{ 0, 1, 0, 1, 0, 1 }\n, Relationship.EQ, 23.0));\nconstraints.add(new LinearConstraint(new double[] \n{ 1, 0, 0, 0, 0, 0 }\n, Relationship.GEQ, 10.0));\nconstraints.add(new LinearConstraint(new double[] \n{ 0, 0, 1, 0, 0, 0 }\n, Relationship.GEQ, 8.0));\nconstraints.add(new LinearConstraint(new double[] \n{ 0, 0, 0, 0, 1, 0 }\n, Relationship.GEQ, 5.0));\nRealPointValuePair solution = new SimplexSolver().optimize(f, constraints, GoalType.MAXIMIZE, true);\nthat returns 22.20, with x0 = 15.0, x1 = 23.0, x2 = 8.0, x3 = 0.0, x4 = 0.0, x5 = 0.0;\nIs it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8, and the last constraint (x4 >= 5.0) is not satisfied...\nAm I using the interface wrongly?\n"
            },
            "84": {
                "commit_sha_buggy": "6eeb2b31a0e4b9690666f26d148d0eafe1f662e7",
                "commit_sha_fixed": "317793eeff84dc9b260301adbe4aa8f5c79f703a",
                "report_id": "MATH-283",
                "report_url": "https://issues.apache.org/jira/browse/MATH-283",
                "issue_title": "[MATH-283] MultiDirectional optimzation loops forver if started at the correct solution - ASF JIRA",
                "issue_description": "\nMultiDirectional.iterateSimplex loops forever if the starting point is the correct solution.\nsee the attached test case (testMultiDirectionalCorrectStart) as an example.\n"
            },
            "85": {
                "commit_sha_buggy": "8de8a3b6fa5f4d7ea817f915d957ef309441762d",
                "commit_sha_fixed": "9be86f674f91fa3fe0a8694e7b98472dabe6886d",
                "report_id": "MATH-280",
                "report_url": "https://issues.apache.org/jira/browse/MATH-280",
                "issue_title": "[MATH-280] bug in inverseCumulativeProbability() for Normal Distribution - ASF JIRA",
                "issue_description": "\n\n@version $Revision: 617953 $ $Date: 2008-02-02 22:54:00 -0700 (Sat, 02 Feb 2008) $\n */\npublic class NormalDistributionImpl extends AbstractContinuousDistribution \n\n\n@version $Revision: 506600 $ $Date: 2007-02-12 12:35:59 -0700 (Mon, 12 Feb 2007) $\n */\npublic abstract class AbstractContinuousDistribution\n\nThis code:\n        \tDistributionFactory factory = app.getDistributionFactory();\n        \tNormalDistribution normal = factory.createNormalDistribution(0,1);\n        \tdouble result = normal.inverseCumulativeProbability(0.9772498680518209);\ngives the exception below. It should return (approx) 2.0000...\nnormal.inverseCumulativeProbability(0.977249868051820); works fine\nThese also give errors:\n0.9986501019683698 (should return 3.0000...)\n0.9999683287581673 (should return 4.0000...)\norg.apache.commons.math.MathException: Number of iterations=1, maximum iterations=2,147,483,647, initial=1, lower bound=0, upper bound=179,769,313,486,231,570,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000, final a value=0, final b value=2, f(a)=-0.477, f(b)=0\n\tat org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103)\n\tat org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)\n"
            },
            "86": {
                "commit_sha_buggy": "75f5c92aeb47e264c196a8c38a495adac89f493c",
                "commit_sha_fixed": "bd8f05c4dda4b5b00e525e08fd6c95d256423c97",
                "report_id": "MATH-274",
                "report_url": "https://issues.apache.org/jira/browse/MATH-274",
                "issue_title": "[MATH-274] testing for symmetric positive definite matrix in CholeskyDecomposition - ASF JIRA",
                "issue_description": "\nI used this matrix:\n        double[][] cv = {\n\n{0.40434286, 0.09376327, 0.30328980, 0.04909388}\n,\n\n{0.09376327, 0.10400408, 0.07137959, 0.04762857}\n,\n\n{0.30328980, 0.07137959, 0.30458776, 0.04882449},\n            {0.04909388, 0.04762857, 0.04882449, 0.07543265}\n        };\n\nAnd it works fine, because it is symmetric positive definite\n\nI tried this matrix:\n\n        double[][] cv = {\n            {0.40434286, -0.09376327, 0.30328980, 0.04909388},\n            {-0.09376327, 0.10400408, 0.07137959, 0.04762857},\n            {0.30328980, 0.07137959, 0.30458776, 0.04882449}\n,\n            {0.04909388, 0.04762857, 0.04882449, 0.07543265}\n        };\nAnd it should throw an exception but it does not.  I tested the matrix in R and R's cholesky decomposition method returns that the matrix is not symmetric positive definite.\nObviously your code is not catching this appropriately.\nBy the way (in my opinion) the use of exceptions to check these conditions is not the best design or use for exceptions.  If you are going to force the use to try and catch these exceptions at least provide methods  to test the conditions prior to the possibility of the exception.  \n"
            },
            "87": {
                "commit_sha_buggy": "d0c52c49b7efa5367b154443bba9910cb19e6419",
                "commit_sha_fixed": "75f5c92aeb47e264c196a8c38a495adac89f493c",
                "report_id": "MATH-273",
                "report_url": "https://issues.apache.org/jira/browse/MATH-273",
                "issue_title": "[MATH-273] Basic variable is not found correctly in simplex tableau - ASF JIRA",
                "issue_description": "\nThe last patch to SimplexTableau caused an automated test suite I'm running at work to go down a new code path and uncover what is hopefully the last bug remaining in the Simplex code.\nSimplexTableau was assuming an entry in the tableau had to be nonzero to indicate a basic variable, which is incorrect - the entry should have a value equal to 1.\n"
            },
            "88": {
                "commit_sha_buggy": "1b48dbabe18ca22396bd737df73e241cfdf8c0c5",
                "commit_sha_fixed": "24a6a2692e942969f5c39bd88d3d12ac0f0bf0d9",
                "report_id": "MATH-272",
                "report_url": "https://issues.apache.org/jira/browse/MATH-272",
                "issue_title": "[MATH-272] Simplex Solver arrives at incorrect solution - ASF JIRA",
                "issue_description": "\nI have reduced the problem reported to me down to a minimal test case which I will attach.\n"
            },
            "89": {
                "commit_sha_buggy": "0c84b28c3542f3340f7ec0dffc34c60dff66604e",
                "commit_sha_fixed": "62b3877f953dd47c4d301be35c77446e2cf55311",
                "report_id": "MATH-259",
                "report_url": "https://issues.apache.org/jira/browse/MATH-259",
                "issue_title": "[MATH-259] Bugs in Frequency API - ASF JIRA",
                "issue_description": "\nI think the existing Frequency API has some bugs in it.\nThe addValue(Object v) method allows one to add a plain Object, but one cannot add anything further to the instance, as the second add fails with IllegalArgumentException.\nIn fact, the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects.\nThis could be fixed by checking that the object is Comparable.\nSimilar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable.\nThe getCount(Object) and getPct(Object) methods don't fail when given a non-Comparable object (because the class cast exception is caught), however they just return 0 as if the object was not present:\n\n        final Object OBJ = new Object();\n        f.addValue(OBJ); // This ought to fail, but doesn't, causing the unexpected behaviour below\n        System.out.println(f.getCount(OBJ)); // 0\n        System.out.println(f.getPct(OBJ)); // 0.0\n\n\nRather than adding extra checks for Comparable, it seems to me that the API would be much improved by using Comparable instead of Object.\nAlso, it should make it easier to implement generics.\nHowever, this would cause compilation failures for some programs that pass Object rather than Comparable to the class.\nThese would need recoding, but I think they would continue to run OK against the new API.\nIt would also affect the run-time behaviour slightly, as the first attempt to add a non-Comparable object would fail, rather than the second add of a possibly valid object.\nBut is that a viable program? It can only add one object, and any attempt to get statistics will either return 0 or an Exception, and applying the instanceof fix would also cause it to fail.\n"
            },
            "90": {
                "commit_sha_buggy": "43336b08c6c27d55c1c6e8c1b6330cb44a29044e",
                "commit_sha_fixed": "0c84b28c3542f3340f7ec0dffc34c60dff66604e",
                "report_id": "MATH-259",
                "report_url": "https://issues.apache.org/jira/browse/MATH-259",
                "issue_title": "[MATH-259] Bugs in Frequency API - ASF JIRA",
                "issue_description": "\nI think the existing Frequency API has some bugs in it.\nThe addValue(Object v) method allows one to add a plain Object, but one cannot add anything further to the instance, as the second add fails with IllegalArgumentException.\nIn fact, the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects.\nThis could be fixed by checking that the object is Comparable.\nSimilar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable.\nThe getCount(Object) and getPct(Object) methods don't fail when given a non-Comparable object (because the class cast exception is caught), however they just return 0 as if the object was not present:\n\n        final Object OBJ = new Object();\n        f.addValue(OBJ); // This ought to fail, but doesn't, causing the unexpected behaviour below\n        System.out.println(f.getCount(OBJ)); // 0\n        System.out.println(f.getPct(OBJ)); // 0.0\n\n\nRather than adding extra checks for Comparable, it seems to me that the API would be much improved by using Comparable instead of Object.\nAlso, it should make it easier to implement generics.\nHowever, this would cause compilation failures for some programs that pass Object rather than Comparable to the class.\nThese would need recoding, but I think they would continue to run OK against the new API.\nIt would also affect the run-time behaviour slightly, as the first attempt to add a non-Comparable object would fail, rather than the second add of a possibly valid object.\nBut is that a viable program? It can only add one object, and any attempt to get statistics will either return 0 or an Exception, and applying the instanceof fix would also cause it to fail.\n"
            },
            "91": {
                "commit_sha_buggy": "9fb5d27fd15d856b136fbadd3d7bb7dfbd0ddf50",
                "commit_sha_fixed": "e1df5f5486f10ac521dfc3dc20d1bfe508e67aa8",
                "report_id": "MATH-252",
                "report_url": "https://issues.apache.org/jira/browse/MATH-252",
                "issue_title": "[MATH-252] Fraction.comparTo returns 0 for some differente fractions - ASF JIRA",
                "issue_description": "\nIf two different fractions evaluate to the same double due to limited precision,\nthe compareTo methode returns 0 as if they were identical.\n\n// value is roughly PI - 3.07e-18\nFraction pi1 = new Fraction(1068966896, 340262731);\n\n// value is roughly PI + 1.936e-17\nFraction pi2 = new Fraction( 411557987, 131002976);\n\nSystem.out.println(pi1.doubleValue() - pi2.doubleValue()); // exactly 0.0 due to limited IEEE754 precision\nSystem.out.println(pi1.compareTo(pi2)); // display 0 instead of a negative value\n\n\n"
            },
            "92": {
                "commit_sha_buggy": "63c7bc9d7cbee21a7f6acc5a9b85d1b8b0e3a205",
                "commit_sha_fixed": "85a8ab2dcfc26e83be1514acdb11d3feaac3e73d",
                "report_id": "MATH-241",
                "report_url": "https://issues.apache.org/jira/browse/MATH-241",
                "issue_title": "[MATH-241] MathUtils.binomialCoefficient(n,k) fails for large results - ASF JIRA",
                "issue_description": "\nProbably due to rounding errors, MathUtils.binomialCoefficient(n,k) fails for results near Long.MAX_VALUE.\nThe existence of failures can be demonstrated by testing the recursive property:\n\n         assertEquals(MathUtils.binomialCoefficient(65,32) + MathUtils.binomialCoefficient(65,33),\n                 MathUtils.binomialCoefficient(66,33));\n\n\nOr by directly using the (externally calculated and hopefully correct) expected value:\n\n         assertEquals(7219428434016265740L, MathUtils.binomialCoefficient(66,33));\n\n\nI suggest a nonrecursive test implementation along the lines of\nMathUtilsTest.java\n    /**\n     * Exact implementation using BigInteger and the explicit formula\n     * (n, k) == ((k-1)*...*n) / (1*...*(n-k))\n     */\n\tpublic static long binomialCoefficient(int n, int k) {\n\t\tif (k == 0 || k == n)\n\t\t\treturn 1;\n\t\tBigInteger result = BigInteger.ONE;\n\t\tfor (int i = k + 1; i <= n; i++) {\n\t\t\tresult = result.multiply(BigInteger.valueOf(i));\n\t\t}\n\t\tfor (int i = 1; i <= n - k; i++) {\n\t\t\tresult = result.divide(BigInteger.valueOf(i));\n\t\t}\n\t\tif (result.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) > 0) {\n\t\t\tthrow new ArithmeticException(\n                                \"Binomial coefficient overflow: \" + n + \", \" + k);\n\t\t}\n\t\treturn result.longValue();\n\t}\n\n\nWhich would allow you to test the expected values directly:\n\n         assertEquals(binomialCoefficient(66,33), MathUtils.binomialCoefficient(66,33));\n\n\n"
            },
            "93": {
                "commit_sha_buggy": "3112f69e1d789e00fb21a1dde901b313547fed60",
                "commit_sha_fixed": "7cd3d822b65b7acdd1f6e1c82b291cd994f4fe05",
                "report_id": "MATH-240",
                "report_url": "https://issues.apache.org/jira/browse/MATH-240",
                "issue_title": "[MATH-240] MathUtils.factorial(n) fails for n >= 17 - ASF JIRA",
                "issue_description": "\nThe result of MathUtils.factorial( n ) for n = 17, 18, 19 is wrong, probably because of rounding errors in the double calculations.\nReplace the first line of MathUtilsTest.testFactorial() by\n        for (int i = 1; i <= 20; i++) {\nto check all valid arguments for the long result and see the failure.\nI suggest implementing a simple loop to multiply the long result - or even using a precomputed long[] - instead of adding logarithms.\n"
            },
            "94": {
                "commit_sha_buggy": "ee88057ba86b543c4f678f8e28b1620c22b19f0f",
                "commit_sha_fixed": "a96e597894562c2cf01fc678f6c435d65ccc31c5",
                "report_id": "MATH-238",
                "report_url": "https://issues.apache.org/jira/browse/MATH-238",
                "issue_title": "[MATH-238] MathUtils.gcd(u, v) fails when u and v both contain a high power of 2 - ASF JIRA",
                "issue_description": "\nThe test at the beginning of MathUtils.gcd(u, v) for arguments equal to zero fails when u and v contain high enough powers of 2 so that their product overflows to zero.\n        assertEquals(3 * (1<<15), MathUtils.gcd(3 * (1<<20), 9 * (1<<15)));\nFix: Replace the test at the start of MathUtils.gcd()\n        if (u * v == 0) {\nby\n        if (u == 0 || v == 0) {\n"
            },
            "95": {
                "commit_sha_buggy": "e640d1613751a99ae4c468c9567f21ea13b496fc",
                "commit_sha_fixed": "fbf87122e0f7229892b6dbbf2e211cc46acea008",
                "report_id": "MATH-227",
                "report_url": "https://issues.apache.org/jira/browse/MATH-227",
                "issue_title": "[MATH-227] denominatorDegreeOfFreedom in FDistribution leads to IllegalArgumentsException in UnivariateRealSolverUtils.bracket - ASF JIRA",
                "issue_description": "\nWe are using the FDistributionImpl from the commons.math project to do\nsome statistical calculations, namely receiving the upper and lower\nboundaries of a confidence interval. Everything is working fine and the\nresults are matching our reference calculations.\nHowever, the FDistribution behaves strange if a\ndenominatorDegreeOfFreedom of 2 is used, with an alpha-value of 0.95.\nThis results in an IllegalArgumentsException, stating:\nInvalid endpoint parameters:  lowerBound=0.0 initial=Infinity\nupperBound=1.7976931348623157E308\ncoming from\norg.apache.commons.math.analysis.UnivariateRealSolverUtils.bracket\nThe problem is the 'initial' parameter to that function, wich is\nPOSITIVE_INFINITY and therefore not within the boundaries. I already\npinned down the problem to the FDistributions getInitialDomain()-method,\nwich goes like:\n        return getDenominatorDegreesOfFreedom() /\n                    (getDenominatorDegreesOfFreedom() - 2.0);\nObviously, in case of denominatorDegreesOfFreedom == 2, this must lead\nto a division-by-zero, resulting in POSTIVE_INFINITY. The result of this\noperation is then directly passed into the\nUnivariateRealSolverUtils.bracket() - method as second argument.\n"
            },
            "96": {
                "commit_sha_buggy": "704342d6280becc3be194a23dfda2e56c2a64aed",
                "commit_sha_fixed": "e6449cccdeaba96ffba4c27db322c5c3d5c18662",
                "report_id": "MATH-221",
                "report_url": "https://issues.apache.org/jira/browse/MATH-221",
                "issue_title": "[MATH-221] Result of multiplying and equals for complex numbers is wrong - ASF JIRA",
                "issue_description": "\nHi.\nThe bug relates on complex numbers.\nThe methods \"multiply\" and \"equals\" of the class Complex are involved.\nmathematic background:  (0,i) * (-1,0i) = (0,-i).\nlittle java program + output that shows the bug:\n-----------------------------------------------------------------------\n\nimport org.apache.commons.math.complex.*;\npublic class TestProg {\n        public static void main(String[] args) {\n\n                ComplexFormat f = new ComplexFormat();\n                Complex c1 = new Complex(0,1);\n                Complex c2 = new Complex(-1,0);\n\n                Complex res = c1.multiply(c2);\n                Complex comp = new Complex(0,-1);\n\n                System.out.println(\"res:  \"+f.format(res));\n                System.out.println(\"comp: \"+f.format(comp));\n\n                System.out.println(\"res=comp: \"+res.equals(comp));\n        }\n}\n\n\n-----------------------------------------------------------------------\nres:  -0 - 1i\ncomp: 0 - 1i\nres=comp: false\n-----------------------------------------------------------------------\nI think the \"equals\" should return \"true\".\nThe problem could either be the \"multiply\" method that gives (-0,-1i) instead of (0,-1i),\nor if you think thats right, the equals method has to be modified.\nGood Luck\nDieter\n"
            },
            "97": {
                "commit_sha_buggy": "7cf0c980d5d814daf187502bc07da0542ed7a828",
                "commit_sha_fixed": "ed492bd0c5c5c3a0258a65cb31cc8723d8f011fd",
                "report_id": "MATH-204",
                "report_url": "https://issues.apache.org/jira/browse/MATH-204",
                "issue_title": "[MATH-204] BrentSolver throws IllegalArgumentException  - ASF JIRA",
                "issue_description": "\nI am getting this exception:\njava.lang.IllegalArgumentException: Function values at endpoints do not have different signs.  Endpoints: [-100000.0,1.7976931348623157E308]  Values: [0.0,-101945.04630982173]\nat org.apache.commons.math.analysis.BrentSolver.solve(BrentSolver.java:99)\nat org.apache.commons.math.analysis.BrentSolver.solve(BrentSolver.java:62)\nThe exception should not be thrown with values  [0.0,-101945.04630982173] because 0.0 is positive.\nAccording to Brent Worden, the algorithm should stop and return 0 as the root instead of throwing an exception.\nThe problem comes from this method:\n    public double solve(double min, double max) throws MaxIterationsExceededException, \n        FunctionEvaluationException {\n        clearResult();\n        verifyInterval(min, max);\n        double yMin = f.value(min);\n        double yMax = f.value(max);\n        // Verify bracketing\n        if (yMin * yMax >= 0) \n{\n            throw new IllegalArgumentException\n            (\"Function values at endpoints do not have different signs.\" +\n                    \"  Endpoints: [\" + min + \",\" + max + \"]\" + \n                    \"  Values: [\" + yMin + \",\" + yMax + \"]\");       \n        }\n\n        // solve using only the first endpoint as initial guess\n        return solve(min, yMin, max, yMax, min, yMin);\n    }\nOne way to fix it would be to add this code after the assignment of yMin and yMax:\n        if (yMin ==0 || yMax == 0) \n{\n        \treturn 0;\n       \t}\n            "
            },
            "98": {
                "commit_sha_buggy": "26cf6d543deeb2e59564ba23568c83eda2b389bd",
                "commit_sha_fixed": "a0f3e0435c405ec842240413e2165863c9c76a16",
                "report_id": "MATH-209",
                "report_url": "https://issues.apache.org/jira/browse/MATH-209",
                "issue_title": "[MATH-209] RealMatrixImpl#operate gets result vector dimensions wrong - ASF JIRA",
                "issue_description": "\norg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix.\nThus line 640 in RealMatrixImpl.java should read\ndouble[] out = new double[nRows];\ninstead of\ndouble[] out = new double[v.length];\n"
            },
            "99": {
                "commit_sha_buggy": "924b6d76a2d44baf858c3aee46ab1439c9641959",
                "commit_sha_fixed": "58b5609fe8f99aabc990d885bf6c4d85631b7c79",
                "report_id": "MATH-243",
                "report_url": "https://issues.apache.org/jira/browse/MATH-243",
                "issue_title": "[MATH-243] MathUtils.gcd(Integer.MIN_VALUE, 0) should throw an Exception instead of returning Integer.MIN_VALUE - ASF JIRA",
                "issue_description": "\nThe gcd method should throw an Exception for gcd(Integer.MIN_VALUE, 0), like for gcd(Integer.MIN_VALUE, Integer.MIN_VALUE). The method should only return nonnegative results.\n"
            },
            "100": {
                "commit_sha_buggy": "0e9b00010655cffb2bd0443cca5706588bfc628d",
                "commit_sha_fixed": "876d133334e8dde309cc11f884c0dd4cc9ce530e",
                "report_id": "MATH-200",
                "report_url": "https://issues.apache.org/jira/browse/MATH-200",
                "issue_title": "[MATH-200] AbstractEstimator: getCovariances() and guessParametersErrors() crash when having bound parameters - ASF JIRA",
                "issue_description": "\nthe two methods getCovariances() and guessParametersErrors() from org.apache.commons.math.estimation.AbstractEstimator crash with ArrayOutOfBounds exception when some of the parameters are bound. The reason is that the Jacobian is calculated only for the unbound parameters. in the code you loop through all parameters.\nline #166: final int cols = problem.getAllParameters().length;\nshould be replaced by:  final int cols = problem.getUnboundParameters().length;\n(similar changes could be done in guessParametersErrors())\nthe dissadvantage of the above bug fix is that what is returned to the user is an array with smaller size than the number of all parameters. Alternatively, you can have some logic in the code which writes zeros for the elements of the covariance matrix corresponding to the bound parameters\n"
            },
            "101": {
                "commit_sha_buggy": "29b732ce0f974e2347b50477c401f0c503a8a981",
                "commit_sha_fixed": "32643d19538ad853a1280eb4060c4f15ac6dc3dd",
                "report_id": "MATH-198",
                "report_url": "https://issues.apache.org/jira/browse/MATH-198",
                "issue_title": "[MATH-198] java.lang.StringIndexOutOfBoundsException in ComplexFormat.parse(String source, ParsePosition pos) - ASF JIRA",
                "issue_description": "\nThe parse(String source, ParsePosition pos) method in the ComplexFormat class does not check whether the imaginary character is set or not which produces StringIndexOutOfBoundsException in the substring method :\n(line 375 of ComplexFormat)\n...\n        // parse imaginary character\n        int n = getImaginaryCharacter().length();\n        startIndex = pos.getIndex();\n        int endIndex = startIndex + n;\n        if (source.substring(startIndex, endIndex).compareTo(\n            getImaginaryCharacter()) != 0) {\n...\nI encoutered this exception typing in a JTextFied with ComplexFormat set to look up an AbstractFormatter.\nIf only the user types the imaginary part of the complex number first, he gets this exception.\nSolution: Before setting to n length of the imaginary character, check if the source contains it. My proposal:\n...\n        int n = 0;\n        if (source.contains(getImaginaryCharacter()))\n        n = getImaginaryCharacter().length();\n...\t\t \nF.S.\n"
            },
            "102": {
                "commit_sha_buggy": "f9b16a4ae42164d096dd21cc060c0802039ba15a",
                "commit_sha_fixed": "a1bac127067c912b4a9f7a2957c427853a36c730",
                "report_id": "MATH-175",
                "report_url": "https://issues.apache.org/jira/browse/MATH-175",
                "issue_title": "[MATH-175] chiSquare(double[] expected, long[] observed) is returning incorrect test statistic - ASF JIRA",
                "issue_description": "\nChiSquareTestImpl is returning incorrect chi-squared value. An implicit assumption of public double chiSquare(double[] expected, long[] observed) is that the sum of expected and observed are equal. That is, in the code:\nfor (int i = 0; i < observed.length; i++) \n{\n            dev = ((double) observed[i] - expected[i]);\n            sumSq += dev * dev / expected[i];\n        }\nthis calculation is only correct if sum(observed)==sum(expected). When they are not equal then one must rescale the expected value by sum(observed) / sum(expected) so that they are.\nIronically, it is an example in the unit test ChiSquareTestTest that highlights the error:\nlong[] observed1 = \n{ 500, 623, 72, 70, 31 }\n;\n        double[] expected1 = \n{ 485, 541, 82, 61, 37 }\n;\n        assertEquals( \"chi-square test statistic\", 16.4131070362, testStatistic.chiSquare(expected1, observed1), 1E-10);\n        assertEquals(\"chi-square p-value\", 0.002512096, testStatistic.chiSquareTest(expected1, observed1), 1E-9);\n16.413 is not correct because the expected values do not make sense, they should be: 521.19403 581.37313  88.11940  65.55224  39.76119 so that the sum of expected equals 1296 which is the sum of observed.\nHere is some R code (r-project.org) which proves it:\n> o1\n[1] 500 623  72  70  31\n> e1\n[1] 485 541  82  61  37\n> chisq.test(o1,p=e1,rescale.p=TRUE)\n        Chi-squared test for given probabilities\ndata:  o1 \nX-squared = 9.0233, df = 4, p-value = 0.06052\n> chisq.test(o1,p=e1,rescale.p=TRUE)$observed\n[1] 500 623  72  70  31\n> chisq.test(o1,p=e1,rescale.p=TRUE)$expected\n[1] 521.19403 581.37313  88.11940  65.55224  39.76119\n"
            },
            "103": {
                "commit_sha_buggy": "b8058233e92ad635fe204f450235cad597cd70f2",
                "commit_sha_fixed": "4ce05bcd51ec956d789d20b59c743603d24a8ab7",
                "report_id": "MATH-167",
                "report_url": "https://issues.apache.org/jira/browse/MATH-167",
                "issue_title": "[MATH-167] ConvergenceException in normal CDF - ASF JIRA",
                "issue_description": "\nNormalDistributionImpl::cumulativeProbability(double x) throws ConvergenceException\nif x deviates too much from the mean. For example, when x=+/-100, mean=0, sd=1.\nOf course the value of the CDF is hard to evaluate in these cases,\nbut effectively it should be either zero or one.\n"
            },
            "104": {
                "commit_sha_buggy": "c43fa5d5abc9a17a1bcc05831dfc42a5d0195bff",
                "commit_sha_fixed": "e39a7750ef362679599b623b05bfadb150832515",
                "report_id": "MATH-166",
                "report_url": "https://issues.apache.org/jira/browse/MATH-166",
                "issue_title": "[MATH-166] Special functions not very accurate - ASF JIRA",
                "issue_description": "\nThe Gamma and Beta functions return values in double precision but the default epsilon is set to 10e-9. I think that the default should be set to the highest possible accuracy, as this is what I'd expect to be returned by a double precision routine. Note that the erf function already uses a call to Gamma.regularizedGammaP with an epsilon of 1.0e-15.\n"
            },
            "105": {
                "commit_sha_buggy": "ab1b9500fd4b6898757e9c74dc2eeae692b25146",
                "commit_sha_fixed": "fc21b26f84312e4f75e8b144238618c73a8b091f",
                "report_id": "MATH-85",
                "report_url": "https://issues.apache.org/jira/browse/MATH-85",
                "issue_title": "[MATH-85] [math]  SimpleRegression getSumSquaredErrors - ASF JIRA",
                "issue_description": "\ngetSumSquaredErrors returns -ve value. See test below:\npublic void testSimpleRegression() {\n\t\tdouble[] y = \n{  8915.102, 8919.302, 8923.502}\n;\n\t\tdouble[] x = \n{ 1.107178495, 1.107264895, 1.107351295}\n;\n\t\tdouble[] x2 = \n{ 1.107178495E2, 1.107264895E2, 1.107351295E2}\n;\n\t\tSimpleRegression reg = new SimpleRegression();\n\t\tfor (int i = 0; i < x.length; i++) \n{\n\t\t\treg.addData(x[i],y[i]);\n\t\t}\n\t\tassertTrue(reg.getSumSquaredErrors() >= 0.0); // OK\n\t\treg.clear();\n\t\tfor (int i = 0; i < x.length; i++) \n{\n\t\t\treg.addData(x2[i],y[i]);\n\t\t}\n\t\tassertTrue(reg.getSumSquaredErrors() >= 0.0); // FAIL\n\t}\n"
            },
            "106": {
                "commit_sha_buggy": "5de83dca70afabf12bd46bb9ab438753c14c7453",
                "commit_sha_fixed": "41ba9e00e3bbde990f6821f67f0da2a5575b9ac3",
                "report_id": "MATH-60",
                "report_url": "https://issues.apache.org/jira/browse/MATH-60",
                "issue_title": "[MATH-60] [math] Function math.fraction.ProperFractionFormat.parse(String, ParsePosition) return illogical result - ASF JIRA",
                "issue_description": "\nHello,\nI find illogical returned result from function \"Fraction parse(String source, \nParsePostion pos)\" (in class ProperFractionFormat of the Fraction Package) of \nthe Commons Math library. Please see the following code segment for more \ndetails:\n\"\nProperFractionFormat properFormat = new ProperFractionFormat();\nresult = null;\nString source = \"1 -1 / 2\";\nParsePosition pos = new ParsePosition(0);\n//Test 1 : fail \npublic void testParseNegative(){\n   String source = \"-1 -2 / 3\";\n   ParsePosition pos = new ParsePosition(0);\n   Fraction actual = properFormat.parse(source, pos);\n   assertNull(actual);\n}\n// Test2: success\npublic void testParseNegative(){\n   String source = \"-1 -2 / 3\";\n   ParsePosition pos = new ParsePosition(0);\n   Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3\n   assertEquals(1, source.getNumerator());\n   assertEquals(3, source.getDenominator());\n}\n\"\nNote: Similarly, when I passed in the following inputs: \n  input 2: (source = \u201c1 2 / -3\u201d, pos = 0)\n  input 3: ( source = \u201d -1 -2 / 3\u201d, pos = 0)\nFunction \"Fraction parse(String, ParsePosition)\" returned Fraction 1/3 (means \nthe result Fraction had numerator = 1 and  denominator = 3)for all 3 inputs \nabove.\nI think the function does not handle parsing the numberator/ denominator \nproperly incase input string provide invalid numerator/denominator. \nThank you!\n"
            }
        }
    },
    "Math": {
        "owner_repo": "apache/commons-math",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3066a8085f86b743da14a161427c403a7038e8b0",
                "commit_sha_fixed": "0880a21c56cec1a2442b5123c3845bfc99e83a7f",
                "report_id": "MATH-1356",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1356",
                "issue_title": "[MATH-1356] HypergeometricDistribution probability give NaN result - ASF JIRA",
                "issue_description": "\nHi,\nUnless I am mistaken the HypergeometricDistribution probability method returns NaN for the following cases :\nHypergeometricDistribution hgd = new HypergeometricDistribution(11,11,1);\ndouble probIT = hgd.probability(1);\nHypergeometricDistribution hgd = new HypergeometricDistribution(11,11,11);\ndouble probIT = hgd.probability(11);\nI think it should return 1.0\nThanks,\nThomas\n"
            },
            "2": {
                "commit_sha_buggy": "12c9a04414e95257cf0309e96ae8e1db36affdf2",
                "commit_sha_fixed": "7a8dc00b8be18a9271e2d9c2444ba91077ffafa5",
                "report_id": "MATH-1342",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1342",
                "issue_title": "[MATH-1342] ODE failure with close events - ASF JIRA",
                "issue_description": "\nODE integration crashes if two events are closer to each other than the root finder's tolerance.\n"
            },
            "3": {
                "commit_sha_buggy": "c9b1c8f9662f865a613632e1d390922050130b60",
                "commit_sha_fixed": "564345179f3f33d249daca36f0054773996d5782",
                "report_id": "MATH-1297",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1297",
                "issue_title": "[MATH-1297] multistep integrator start failure triggers NPE - ASF JIRA",
                "issue_description": "\nMultistep ODE integrators like Adams-Bashforth and Adams-Moulton require a starter procedure.\nIf the starter integrator is not configured properly, it will not create the necessary number of initial points and the multistep integrator will not be initialized correctly. This results in NullPointErException when the scaling array is referenced later on.\nThe following test case (with an intentionally wrong starter configuration) shows the problem.\n\n@Test\npublic void testStartFailure() {\n\n     TestProblem1 pb = new TestProblem1();\n      double minStep = 0.0001 * (pb.getFinalTime() - pb.getInitialTime());\n      double maxStep = pb.getFinalTime() - pb.getInitialTime();\n      double scalAbsoluteTolerance = 1.0e-6;\n      double scalRelativeTolerance = 1.0e-7;\n\n      MultistepIntegrator integ =\n          new AdamsBashforthIntegrator(4, minStep, maxStep,\n                                                            scalAbsoluteTolerance,\n                                                            scalRelativeTolerance);\n      integ.setStarterIntegrator(new DormandPrince853Integrator(0.2 * (pb.getFinalTime() - pb.getInitialTime()),\n                                                                pb.getFinalTime() - pb.getInitialTime(),\n                                                                0.1, 0.1));\n      TestProblemHandler handler = new TestProblemHandler(pb, integ);\n      integ.addStepHandler(handler);\n      integ.integrate(pb,\n                             pb.getInitialTime(), pb.getInitialState(),\n                             pb.getFinalTime(), new double[pb.getDimension()]);\n\n    }\n\n\nFailure to start the integrator should be detected and an appropriate exception should be triggered.\n"
            },
            "4": {
                "commit_sha_buggy": "793e9df0436cefdbf523bba70ac621493ce9e649",
                "commit_sha_fixed": "a94ff90ab6cd2d92ccb2eb1fd7913b4e5256f02b",
                "report_id": "MATH-1269",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1269",
                "issue_title": "[MATH-1269] FastMath.exp may return NaN for non-NaN arguments - ASF JIRA",
                "issue_description": "\nI have observed that FastMath.exp(709.8125) returns NaN. However, the exponential function must never return NaN (if the argument is not NaN). The result must always be non-negative or positive infinity.\n"
            },
            "5": {
                "commit_sha_buggy": "260a4392a8a257cbb34fe3564301659589c05240",
                "commit_sha_fixed": "9e0c5ad4b3148f42f3940faf7d67b305e34bef0d",
                "report_id": "MATH-1283",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1283",
                "issue_title": "[MATH-1283] Gamma function computation - ASF JIRA",
                "issue_description": "\nIn the gamma method, when handling the case \"absX > 20\", the computation of gammaAbs should replace \"x\" (see code below with x in bold) by \"absX\".\nFor large negative values of x, the function returns with the wrong sign.\nfinal double gammaAbs = SQRT_TWO_PI / x *\n                                     FastMath.pow(y, absX + 0.5) *\n                                     FastMath.exp(-y) * lanczos(absX);\n"
            },
            "6": {
                "commit_sha_buggy": "6fe2094e30107512e470571bceac91cbedbd21d0",
                "commit_sha_fixed": "fb0078159d2463da149de54018fca79a9447153e",
                "report_id": "MATH-1277",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1277",
                "issue_title": "[MATH-1277] Incorrect Kendall Tau calc due to data type mistmatch - ASF JIRA",
                "issue_description": "\nThe Kendall Tau calculation returns a number from -1.0 to 1.0\ndue to a mixing of ints and longs, a mistake occurs on large size columns (arrays) passed to the function. an array size of > 50350 triggers the condition in my case - although it may be data dependent\nthe ver 3.5 library returns 2.6 as a result (outside of the defined range of Kendall Tau)\nwith the cast to long below - the result reutns to its expected value\ncommons.math3.stat.correlation.KendallsCorrelation.correlation\nhere's the sample code I used:\nI added the cast to long of swaps in the \n\t\t\tint swaps = 1077126315;\n\t\t\t final long numPairs = sum(50350 - 1);\n\t\t\t    long tiedXPairs = 0;\n\t\t        long tiedXYPairs = 0;\n\t\t        long tiedYPairs = 0;\n\t\t  final long concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * (long) swaps;\n\t        final double nonTiedPairsMultiplied = 1.6e18;\n\t        double myTest = concordantMinusDiscordant / FastMath.sqrt(nonTiedPairsMultiplied);\n"
            },
            "7": {
                "commit_sha_buggy": "941b13f8ede6dbaa4fa64ebb9b9156c2709cd281",
                "commit_sha_fixed": "26e878ab3a5b0844e09ce305fa07eb2d0ad93d41",
                "report_id": "MATH-1272",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1272",
                "issue_title": "[MATH-1272] FastMath.pow(double, long) enters an infinite loop with Long.MIN_VALUE - ASF JIRA",
                "issue_description": "\nFastMath.pow(double, long) enters an infinite loop with Long.MIN_VALUE. It cannot be negated, so unsigned shift (>>>) is required instead of a signed one (>>).\n"
            },
            "8": {
                "commit_sha_buggy": "44c6d267aecde0d20cd6d700ba0e6899e02e536e",
                "commit_sha_fixed": "4c4b3e2e32ddae35e4c1a6ffce1cd2b2eafa958b",
                "report_id": "MATH-1261",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1261",
                "issue_title": "[MATH-1261] Overflow checks in Fraction multiply(int) / divide(int) - ASF JIRA",
                "issue_description": "\nThe member methods multiply(int) / divide(int) in the class org.apache.commons.math3.fraction.Fraction do not have overflow checks.\n\nreturn new Fraction(numerator * i, denominator);\n\n\nshould be\n\nreturn new Fraction(ArithmeticUtils.mulAndCheck(numerator, i), denominator);\n\n\nor, considering the case gcd(i, denominator) > 1,\n\nreturn multiply(new Fraction(i));\n\n\n"
            },
            "9": {
                "commit_sha_buggy": "e7e8c3f7177e22b5fa766d931d52142c9fc55f49",
                "commit_sha_fixed": "03178c8b15f1b522b98ded0f83cfb0e79f5ec4d3",
                "report_id": "MATH-1257",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1257",
                "issue_title": "[MATH-1257] NormalDistribution.cumulativeProbability() suffers from cancellation - ASF JIRA",
                "issue_description": "\nI see the following around line 194:\n\n        return 0.5 * (1 + Erf.erf(dev / (standardDeviation * SQRT2)));\n\n\nWhen erf() returns a very small value, this cancels in the addition with the \"1.0\" which leads to poor precision in the results.\nI would suggest changing this line to read more like:\n\nreturn 0.5 * Erf.erfc( -dev / standardDeviation * SQRT2 );\n\n\nShould you want some test cases for \"extreme values\" (one might argue that within 10 standard deviations isn't all that extreme) then you can check the following: http://www.jstatsoft.org/v52/i07/ then look in the v52i07-xls.zip at replication-01-distribution-standard-normal.xls\nI think you will also find that evaluation of expressions such as \n\nNormalDistribution( 0, 1 ).cumulativeProbability( -10.0 );\n\nare pretty far off.\n"
            },
            "10": {
                "commit_sha_buggy": "4f548acfd1236ed5024eff0ee081dced6e078659",
                "commit_sha_fixed": "41f297809965523fcd021bef20b304b3584d9b4f",
                "report_id": "MATH-1256",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1256",
                "issue_title": "[MATH-1256] Interval class upper and lower check - ASF JIRA",
                "issue_description": "\nIn class Interval, which is in the package org.apache.commons.math4.geometry.euclidean.oned it is possible to pass the value for variable upper  less than the value of variable lower, which is logically incorrect and  also causes the method getSize() to return negative value.\nFor example:\n @Test\n  public void test1()  throws Throwable  \n{\n      Interval interval0 = new Interval(0.0, (-1.0));\n      double double0 = interval0.getSize();\n      assertEquals((-1.0), double0, 0.01D);\n  }\n\n            "
            },
            "11": {
                "commit_sha_buggy": "5d49c9797e5263eb93e934786c15e0dde38e2d47",
                "commit_sha_fixed": "09fe956a62e19c160d0093f8fecf254c2bb6f0cb",
                "report_id": "MATH-1252",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1252",
                "issue_title": "[MATH-1252] ResizableDoubleArray does not work with double array of size 1 - ASF JIRA",
                "issue_description": "\nWhen attempting to create a ResizableDoubleArray with an array of a single value (e.g. \n{4.0}\n), the constructor creates an internal array with 16 entries that are all 0.0\nBug looks like it might be on line 414 of ResizableDoubleArray.java:\n        if (data != null && data.length > 1) {\n"
            },
            "12": {
                "commit_sha_buggy": "276e22858cdd56f5725e0c2f7a3522df99967973",
                "commit_sha_fixed": "471e6b078a7891aea99b77f200e828a7b1c9bc00",
                "report_id": "MATH-1241",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1241",
                "issue_title": "[MATH-1241] Digamma calculation produces SOE on NaN argument - ASF JIRA",
                "issue_description": "\nDigamma doesn't work particularly well with NaNs.\nHow to reproduce: call Gamma.digamma(Double.NaN)\nExpected outcome: returns NaN or throws a meaningful exception\nReal outcome: crashes with StackOverflowException, as digamma enters infinite recursion.\n"
            },
            "13": {
                "commit_sha_buggy": "12ec16006ab2b2f8f5bf4b1caff265ae7da9d344",
                "commit_sha_fixed": "8f35fcb8f7b17c7201a31f157e7d77bf3e6fe2b5",
                "report_id": "MATH-1232",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1232",
                "issue_title": "[MATH-1232] UknownParameterException message prints {0} instead of parameter name - ASF JIRA",
                "issue_description": "\nThe constructor for UnknownParameterException stores the\nparameter name internally but does not forward it to the base class which creates the error message.\n"
            },
            "14": {
                "commit_sha_buggy": "d746a54c2ee50711283bb49e557f58ca491e1bac",
                "commit_sha_fixed": "a56d4998cf16ff08f5593fb7d4dda66ca05dc269",
                "report_id": "MATH-1204",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1204",
                "issue_title": "[MATH-1204] bracket function gives up too early  - ASF JIRA",
                "issue_description": "\nIn UnivariateSolverUtils.bracket(...) the search ends prematurely if a = lowerBound, which ignores some roots in the interval. \n"
            },
            "15": {
                "commit_sha_buggy": "7fb571b16cc4a0912e8d74609941563c79fe9e97",
                "commit_sha_fixed": "2fb2221d487d925fd5d716173a80c798986aadf0",
                "report_id": "MATH-1181",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1181",
                "issue_title": "[MATH-1181] KolmogorovSmirnov test algorithm choice prone to integer overflow - ASF JIRA",
                "issue_description": "\nThe computation used to select the algorithm in the 2-sample KS test is prone to integer overflow, resulting in the \"exact\" method being chosen for very large samples, resulting in impractically long execution time.\n"
            },
            "16": {
                "commit_sha_buggy": "2bc9e7ea86a8cc1c3b2436c46115c87080228004",
                "commit_sha_fixed": "76f154179b8dc6940355d7fe7db468314ca39e84",
                "report_id": "MATH-1145",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1145",
                "issue_title": "[MATH-1145] Integer overflows MannWhitneyUTest#mannWhitneyU - ASF JIRA",
                "issue_description": "\nIn the calculation of MannWhitneyUTest#mannWhitneyU there are two instances where the lengths of the input arrays are multiplied together. Because Array#length is an integer this means that the effective maximum size of your dataset until reaching overflow is Math.sqrt(Integer.MAX_VALUE).\nThe following is a link to a diff, with a test the exposes the issue, and a fix (casting lengths up into doubles before multiplying).\nhttps://gist.github.com/aconbere/4fef56e5182e510aceb3\n"
            },
            "17": {
                "commit_sha_buggy": "a7363a2ae67b585790896de45f57154474480fc9",
                "commit_sha_fixed": "cc4ab51ee9e001a0a999a2a43ad5bd323494b800",
                "report_id": "MATH-1136",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1136",
                "issue_title": "[MATH-1136] BinomialDistribution deals with degenerate cases incorrectly - ASF JIRA",
                "issue_description": "\nThe following calculation returns false results:\nnew BinomialDistribution(0, 0.01).logProbability(0)\nIt evaluates to Double.NaN when it should be 0 (cf., for example, \"dbinom(0, 0, 0.01, log=T)\" in R).\nI attach a patch dealing with the problem. The patch also adds a test for this bug.\n"
            },
            "18": {
                "commit_sha_buggy": "ad882055edb50369bd174ae56a372838aa89cdae",
                "commit_sha_fixed": "a7363a2ae67b585790896de45f57154474480fc9",
                "report_id": "MATH-1135",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1135",
                "issue_title": "[MATH-1135] Bug in MonotoneChain: a collinear point landing on the existing boundary should be dropped (patch) - ASF JIRA",
                "issue_description": "\nThe is a bug on the code in MonotoneChain.java that attempts to handle the case of a point on the line formed by the previous last points and the last point of the chain being constructed. When `includeCollinearPoints` is false, the point should be dropped entirely. In common-math 3,3, the point is added, which in some cases can cause a `ConvergenceException` to be thrown.\nIn the patch below, the data points are from a case that showed up in testing before we went to production.\n\nIndex: src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java\n===================================================================\n--- src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java\t(revision 1609491)\n+++ src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java\t(working copy)\n@@ -160,8 +160,8 @@\n                 } else {\n                     if (distanceToCurrent > distanceToLast) {\n                         hull.remove(size - 1);\n+                        hull.add(point);\n                     }\n-                    hull.add(point);\n                 }\n                 return;\n             } else if (offset > 0) {\nIndex: src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java\n===================================================================\n--- src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java\t(revision 1609491)\n+++ src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java\t(working copy)\n@@ -204,6 +204,24 @@\n     }\n \n     @Test\n+    public void testCollinnearPointOnExistingBoundary() {\n+        final Collection<Vector2D> points = new ArrayList<Vector2D>();\n+        points.add(new Vector2D(7.3152, 34.7472));\n+        points.add(new Vector2D(6.400799999999997, 34.747199999999985));\n+        points.add(new Vector2D(5.486399999999997, 34.7472));\n+        points.add(new Vector2D(4.876799999999999, 34.7472));\n+        points.add(new Vector2D(4.876799999999999, 34.1376));\n+        points.add(new Vector2D(4.876799999999999, 30.48));\n+        points.add(new Vector2D(6.0959999999999965, 30.48));\n+        points.add(new Vector2D(6.0959999999999965, 34.1376));\n+        points.add(new Vector2D(7.315199999999996, 34.1376));\n+        points.add(new Vector2D(7.3152, 30.48));\n+\n+        final ConvexHull2D hull = generator.generate(points);\n+        checkConvexHull(points, hull);\n+    }\n+\n+    @Test\n     public void testIssue1123() {\n \n         List<Vector2D> points = new ArrayList<Vector2D>();\n\n\n"
            },
            "19": {
                "commit_sha_buggy": "e1db2379ff3a09614f7287354406cb984f87f43d",
                "commit_sha_fixed": "a197ba858ecf364f9ddf2fe56f3611cf97b4c3b1",
                "report_id": "MATH-1123",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1123",
                "issue_title": "[MATH-1123] NPE in BSPTree#fitToCell() - ASF JIRA",
                "issue_description": "\nHello, \nI faced a NPE using  BSPTree#fitToCell() from the SVN trunk. I fixed the problem using a small patch I will attach to the ticket.\n"
            },
            "20": {
                "commit_sha_buggy": "013f3687471d5ccec937dfc1e321b3b60b5d3524",
                "commit_sha_fixed": "5a6ccd587231ed1268dbdf142bf1f98065ad8348",
                "report_id": "MATH-1121",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1121",
                "issue_title": "[MATH-1121] Brent optimizer doesn't use the Base optimizer iteration counter - ASF JIRA",
                "issue_description": "\nBrentOptimizer uses \"iter\" defined in \"doOptimize\"  to count iterations.\nIt should ideally use the iteration counter defined for the BaseOptimizer.\n"
            },
            "21": {
                "commit_sha_buggy": "f4c926ea82771de22a32150a8b0b1a502faf34b2",
                "commit_sha_fixed": "2a6c6409a919c1091ef3af778cc9738c57d67575",
                "report_id": "MATH-1115",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1115",
                "issue_title": "[MATH-1115] Constructor of PolyhedronsSet throws NullPointerException - ASF JIRA",
                "issue_description": "\nThe following statement throws a NullPointerException:\nnew org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet(0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d);\nI found that other numbers also produce that effect. The stack trace:\njava.lang.NullPointerException\n        at org.apache.commons.math3.geometry.partitioning.BSPTree.fitToCell(BSPTree.java:297)\n        at org.apache.commons.math3.geometry.partitioning.BSPTree.insertCut(BSPTree.java:155)\n        at org.apache.commons.math3.geometry.partitioning.RegionFactory.buildConvex(RegionFactory.java:55)\n        at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.buildBoundary(PolyhedronsSet.java:119)\n        at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.<init>(PolyhedronsSet.java:97)\n"
            },
            "22": {
                "commit_sha_buggy": "cbc32459f8f36e5c57a9db74709e813e5f77bb5e",
                "commit_sha_fixed": "f4c926ea82771de22a32150a8b0b1a502faf34b2",
                "report_id": "MATH-1117",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1117",
                "issue_title": "[MATH-1117] twod.PolygonsSet.getSize produces NullPointerException if BSPTree has no nodes - ASF JIRA",
                "issue_description": "\norg.apache.commons.math3.geometry.euclidean.twod.PolygonsSet.getSize() uses a tree internally:\nfinal BSPTree<Euclidean2D> tree = getTree(false);\nHowever, if that tree contains no data, it seems that the reference returned is null, which causes a subsequent NullPointerException.\nProbably an exception with a message (\"tree has no data\") would clarify that this is an API usage error.\n"
            },
            "23": {
                "commit_sha_buggy": "a6f963066692aabd04aad9114e6ea1ccb32cbb5c",
                "commit_sha_fixed": "e2dc384d7bbe3414047049a67ca48b4885eba493",
                "report_id": "MATH-1106",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1106",
                "issue_title": "[MATH-1106] LevenburgMaquardt switched evaluation and iterations - ASF JIRA",
                "issue_description": ""
            },
            "24": {
                "commit_sha_buggy": "c9181d3b05de8f4d0de517355f35600aa21bb16c",
                "commit_sha_fixed": "e91d0f0510ee8d69c76ee89b4e57341418866c6b",
                "report_id": "MATH-1089",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1089",
                "issue_title": "[MATH-1089] Precision.round() returns different results when provided negative zero as double or float - ASF JIRA",
                "issue_description": "\nPrecision.round(-0.0d, x) = 0.0\nPrecision.round(-0.0f, x) = -0.0\nAfter discussion on the mailinglist, the result should always be -0.0.\n"
            },
            "25": {
                "commit_sha_buggy": "f7222ca6c3b6c1018a52fd649029394e6608f1db",
                "commit_sha_fixed": "b285f17023da248bdcb3093283e4b9e930bdd09c",
                "report_id": "MATH-1080",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1080",
                "issue_title": "[MATH-1080] The LinearConstraintSet shall return its constraints in a deterministic way - ASF JIRA",
                "issue_description": "\nAs previously discussed on the mailinglist, the LinearConstraintSet should return its internally stored LinearConstraints in the same iteration order as they have been provided via its constructor.\nThis ensures that the execution of the same linear problem results in the same results each time it is executed. This is especially important when linear problems are loaded from a file, e.g. mps format, and makes it simpler to debug problems and compare with other solvers which do the same thing.\n"
            },
            "26": {
                "commit_sha_buggy": "ba3c2201c6689818c457b5a03d14eb75af55063c",
                "commit_sha_fixed": "8e5867eda8328e4cb2e103d098d0c9f3c2fab50e",
                "report_id": "MATH-1070",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1070",
                "issue_title": "[MATH-1070] Incorrect rounding of float - ASF JIRA",
                "issue_description": "\npackage org.apache.commons.math3.util \nexample of usage of round functions of Precision class:\nPrecision.round(0.0f, 2, BigDecimal.ROUND_UP) = 0.01\nPrecision.round((float)0.0, 2, BigDecimal.ROUND_UP) = 0.01\nPrecision.round((float) 0.0, 2) = 0.0\nPrecision.round(0.0, 2, BigDecimal.ROUND_UP) = 0.0\nSeems the reason is usage of extending float to double inside round functions and getting influence of memory trash as value.\nI think, same problem will be found at usage of other round modes.\n"
            },
            "27": {
                "commit_sha_buggy": "67fc63b9942aeaac2c36cc25c746eb77c922d45c",
                "commit_sha_fixed": "4ebd967c96c43ae3f1009c3592e0a0588eae0f8a",
                "report_id": "MATH-1058",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1058",
                "issue_title": "[MATH-1058] Beta, LogNormalDistribution, WeibullDistribution give slightly wrong answer for extremely small args due to log/exp inaccuracy - ASF JIRA",
                "issue_description": "\nBackground for those who aren't familiar: math libs like Math and FastMath have two mysterious methods, log1p and expm1. log1p = log(1+x) and expm1 = exp-1 mathetmatically, but can return a correct answer even when x was small, where floating-point error due to the addition/subtraction introduces a relatively large error.\nThere are three instances in the code that can employ these specialized methods and gain a measurable improvement in accuracy. See patch and tests for an example \u2013 try the tests without the code change to see the error.\n"
            },
            "28": {
                "commit_sha_buggy": "d1c7e82e93470cb39edd6c9621c67c54318f6082",
                "commit_sha_fixed": "6683216e612474b605a5bfb7fa684352528ab784",
                "report_id": "MATH-1029",
                "report_url": "https://issues.apache.org/jira/browse/MATH-1029",
                "issue_title": "[MATH-1029] Creating BigFraction objects is not consistent for negative/positive values - ASF JIRA",
                "issue_description": "\nCreating a BigFraction object for large integer values will return different results whether the argument is positive or negative:\n\n  BigFraction f1 = new BigFraction(-1e10, 1000); -> will return a fraction with a numerator of -1e10 and denominator of 1\n  BigFraction f2 = new BigFraction(1e10, 1000); -> will throw a FractionConversionException\n\n\nthe problem is in the check for overflow, it is not done on the absolute value of the argument, also it should be done only after the check if the argument is actually an integer.\n"
            },
            "29": {
                "commit_sha_buggy": "43a6f15a1af977d6bf950dca17ab248e72ad8e95",
                "commit_sha_fixed": "73605560b9f0205ac641ec602145756305a41f79",
                "report_id": "MATH-938",
                "report_url": "https://issues.apache.org/jira/browse/MATH-938",
                "issue_title": "[MATH-938] Line.revert() is imprecise - ASF JIRA",
                "issue_description": "\nLine.revert() only maintains ~10 digits for the direction. This becomes an issue when the line's position is evaluated far from the origin. A simple fix would be to use Vector3D.negate() for the direction.\nAlso, is there a reason why Line is not immutable? It is just comprised of two vectors.\n"
            },
            "30": {
                "commit_sha_buggy": "0912bac5201d98af64a832766146797a9d75bb6f",
                "commit_sha_fixed": "5b9302d5be3c35f6336ebb6b7f6cbfe732761d72",
                "report_id": "MATH-778",
                "report_url": "https://issues.apache.org/jira/browse/MATH-778",
                "issue_title": "[MATH-778] Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n) - ASF JIRA",
                "issue_description": "\nIn class org.apache.commons.math3.Dfp,  the method multiply(int n) is limited to 0 <= n <= 9999. This is not consistent with the general contract of FieldElement.multiply(int n), where there should be no limitation on the values of n.\n"
            },
            "31": {
                "commit_sha_buggy": "8f423828e0d9f34896f87d803c559adf2d953f30",
                "commit_sha_fixed": "dd6cefb0ccb596d0597e2a9991766e109153ab25",
                "report_id": "MATH-780",
                "report_url": "https://issues.apache.org/jira/browse/MATH-780",
                "issue_title": "[MATH-780] BSPTree class and recovery of a Euclidean 3D BRep - ASF JIRA",
                "issue_description": "\nNew to the work here. Thanks for your efforts on this code.\nI create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(x,y,z) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem.\nAny ideas?\n"
            },
            "32": {
                "commit_sha_buggy": "fbbb96eb1784f1e7f8ac1ffc5c66fffa227206b2",
                "commit_sha_fixed": "328513f3adbcb683aebda8f1b38a0cb14d33de4e",
                "report_id": "MATH-555",
                "report_url": "https://issues.apache.org/jira/browse/MATH-555",
                "issue_title": "[MATH-555] MathUtils round method should propagate rather than wrap Runitme exceptions - ASF JIRA",
                "issue_description": "\nMathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.\n"
            },
            "33": {
                "commit_sha_buggy": "38983e820763c882e778c7d5c68b673fb45a210e",
                "commit_sha_fixed": "b01fcc31b9581676aeff2faae06738fa240657bc",
                "report_id": "MATH-290",
                "report_url": "https://issues.apache.org/jira/browse/MATH-290",
                "issue_title": "[MATH-290] NullPointerException in SimplexTableau.initialize - ASF JIRA",
                "issue_description": "\nSimplexTableau throws a NullPointerException when no solution can be found instead of a NoFeasibleSolutionException\nHere is the code that causes the NullPointerException:\nLinearObjectiveFunction f = new LinearObjectiveFunction(new double[] \n{ 1, 5 }\n, 0 );\nCollection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\nconstraints.add(new LinearConstraint(new double[] \n{ 2, 0 }\n, Relationship.GEQ, -1.0));\nRealPointValuePair solution = new SimplexSolver().optimize(f, constraints, GoalType.MINIMIZE, true);\nNote: Tested both with Apache Commons Math 2.0 release and SVN trunk\n"
            },
            "34": {
                "commit_sha_buggy": "b736c8bda6122b7f9f69cf0f52d80a23c3910bd8",
                "commit_sha_fixed": "2c443ab8b0efce5485f63eed62213091a188c993",
                "report_id": "MATH-200",
                "report_url": "https://issues.apache.org/jira/browse/MATH-200",
                "issue_title": "[MATH-200] AbstractEstimator: getCovariances() and guessParametersErrors() crash when having bound parameters - ASF JIRA",
                "issue_description": "\nthe two methods getCovariances() and guessParametersErrors() from org.apache.commons.math.estimation.AbstractEstimator crash with ArrayOutOfBounds exception when some of the parameters are bound. The reason is that the Jacobian is calculated only for the unbound parameters. in the code you loop through all parameters.\nline #166: final int cols = problem.getAllParameters().length;\nshould be replaced by:  final int cols = problem.getUnboundParameters().length;\n(similar changes could be done in guessParametersErrors())\nthe dissadvantage of the above bug fix is that what is returned to the user is an array with smaller size than the number of all parameters. Alternatively, you can have some logic in the code which writes zeros for the elements of the covariance matrix corresponding to the bound parameters\n"
            },
            "35": {
                "commit_sha_buggy": "cd5f65c4c7bd17d81ecb3924f444f2078a3ff580",
                "commit_sha_fixed": "faead6c3fbe343ba97e70f8eda74a488c916b29a",
                "report_id": "MATH-199",
                "report_url": "https://issues.apache.org/jira/browse/MATH-199",
                "issue_title": "[MATH-199] exception in LevenbergMarquardtEstimator - ASF JIRA",
                "issue_description": "\nI get this exception:\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: -1\n       at org.apache.commons.math.estimation.LevenbergMarquardtEstimator.qrDecomposition(LevenbergMarquardtEstimator.java:772)\n       at org.apache.commons.math.estimation.LevenbergMarquardtEstimator.estimate(LevenbergMarquardtEstimator.java:232)\n       at quadraticFitterProblem.QuadraticFitterProblem.<init>(QuadraticFitterProblem.java:27)\n       at quadraticFitterProblem.QuadraticFitterProblem.main(QuadraticFitterProblem.java:40)\non the code below.\nThe exception does not occur all the weights in the quadraticFitter are 0.0;\n---------------------------------------------------------------------------------------------\npackage quadraticFitterProblem;\nimport org.apache.commons.math.estimation.EstimationException;\nimport org.apache.commons.math.estimation.LevenbergMarquardtEstimator;\n//import org.apache.commons.math.estimation.WeightedMeasurement;\nimport com.strategicanalytics.dtd.data.smoothers.QuadraticFitter;\npublic class QuadraticFitterProblem {\n       private QuadraticFitter quadraticFitter;\n       public QuadraticFitterProblem() {\n         // create the uninitialized fitting problem\n         quadraticFitter = new QuadraticFitter();\n         quadraticFitter.addPoint (0,  -3.182591015485607, 0.0);\n         quadraticFitter.addPoint (1,  -2.5581184967730577, 4.4E-323);\n         quadraticFitter.addPoint (2,  -2.1488478161387325, 1.0);\n         quadraticFitter.addPoint (3,  -1.9122489313410047, 4.4E-323);\n         quadraticFitter.addPoint (4,  1.7785661310051026, 0.0);\n         try \n{\n           // solve the problem, using a Levenberg-Marquardt algorithm with\ndefault settings\n           LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n           //WeightedMeasurement[] wm = quadraticFitter.getMeasurements();\n           estimator.estimate(quadraticFitter);\n\n         }\n catch (EstimationException ee) \n{\n               System.err.println(ee.getMessage());\n         }\n       }\n       /**\n\n@param args\n        *\n        */\n       public static void main(String[] args) \n{\n\n                       new QuadraticFitterProblem();\n                       System.out.println (\"Done.\");\n       }\n\n}\n----------------------------------------------------------------------------------------------\nimport org.apache.commons.math.estimation.EstimatedParameter;\n//import org.apache.commons.math.estimation.EstimationException;\n//import org.apache.commons.math.estimation.LevenbergMarquardtEstimator;\nimport org.apache.commons.math.estimation.SimpleEstimationProblem;\nimport org.apache.commons.math.estimation.WeightedMeasurement;\npublic class QuadraticFitter extends SimpleEstimationProblem {\n       // y = a x<sup>2</sup> + b x + c\n   private EstimatedParameter a;\n   private EstimatedParameter b;\n   private EstimatedParameter c;\n   /**\n\nconstructor\n    *\n    *Fitter for a quadratic model to a sample of 2D points.\n<p>The model is y = a x<sup>2</sup> + b x + c\nits three parameters of the model are a, b and c.</p>\n    */\n   public QuadraticFitter() \n{\n\n       // three parameters of the model\n       a = new EstimatedParameter(\"a\", 0.0);\n       b = new EstimatedParameter(\"b\", 0.0);\n       c = new EstimatedParameter(\"c\", 0.0);\n\n       // provide the parameters to the base class which\n       // implements the getAllParameters and getUnboundParameters methods\n       addParameter(a);\n       addParameter(b);\n       addParameter(c);\n   }\n\n   /**\n\nAdd a sample point\n    *\n@param x abscissa\n@param y ordinate\n@param w weight\n    */\n   public void addPoint(double x, double y, double w) \n{\n       addMeasurement(new LocalMeasurement(x, y, w));\n   }\n\n   /**\n\nGet the value of the quadratic coefficient.\n    *\n@return the value of a for the quadratic model\ny = a x<sup>2</sup> + b x + c\n    */\n   public double getA() \n{\n       return a.getEstimate();\n   }\n\n   /**\n\nGet the value of the linear coefficient.\n    *\n@return the value of b for the quadratic model\ny = a x<sup>2</sup> + b x + c\n    */\n   public double getB() \n{\n       return b.getEstimate();\n   }\n\n   /**\n\nGet the value of the constant coefficient.\n    *\n@return the value of ac for the quadratic model\ny = a x<sup>2</sup> + b x + c\n    */\n   public double getC() \n{\n       return c.getEstimate();\n   }\n\n   /**\n\nGet the theoretical value of the model for some x.\n<p>The theoretical value is the value computed using\nthe current state of the problem parameters.</p>\n    *\nNote the use of H\u00f6rner's method (synthetic division) for\nevaluating polynomials,\n(more efficient)\n    *\n@param x explanatory variable\n@return the theoretical value y = a x<sup>2</sup> + b x + c\n    */\n   public double theoreticalValue(double x) \n{\n       //System.out.println (\"x = \" + x + \"  a.getEstimate() = \" +\na.getEstimate() + \"  b.getEstimate() = \" + b.getEstimate() + \"\nc.getEstimate() = \" + c.getEstimate());\n       return ( (a.getEstimate() * x + b.getEstimate() ) * x +\nc.getEstimate());\n   }\n\n   /**\n\nGet the partial derivative of the theoretical value\nof the model for some x.\n<p>The derivative is computed using\nthe current state of the problem parameters.</p>\n    *\n@param x explanatory variable\n@param parameter estimated parameter (either a, b, or c)\n@return the partial derivative dy/dp\n    */\n   private double partial(double x, EstimatedParameter parameter) {\n       // since we know the only parameters are a, b and c in this\n       // class we simply use \"==\" for efficiency\n       if (parameter == a) \n{\n           return x * x;\n       }\n else if (parameter == b) \n{\n           return x;\n       }\n else \n{\n           return 1.0;\n       }\n\n   }\n   /** Internal measurements class.\n\n<p>The measurement is the y value for a fixed specified x.</p>\n    */\n   private class LocalMeasurement extends WeightedMeasurement {\n\n       static final long serialVersionUID = 1;\n       private final double x;\n       // constructor\n       public LocalMeasurement(double x, double y, double w) \n{\n           super(w, y);\n           this.x = x;\n       }\n\n       public double getTheoreticalValue() \n{\n           // the value is provided by the model for the local x\n           return theoreticalValue(x);\n       }\n\n       public double getPartial(EstimatedParameter parameter) \n{\n           // the value is provided by the model for the local x\n           return partial(x, parameter);\n       }\n\n   }\n }\n"
            }
        }
    },
    "Mockito": {
        "owner_repo": "mockito/mockito",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "837fd054a0da2c8706732dcd4bc880a64b957c78",
                "commit_sha_fixed": "4e9d7607825c3c668fd43f19507bfead566c528c",
                "report_id": "188",
                "report_url": "https://github.com/mockito/mockito/issues/188",
                "issue_title": "ArgumentCaptor no longer working for varargs",
                "issue_description": "I ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n"
            },
            "2": {
                "commit_sha_buggy": "d30450fa1172d79cc051b2fe8064744c2ac7a003",
                "commit_sha_fixed": "80452c7a42777513c35fd30c4e12bcd7ee438fb9",
                "report_id": "197",
                "report_url": "https://github.com/mockito/mockito/issues/197",
                "issue_title": "Mockito.after() method accepts negative timeperiods and subsequent verifications always pass",
                "issue_description": "e.g.\n\n```\nRunnable runnable = Mockito.mock(Runnable.class);\nMockito.verify(runnable, Mockito.never()).run(); // passes as expected\nMockito.verify(runnable, Mockito.after(1000).never()).run(); // passes as expected\nMockito.verify(runnable, Mockito.after(-1000).atLeastOnce()).run(); // passes incorrectly\n```\n"
            },
            "3": {
                "commit_sha_buggy": "4e9d7607825c3c668fd43f19507bfead566c528c",
                "commit_sha_fixed": "3eec7451d6c83c280743c39b39c77a179abb30f9",
                "report_id": "188",
                "report_url": "https://github.com/mockito/mockito/issues/188",
                "issue_title": "ArgumentCaptor no longer working for varargs",
                "issue_description": "I ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n"
            },
            "4": {
                "commit_sha_buggy": "c25cb6bff7eb4774efda345e8bf9eaad4c66a652",
                "commit_sha_fixed": "42b391d4209024292b6101048389570e4ec36b2a",
                "report_id": "187",
                "report_url": "https://github.com/mockito/mockito/issues/187",
                "issue_title": "java.lang.ClassCastException: java.lang.Class cannot be cast to java.lang.String",
                "issue_description": "Exception throws on verifyZeroInteractions when using mock with default answer.\nchecked on versions 1.10.5-2.0.5\nall ok on 1.9.5\n"
            },
            "5": {
                "commit_sha_buggy": "fff76563d9e0ed412dc828c53cfdc7d142997a31",
                "commit_sha_fixed": "42a24dde02923185db3f79ae57e7819f7d70af55",
                "report_id": "152",
                "report_url": "https://github.com/mockito/mockito/issues/152",
                "issue_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError, NoClassDefFoundError)",
                "issue_description": "If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit, then the JVM may fail with a `VerifyError` or a `NoClassDefFoundError`.\n\nThis issue has been reported on the [mailing list](https://groups.google.com/forum/#!topic/mockito/A6D7myKiD5k) and on [StackOverflow](http://stackoverflow.com/questions/27721621/java-lang-verifyerror-with-mockito-1-10-17)\n\nA simple test like that with **TestNG** (and no JUnit in the class path of course) exposes the issue:\n\n```\nimport org.testng.annotations.Test;\nimport java.util.Observable;\nimport static org.mockito.Mockito.*;\n\npublic class VerifyErrorOnVerificationWithTimeoutTest {\n    @Test public void should_not_throw_VerifyError() {\n        verify(mock(Observable.class), timeout(500)).countObservers();\n    }\n}\n```\n\nWith TestNG 5.13.1, the stack trace is :\n\n```\njava.lang.VerifyError: (class: org/mockito/internal/verification/VerificationOverTimeImpl, method: verify signature: (Lorg/mockito/internal/verification/api/VerificationData;)V) Incompatible argument to function\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\n```\n\nTestNG includes a dependency on JUnit 3.8.1, which has the `junit.framework.ComparisonFailure`, but the JVM cannot perform the linking at runtime (`VerifyError` extends `LinkageError`), probably because for the JVM there's some incompatible changes in this class between version 3.x and 4.x.\nNote that Mockito is compiled against JUnit 4.x. This also reveal that Mockito is not anymore compatible with JUnit 3.x.\n\nWith TestNG 6.8.13, the stack trace is :\n\n```\njava.lang.NoClassDefFoundError: junit/framework/ComparisonFailure\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClassCond(ClassLoader.java:637)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:621)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n    at java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\nCaused by: java.lang.ClassNotFoundException: junit.framework.ComparisonFailure\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    ... 49 more\n```\n\nIndeed JUnit is not anymore a dependency of TestNG.\n\nIn this specific case the issue is that the `Timeout` class wraps a `VerficationOverTimeImpl` that uses in try/catch block the exception `org.mockito.exceptions.verification.junit.ArgumentsAreDifferent` which extends `junit.framework.ComparisonFailure`.\n\nAt this time it seems to be the only place where JUnit is needed, this affect the following public API : \n\n``` java\nMockito.timeout(...)\nMockito.after(...)\n```\n"
            },
            "6": {
                "commit_sha_buggy": "a7ba606944563adcdc631a2c04463a8124d26b02",
                "commit_sha_fixed": "dc205824dbc289acbcde919e430176ad72da847f",
                "report_id": "134",
                "report_url": "https://github.com/mockito/mockito/issues/134",
                "issue_title": "Argument matcher anyXxx() (i.e. anyString(), anyList()) should not match nulls",
                "issue_description": "This is a bug I'm seeing in 1.10.8 version (older version has the same issue - tested with 1.9.0).\n\nGiven:\n\n``` java\nFunction<Object, Integer> function = Mockito.mock(Function.class);\nwhen(function.apply(Mockito.anyString())).thenReturn(1);\nInteger result = function.apply(2);\n```\n\nExpected behavior:\n\n``` java\nresult == null;\n```\n\nActual behavior:\n\n``` java\nresult == 1;\n```\n\nNote that the function is called with an integer (not a string), and still the mocked function return the value which it should return only when a string is passed. The same works when using anyBoolean() or any other methof from any\\* family.\n"
            },
            "7": {
                "commit_sha_buggy": "3c8892b8a077598ecf988115214e5e01c310b08b",
                "commit_sha_fixed": "0aaa36ce6924ca87f88e3723771413b42b80dc5a",
                "report_id": "128",
                "report_url": "https://github.com/mockito/mockito/issues/128",
                "issue_title": "Deep stubbing with generic responses in the call chain is not working",
                "issue_description": "Deep stubbing will throw an Exception if multiple generics occur in the call chain. For instance, consider having a mock `myMock1` that provides a function that returns a generic `T`. If `T` also has a function that returns a generic, an Exception with the message \"Raw extraction not supported for : 'null'\" will be thrown.\n\nAs an example the following test will throw an Exception:\n\n``` Java\npublic class MockitoGenericsDeepStubTest {\n\n    @Test\n    public void discoverDeepMockingOfGenerics() {\n        MyClass1 myMock1 = mock(MyClass1.class, RETURNS_DEEP_STUBS);\n\n        when(myMock1.getNested().getNested().returnSomething()).thenReturn(\"Hello World.\");\n    }\n\n    public static interface MyClass1 <MC2 extends MyClass2> {\n        public MC2 getNested();\n    }\n\n    public static interface MyClass2<MC3 extends MyClass3> {\n        public MC3 getNested();\n    }\n\n    public static interface MyClass3 {\n        public String returnSomething();\n    }\n}\n```\n\nYou can make this test run if you step into the class `ReturnsDeepStubs` and change the method `withSettingsUsing` to return `MockSettings` with `ReturnsDeepStubs` instead of `ReturnsDeepStubsSerializationFallback` as default answer:\n\n``` Java\nprivate MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata, MockCreationSettings parentMockSettings) {\n    MockSettings mockSettings = returnTypeGenericMetadata.hasRawExtraInterfaces() ?\n            withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces())\n            : withSettings();\n\n    return propagateSerializationSettings(mockSettings, parentMockSettings)\n            .defaultAnswer(this);\n}\n```\n\nHowever, this breaks other tests and features.\n\nI think, the issue is that further generics are not possible to be mocked by `ReturnsDeepStubsSerializationFallback` since the `GenericMetadataSupport` is \"closed\" at this point.\n\nThanks and kind regards\nTobias\n"
            },
            "8": {
                "commit_sha_buggy": "9fb7d8b62814f959ceca6096d785b96c11bdfd0a",
                "commit_sha_fixed": "5a03bf5d0c9aedac9cfbf074833167c1eca6439f",
                "report_id": "114",
                "report_url": "https://github.com/mockito/mockito/issues/114",
                "issue_title": "1.10 regression (StackOverflowError) with interface where generic type has itself as upper bound",
                "issue_description": "Add this to `GenericMetadataSupportTest`:\n\n``` java\n    interface GenericsSelfReference<T extends GenericsSelfReference<T>> {\n        T self();\n    }\n\n    @Test\n    public void typeVariable_of_self_type() {\n        GenericMetadataSupport genericMetadata = inferFrom(GenericsSelfReference.class).resolveGenericReturnType(firstNamedMethod(\"self\", GenericsSelfReference.class));\n\n        assertThat(genericMetadata.rawType()).isEqualTo(GenericsSelfReference.class);\n    }\n```\n\nIt fails on master and 1.10.8 with this:\n\n```\njava.lang.StackOverflowError\n    at sun.reflect.generics.reflectiveObjects.TypeVariableImpl.hashCode(TypeVariableImpl.java:201)\n    at java.util.HashMap.hash(HashMap.java:338)\n    at java.util.HashMap.get(HashMap.java:556)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:193)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:196)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:196)\n```\n\nIt worked on 1.9.5. May be caused by the changes in ab9e9f3 (cc @bric3).\n\n(Also note that while the above interface looks strange, it is commonly used for builder hierarchies, where base class methods want to return this with a more specific type.)\n"
            },
            "9": {
                "commit_sha_buggy": "f45c2dc0c21f365218fa093106e45dbb0b54746a",
                "commit_sha_fixed": "31f908029b8cd9b1f32bed3a41651b30ebb47b9f",
                "report_id": "122",
                "report_url": "https://github.com/mockito/mockito/issues/122",
                "issue_title": "Problem spying on abstract classes",
                "issue_description": "There's a problem with spying on abstract classes when the real implementation calls out to the abstract method. More details: #121 \n"
            },
            "10": {
                "commit_sha_buggy": "b00a6d252f87c886e5f8830bbdb6c1af2bd0ee9c",
                "commit_sha_fixed": "1beeae39ac9f79d6a0db285dec311b78025ac062",
                "report_id": "99",
                "report_url": "https://github.com/mockito/mockito/issues/99",
                "issue_title": "RETURNS_DEEP_STUBS automatically tries to create serializable mocks",
                "issue_description": "I am just migrating from mockito 1.9.5 to 1.10.5\n\nThe following code runs fine with version 1.9.5. but breaks now:\n\n``` java\n\n  @Test\n  public void test() {\n    ToBeMocked mock = mock(ToBeMocked.class, RETURNS_DEEP_STUBS);\n    assertThat(mock.getSomething()).isNotNull();\n  }\n\n  public static class ToBeMocked {\n\n    NotSerializableReturnValue field1;\n\n    public ToBeMocked(NotSerializableReturnValue field1) {\n      this.field1 = field1;\n    }\n\n    public NotSerializableReturnValue getSomething() {\n      return field1;\n    }\n  }\n\n  public static class NotSerializableReturnValue {\n\n    String field1 = \"\";\n\n    public NotSerializableReturnValue(String field1) {\n      this.field1 = field1;\n    }\n\n    public String getSomething2() {\n      return field1;\n    }\n  }\n```\n\norg.mockito.exceptions.base.MockitoException: \nYou are using the setting 'withSettings().serializable()' however the type you are trying to mock 'NotSerializableReturnValue'\ndo not implement Serializable AND do not have a no-arg constructor.\n"
            },
            "11": {
                "commit_sha_buggy": "57be784ef15d4d4d685e59d7e855e01de81a77a5",
                "commit_sha_fixed": "1802cf79c482f2df29abb3d6735bcf0b16cedb7d",
                "report_id": "87",
                "report_url": "https://github.com/mockito/mockito/issues/87",
                "issue_title": "Fixed DelegatingMethod.equals() so that it's easier to extend Mockito by custom verification modes",
                "issue_description": "Currently if you create a DelegatingMethod and compare it to itself using .equals() it will show as not equal because the .equals() method expects a java.lang.reflect.Method (without explicitly stating such).  This has a knock on effect on the evaluation of InvocationImpl.equals() which at runtime may be using a DelegatingMethod in its .equals().\n\nI have changed .equals() and .hashCode() in DelegatingMethod to a more appropriate implementation, which can handle both the case where the input object is a DelegatingMethod and where it is a java.lang.reflect.Method.\n\nI ran up against this issue when creating a custom VerificationMode which used InvocationImpl.equals() to check that the appropriate invocation was made.  My comparison failed even though I was comparing two references to the same InvocationImpl instance.\n"
            },
            "12": {
                "commit_sha_buggy": "a154b66c1a87eb4ff26d91781414dde042bb9a9f",
                "commit_sha_fixed": "7a647a702c8af81ccf5d37b09c11529c6c0cb1b7",
                "report_id": "188",
                "report_url": "https://github.com/mockito/mockito/issues/188",
                "issue_title": "ArgumentCaptor no longer working for varargs",
                "issue_description": "I ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n"
            },
            "13": {
                "commit_sha_buggy": "88100667b90c4621178fd870fa1ca43060512fc6",
                "commit_sha_fixed": "2037361bea014c9ac87393eb96a95374dff46182",
                "report_id": "138",
                "report_url": "https://github.com/mockito/mockito/issues/138",
                "issue_title": "fix proposal for #114",
                "issue_description": ""
            },
            "14": {
                "commit_sha_buggy": "c478a8809b640713e8ffb6da2f554dda3a3674b0",
                "commit_sha_fixed": "9b2cf8072ece7c7629eff6037853b3e14ab5f524",
                "report_id": "138",
                "report_url": "https://github.com/mockito/mockito/issues/138",
                "issue_title": "fix proposal for #114",
                "issue_description": ""
            },
            "15": {
                "commit_sha_buggy": "77c6703f60d87b88b0e5b175b8fb0462483a8f69",
                "commit_sha_fixed": "81a380951402d2a158af115ed616ab36e94793b8",
                "report_id": "211",
                "report_url": "https://github.com/mockito/mockito/issues/211",
                "issue_title": "ArgumentCaptor no longer working for varargs",
                "issue_description": "Fixes #188 . These commits should fix issue with capturing varargs.\n"
            },
            "16": {
                "commit_sha_buggy": "188cbae7ae307e7c81c4ad321a4837dd93157b67",
                "commit_sha_fixed": "620f8faed0ad132961aae3a8671120e0929ce828",
                "report_id": "151",
                "report_url": "https://github.com/mockito/mockito/issues/151",
                "issue_title": "Investigate why #125 did not trigger release",
                "issue_description": "Investigate why #125 did not trigger release\n"
            },
            "17": {
                "commit_sha_buggy": "b6790ee34d8d858a89b80a9ae40f19d87ce1dab8",
                "commit_sha_fixed": "77cb2037314dd024eb53ffe2e9e06304088a2d53",
                "report_id": "152",
                "report_url": "https://github.com/mockito/mockito/issues/152",
                "issue_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError, NoClassDefFoundError)",
                "issue_description": "If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit, then the JVM may fail with a `VerifyError` or a `NoClassDefFoundError`.\n\nThis issue has been reported on the [mailing list](https://groups.google.com/forum/#!topic/mockito/A6D7myKiD5k) and on [StackOverflow](http://stackoverflow.com/questions/27721621/java-lang-verifyerror-with-mockito-1-10-17)\n\nA simple test like that with **TestNG** (and no JUnit in the class path of course) exposes the issue:\n\n```\nimport org.testng.annotations.Test;\nimport java.util.Observable;\nimport static org.mockito.Mockito.*;\n\npublic class VerifyErrorOnVerificationWithTimeoutTest {\n    @Test public void should_not_throw_VerifyError() {\n        verify(mock(Observable.class), timeout(500)).countObservers();\n    }\n}\n```\n\nWith TestNG 5.13.1, the stack trace is :\n\n```\njava.lang.VerifyError: (class: org/mockito/internal/verification/VerificationOverTimeImpl, method: verify signature: (Lorg/mockito/internal/verification/api/VerificationData;)V) Incompatible argument to function\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\n```\n\nTestNG includes a dependency on JUnit 3.8.1, which has the `junit.framework.ComparisonFailure`, but the JVM cannot perform the linking at runtime (`VerifyError` extends `LinkageError`), probably because for the JVM there's some incompatible changes in this class between version 3.x and 4.x.\nNote that Mockito is compiled against JUnit 4.x. This also reveal that Mockito is not anymore compatible with JUnit 3.x.\n\nWith TestNG 6.8.13, the stack trace is :\n\n```\njava.lang.NoClassDefFoundError: junit/framework/ComparisonFailure\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClassCond(ClassLoader.java:637)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:621)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n    at java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\nCaused by: java.lang.ClassNotFoundException: junit.framework.ComparisonFailure\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    ... 49 more\n```\n\nIndeed JUnit is not anymore a dependency of TestNG.\n\nIn this specific case the issue is that the `Timeout` class wraps a `VerficationOverTimeImpl` that uses in try/catch block the exception `org.mockito.exceptions.verification.junit.ArgumentsAreDifferent` which extends `junit.framework.ComparisonFailure`.\n\nAt this time it seems to be the only place where JUnit is needed, this affect the following public API : \n\n``` java\nMockito.timeout(...)\nMockito.after(...)\n```\n"
            },
            "18": {
                "commit_sha_buggy": "6237bd6e841dcae7b0e4d8cc3d0b7e14bf6694cc",
                "commit_sha_fixed": "8ceb04ad7317d8db24476b3b5f56ec9f658bc43a",
                "report_id": "210",
                "report_url": "https://github.com/mockito/mockito/issues/210",
                "issue_title": "Return empty value for Iterables",
                "issue_description": "http://code.google.com/p/mockito/issues/detail?id=175\n\nI expect an Iterable to be mocked by default with an empty Iterable. I understand from the initial issue this behavior would be introduced in Mockito 2, but beta-8 still returns null.\n\nCould we return null for Iterables ?\n\nShould we have the same behavior for Iterator ?\n\nThanks\n"
            },
            "19": {
                "commit_sha_buggy": "03028f0095d527ff9bd84bc929fc4931f17abf13",
                "commit_sha_fixed": "110ffa80070bf54ab8efabdaaa27b193a93d6128",
                "report_id": "205",
                "report_url": "https://github.com/mockito/mockito/issues/205",
                "issue_title": "InjectMocks injects mock into wrong field",
                "issue_description": "Using `1.10.19`.\n\nWhen using `@InjectMocks` on some Android `TextView`s, the mock is injected into the wrong field.\n\nWe have two fields, `txtGateView` & `txtNextStep` in a class, and our test mocks out `txtNextStep`, then tried to inject. This field is injected wrong, see screenshot.\n\n![image](https://cloud.githubusercontent.com/assets/1404810/7410003/4f200580-ef2b-11e4-9c39-7a699dc4fefa.png)\n\nFrom our quick testing, the name `txtNextView` doesn't matter, that can be changed. But both `txtGateView` and `txtGateLabel` messed things up. If we mock out both fields, it works correctly.\n\nTestproject: https://github.com/SimenB/emptyandroid\n\nI don't know if it's because it's Android, but it was easiest for me to create a minimal test from existing code.\n"
            },
            "20": {
                "commit_sha_buggy": "98610b68e93e75a5b1db2687894bb30ff2b09c90",
                "commit_sha_fixed": "7616cd17d5e1dc7c3dee080c6969183821d4797a",
                "report_id": "92",
                "report_url": "https://github.com/mockito/mockito/issues/92",
                "issue_title": "Allow convenient spying on abstract classes",
                "issue_description": "I posted this in GoogleCode and was asked to submit in github.\n\nMockito is easy to use when the test needs to provide canned values for a certain method.\n\nBut it gets harder when a canned value isn't sufficient.\n##### Example 1: Fake with trivial Logic\n\n```\ninterface UserAccount {\n  List<String> getEmails();\n  void addEmail(String email);\n  // 12 other methods ...\n}\n```\n\nWhen mocking such domain entity object, it's tedious to manually program getEmails()/addEmail() with when().thenReturn() and to make sure the two methods are logically consistent, that is, getEmails() returns all emails added.\n##### Example 2: callback-style API\n\n```\ninterface AccountService {\n  void getAccount(String id, AsyncCallback<UserAccount> callback);\n}\n```\n\nStubbing AccountService isn't easy. It'd require use of Answer, and the Answer API isn't statically type safe:\n\n```\nwhen(service.getAccount(eq(id), any(AsyncCallback.class)).thenAnswer(new Answer<Void>() {\n  AsyncCallback<UserAccount> callback = (AsyncCallback<UserAccount>) getArguments()[1];\n  ...\n});\n```\n##### Example 3: Uninteresting parameters\n\n```\ninterface AccountRpcService {\n  FutureAccount getAccount(RpcContext context, String id);\n}\n```\n\nNone of the tests care about the context object. It's an uninteresting parameter imposed by the framework.\n\nIf AccountRpcService were directly mocked, all tests would have to use isA() to repetitively mention this uninteresting parameter, like this:\n\n`when(service.getAccount(isA(RpcContext.class), eq(\"id\")).thenReturn(...);`\n\nAnd all other parameters are required to be wrapped in eq().\n#### Proposal\n\nI propose adding support for abstract classes to mockito to make it easier to deal with tests like above:\n##### For example 1\n\n```\nabstract class FakeUserAccount implements UserAccount {\n  private final List<String> emails = new ArrayList<>();\n\n  @Override public void addEmail(String email) {\n    emails.add(email);\n  }\n  @Override List<String> getEmails() {\n    return ImmutableList.copyOf(emails);\n  }\n}\n\n@Fake private FakeUserAccount userAccount; // Mockito instantiates abstract class.\n```\n##### For example 2\n\n```\nabstract class MockAccountService implements AccountService {\n  @Override public void getAccount(String id, AsyncCallback<UserAccount> callback) {\n    callback.onSuccess(getAccount(id));\n  }\n  abstract UserAccount getAccount(String id);\n}\n\n@Fake private MockAccountService service;\n\n...\n\nwhen(service.getAccount(\"id\")).thenReturn(account);\n```\n##### For example 3\n\n```\nabstract class MockAccountRpcService implements AccountRpcService {\n  @Override Future<Account> getAccount(RpcContext context, String id) {\n    checkNotNull(context);  // Common sanity test. Don't have to repeat it in tests.\n    return getAccount(id);\n  }\n\n  abstract Future<Account> getAccount(String id);\n}\n\n@Fake private MockAccountRpcService service;\n\nwhen(service.getAccount(\"id\")).thenReturn(...);\n```\n\nMy work place internally implemented a default Answer to support abstract classes. We found that the support of abstract classes helps us to avoid overusing mocks when we should be using fakes. And in situations like above we get cleaner test code.\n\nBut because it's not integrated in the core Mockito, there are gotchas with our implementation (like, you can't have private/final methods in your fake).\n\nIf the idea sounds okay to give a try, I'll volunteer to submit a patch.\n\nThanks!\n"
            },
            "21": {
                "commit_sha_buggy": "c03a47fb2d3d4df94ba608c26a0a7570798b3611",
                "commit_sha_fixed": "8912aa176ea8414c2fc57df0d9b030b918630e9f",
                "report_id": "92",
                "report_url": "https://github.com/mockito/mockito/issues/92",
                "issue_title": "Allow convenient spying on abstract classes",
                "issue_description": "I posted this in GoogleCode and was asked to submit in github.\n\nMockito is easy to use when the test needs to provide canned values for a certain method.\n\nBut it gets harder when a canned value isn't sufficient.\n##### Example 1: Fake with trivial Logic\n\n```\ninterface UserAccount {\n  List<String> getEmails();\n  void addEmail(String email);\n  // 12 other methods ...\n}\n```\n\nWhen mocking such domain entity object, it's tedious to manually program getEmails()/addEmail() with when().thenReturn() and to make sure the two methods are logically consistent, that is, getEmails() returns all emails added.\n##### Example 2: callback-style API\n\n```\ninterface AccountService {\n  void getAccount(String id, AsyncCallback<UserAccount> callback);\n}\n```\n\nStubbing AccountService isn't easy. It'd require use of Answer, and the Answer API isn't statically type safe:\n\n```\nwhen(service.getAccount(eq(id), any(AsyncCallback.class)).thenAnswer(new Answer<Void>() {\n  AsyncCallback<UserAccount> callback = (AsyncCallback<UserAccount>) getArguments()[1];\n  ...\n});\n```\n##### Example 3: Uninteresting parameters\n\n```\ninterface AccountRpcService {\n  FutureAccount getAccount(RpcContext context, String id);\n}\n```\n\nNone of the tests care about the context object. It's an uninteresting parameter imposed by the framework.\n\nIf AccountRpcService were directly mocked, all tests would have to use isA() to repetitively mention this uninteresting parameter, like this:\n\n`when(service.getAccount(isA(RpcContext.class), eq(\"id\")).thenReturn(...);`\n\nAnd all other parameters are required to be wrapped in eq().\n#### Proposal\n\nI propose adding support for abstract classes to mockito to make it easier to deal with tests like above:\n##### For example 1\n\n```\nabstract class FakeUserAccount implements UserAccount {\n  private final List<String> emails = new ArrayList<>();\n\n  @Override public void addEmail(String email) {\n    emails.add(email);\n  }\n  @Override List<String> getEmails() {\n    return ImmutableList.copyOf(emails);\n  }\n}\n\n@Fake private FakeUserAccount userAccount; // Mockito instantiates abstract class.\n```\n##### For example 2\n\n```\nabstract class MockAccountService implements AccountService {\n  @Override public void getAccount(String id, AsyncCallback<UserAccount> callback) {\n    callback.onSuccess(getAccount(id));\n  }\n  abstract UserAccount getAccount(String id);\n}\n\n@Fake private MockAccountService service;\n\n...\n\nwhen(service.getAccount(\"id\")).thenReturn(account);\n```\n##### For example 3\n\n```\nabstract class MockAccountRpcService implements AccountRpcService {\n  @Override Future<Account> getAccount(RpcContext context, String id) {\n    checkNotNull(context);  // Common sanity test. Don't have to repeat it in tests.\n    return getAccount(id);\n  }\n\n  abstract Future<Account> getAccount(String id);\n}\n\n@Fake private MockAccountRpcService service;\n\nwhen(service.getAccount(\"id\")).thenReturn(...);\n```\n\nMy work place internally implemented a default Answer to support abstract classes. We found that the support of abstract classes helps us to avoid overusing mocks when we should be using fakes. And in situations like above we get cleaner test code.\n\nBut because it's not integrated in the core Mockito, there are gotchas with our implementation (like, you can't have private/final methods in your fake).\n\nIf the idea sounds okay to give a try, I'll volunteer to submit a patch.\n\nThanks!\n"
            },
            "22": {
                "commit_sha_buggy": "920ec4c3efe3133aa5009fcc9757a3cd07c5ac02",
                "commit_sha_fixed": "d0c872e4b0837aef1e1635bf5f15d33c3d8d9698",
                "report_id": "484",
                "report_url": "https://github.com/mockito/mockito/issues/484",
                "issue_title": "Can not Return deep stubs from generic method that returns generic type",
                "issue_description": "Hey,\n\nif I try to mock a generic method which a generic returntype, where the returntype is derived from the generic type of the method using deep stubs I get a `ClassCastException` when calling `when` on it.\n\n```\ninterface I {\n    <T> Supplier<T> m(Class<T> type);\n}\n@Test\npublic void test() throws Exception {\n    I i = mock(I.class, RETURNS_DEEP_STUBS);\n    when(i.m(Boolean.class).get()); // <- ClassCastException\n}\n```\n\nWhen you don't use deep stubs and a raw `Supplier` mock to pass around it works:\n\n```\nI i = mock(I.class);\nSupplier s = mock(Supplier.class);\nwhen(i.m(Boolean.class)).thenReturn(s);\nwhen(i.m(Boolean.class).get());\n```\n\nThe `ClassCastException`:\n\n```\njava.lang.ClassCastException: org.mockito.internal.creation.cglib.ClassImposterizer$ClassWithSuperclassToWorkAroundCglibBug$$EnhancerByMockitoWithCGLIB$$cdb13154 cannot be cast to java.lang.String\n  at MockitoGenerics.test(MockitoGenerics.java:21)\n  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:483)\n  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n  at org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n  at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n  at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n```\n\nTested using mockito 1.10.19, jdk 1.8.0_20 and no Powermock\n"
            },
            "23": {
                "commit_sha_buggy": "c17169c2cbb0b3d055d64ec2c4859122ca919c42",
                "commit_sha_fixed": "82935114a09390cbab0c6b6df9b6fd6788bf55d9",
                "report_id": "399",
                "report_url": "https://github.com/mockito/mockito/issues/399",
                "issue_title": "WrongTypeOfReturnValue when abstract class have two abstract method",
                "issue_description": "Hey\nI found a strange problem, when i create a abstract class:\n\n``` java\nabstract class AbstractClass {\n    abstract protected Long lol();\n    abstract protected String wow();\n    public String give() {\n        wow();\n        lol();\n        return \"give\";\n    }\n}\n```\n\nand i have another class extends abstract Class:\n\n``` java\npublic class ClassExtendsAbstractClass extends AbstractClass {\n@Override\n protected Long lol() {\n        return 2L;\n    }\n    @Override\n    protected String wow() {\n        return \"WOW\";\n    }\n}\n```\n\nand I have class:\n\n``` java\npublic class A {\n  private ClassExtendsAbstractClass classExtendsAbstractClass;\n  public A(ClassExtendsAbstractClass classExtendsAbstractClass) {\n    this.classExtendsAbstractClass = classExtendsAbstractClass;\n  }\n  public String doSomeThing(){\n    return classExtendsAbstractClass.wow();\n  }\n}\n```\n\nand when i try mock method doSomeThing() from A class in test:\n\n``` java\n  @Mock\n  private ClassExtendsAbstractClass classExtendsAbstractClass;\n  private A a;\n\n  @Before\n  public void before(){\n    Mockito.when(classExtendsAbstractClass.give()).thenReturn(\"aaa\");\n  }\n  @Test\n  public void test() {\n    a = new A(classExtendsAbstractClass);\n  }\n```\n\nI get the error:\n\n> org.mockito.exceptions.misusing.WrongTypeOfReturnValue: \n> String cannot be returned by lol()\n> lol() should return Long\n\nThis is strange behavior, because the method `lol()` should not be called, but when I delete one abstract method everything is good.\n"
            },
            "24": {
                "commit_sha_buggy": "585b06d890b5e78857a5c5d5a2301065c2cac08b",
                "commit_sha_fixed": "c17169c2cbb0b3d055d64ec2c4859122ca919c42",
                "report_id": "467",
                "report_url": "https://github.com/mockito/mockito/issues/467",
                "issue_title": "fix some rawtype warnings in tests",
                "issue_description": ""
            },
            "25": {
                "commit_sha_buggy": "d8b18f2e77c3f352677a6993225c4333b98d0481",
                "commit_sha_fixed": "a6ccf070a267e0a165b8efaaefa8938e787bb6a0",
                "report_id": "230",
                "report_url": "https://github.com/mockito/mockito/issues/230",
                "issue_title": "Null Pointer when invoking Whitebox.invokeMethod() with null one of the params null ",
                "issue_description": "Getting below exceptions when trying to invoke Whitebox.invokeMethod(erxProviderManager, \"setCommand\", Provider, null,retait, mail);\n\nVersion used 1.6.2\n\nFAILED: testSetEnrollmentCommandWithUnEnrollmentWithNull\njava.lang.NullPointerException\n    at java.lang.Class.isAssignableFrom(Native Method)\n    at org.powermock.reflect.internal.WhiteboxImpl.checkIfParameterTypesAreSame(WhiteboxImpl.java:2257)\n    at org.powermock.reflect.internal.WhiteboxImpl.getMethods(WhiteboxImpl.java:1800)\n    at org.powermock.reflect.internal.WhiteboxImpl.getBestMethodCandidate(WhiteboxImpl.java:955)\n    at org.powermock.reflect.internal.WhiteboxImpl.findMethodOrThrowException(WhiteboxImpl.java:832)\n    at org.powermock.reflect.internal.WhiteboxImpl.doInvokeMethod(WhiteboxImpl.java:770)\n    at org.powermock.reflect.internal.WhiteboxImpl.invokeMethod(WhiteboxImpl.java:638)\n    at org.powermock.reflect.Whitebox.invokeMethod(Whitebox.java:401)\n"
            },
            "26": {
                "commit_sha_buggy": "41441c6b00e64c9f1f1275ff01a0ac4f7c4ae13e",
                "commit_sha_fixed": "af44738c7de74f24e37ea0c1242e73b07c3f4362",
                "report_id": "352",
                "report_url": "https://github.com/mockito/mockito/issues/352",
                "issue_title": "use @InjectMocks for final fields",
                "issue_description": "I'm trying to upgrade the mockito version that we're using (1.8.5) to a newer version but there is a problem with @InjectMocks which since 1.9.0 doesn't inject into final field anymore.\n\nWere there any reasons for that feature to be removed?\nIs there another way to achieve this without polutting our class with useless (outside testing context) constructors / accessors? \n\nIs there a possibility to get that feature back?\n"
            },
            "27": {
                "commit_sha_buggy": "19ade1ff81503b05a34ba8fff4ee9c9b63860587",
                "commit_sha_fixed": "a8ec4fa290bc1cdde060218d6bb811ac1fa6da6f",
                "report_id": "282",
                "report_url": "https://github.com/mockito/mockito/issues/282",
                "issue_title": "Exception when stubbing more than once with when...thenThrow",
                "issue_description": "If I create a mock and stub a method so it throws an exception and do that twice the first exception will be thrown upon invoking the second stub instruction.\n\nExample:\n\n```\n@Test\npublic void testThrowException() {\n    Object o = Mockito.mock(Object.class);\n    // test behavior with Runtimeexception\n    Mockito.when(o.toString()).thenThrow(RuntimeException.class);\n    // ...\n    // test behavior with another exception\n    // this throws a RuntimeException\n    Mockito.when(o.toString()).thenThrow(IllegalArgumentException.class);\n    // ...\n}\n```\n\nI can work around this if I do it the other way around with doThrow...when. But I lose type safety then. Can you fix this?\n"
            },
            "28": {
                "commit_sha_buggy": "7639f331b8c002647dd02f914bbd3f3203832cb9",
                "commit_sha_fixed": "0464f5657dc8c76a4ff209a2cf7fd6312885cdc3",
                "report_id": "236",
                "report_url": "https://github.com/mockito/mockito/issues/236",
                "issue_title": "nicer textual printing of typed parameters",
                "issue_description": "When matchers fail but yield the same toString(), Mockito prints extra type information. However, the type information is awkwardly printed for Strings. I've encountered this issue while working on removing hard dependency to hamcrest.\n\n```\n//current:\nsomeMethod(1, (Integer) 2);\nsomeOther(1, \"(String) 2\");\n//desired:\nsomeOther(1, (String) \"2\");\n```\n"
            },
            "29": {
                "commit_sha_buggy": "df41fbe00b1300cfe5076bb4e9242214fbe677f9",
                "commit_sha_fixed": "918f0a5aed6454b307004b6c9c86afc8e96353ff",
                "report_id": "229",
                "report_url": "https://github.com/mockito/mockito/issues/229",
                "issue_title": "Fixes #228: fixed a verify() call example in @Captor javadoc",
                "issue_description": ""
            },
            "30": {
                "commit_sha_buggy": "62b6bdf44baeee172b2b1684835fb995bad2a47d",
                "commit_sha_fixed": "3c924f80a4db3692a13341f0da4517052ab77a2a",
                "report_id": "225",
                "report_url": "https://github.com/mockito/mockito/issues/225",
                "issue_title": "Failing tests on Windows machine",
                "issue_description": "I just posted on the Google Forums, but someway somehow my post immediately disappeared in the void. So I am reposting it again here.\n\nI have 3 failing tests on my Windows 8.1 machine.\n1. DefaultMockingDetailsTest.should_get_extra_interfaces\n2. NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy\n3. ClassLoadersTest.excluding_class_loader_cannot_load_classes_when_no_correct_source_url_set\n\nFor the first test, I was able to let it pass by changing line https://github.com/mockito/mockito/blob/master/test/org/mockito/internal/util/DefaultMockingDetailsTest.java#L56 to\n\n``` java\nBar bar = mock(Bar.class, withSettings().extraInterfaces(List.class, Observer.class));\n```\n\nI am not sure if this is indeed the correct test, so please let me know.\n\nFor the 2nd test, I first get the stack trace\n\n```\njava.lang.AssertionError: 'org\\mockito\\configuration\\MockitoConfiguration' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: org\\mockito\\configuration\\MockitoConfiguration (wrong name: org/mockito/configuration/MockitoConfiguration)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\n\n\n```\n\nWhen I change line https://github.com/mockito/mockito/blob/master/test/org/mockitoutil/ClassLoaders.java#L361 to\n\n``` java\nString temp = file.getAbsolutePath().substring(root.getAbsolutePath().length() + 1).replace('/', '.').replace('\\\\', '.');\n```\n\nI get the following stack trace:\n\n```\njava.lang.AssertionError: 'org.mockito.internal.progress.TimesTest' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: junit/framework/Assert\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\nCaused by: java.lang.ClassNotFoundException: classes with prefix : [junit, org.junit] are excluded\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:155)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 51 more\n```\n\nThe reason I changed that line is because the temp result does not contain dots on windows machines, due to the fact that absolutepath does not return a path seperated by `/` but by `\\\\`.\nHowever then the test fails because the `TimesTest` in `test/` does indeed depend on junit. Shouldn't it only load classes that are under `src/`?\n\nThe 3rd test I sadly have no clue why it is succeeding and not throwing an exception.\n\nLooking forward to your responses =]\n"
            },
            "31": {
                "commit_sha_buggy": "81a380951402d2a158af115ed616ab36e94793b8",
                "commit_sha_fixed": "62b6bdf44baeee172b2b1684835fb995bad2a47d",
                "report_id": "225",
                "report_url": "https://github.com/mockito/mockito/issues/225",
                "issue_title": "Failing tests on Windows machine",
                "issue_description": "I just posted on the Google Forums, but someway somehow my post immediately disappeared in the void. So I am reposting it again here.\n\nI have 3 failing tests on my Windows 8.1 machine.\n1. DefaultMockingDetailsTest.should_get_extra_interfaces\n2. NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy\n3. ClassLoadersTest.excluding_class_loader_cannot_load_classes_when_no_correct_source_url_set\n\nFor the first test, I was able to let it pass by changing line https://github.com/mockito/mockito/blob/master/test/org/mockito/internal/util/DefaultMockingDetailsTest.java#L56 to\n\n``` java\nBar bar = mock(Bar.class, withSettings().extraInterfaces(List.class, Observer.class));\n```\n\nI am not sure if this is indeed the correct test, so please let me know.\n\nFor the 2nd test, I first get the stack trace\n\n```\njava.lang.AssertionError: 'org\\mockito\\configuration\\MockitoConfiguration' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: org\\mockito\\configuration\\MockitoConfiguration (wrong name: org/mockito/configuration/MockitoConfiguration)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\n\n\n```\n\nWhen I change line https://github.com/mockito/mockito/blob/master/test/org/mockitoutil/ClassLoaders.java#L361 to\n\n``` java\nString temp = file.getAbsolutePath().substring(root.getAbsolutePath().length() + 1).replace('/', '.').replace('\\\\', '.');\n```\n\nI get the following stack trace:\n\n```\njava.lang.AssertionError: 'org.mockito.internal.progress.TimesTest' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: junit/framework/Assert\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\nCaused by: java.lang.ClassNotFoundException: classes with prefix : [junit, org.junit] are excluded\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:155)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 51 more\n```\n\nThe reason I changed that line is because the temp result does not contain dots on windows machines, due to the fact that absolutepath does not return a path seperated by `/` but by `\\\\`.\nHowever then the test fails because the `TimesTest` in `test/` does indeed depend on junit. Shouldn't it only load classes that are under `src/`?\n\nThe 3rd test I sadly have no clue why it is succeeding and not throwing an exception.\n\nLooking forward to your responses =]\n"
            },
            "32": {
                "commit_sha_buggy": "d973b6f4fd6aad3b17a1758c920a3b962269b2ba",
                "commit_sha_fixed": "4f7060cc54bb50292ccfbf3b9fca27f0282abf51",
                "report_id": "216",
                "report_url": "https://github.com/mockito/mockito/issues/216",
                "issue_title": "Mockito can't create mock on public class that extends package-private class",
                "issue_description": "I created simple project to demonstrate this:\nhttps://github.com/astafev/mockito-package-private-class/\n\nPlease take a look. Even if it can't be implemented, I think that mockito should throw some normal exception at time of creation.\nIn my variant on first creation it returns wrong-working mock (invokes real method instead of stubbed). On second creation throws exception that doesn't really connected with problem.\n\nEverything works fine if you mock package-private parent.\n"
            },
            "33": {
                "commit_sha_buggy": "57bafd2c3ad7db992667b7f9d56dfe9aca0d82f4",
                "commit_sha_fixed": "5cb37751c0aba81d025dc5fe4f2f9a3bf86cc958",
                "report_id": "200",
                "report_url": "https://github.com/mockito/mockito/issues/200",
                "issue_title": "ArgumentCaptor.fromClass's return type should match a parameterized type",
                "issue_description": "`ArgumentCaptor.fromClass`'s return type should match a parameterized type.  I.e. the expression `ArgumentCaptor.fromClass(Class<S>)` should be of type `ArgumentCaptor<U>` where `S` is a subtype of `U`.   \n\nFor example:\n\n```\nArgumentCaptor<Consumer<String>> captor = ArgumentCaptor.fromClass(Consumer.class)\n```\n\ndoes not type check (i.e. it is a compile time error). It should type check. \n\nThe reasons that it is desirable for `ArgumentCaptor.fromClass` to allow expressions such as the example above to type check are:\n\n1) `ArgumentCaptor.fromClass` is intended to be a convenience method to allow the user to construct an ArgumentCaptor without casting the returned value.\n\nCurrently, the user can devise a workaround such as: \n\n```\nArgumentCaptor<? extends Consumer<String>> captor \n= ArgumentCaptor.fromClass(Consumer.class)\n```\n\nThis workaround is inconvenient, and so contrary to `ArgumentCaptor.fromClass` being a convenience method.\n\n2) It is inconsistent with `@Captor`, which can be applied to a field with a paramterized type.  I.e.\n\n```\n@Captor ArgumentCaptor<Consumer<String>> captor \n```\n\ntype checks.\n"
            },
            "34": {
                "commit_sha_buggy": "0ebc2ea06b5abdb441a57a8e0f01305a7839c3d9",
                "commit_sha_fixed": "e8cebe01abae49a09aadd6a26c6f7e2f90e5e772",
                "report_id": "157",
                "report_url": "https://github.com/mockito/mockito/issues/157",
                "issue_title": "Source files should not be put in binary JAR ",
                "issue_description": "Source files (`*.java`) should not be put into binary `mockito-core.jar`. It stupefies Idea to show decompiled file even when source jar is available.\n"
            },
            "35": {
                "commit_sha_buggy": "bff7ae0f4db9c5c0f7bfcdd3a47d4fa0fdaa1232",
                "commit_sha_fixed": "27a2f515197d4688c4df82afb791bf8ce20a5504",
                "report_id": "98",
                "report_url": "https://github.com/mockito/mockito/issues/98",
                "issue_title": "possible NPE exception when class cannot be mocked via PowerMockito",
                "issue_description": "In version 1.10.5, the catch block needs to guard against a null proxyInstance:\n\njava.lang.NullPointerException\n    at org.mockito.internal.creation.jmock.ClassImposterizer.imposterise(ClassImposterizer.java:65)\n    at org.powermock.api.mockito.internal.mockcreation.MockCreator.createMethodInvocationControl(MockCreator.java:111)\n    at org.powermock.api.mockito.internal.mockcreation.MockCreator.mock(MockCreator.java:60)\n    at org.powermock.api.mockito.PowerMockito.mock(PowerMockito.java:143)\n    at com.seagullsw.appinterface.server.osgi.JCicsOsgiTestCase.executeOsgiRequest(JCicsOsgiTestCase.java:167)\n    at com.seagullsw.appinterface.server.osgi.JCicsOsgiTestCase.executeOsgiRequest(JCicsOsgiTestCase.java:122)\n    at com.seagullsw.appinterface.server.osgi.JCicsOsgiTestCase.checkFunctionReturnString(JCicsOsgiTestCase.java:99)\n    at com.seagullsw.appinterface.server.osgi.JCicsOsgiTestCase.testJcicsOsgiRoundtrip(JCicsOsgiTestCase.java:230)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:68)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:310)\n    at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:88)\n    at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:96)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.executeTest(PowerMockJUnit44RunnerDelegateImpl.java:294)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTestInSuper(PowerMockJUnit47RunnerDelegateImpl.java:127)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTest(PowerMockJUnit47RunnerDelegateImpl.java:82)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runBeforesThenTestThenAfters(PowerMockJUnit44RunnerDelegateImpl.java:282)\n    at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:86)\n    at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:49)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:207)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:146)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:120)\n    at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:33)\n    at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:45)\n    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:122)\n    at org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:104)\n    at org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:53)\n    at org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:53)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n"
            },
            "36": {
                "commit_sha_buggy": "ecbd951497132c68dd2b264d7014251e33acba92",
                "commit_sha_fixed": "84c142f56fe971ed52ecfe42b42bc0aa7bef8354",
                "report_id": "140",
                "report_url": "https://github.com/mockito/mockito/issues/140",
                "issue_title": "Make Mockito JUnit rule easier to use",
                "issue_description": "- Mockito JUnit rule easier to use by avoiding the need to pass test instance\n- Make it compatible with JUnit 4.7+ instead of 4.9+\n"
            },
            "37": {
                "commit_sha_buggy": "3b603ebf4bd3b416a2a00b7729233ae44ec75943",
                "commit_sha_fixed": "c0222c2dbfbd2b053961a46e4c2a3973aec55a75",
                "report_id": "140",
                "report_url": "https://github.com/mockito/mockito/issues/140",
                "issue_title": "Make Mockito JUnit rule easier to use",
                "issue_description": "- Mockito JUnit rule easier to use by avoiding the need to pass test instance\n- Make it compatible with JUnit 4.7+ instead of 4.9+\n"
            },
            "38": {
                "commit_sha_buggy": "a663d2fe76bf1ff54bbe59bddcb52f9badec3f2a",
                "commit_sha_fixed": "c1f2c4e6b5bab4cfc004f22999e11e8ac140d377",
                "report_id": "79",
                "report_url": "https://github.com/mockito/mockito/issues/79",
                "issue_title": "Generate change list separated by types using labels",
                "issue_description": "As discussed on the mailing list instead of one big list of \"Improvements\" the change list for the release is divided into change types based on labels. It is required to specify which labels should be considered separately. Some other labels can be excluded (like \"question\" or \"refactoring\").\n\n```\nnew ReleaseNotesBuilderFactory(project)\n(...)\n    .showSeparatelyChangesWithLabelMappings([\"enhancement\": \"Improvements\", \"bug\": \"Fixed bugs\", \"doc\": \"Documentation\"])\n    .ignoreChangesWithLabels([\"refactoring\", \"invalid\", \"question\", \"wontfix\", \"duplicate\"])\n```\n\nThere is also `headerForOtherChanges` method to override default \"Other\" header.\n\nI changed internally `Improvement` to `Change` to better give meaning of change, but it is done in a separate commit, so can be easily reverted/amended if you don't like it (or have a better name).\n\nSample changelog generated for current release. Number of issues is the same as with the old mechanism. Many of them are placed in \"Other\" section as don't have labels assigned.\n- Changes: 20\n  - Improvements: 11\n    - Improved the javadoc example of custom Answer implementation [(#22)](https://github.com/mockito/mockito/pull/22)\n    - Avoided classloader issue when testing in Eclipse plugins environment [(#24)](https://github.com/mockito/mockito/pull/24)\n    - Removed .java files from main mockito jar artifacts [(#28)](https://github.com/mockito/mockito/pull/28)\n    - Smarter constructor injection by choosing \"biggest\" constructor instead of the default one [(#29)](https://github.com/mockito/mockito/pull/29)\n    - Deep stub style mocks can be serialized [(#30)](https://github.com/mockito/mockito/pull/30)\n    - Fixed the behavior of compareTo method of the mock objects [(#32)](https://github.com/mockito/mockito/pull/32)\n    - New \"MockingDetails.getInvocations\" method for inspecting what happened with the mock [(#10)](https://github.com/mockito/mockito/pull/10)\n    - Mock serialization/deserialization across classloader/JVM [(#5)](https://github.com/mockito/mockito/pull/5)\n    - Improved MockitoTestNGListener by making it reset argument captors before each test [(#6)](https://github.com/mockito/mockito/pull/6)\n    - Improve NoInteractionsWanted report to include the name of the mock [(#63)](https://github.com/mockito/mockito/pull/63)\n    - New \"getArgumentAt\" method for convenient implementation of custom Answers [(#41)](https://github.com/mockito/mockito/pull/41)\n  - Fixed bugs: 1\n    - Allow calling real implementation of jdk8 extension methods [(#39)](https://github.com/mockito/mockito/pull/39)\n  - Documentation: 0\n  - Other: 8\n    - Fixed wrong javadoc for AdditionalAnswers [(#56)](https://github.com/mockito/mockito/pull/56)\n    - Added useful links to README.md [(#58)](https://github.com/mockito/mockito/pull/58)\n    - Deprecated timeout().never(), in line with timeout().atMost() [(#14)](https://github.com/mockito/mockito/pull/14)\n    - Verification with timout measures time more more accurately [(#15)](https://github.com/mockito/mockito/pull/15)\n    - New \"then\" method for BDD-style interaction testing [(#38)](https://github.com/mockito/mockito/pull/38)\n    - Enabled continuous integration with Travis CI and coverage tracking with coveralls [(#18)](https://github.com/mockito/mockito/pull/18)\n    - Coveralls coverage tracking tool allows Mockito source code preview [(#62)](https://github.com/mockito/mockito/pull/62)\n    - Improved behavior of EqualsWithDelta with regards to null handling [(#21)](https://github.com/mockito/mockito/pull/21)\n\nI have to take a look why some labelled issues were ommited (in both mechanisms).\n\nWhat do you think about that?\n"
            }
        }
    },
    "Time": {
        "owner_repo": "JodaOrg/joda-time",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8612f9e5b88c1bea933ef9ab1e431f5db3006b48",
                "commit_sha_fixed": "9a62b06be5d0df8e833ff8583398cca386608cac",
                "report_id": "93",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/93",
                "issue_title": "Partial.with fails with NPE",
                "issue_description": "With the latest master:\n\n``` java\nnew Partial(yearOfCentury(),  1).with(weekyear(), 1);\n// NullPointerException\n// org.joda.time.Partial.with (Partial.java:447)\n```\n\nFails with yearOfCentury, year and yearOfEra. Probably because weekyear has a null range duration type.\n"
            },
            "2": {
                "commit_sha_buggy": "8d109fe1a999a11b4557536dd96f9210460a5936",
                "commit_sha_fixed": "8612f9e5b88c1bea933ef9ab1e431f5db3006b48",
                "report_id": "93",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/93",
                "issue_title": "Partial.with fails with NPE",
                "issue_description": "With the latest master:\n\n``` java\nnew Partial(yearOfCentury(),  1).with(weekyear(), 1);\n// NullPointerException\n// org.joda.time.Partial.with (Partial.java:447)\n```\n\nFails with yearOfCentury, year and yearOfEra. Probably because weekyear has a null range duration type.\n"
            },
            "3": {
                "commit_sha_buggy": "3ba9ba799b3261b7332a467a88be142c83b298fd",
                "commit_sha_fixed": "8d109fe1a999a11b4557536dd96f9210460a5936",
                "report_id": "77",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/77",
                "issue_title": "addDays(0) changes value of MutableDateTime",
                "issue_description": "Upon DST transition from summer to winter time zone, adding the amount of zero days to a mutable date time object changes the value of the object.\n\nThe code\n\n``` java\nfinal MutableDateTime mdt = new MutableDateTime(2011, 10, 30, 3, 0, 0, 0, DateTimeZone.forID(\"Europe/Berlin\"));\nSystem.out.println(\"Start date:   \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addHours(-1);\nSystem.out.println(\"addHours(-1): \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addHours(0);\nSystem.out.println(\"addHours(0):  \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addDays(0);\nSystem.out.println(\"addDays(0):   \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\n```\n\nprints\n\n```\nStart date:   2011-10-30T03:00:00.000+01:00 (1319940000000)    //OK\naddHours(-1): 2011-10-30T02:00:00.000+01:00 (1319936400000)    //OK\naddHours(0):  2011-10-30T02:00:00.000+01:00 (1319936400000)    //OK, no change in time\naddDays(0):   2011-10-30T02:00:00.000+02:00 (1319932800000)    //error, time has changed by 1 hour\n```\n\nThe methods addMonths and addYears show the same problem; addSeconds, addMinutes and addHours are ok.\n\nI have tested with version 2.3. However, if I repeat the test with Joda 1.5.2, the invocation of addDays(0) does not change the date's value.\n"
            },
            "4": {
                "commit_sha_buggy": "bcb044669b4d1f8d334861ccbd169924d6ef3b54",
                "commit_sha_fixed": "3ba9ba799b3261b7332a467a88be142c83b298fd",
                "report_id": "88",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/88",
                "issue_title": "Constructing invalid Partials",
                "issue_description": "Partials can be constructed by invoking a constructor `Partial(DateTimeFieldType[], int[])` or by merging together a set of partials using `with`, each constructed by calling `Partial(DateTimeFieldType, int)`, e.g.:\n\n``` java\nPartial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});\nPartial b = new Partial(year(), 1).with(hourOfDay(), 1);\nassert(a == b);\n```\n\nHowever, the above doesn't work in all cases:\n\n``` java\nnew Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate\nnew Partial(clockhourOfDay(), 1).with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>\n```\n\nI suppose the Partials should not allow to be constructed in either case. Is that right?\n\nThere's also a related issue (probably stems from the fact that the Partial is invalid):\n\n``` java\nnew Partial(clockhourOfDay(), 1).with(hourOfDay(), 1).isEqual(new Partial(hourOfDay() ,1).with(clockhourOfDay(), 1)) // throws objects must have matching field types\n```\n"
            },
            "5": {
                "commit_sha_buggy": "a38b5e0c620a4a4dc310d35105e3e432c4e91fc3",
                "commit_sha_fixed": "a6cb59ed2280ab0a32995fa8b5f1a7b0d47cb815",
                "report_id": "79",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/79",
                "issue_title": "none standard PeriodType without year throws exception",
                "issue_description": "Hi.\n\nI tried to get a Period only for months and weeks with following code:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));\nreturn p.getMonths();\n```\n\nThis throws following exception:\n\n```\n 10-17 14:35:50.999: E/AndroidRuntime(1350): java.lang.UnsupportedOperationException: Field is not supported\n 10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.PeriodType.setIndexedField(PeriodType.java:690)\n 10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.withYears(Period.java:896) 10-17\n 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.normalizedStandard(Period.java:1630)\n```\n\nEven removing the year component with .withYearsRemoved() throws the same exception:\n\nthis works:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).normalizedStandard(PeriodType.standard());\nreturn p.getMonths();\n```\n\nthis fails:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().withYearsRemoved()).normalizedStandard(PeriodType.standard().withYearsRemoved());\nreturn p.getMonths();\n```\n"
            },
            "6": {
                "commit_sha_buggy": "91b1ba4ed42ca0b345370ea3cc0ddcdb33781c6d",
                "commit_sha_fixed": "28aeba952e838fb12c9b934ce6ef65658e45d7b2",
                "report_id": "28",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/28",
                "issue_title": "Questionable behaviour of GJChronology when dates pass 1BC",
                "issue_description": "I expect the following test to pass:\n\n```\nChronology chronology = GJChronology.getInstance();\n\nLocalDate start = new LocalDate(2013, 5, 31, chronology);\nLocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC\nassertThat(start.minusYears(2013), is(equalTo(expectedEnd)));\nassertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));\n```\n\nThe error it gives is:\n\n```\norg.joda.time.IllegalFieldValueException: Value 0 for year is not supported\n```\n\nHowever, I never provided \"0\" for the year myself. I thought it was the job of the framework to skip over non-existent year 0 for me to return 1 BC?\n"
            },
            "7": {
                "commit_sha_buggy": "6bf5bba0f77f3023dec23a1de6e0a8cef8585f61",
                "commit_sha_fixed": "1adb1e69863dcd1ff282692bf1452c422528eeb9",
                "report_id": "21",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/21",
                "issue_title": "DateTimeFormat.parseInto sometimes miscalculates year (2.2)",
                "issue_description": "There appears to be a bug in the fix to http://sourceforge.net/p/joda-time/bugs/148 (which I also reported).\n\nThe following code (which can be added to org.joda.time.format.TestDateTimeFormatter) breaks, because the input mutable date time's millis appear to be mishandled and the year for the parse is changed to 1999:\n\n``` java\n    public void testParseInto_monthDay_feb29_startOfYear() {\n        DateTimeFormatter f = DateTimeFormat.forPattern(\"M d\").withLocale(Locale.UK);\n        MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);\n        assertEquals(4, f.parseInto(result, \"2 29\", 0));\n        assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);\n    }\n```\n"
            },
            "8": {
                "commit_sha_buggy": "96f586cb8dac7eee62e9be519a3eab125c47bb23",
                "commit_sha_fixed": "362ed1787724cda3ded37de2b0aa0f13adf0a66e",
                "report_id": "42",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/42",
                "issue_title": "DateTimeZone.forOffsetHoursMinutes cannot handle negative offset < 1 hour",
                "issue_description": "`DateTimeZone.forOffsetHoursMinutes(h,m)` cannot handle negative offset < 1 hour like `-0:30` due to argument range checking. I used `forOffsetMillis()` instead.\n\nThis should probably be mentioned in the documentation or negative minutes be accepted.\n"
            },
            "9": {
                "commit_sha_buggy": "08a3a0b969b1e5d1d06489a698fe9c9b69e2f2d9",
                "commit_sha_fixed": "96f586cb8dac7eee62e9be519a3eab125c47bb23",
                "report_id": "43",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/43",
                "issue_title": "Ensure there is a max/min valid offset",
                "issue_description": "`DateTimeZone` does not apply a max/min value for an offset. However the parse method is limited to 23:59. Make 23:59:59.999 the maximum.\n"
            },
            "10": {
                "commit_sha_buggy": "efce99164f0bbd2c70e7f9d71884a32473e02c6d",
                "commit_sha_fixed": "3a413d7844c22dc6ddd50bf5d0d55ff3589e47ac",
                "report_id": "22",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/22",
                "issue_title": "Days#daysBetween throw exception for MonthDay with 29 February",
                "issue_description": "final LocalDate january12012 = new LocalDate(2012, 1,1);\nfinal LocalDate february292012 = new LocalDate(2012, 2, 29);\n// OK\nassertEquals(59, Days.daysBetween(january12012, february292012).getDays());\n\nfinal MonthDay january1 = new MonthDay(1,1);\nfinal MonthDay february29 = new MonthDay(2, 29);\n// FAIL\nassertEquals(59, Days.daysBetween(january1, february29).getDays());\n\norg.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\n    at org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:217)\n    at org.joda.time.field.PreciseDurationDateTimeField.set(PreciseDurationDateTimeField.java:78)\n    at org.joda.time.chrono.BaseChronology.set(BaseChronology.java:240)\n    at org.joda.time.base.BaseSingleFieldPeriod.between(BaseSingleFieldPeriod.java:103)\n    at org.joda.time.Days.daysBetween(Days.java:141)\n\nIs there a way to avoid this happening? I understand fiddling around with the leap year, you're bound to get issues.\n\nThanks! \n"
            },
            "11": {
                "commit_sha_buggy": "6d5104753470c130336e319a64009c0553b29c96",
                "commit_sha_fixed": "57eb4cbb9044771cd46a9eee0c62016618930226",
                "report_id": "18",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/18",
                "issue_title": "NPE in DateTimeZoneBuilder",
                "issue_description": "When a DateTimeZone is build with duplicate-named 'recurring saving time' in a first thread, all goes Ok: a warning message is generated and an identifier is automatically generated in PrecalculatedZone.create(). When a second thread does the same, an NPE is generated in ZoneInfoCompiler.verbose().\n\nThe cause is that the cVerbose ThreadLocal is incorrectly initialized in ZoneInfoCompiler:\n\n``` java\n   static {\n        cVerbose.set(Boolean.FALSE);\n    }\n```\n\n...will initialize cVerbose only for the first thread and not for the subsequent ones. The NPE is caused by the autoboxing in:\n\n``` java\n   public static boolean verbose() {\n        return cVerbose.get();\n    }\n```\n\nA better approach could be to remove the initialization and test for null:\n\n``` java\npublic static boolean verbose(){\n    Boolean verbose = cVerbose.get();\n    return (verbose != null) ? verbose : false;\n}\n```\n\n---\n\nHere follows a test case:\n\n``` java\n    @Test\n    public void testDateTimeZoneBuilder() throws Exception {\n        getTestDataTimeZoneBuilder().toDateTimeZone(\"TestDTZ1\", true);\n        Thread t = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                getTestDataTimeZoneBuilder().toDateTimeZone(\"TestDTZ2\", true);\n            }\n        });\n        t.start();\n        t.join();\n    }\n\n    private DateTimeZoneBuilder getTestDataTimeZoneBuilder() {\n         return new DateTimeZoneBuilder()\n         .addCutover(1601, 'w', 1, 1, 1, false, 7200000)\n         .setStandardOffset(3600000)\n         .addRecurringSavings(\"\", 3600000, 1601, Integer.MAX_VALUE, 'w', 3, -1, 1, false, 7200000)\n         .addRecurringSavings(\"\", 0, 1601, Integer.MAX_VALUE, 'w', 10, -1, 1, false, 10800000);\n    }\n```\n"
            },
            "12": {
                "commit_sha_buggy": "f2f9c8146446eff341dc7b66b5237b56d50abec0",
                "commit_sha_fixed": "77a6b3a44da7ae4af62e88b4b27eeefec2d768c2",
                "report_id": "8",
                "report_url": "https://github.com/JodaOrg/joda-time/issues/8",
                "issue_title": "Check Calendar.ERA in LocalDate.fromCalendarFields",
                "issue_description": ""
            },
            "13": {
                "commit_sha_buggy": "6a1b24c5d85270b57706b3f7ca0b4c05a752b3ff",
                "commit_sha_fixed": "5d08a1cdbfa6ce86a0baf637493c464e91e91968",
                "report_id": "160",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/160",
                "issue_title": "Joda - Time / Bugs / #160 Negative millis display incorrectly in Period.toString",
                "issue_description": "\nThis code:\nimport org.joda.time.Duration;\nimport org.joda.time.Period;\npublic class A {\npublic static void main(String[] args) {\nSystem.out.println(\"new Duration(-1000).getMillis() = \" + new Duration(-1000).getMillis());\nSystem.out.println(\"new Duration(-1000).toString() = \" + new Duration(-1000).toString());\nSystem.out.println(\"new Period(-1000).getSeconds() = \" + new Period(-1000).getSeconds());\nSystem.out.println(\"new Period(-1000).toString() = \" + new Period(-1000).toString());\nSystem.out.println(\"new Duration(-100).getMillis() = \" + new Duration(-100).getMillis());\nSystem.out.println(\"new Duration(-100).toString() = \" + new Duration(-100).toString());\nSystem.out.println(\"new Period(-100).getMillis() = \" + new Period(-100).getMillis());\nSystem.out.println(\"new Period(-100).toString() = \" + new Period(-100).toString());\n}\n}\nProduces output:\nnew Duration(-1000).getMillis() = -1000\nnew Duration(-1000).toString() = PT-1S\nnew Period(-1000).getSeconds() = -1\nnew Period(-1000).toString() = PT-1S\nnew Duration(-100).getMillis() = -100\nnew Duration(-100).toString() = PT-0.100S\nnew Period(-100).getMillis() = -100\nnew Period(-100).toString() = PT0.100S\nThe last line should produce \"PT-0.100S\" instead of \"PT0.100S\".\n"
            },
            "14": {
                "commit_sha_buggy": "cc3262ff42e41f3b1f64290262704da3895fbe85",
                "commit_sha_fixed": "2ea856328ed5710537778d755a5ff52a6831a2ee",
                "report_id": "151",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/151",
                "issue_title": "Joda - Time / Bugs / #151 Unable to add days to a MonthDay set to the ISO leap date",
                "issue_description": "\nIt's not possible to add days to a MonthDay set to the ISO leap date (February 29th). This is even more bizarre given the exact error message thrown.\nSample snippet:\nfinal MonthDay isoLeap = new MonthDay(DateTimeConstants.FEBRUARY, 29, ISOChronology.getInstanceUTC());\nSystem.out.println(isoLeap);\nSystem.out.println(isoLeap.plusDays(2));\n\nWhich generates the following combined console output and stack trace: \n--02-29\nException in thread \"main\" org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\nat org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:215)\nat org.joda.time.field.PreciseDurationDateTimeField.set(PreciseDurationDateTimeField.java:78)\nat org.joda.time.chrono.BasicMonthOfYearDateTimeField.add(BasicMonthOfYearDateTimeField.java:212)\nat org.joda.time.field.BaseDateTimeField.add(BaseDateTimeField.java:324)\nat org.joda.time.MonthDay.withFieldAdded(MonthDay.java:519)\nat org.joda.time.MonthDay.minusDays(MonthDay.java:672)\nat ext.site.time.chrono.Main.m7(Main.java:191)\nat ext.site.time.chrono.Main.main(Main.java:27)\nThe follwing method calls and parameters also generate the same or related error: \nisoLeap.plusMonths(1);\nisoLeap.plusMonths(-1);\nisoLeap.minusMonths(1);\nisoLeap.minusMonths(-1);\nisoLeap.minusDays(-1);\n\nHowever, the following methods work: \nisoLeap.minusDays(1);\nisoLeap.plusDays(-1);\n\nPerforming operations on dates around the ISO leap date react as if it exists, ie:\nSystem.out.println(isoLeap.minusDays(1).plusDays(2));\n\nPrints out '--03-01' as expected.\n"
            },
            "15": {
                "commit_sha_buggy": "383354adc669c3fd8d9e6fe3a25403df993e11e7",
                "commit_sha_fixed": "0cefc4c212e92e5dccdfa658785c419483317558",
                "report_id": "147",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/147",
                "issue_title": "Joda - Time / Bugs / #147 possibly a bug in org.joda.time.field.FieldUtils.safeMultipl",
                "issue_description": "\nIt seems to me that as currently written in joda-time-2.1.jar\norg.joda.time.field.FieldUtils.safeMultiply(long val1, int scalar)\ndoesn't detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.\nThe attached file demonstrates what I think is the bug and suggests a patch.\nI looked at the Joda Time bugs list in SourceForge but couldn't see anything that looked relevant: my apologies if I've missed something, or if I'm making a mistake with this bug report.\nColin Bartlett\n"
            },
            "16": {
                "commit_sha_buggy": "dba7c37ea3d83b32779d3bb13cb184aedf761a8a",
                "commit_sha_fixed": "706513d59425e7a9dc6bdb972f25b03b02e48558",
                "report_id": "148",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/148",
                "issue_title": "Joda - Time / Bugs / #148 DateTimeFormatter.parseInto broken when no year in format",
                "issue_description": "\nIn Joda Time 2.0, the default year was set to 2000 so that Feb 29 could be parsed correctly. However, parseInto now overwrites the given instant's year with 2000 (or whatever iDefaultYear is set to). The correct behavior would seem to be to use the given instant's year instead of iDefaultYear.\nThis does mean that Feb 29 might not be parseable if the instant's year is not a leap year, but in this case the caller asked for that in a sense.\n"
            },
            "17": {
                "commit_sha_buggy": "cdeacf09e33ddbaf75a4563d7bc62063f50972b1",
                "commit_sha_fixed": "a8913f5ad5dfde59263c981c9e9eb28e43fd2e00",
                "report_id": "141",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/141",
                "issue_title": "Joda - Time / Bugs / #141 Bug on withLaterOffsetAtOverlap method",
                "issue_description": "\nThe method withLaterOffsetAtOverlap created to workaround the issue 3192457 seems to not be working at all.\nI won\u00b4t write many info about the problem to solve because the issue 3192457 have this info indeed.\nBut If something is unclear I can answer on the comments.\nProblem demonstration:\nTimeZone.setDefault(TimeZone.getTimeZone(\"America/Sao_Paulo\"));\nDateTimeZone.setDefault( DateTimeZone.forID(\"America/Sao_Paulo\") );\n    DateTime dtch;\n    {\n        dtch = new DateTime(2012,2,25,5,5,5,5).millisOfDay().withMaximumValue();\n        System.out.println( dtch ); // prints: 2012-02-25T23:59:59.999-02:00 //Were are at the first 23:** of the day.\n        //At this point dtch have the -03:00 offset\n    }\n    {\n        dtch = dtch.plus(60001);\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-03:00 //Were are at the first minute of the second 23:** of the day. Ok its correct\n        //At this point dtch have the -03:00 offset\n    }\n    {\n        dtch = dtch.withEarlierOffsetAtOverlap();\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-02:00 //Were are at the first minute of the first 23:** of the day. Ok its correct\n        //At this point dtch have the -02:00 offset ( because we called withEarlierOffsetAtOverlap() ) // This method is working perfectly\n    }       \n    {\n        dtch = dtch.withLaterOffsetAtOverlap();\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-02:00 //Were are at the first minute of the first 23:** of the day. \n        // Here is the problem we should have a -03:00 offset here since we called withLaterOffsetAtOverlap() expecting to change to the second 23:** of the day\n    }\n\nOn the last two brackets we can see that withLaterOffsetAtOverlap is not undoing withEarlierOffsetAtOverlap as it should ( and not even working at all )\n"
            },
            "18": {
                "commit_sha_buggy": "e16eb72a29d06ce36030b109156bea3244273fb8",
                "commit_sha_fixed": "b609d7d66d180f2eb537b27f5d605d0596e096ce",
                "report_id": "130",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/130",
                "issue_title": "Joda - Time / Bugs / #130 GJChronology rejects valid Julian dates",
                "issue_description": "\nExample:\nDateTime jdt = new DateTime(1500, 2, 29, 0, 0, 0, 0, JulianChronology.getInstanceUTC()); // Valid.\nDateTime gjdt = new DateTime(1500, 2, 29, 0, 0, 0, 0, GJChronology.getInstanceUTC()); // Invalid.\nThe 2nd statement fails with \"org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\".\nGiven that I left the cutover date at the default (October 15, 1582), isn't 1500/02/29 a valid date in the GJChronology?\n"
            },
            "19": {
                "commit_sha_buggy": "a92450e88df85d6b7a0fa53517da46286c24f53f",
                "commit_sha_fixed": "82c5e4f9550e4df36e07b66f35f7c3e9d7eb5eba",
                "report_id": "124",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/124",
                "issue_title": "Joda - Time / Bugs / #124 Inconsistent interpretation of ambiguous time during DST",
                "issue_description": "\nThe inconsistency appears for timezone Europe/London.\nConsider the following code\n\u2026\nDateTime britishDate = new DateTime(2011, 10, 30, 1, 59, 0, 0, DateTimeZone.forID(\"Europe/London\"));\nDateTime norwDate = new DateTime(2011, 10, 30, 2, 59, 0, 0, DateTimeZone.forID(\"Europe/Oslo\"));\nDateTime finnishDate = new DateTime(2011, 10, 30, 3, 59, 0, 0, DateTimeZone.forID(\"Europe/Helsinki\"));\n    System.out.println(britishDate);\n    System.out.println(norwDate);\n    System.out.println(finnishDate);\n\n\u2026\nThese three DateTime objects should all represent the same moment in time even if they are ambiguous. And using jodatime 1.6.2 this is the case. The code produces the following output:\n2011-10-30T01:59:00.000Z\n2011-10-30T02:59:00.000+01:00\n2011-10-30T03:59:00.000+02:00\nUsing jodatime 2.0 however, the output is:\n2011-10-30T01:59:00.000Z\n2011-10-30T02:59:00.000+02:00\n2011-10-30T03:59:00.000+03:00\nwhich IMO is wrong for Europe/London. Correct output should have been \n2011-10-30T01:59:00.000+01:00\nThe release notes for 2.0 states that: \n\"Now, it always returns the earlier instant (summer time) during an overlap. \u2026\"\n"
            },
            "20": {
                "commit_sha_buggy": "17a60c9a7253d9a8fce6afe2ce46bea78ac53ebe",
                "commit_sha_fixed": "a92450e88df85d6b7a0fa53517da46286c24f53f",
                "report_id": "126",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/126",
                "issue_title": "Joda - Time / Bugs / #126 Errors creating/parsing dates with specific time zones. ",
                "issue_description": "\nConsider the following test code using Joda 2.0\nimport org.joda.time.DateTime;\nimport org.joda.time.DateTimeZone;\nimport org.joda.time.format.DateTimeFormat;\nimport org.joda.time.format.DateTimeFormatter;\nimport java.util.Set;\npublic class JodaDateTimeZoneTester {\nprivate static DateTimeFormatter formatter = DateTimeFormat.forPattern(\"MM/dd/yyyy HH:mm:ss.SSS ZZZ\");\nprivate static int numTimeZonesTested = 0;\nprivate static int numTimeZonesPassed = 0;\nprivate static int numTimeZonesFailed = 0;\nprivate static int numTimeZonesException = 0;\n\nprivate static String convertDateTimeToFormattedString(DateTime dateTime) {\n    return formatter.print(dateTime);\n}\n\nprivate static DateTime parseStringToDateTime(String formattedDateTime) {\n    return formatter.parseDateTime(formattedDateTime);\n}\n\nprivate static void testDateTimeFormatter(DateTime dateTime, String timeZone) {\n    numTimeZonesTested++;\n\n    final String dateTimeZoneId = dateTime.getZone().getID();\n\n    if (!timeZone.equals(dateTimeZoneId)) {\n        numTimeZonesFailed++;\n        System.out.println(timeZone + \" failed to construct into the proper date time zone - constructed time zone = \" + dateTimeZoneId);\n        return;\n    }\n    try {\n        DateTime convertedDateTime = parseStringToDateTime(convertDateTimeToFormattedString(dateTime));\n\n        if (dateTime.equals(convertedDateTime)) {\n            numTimeZonesPassed++;\n            //System.out.println(dateTime.getZone().getID() + \" passed.\");\n        } else {\n            numTimeZonesFailed++;\n            System.out.println(\"Formatter failed for time zone ID: \" + dateTimeZoneId + \"    converted it to: \" + convertedDateTime.getZone().getID());\n        }\n    } catch (IllegalArgumentException iae) {\n        numTimeZonesException++;\n        System.out.println(\"Formatter threw exception for time zone id: \" + dateTimeZoneId);\n    }\n}\n\npublic static void main(String[] args) {\n    Set<String> timeZones = DateTimeZone.getAvailableIDs();\n\n    for (String timeZone : timeZones) {\n        testDateTimeFormatter(DateTime.now().withZone(DateTimeZone.forID(timeZone)), timeZone);\n    }\n\n    System.out.println();\n    System.out.println(\"Number of Time Zones tested: \" + numTimeZonesTested);\n    System.out.println(\"Number passed:     \" + numTimeZonesPassed);\n    System.out.println(\"Number failed:     \" + numTimeZonesFailed);\n    System.out.println(\"Number exceptions: \" + numTimeZonesException);\n    System.out.println();\n}\n\n}\nThe results are out of 572 time zones 130 fail and 30 throw exceptions. \nThe failures are the most interesting. When I query DateTimeZone to get its time zone ids I will get a time zone like America/Atka. When I take that id and create a date time with it its time zone id is America/Adak. It is like there are multiple list of time zones in Joda time and they are out of sync. \nSource code is attached. \n"
            },
            "22": {
                "commit_sha_buggy": "14dedcbc04682c1b1b6c5ebe91bc930b79eeb572",
                "commit_sha_fixed": "57c8aaf94b95323c295dcfec5f40f181846164e7",
                "report_id": "113",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/113",
                "issue_title": "Joda - Time / Bugs / #113 Duration.toPeriod with fixed time zones.",
                "issue_description": "\nI have a question concerning the conversion of a Duration to Period. I'm not sure if this is a bug, or if there is a different way to do this.\nThe basis of the problem, is that using Duration.toPeriod() uses the chronology of the default time zone to do the conversion. This can cause different results from a timezone with DST and one without. This can be reproduced easily with this test.\n//set default time zone with this argument -Duser.timezone=\"GMT\"\npublic void testForJodaForum()\n{\n    System.out.println(\"Timezone: \" + DateTimeZone.getDefault());\n\n    //Duration of more than 24 hours\n    Duration aDuration = new Duration(DateTimeConstants.MILLIS_PER_HOUR * 30 + DateTimeConstants.MILLIS_PER_MINUTE * 50\n        + DateTimeConstants.MILLIS_PER_SECOND * 14);\n\n    System.out.println(\"Duration before: \" + aDuration);\n    Period period = aDuration.toPeriod();\n    System.out.println(\"Period after: \" + period);        \n}\n\nA fixed time zone produces this output\nTimezone: Etc/GMT\nDuration before: PT111014S\nPeriod after: P1DT6H50M14S\nA DST time zone produces this output\nTimezone: America/Chicago\nDuration before: PT111014S\nPeriod after: PT30H50M14S\nIn the joda code, Duration.toPeriod() uses a period constructor that takes the chronology, but null is passed in, so the chronology of the default time zone is used, which leads to this behavior.\nThe javadoc of toPeriod() states that only precise fields of hours, minutes, seconds, and millis will be converted. But for a fixed timezone, days and weeks are also precise, which is stated in the javadoc for toPeriod(Chronology chrono). In our app, we need consistent behavior regardless of the default time zone, which is to have all the extra hours put into the hours bucket. Since Duration is supposed to be a 'time zone independent' length of time, I don't think we should have to do any chronology manipulation to get this to work.\nAny help is appreciated.\nThanks,\nCameron\n"
            },
            "23": {
                "commit_sha_buggy": "bfd37a81dd7f4c9e35340f3de0b5b1e8066a141b",
                "commit_sha_fixed": "14dedcbc04682c1b1b6c5ebe91bc930b79eeb572",
                "report_id": "112",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/112",
                "issue_title": "Joda - Time / Bugs / #112 Incorrect mapping of the MET time zone",
                "issue_description": "\nThis timezone is mapped to Asia/Tehran in DateTimeZone. It should be middle europena time.\nI know that this bug has been raised before (Incorrect mapping of the MET time zone - ID: 2012274), and there is a comment stating that you won't break backward compatibility to fix this bug.\n\nI disagree that this is a backward compatibility argument\nNo matter how you look at it, it is a bug.\n\nYou could very well state that ALL bugs won't be fixed, because of backward compatibility.\nI request again that this bug be fixed.\n"
            },
            "24": {
                "commit_sha_buggy": "c3bec2cd4eea2e87c650f5ad9b537dddb804778c",
                "commit_sha_fixed": "d50efdf75a8daeced88d79b168f68d189fb87e13",
                "report_id": "107",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/107",
                "issue_title": "Joda - Time / Bugs / #107 Incorrect date parsed when week and month used together",
                "issue_description": "\nI have following code snippet :\n    DateTimeFormatter dtf = DateTimeFormat.forPattern(\"xxxxMM'w'ww\");\nDateTime dt = dtf.parseDateTime(\"201101w01\");       \nSystem.out.println(dt);\n\nIt should print 2011-01-03 but it is printing 2010-01-04. \nPlease let me know if I am doing something wrong here. \n"
            },
            "25": {
                "commit_sha_buggy": "c7a581e55fc988bd90fa4bb1b0acece5181b7c5f",
                "commit_sha_fixed": "552be4b677ec30a34d04d234395ba1a8c7beaacf",
                "report_id": "90",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/90",
                "issue_title": "Joda - Time / Bugs / #90 DateTimeZone.getOffsetFromLocal error during DST transition",
                "issue_description": "\nThis may be a failure of my understanding, but the comments in DateTimeZone.getOffsetFromLocal lead me to believe that if an ambiguous local time is given, the offset corresponding to the later of the two possible UTC instants will be returned - i.e. the greater offset.\nThis doesn't appear to tally with my experience. In fall 2009, America/Los_Angeles changed from -7 to -8 at 2am wall time on November 11. Thus 2am became 1am - so 1:30am is ambiguous. I would therefore expect that constructing a DateTime for November 11th, 1:30am would give an instant corresponding with the later value (i.e. 9:30am UTC). This appears not to be the case:\nimport org.joda.time.DateTime;\nimport org.joda.time.DateTimeZone;\npublic class TzTest {\npublic static void main(String[] args) throws Exception {\nDateTimeZone zone = DateTimeZone.forID(\"America/Los_Angeles\");\nDateTime when1 = new DateTime(2009, 11, 1, 0, 30, 0, 0, zone);\nDateTime when2 = new DateTime(2009, 11, 1, 1, 30, 0, 0, zone);\nDateTime when3 = new DateTime(2009, 11, 1, 2, 30, 0, 0, zone);\nSystem.out.println(when1);\nSystem.out.println(when2);\nSystem.out.println(when3);\n}\n}\nResults:\n2009-11-01T00:30:00.000-07:00 // Correct\n2009-11-01T01:30:00.000-07:00 // Should be -08:00\n2009-11-01T02:30:00.000-08:00 // Correct\n"
            },
            "26": {
                "commit_sha_buggy": "218a7fe91a685e089ab8fd7700806f7a6083f18d",
                "commit_sha_fixed": "c7a581e55fc988bd90fa4bb1b0acece5181b7c5f",
                "report_id": "60",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/60",
                "issue_title": "Joda - Time / Bugs / #60 .withHourOfDay() sets hour inconsistantly on DST transition.",
                "issue_description": "\nWhen the hour of day is set to the ambiguous hour on the daylight to\nstandard time transition in a given time zone the result is inconsistent for different time zones. Shoul the hour be set to the\ndaylight hour or the standard hour for all time zones? I can't find anything\nthat documents this behavior.\nMy test code below returns different results for different time zones.\n/\n Verify Joda converts the hour of day the same for regions north and\nsouth of the equator on the DST daylight to standard time transition.\n*/\n@Test\npublic void jodaTest ()\n{\nChronology chronUTC =\nGregorianChronology.getInstance(DateTimeZone.UTC);\nDateTime usCentralStandardInUTC = new DateTime(2008, 11, 2, 7, 0, 0,\n0, chronUTC);\nDateTime usCentralDaylightInUTC = new DateTime(2008, 11, 2, 6, 0, 0,\n0, chronUTC);\nChronology chronUSCentral =\nGregorianChronology.getInstance(DateTimeZone.forID(\"US/Central\"));\nAssert.assertTrue(\"Should be standard time\",\nchronUSCentral.getZone().isStandardOffset(\nusCentralStandardInUTC.getMillis()));\nAssert.assertFalse(\"Should be daylight time\",\nchronUSCentral.getZone().isStandardOffset(\nusCentralDaylightInUTC.getMillis()));\nDateTime usCentralStandardInUSCentral =\nusCentralStandardInUTC.toDateTime(chronUSCentral);\nDateTime usCentralDaylightInUSCentral =\nusCentralDaylightInUTC.toDateTime(chronUSCentral);\nassertEquals(1, usCentralStandardInUSCentral.getHourOfDay());\nassertEquals(usCentralStandardInUSCentral.getHourOfDay(),\nusCentralDaylightInUSCentral.getHourOfDay());\nAssert.assertTrue(usCentralStandardInUSCentral.getMillis() !=\nusCentralDaylightInUSCentral.getMillis());\nDateTime australiaNSWStandardInUTC = new DateTime(2008, 4, 5, 16, 0,\n0, 0, chronUTC);\nDateTime australiaNSWDaylightInUTC = new DateTime(2008, 4, 5, 15, 0,\n0, 0, chronUTC);\nChronology chronAusNSW =\nGregorianChronology.getInstance(DateTimeZone.forID(\"Australia/NSW\"));\nAssert.assertTrue(\"Should be standard time\",\nchronAusNSW.getZone().isStandardOffset(\naustraliaNSWStandardInUTC.getMillis()));\nAssert.assertFalse(\"Should be daylight time\",\nchronAusNSW.getZone().isStandardOffset(\naustraliaNSWDaylightInUTC.getMillis()));\nDateTime australiaNSWStandardInAustraliaNSW =\naustraliaNSWStandardInUTC.toDateTime(chronAusNSW);\nDateTime australiaNSWDaylightInAusraliaNSW =\naustraliaNSWDaylightInUTC.toDateTime(chronAusNSW);\nassertEquals(2, australiaNSWStandardInAustraliaNSW.getHourOfDay());\nassertEquals(australiaNSWStandardInAustraliaNSW.getHourOfDay(),\naustraliaNSWDaylightInAusraliaNSW.getHourOfDay());\nAssert.assertTrue(australiaNSWStandardInAustraliaNSW.getMillis() !=\naustraliaNSWDaylightInAusraliaNSW.getMillis());\n// Verify that setting the hour of day on the DST boundary results\nin a daylight time for\n// both time zones.\nassertEquals(usCentralDaylightInUSCentral,\nusCentralStandardInUSCentral.withHourOfDay(1));\nassertEquals(australiaNSWDaylightInAusraliaNSW,\naustraliaNSWStandardInAustraliaNSW.withHourOfDay(2));\n}\nThe very last assertion fails on the Australia time zone cutover.\njava.lang.AssertionError: expected:<2008-04-06T02:00:00.000+11:00> but\nwas:<2008-04-06T02:00:00.000+10:00>\n"
            },
            "27": {
                "commit_sha_buggy": "d090b642dc04259286d3478cfa49f1da2f0755e6",
                "commit_sha_fixed": "e0559c503f65641b9546c37e7c84c866caf37e66",
                "report_id": "64",
                "report_url": "https://sourceforge.net/p/joda-time/bugs/64",
                "issue_title": "Joda - Time / Bugs / #64 Different behaviour of PeriodFormatter",
                "issue_description": "\nPeriodFormatter pfmt2 = pfmtbuilder2.append(ISOPeriodFormat.standard() ).toFormatter(); is not the same as \nPeriodFormatterBuilder pfmtbuilder1 = new PeriodFormatterBuilder()\n.appendLiteral(\"P\")\n.appendYears()\n.appendSuffix(\"Y\")\n.appendMonths()\n.appendSuffix(\"M\")\n.appendWeeks()\n.appendSuffix(\"W\")\n.appendDays()\n.appendSuffix(\"D\")\n.appendSeparatorIfFieldsAfter(\"T\")\n.appendHours()\n.appendSuffix(\"H\")\n.appendMinutes()\n.appendSuffix(\"M\")\n.appendSecondsWithOptionalMillis()\n.appendSuffix(\"S\");\nwhich is copied from ISOPeriodFormat.standard() method\n"
            }
        }
    },
    "Dbutils": {
        "owner_repo": "apache/commons-dbutils",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3d007fb729d5168f326c800c2e4f79e544443d1a",
                "commit_sha_fixed": "ef498ba4cba355b0ceb677563036385cc9541969",
                "report_id": "DBUTILS-57",
                "report_url": "https://issues.apache.org/jira/browse/DBUTILS-57",
                "issue_title": "[DBUTILS-57] BeanProcessor not able to map an alias column from a HSQLDB query to the any bean properties - ASF JIRA",
                "issue_description": "\nUsing a query with an alias, hsqldb engine doesn't populate the column name metadata only the column label metadata.\nIn such a case the column isn't mapped.\nTo resolve this, the column label should be used in case the column name is not available.\nHere is a snippet from org.apache.commons.dbutils.BeanProcessor.mapColumnsToProperties line 393 : \n...\n       for (int col = 1; col <= cols; col++) {            \n            String columnName = rsmd.getColumnName(col);\n           // columnName is empty, revert to column label\n            if (columnName.length() == 0) \n{\n                columnName = rsmd.getColumnLabel(col);\n            }\n \n            ...\n"
            },
            "2": {
                "commit_sha_buggy": "5d61f564f8b1f5e4620e57cad557173d825046e8",
                "commit_sha_fixed": "c8c9329c518186865a2d279a58b53e291086a280",
                "report_id": "DBUTILS-114",
                "report_url": "https://issues.apache.org/jira/browse/DBUTILS-114",
                "issue_title": "[DBUTILS-114] Order of columns not retained in BasicRowProcessor with HashMap - ASF JIRA",
                "issue_description": "\nThe CaseInsensitiveHashMap extends HashMap. This means that the order of columns defined in a select query is not retained when one wants to iterate over the entry set. This be changed to LinkedHashMap.\n"
            }
        }
    },
    "Functor": {
        "owner_repo": "apache/commons-functor",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f501421ec00fe5c9a15382ec8355b75b096706f3",
                "commit_sha_fixed": "e738aefa204b5e9420a8af0b6882e9be0db4d325",
                "report_id": "FUNCTOR-8",
                "report_url": "https://issues.apache.org/jira/browse/FUNCTOR-8",
                "issue_title": "[FUNCTOR-8] [PATCH] Possible NPE in TransformedGenerator if getWrappedGenerator() is overridden to return null - ASF JIRA",
                "issue_description": "\nIf we override getWrappedGenerator method in TransformedGenerator to return null, it may result in a NullPointerException if hashCode is called.\nAttached the patch for it, and below a snippet of code to reproduce this issue.\n    TransformedGenerator<Integer, Integer> t = new TransformedGenerator<Integer, Integer>(\n\tnew IntegerRange(1, 10), new UnaryFunction<Integer, Integer>() {\n\t\tpublic Integer evaluate(Integer obj) \n{\n\t\t\treturn obj += 1;\n\t\t}\n   \t}) {\n    \t@Override\n\t    protected Generator<? extends Integer> getWrappedGenerator() \n{\n    \t\treturn null;\n    \t}\n    };\n    TransformedGenerator<Integer, Integer> t2 = new TransformedGenerator<Integer, Integer>(\n\tnew IntegerRange(1, 10), new UnaryFunction<Integer, Integer>() {\n\t\tpublic Integer evaluate(Integer obj) \n{\n\t\t\treturn obj -= 1;\n\t\t}\n\t});\n    System.out.println(t.equals(t2));\n    System.out.println(t.hashCode() == t2.hashCode()); // NPE\nCheers,\nBruno P. Kinoshita\n"
            },
            "2": {
                "commit_sha_buggy": "fbc0dc7d81d8b4d3c448155c5907e06d996d9d58",
                "commit_sha_fixed": "f72ca72b68487ad6e9eb9245cc24ff987269bcd1",
                "report_id": "FUNCTOR-21",
                "report_url": "https://issues.apache.org/jira/browse/FUNCTOR-21",
                "issue_title": "[FUNCTOR-21] NPE when UnarySequence is created with an arraylist containing a null element - ASF JIRA",
                "issue_description": "\nIf you create a UnarySequence<?> with an ArrayList that contains a null element and execute the run method, you will receive a NullPointerException. \nThe same happens when you use the constructor UnarySequence(UnaryProcedure<? super A>... procedures). A null procedure is converted into a list with the null object as the sole element.\n"
            }
        }
    },
    "Imaging": {
        "owner_repo": "apache/commons-imaging",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "979c6856b1869ecf1309c926f732ab52af8c3334",
                "commit_sha_fixed": "39f463da29620668e1a4c6459997be52cce72681",
                "report_id": "IMAGING-82",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-82",
                "issue_title": "[IMAGING-82] BMP Physical Width in inches and Physical Height in inches is wrong - ASF JIRA",
                "issue_description": "\nHresolution and Vresolition are in pixels per meter . I have uploaded the correct formula for calculating the Physical Width and Physical Height in inches.\n"
            },
            "3": {
                "commit_sha_buggy": "5ab7a3e29bb8c6a13b961a06db7d9ca3a298f4cf",
                "commit_sha_fixed": "7d886c0bf06232096740c5066aaf5510d8e7abf5",
                "report_id": "IMAGING-169",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-169",
                "issue_title": "[IMAGING-169] PnmImageParser throws NumberFormatException instead of ImageReadException when parsing invalid images - ASF JIRA",
                "issue_description": "\nThe general contract for the image parsers is to throw ImageReadException if they are passed an invalid image. PnmImageParser would throw NumberFormatException if the width or header could not be parsed.\n"
            },
            "4": {
                "commit_sha_buggy": "f1fe855f42701c5d98a9b7c59f3626e762bc06f6",
                "commit_sha_fixed": "801a75dcf871914d243f585c8755140eda52c69f",
                "report_id": "IMAGING-178",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-178",
                "issue_title": "[IMAGING-178] PnmImageParser does not check the validity of input PAM header - ASF JIRA",
                "issue_description": "\nPnmImageParser.java directly calls tokenizer.nextToken() at line no 160, 163, 166, 169 and 172 on java.util.StringTokenizer tokenizer without checking if there are more tokens.  Because tokenizer is built from the bytes string that can be invalid, this can lead to a runtime exception without a useful error message.  This can be easily fixed by calling tokenizer.hasMoreTokens() before calling tokenizer.nextToken() at each line number mentioned before and throwing useful error message.\n"
            },
            "5": {
                "commit_sha_buggy": "cd5ef9b33efea115d54d5f536f157cbae3990366",
                "commit_sha_fixed": "ed6115b320aa309100ba2edabff22f5e0c51a71b",
                "report_id": "IMAGING-176",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-176",
                "issue_title": "[IMAGING-176] TiffImageParser.getImageInfo() throws exception when \"Compression\" field is missing - ASF JIRA",
                "issue_description": "\nA solution that worked for my case was to default to no compression.\nhttps://github.com/apache/commons-imaging/pull/19\n"
            },
            "6": {
                "commit_sha_buggy": "b4374368a133614347ca4583cc3f34c84cf538aa",
                "commit_sha_fixed": "fb0be4a4b561ddc3aa942f2929f734b0bdd9a035",
                "report_id": "IMAGING-209",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-209",
                "issue_title": "[IMAGING-209] PnmImageParser throws ImageWriteException when writing if PnmImageParser.PARAM_KEY_PNM_RAWBITS is provided - ASF JIRA",
                "issue_description": "\nCode sample:\n\n\r\nMap<String, Object> params = new HashMap<>();\r\nparams.put(PnmImageParser.PARAM_KEY_PNM_RAWBITS, PnmImageParser.PARAM_VALUE_PNM_RAWBITS_YES);\r\nImaging.writeImage(image, file, ImageFormats.PNM, params);\r\n\n\nError message is: \"Unknown parameter: PNM_RAWBITS:\nThis happens because used parameters are cleared from the map after usage and any remaining parameters are determined to be unknown, but PnmImageParser.PARAM_KEY_PNM_RAWBITS is never cleared.\nI will provide a patch on Github shortly.\n"
            },
            "7": {
                "commit_sha_buggy": "c5ca63fe3864a0fd7673641d08049741e94a0287",
                "commit_sha_fixed": "4701b96281124b9ccd6ecd35c3f16aa73345f315",
                "report_id": "IMAGING-203",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-203",
                "issue_title": "[IMAGING-203] JPEG segment size not validated - ASF JIRA",
                "issue_description": "\nUsing my AFL-based fuzzer for Java, Kelinci (https://github.com/isstac/kelinci) I found that a NegativeArraySizeException may be throw when attempting to read an invalid JPEG image.\nEach JPEG segment starts with a two-byte unsigned integer specifying the segment size. Segments are parsed by org.apache.commons.imaging.formats.jpeg.JpegUtils.traverseJFIF(). As the specified size includes these two bytes, the method subtracts 2 from the size before it is used. It then attempts to allocate a buffer for the segment, which fails if the specified size is 0 or 1. The method should throw an ImageReadException instead.\n"
            },
            "8": {
                "commit_sha_buggy": "eb98398bd111cdc35b2c9a5fc8022a28d7c99035",
                "commit_sha_fixed": "f5574bfe285edd79207fe8c30f53cb0af06e26bb",
                "report_id": "IMAGING-219",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-219",
                "issue_title": "[IMAGING-219] Imaging gets stuck parsing a RGBE input file - ASF JIRA",
                "issue_description": "\nFound by Guido Vranken. The input file attached results in an input reader returning -1 for the .read() method during the RGBE decompress stage.\nThis causes the application to hang. This does not affect Sanselan, as there was no RGBE parser or visitor in that version.\n"
            },
            "10": {
                "commit_sha_buggy": "120ef1c107e8641a4277b46997dd144bb851df5d",
                "commit_sha_fixed": "305e78a0aef8dc0cd267581ebc7a4a5f8316ee18",
                "report_id": "IMAGING-199",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-199",
                "issue_title": "[IMAGING-199] All tEXt chunks are not returned from PngImageParser.getMetadata - ASF JIRA",
                "issue_description": "\nAccording to the PNG spec - Section 4.2.3 - Textual Information -\n\"Any number of text chunks can appear, and more than one with the same keyword is permissible. \"\nUnfortunately the PngImageParser.getMetadata method only supports a single tEXt chunk.  The problem is in the following line:\n        final List<PngChunk> chunks = readChunks(byteSource, new ChunkType[] \n{ ChunkType.tEXt, ChunkType.zTXt, }\n, true);\nTrue is being passed for returnAfterFirst. I believe that false should be passed instead.\nI can submit a pull request if you agree.\n"
            },
            "11": {
                "commit_sha_buggy": "55f7368822b9781d186024524c7cd08adb3a2f59",
                "commit_sha_fixed": "f55035ac7fb451e85e3139c959a25f47f4ffd04a",
                "report_id": "IMAGING-211",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-211",
                "issue_title": "[IMAGING-211] Imaging.getBufferedImage fails throwing java.lang.ArrayIndexOutOfBoundsException for specific inputs -- evintila-april_dynamics - ASF JIRA",
                "issue_description": "\nFor specific inputs, Imaging.getBufferedImage fails throwing java.lang.ArrayIndexOutOfBoundsException: -99, instead of ImageReadException or IOException. \n Example code that can be used to reproduce the problem, with \"testfile_2\" found at this link testfile_2:\n\n\r\n// evintila @ April Dynamics\r\nFile file = new File(\"testfile_2\");\r\nfinal Map<String, Object> params = new HashMap<>();\r\nparams.put(ImagingConstants.BUFFERED_IMAGE_FACTORY,\r\nnew ManagedImageBufferedImageFactory());\r\n\r\ntry\r\n\r\n{ // the problem is here: \r\n    final BufferedImage image = Imaging.getBufferedImage(file, params); }\r\n\r\ncatch (ImageReadException e)\r\n{\r\n\r\n} catch (IOException e)\r\n{\r\n\r\n}\n\nOutput:\n\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: -99\r\nat org.apache.commons.imaging.formats.png.chunks.PngChunkIhdr.<init>(PngChunkIhdr.java:55)\r\nat org.apache.commons.imaging.formats.png.PngImageParser.readChunks(PngImageParser.java:186)\r\nat org.apache.commons.imaging.formats.png.PngImageParser.readChunks(PngImageParser.java:229)\r\nat org.apache.commons.imaging.formats.png.PngImageParser.getBufferedImage(PngImageParser.java:494)\r\nat org.apache.commons.imaging.Imaging.getBufferedImage(Imaging.java:1377)\r\nat org.apache.commons.imaging.Imaging.getBufferedImage(Imaging.java:1365)\n\n\u00a0\n"
            },
            "14": {
                "commit_sha_buggy": "0c773d2a83c81eb470ab491f9bb4eb0031c3f9f1",
                "commit_sha_fixed": "02bd6c4fb271cbf69fe11554b3dbb69279428c6f",
                "report_id": "IMAGING-210",
                "report_url": "https://issues.apache.org/jira/browse/IMAGING-210",
                "issue_title": "[IMAGING-210] Imaging.getBufferedImage fails throwing NegativeArraySizeException for specific inputs -- evintila-april_dynamics - ASF JIRA",
                "issue_description": "\nFor specific inputs, Imaging.getBufferedImage fails throwing java.lang.NegativeArraySizeException, instead of ImageReadException or IOException. \nExample code that can be used to reproduce the problem, with \"testfile\" found at this link https://drive.google.com/open?id=1GYB3ArNv8fk9NUes0wTQ2vioy4iMfmeR:\n// evintila @ April Dynamics\nFile file = new File(\"testfile\");\nfinal Map<String, Object> params = new HashMap<>();\nparams.put(ImagingConstants.BUFFERED_IMAGE_FACTORY,\n    new ManagedImageBufferedImageFactory());\ntry\n{\r\n// the problem is here:\r\nfinal BufferedImage image = Imaging.getBufferedImage(file, params);\r\n}\n catch (ImageReadException e)\n{\n} catch (IOException e)\n{\n}\n"
            }
        }
    },
    "IO": {
        "owner_repo": "apache/commons-io",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e7ca7823f0c4ab695b915d960833a265a383f064",
                "commit_sha_fixed": "1d0c2d0ba1ddc78070e415d05b2bd26cb288cecb",
                "report_id": "IO-84",
                "report_url": "https://issues.apache.org/jira/browse/IO-84",
                "issue_title": "[IO-84] Many classes are limited to length of stream < 2 GB, and behave incorrectly on larger streams - ASF JIRA",
                "issue_description": "\njava int.MAX_VALUE is 2 GB. Classes that handle streams larger than 2 GB will behave incorrectly.\nFor example, see \nhttp://svn.apache.org/viewvc/jakarta/commons/proper/io/trunk/src/java/org/apache/commons/io/IOUtils.java?view=markup\nMethod: int copy(InputStream input, OutputStream output).\nThe correct method would be: long copy(InputStream input, OutputStream output).\nThis issue may affect many classes and routines.\n"
            },
            "2": {
                "commit_sha_buggy": "a354d0a5ebbb00a9758f93e72d51078177576918",
                "commit_sha_fixed": "740afb04f70a27cee28eb8ade5d1b819be71c502",
                "report_id": "IO-101",
                "report_url": "https://issues.apache.org/jira/browse/IO-101",
                "issue_title": "[IO-101] The method EndianUtils.writeSwappedDouble() and EndianUtils.readSwappedDouble() do not match! - ASF JIRA",
                "issue_description": "\nCode:\npublic static void main(String[] args) {\n\t\tdouble[] tests = new double[] \n{34.345, -345.5645, 545.12, 10.043, 7.123456789123}\n;\n\t\tfor (int i = 0; i< tests.length ;i++) \n{\n\t\t\tbyte[] buffer = new byte[8];\t\t\t\n\t\t\tEndianUtils.writeSwappedDouble(buffer, 0, tests[i]);\n\t\t\tdouble val = EndianUtils.readSwappedDouble(buffer, 0);\n\t\t\tSystem.out.println(val);\t\n\t\t}\n\n}\nResult:\n34.344969482421874\n-345.5645\n545.11951171875\n10.043\n7.123456789123\nNote:\nIn my opinion the values shouldn't be changed at all.\n"
            },
            "3": {
                "commit_sha_buggy": "d981b95df458230c30beffa819f3110274bbf7fe",
                "commit_sha_fixed": "403949d8075f3aca227825b69de2de21342071e9",
                "report_id": "IO-112",
                "report_url": "https://issues.apache.org/jira/browse/IO-112",
                "issue_title": "[IO-112] NPE in FileUtils.openOutputStream(File) when file has no parent in path. - ASF JIRA",
                "issue_description": "\n----Original Message----\nFrom: deng xinzi xinzi6388@gmail.com \nSent: Sunday, February 04, 2007 6:19 AM\nTo: commons-dev@jakarta.apache.org\nSubject: [bug]commons-io 1.3 FileUtils.openOutputStream(File file) NullPointException\nFileUtils.openOutputStream(File file)\nWhen the file = new File( \"abc.txt\" );\nThere will be a NullPointerException throw.\nCause\nfile = new File(\"abc.txt\")\nfile.getParentFile() returns null.\nSo I suggest adding the null check code like this.\n            File parent = file.getParentFile();\n            if( parent Unable to render embedded object: File (= null ) {   // ADD THIS) not found.!!\n              if (parent.exists() == false) {\n                if (parent.mkdirs() == false) \n{\n                    throw new IOException(\"File '\" + file + \"' could not be\ncreated\");\n                }\n              }\n            }\n                                       Xinzi ...\n"
            },
            "5": {
                "commit_sha_buggy": "ea3781d3e141599cb3a36f8a236366927a9d10fe",
                "commit_sha_fixed": "4a02524aef7f78af52cc7c7beedfa1eb83f8ccb5",
                "report_id": "IO-128",
                "report_url": "https://issues.apache.org/jira/browse/IO-128",
                "issue_title": "[IO-128] NPE on FilenameUtils.equalsNormalizedOnSystem() - ASF JIRA",
                "issue_description": "\nThe following code in commons-io (1.3.2) throws an NPE exception:\norg.apache.commons.io.FilenameUtils\n    .equalsNormalizedOnSystem(\n            \"//a.html\",\n            \"//ab.html\");\nAnd here is the exception:\njava.lang.NullPointerException: The strings must not be null\n   at org.apache.commons.io.IOCase.checkEquals(IOCase.java:141)\n   at org.apache.commons.io.FilenameUtils.equals(FilenameUtils.java:984)\n   at org.apache.commons.io.FilenameUtils.equalsNormalizedOnSystem(FilenameUtils.java:956)\n   at CodeSnippet_32.run(CodeSnippet_32.java:4)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain1.eval(ScrapbookMain1.java:20)\n   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n   at java.lang.reflect.Method.invoke(Method.java:585)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.evalLoop(ScrapbookMain.java:54)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.main(ScrapbookMain.java:35)\nI think it is wrong a message \"The strings must not be null\", since there is not a null string involved in the call.\nInteresting is if both or 1 of the strings is null, it did not throws an exception.\nAdditional comment from Niall Pemberton (on the dev mail list):\nThe problem is that the FilenameUtils's normalize(String) method\nreturns \"null\" if it thinks the file names are invalid - which in your\ncase it seems to be doing so for both file names.\nSo I guess theres two issues here - you're right the error is\nmisleading and FilenameUtils should check the names again after\ncalling normalize() for nulls and throw a more appropriate message.\n"
            },
            "6": {
                "commit_sha_buggy": "fe3554cc2c0ab534e90742d03d5663c30a173973",
                "commit_sha_fixed": "5ef9722809594f9e087a5be77c098057ef42969a",
                "report_id": "IO-128",
                "report_url": "https://issues.apache.org/jira/browse/IO-128",
                "issue_title": "[IO-128] NPE on FilenameUtils.equalsNormalizedOnSystem() - ASF JIRA",
                "issue_description": "\nThe following code in commons-io (1.3.2) throws an NPE exception:\norg.apache.commons.io.FilenameUtils\n    .equalsNormalizedOnSystem(\n            \"//a.html\",\n            \"//ab.html\");\nAnd here is the exception:\njava.lang.NullPointerException: The strings must not be null\n   at org.apache.commons.io.IOCase.checkEquals(IOCase.java:141)\n   at org.apache.commons.io.FilenameUtils.equals(FilenameUtils.java:984)\n   at org.apache.commons.io.FilenameUtils.equalsNormalizedOnSystem(FilenameUtils.java:956)\n   at CodeSnippet_32.run(CodeSnippet_32.java:4)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain1.eval(ScrapbookMain1.java:20)\n   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n   at java.lang.reflect.Method.invoke(Method.java:585)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.evalLoop(ScrapbookMain.java:54)\n   at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.main(ScrapbookMain.java:35)\nI think it is wrong a message \"The strings must not be null\", since there is not a null string involved in the call.\nInteresting is if both or 1 of the strings is null, it did not throws an exception.\nAdditional comment from Niall Pemberton (on the dev mail list):\nThe problem is that the FilenameUtils's normalize(String) method\nreturns \"null\" if it thinks the file names are invalid - which in your\ncase it seems to be doing so for both file names.\nSo I guess theres two issues here - you're right the error is\nmisleading and FilenameUtils should check the names again after\ncalling normalize() for nulls and throw a more appropriate message.\n"
            },
            "8": {
                "commit_sha_buggy": "c3b706ab8852c57446064031067dcbb92380502d",
                "commit_sha_fixed": "e87486f1a35090a754fdf95f3cd1178bcfd7e2ba",
                "report_id": "IO-163",
                "report_url": "https://issues.apache.org/jira/browse/IO-163",
                "issue_title": "[IO-163] FileUtils.toURLs() uses deprecated (and bad) method of conversion to URL - ASF JIRA",
                "issue_description": "\nThe method FileUtils.toURLs() uses the following method to convert from File to URL:\n    File.toURL();\nThis method has scary warnings that it's a bad way to do the conversion because characters will not be escaped as required in URL strings.  In Java 1.6, this method has actually been deprecated.  All recent JDK versions recommend instead using:\n    File.toURI().toURL();\nas the URI code will properly perform the escaping.\n"
            },
            "9": {
                "commit_sha_buggy": "0b86b74abdfdc8165eec057be2c579be40aea038",
                "commit_sha_fixed": "d55dd62cc0b07e1124369d74dd0095cc2b491dfe",
                "report_id": "IO-179",
                "report_url": "https://issues.apache.org/jira/browse/IO-179",
                "issue_title": "[IO-179] StringIndexOutOfBounds exception on FilenameUtils.getPathNoEndSeparator - ASF JIRA",
                "issue_description": "\npublic void testFilenameUtils() \n{\n String path = \"/foo.xml\";\n org.apache.commons.io.FilenameUtils.getPathNoEndSeparator(path);\n }\n\n\nLeads to:\njava.lang.StringIndexOutOfBoundsException: String index out of range: -1\n\tat java.lang.String.substring(String.java:1768)\n\tat org.apache.commons.io.FilenameUtils.doGetPath(FilenameUtils.java:705)\n\tat org.apache.commons.io.FilenameUtils.getPathNoEndSeparator(FilenameUtils.java:683)\n"
            },
            "10": {
                "commit_sha_buggy": "168faab974a90e242031d39f9e3114dfd55dcddd",
                "commit_sha_fixed": "d7b629b0288bfeaf7d9fbe93d608ebe8ffe6ee0b",
                "report_id": "IO-231",
                "report_url": "https://issues.apache.org/jira/browse/IO-231",
                "issue_title": "[IO-231] FileUtils generate wrong exception message in isFileNewer method - ASF JIRA",
                "issue_description": "\n\nif (!reference.exists()) {\n    throw new IllegalArgumentException(\"The reference file '\" + file + \"' doesn't exist\");\n}\n\n\nIf second argument file does not exist isFileNewer method generates exception with message about first argument file does not exist.\n"
            },
            "11": {
                "commit_sha_buggy": "8f2e98882296a917c500e35aaded0d6bec08d7ce",
                "commit_sha_fixed": "86e4b30ba700cb8bcf4d7488e0d60e07a75d6315",
                "report_id": "IO-243",
                "report_url": "https://issues.apache.org/jira/browse/IO-243",
                "issue_title": "[IO-243] SwappedDataInputStream readBoolean is inverted - ASF JIRA",
                "issue_description": "\nThe method readBoolean in SwappedDataInputStream returns true when the byte is zero, false otherwise. In accordance with the contract in java.io.DataInput, true should indicate a non-zero byte. SwappedDataInputStream is for reading Little Endian formats, it should not change the boolean value of individual bytes.\n"
            },
            "12": {
                "commit_sha_buggy": "4353d481a16f046a19be7995e99bbc6edc18ddad",
                "commit_sha_fixed": "4286199ac5ad636d11f4428d1827b78d94217e06",
                "report_id": "IO-217",
                "report_url": "https://issues.apache.org/jira/browse/IO-217",
                "issue_title": "[IO-217] FileUtils.copyDirectoryToDirectory makes infinite loops - ASF JIRA",
                "issue_description": "\nWhen using FileUtils.copyDirectoryToDirectory, infinite loops has occurred.\n\u2013 detail \u2013\nsrc directory :  D:\\a\ndest directory : D:\\a\ncall : FileUtils.copyDirectoryToDirectory(new File(\"D:\\a\"), new File(\"D:\\a\"));\nexpected result : directory D:\\a\\a will be created\nactual result      : D:\\a\\a\\a\\a.......   was created\ni guess FileUtils.copyDirectoryToDirectory causes of this result.\n(\"destDir.mkdir()\" is done before \"srcDir.listFiles()\")\nam i calling wrong method?\nthank you.\n"
            },
            "13": {
                "commit_sha_buggy": "ed01f165f9bbb7ccbd48dde7dd3106eb044dd859",
                "commit_sha_fixed": "d062bd01f7e9e9194ae0fd9dc01683e7c934c315",
                "report_id": "IO-246",
                "report_url": "https://issues.apache.org/jira/browse/IO-246",
                "issue_title": "[IO-246] FilenameUtils.wildcardMatch gives incorrect results - ASF JIRA",
                "issue_description": "\nThis wildcard pattern \"*?\" does not match correctly. The command:\nSystem.out.println(FilenameUtils.wildcardMatch(\"aaa\", \"*?\"));\nprints out \"false\", even though it matches. The wildcard mask is a bit unusal, but not incorrect. It should match any input with at least one character.\n"
            },
            "14": {
                "commit_sha_buggy": "a8e9eef627d00022fe6a6bbda64a9478c6b89dab",
                "commit_sha_fixed": "e295faec880b136d5c19d4164c17d768d7037af7",
                "report_id": "IO-190",
                "report_url": "https://issues.apache.org/jira/browse/IO-190",
                "issue_title": "[IO-190] FileUtils.copyDirectory preserves destination subdirectories, rather than overwriting with the source subdirectories - ASF JIRA",
                "issue_description": "\nWhen using FileUtils.copyDirectory to copy directories with subdirectories, the source will overwrite all files that exist in the destination directory, but not the subdirectories themselves. The files inside the subdirectories will be overwritten. The only difference that I've noticed thus far is that this preserves the old file dates of the subdirectories rather than using the dates from the source or the current date, if preserveFileDate is set to 'false.'\n"
            },
            "15": {
                "commit_sha_buggy": "709699a220fd036759ce28623a5389624ac81be0",
                "commit_sha_fixed": "9e612272b0f2ae0f3fb0e2163fdcc918bc6731a4",
                "report_id": "IO-248",
                "report_url": "https://issues.apache.org/jira/browse/IO-248",
                "issue_title": "[IO-248] getFullPathNoEndSeparator return empty while path is one level directory - ASF JIRA",
                "issue_description": "\nthe getFullPathNoEndSeparator method in FilenameUtils.java (Revision 736890) \nif filename=\"/\" return \"/\" <<==right\nif filename=\"/abc\" return empty <<==bug\nif filename=\"/abc/xyz\" return \"/abc\" <<==right \n\n885 \tint index = indexOfLastSeparator(filename);\n886 \tif (index < 0) {\n887 \t\treturn filename.substring(0, prefix);\n888 \t}\n889 \tint end = index + (includeSeparator ? 1 : 0);\n================\n                if(end==0) return \"/\";\n>>>>>>>>>>>>>>>>\n890 \treturn filename.substring(0, end);\n\n\n"
            },
            "16": {
                "commit_sha_buggy": "f113fe9d2f6ad04047bde353994e4e475f83b409",
                "commit_sha_fixed": "a8d59e345210ca6fd3fc426ab7fb7b3c2563cb04",
                "report_id": "IO-209",
                "report_url": "https://issues.apache.org/jira/browse/IO-209",
                "issue_title": "[IO-209] FileSystemUtils.freeSpaceKb fails to return correct size for a windows mount point - ASF JIRA",
                "issue_description": "\nFileSystemUtils.freeSpaceKb fails to return correct result for a NTFS mount point or junction.\nSuppose I have a NTFS partition mounted at C:\\Data\\partition1.\nNow assume that the free space on Partition mounted as C: is 1GB and that mounted on \"C:\\Data\\partition1\" is 2GB. A call to FileSystemUtils.freeSpaceKb(\"C:\\Data\\partition1\") will return the free space on C: and not on \"C:\\Data\\partition1\".\nThis is because while running the \"dir /-c\" with the given path, the code just retains first 2 chars i.e. for any path under \"C:\\blah\\de\\blah\", \"dir /-c\" will be called with \"C:\" which will return incorrect result.\n"
            },
            "17": {
                "commit_sha_buggy": "317841f44a515e57356fe50d7eb1be15030dfb5b",
                "commit_sha_fixed": "a360f974003c5c60c16d019e873314c09d965107",
                "report_id": "IO-209",
                "report_url": "https://issues.apache.org/jira/browse/IO-209",
                "issue_title": "[IO-209] FileSystemUtils.freeSpaceKb fails to return correct size for a windows mount point - ASF JIRA",
                "issue_description": "\nFileSystemUtils.freeSpaceKb fails to return correct result for a NTFS mount point or junction.\nSuppose I have a NTFS partition mounted at C:\\Data\\partition1.\nNow assume that the free space on Partition mounted as C: is 1GB and that mounted on \"C:\\Data\\partition1\" is 2GB. A call to FileSystemUtils.freeSpaceKb(\"C:\\Data\\partition1\") will return the free space on C: and not on \"C:\\Data\\partition1\".\nThis is because while running the \"dir /-c\" with the given path, the code just retains first 2 chars i.e. for any path under \"C:\\blah\\de\\blah\", \"dir /-c\" will be called with \"C:\" which will return incorrect result.\n"
            },
            "18": {
                "commit_sha_buggy": "58c093f5d823641031e6a4d6655e8dac0a477ede",
                "commit_sha_fixed": "dccf793eb78ddc93de1f745f39fb58251fc81ad0",
                "report_id": "IO-257",
                "report_url": "https://issues.apache.org/jira/browse/IO-257",
                "issue_title": "[IO-257] BOMInputStream.read(byte[]) can return 0 which it should not - ASF JIRA",
                "issue_description": "\nBOMInputStream.read(byte[]) returns 0 when it should return -1.\nThis is not a valid action (unless buf.length == 0) and can cause problems, e.g. \"java.io.IOException: Underlying input stream returned zero bytes - at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:268)\"\nFrom java.io.InputStream.read(byte[]) JavaDocs: \"If the length of b is zero, then no bytes are read and 0 is returned; otherwise, there is an attempt to read at least one byte. If no byte is available because the stream is at the end of the file, the value -1 is returned; otherwise, at least one byte is read and stored into b.\"\nSuggested fix, change line 287 of BOMInputStream.java from\n        return (secondCount < 0) ? firstCount : firstCount + secondCount;\ninto\n        return (secondCount < 0) ? (firstCount > 0 ? firstCount : -1) : firstCount + secondCount;\n"
            },
            "22": {
                "commit_sha_buggy": "ed1723428847e2e7c24e9a8c3e379fda0c0f7496",
                "commit_sha_fixed": "49f8c2a817f811bdc9fc3e7f550a8e0b13503e7f",
                "report_id": "IO-469",
                "report_url": "https://issues.apache.org/jira/browse/IO-469",
                "issue_title": "[IO-469] \"Self-suppression not permitted\" while using BrokenOutput and BrokenInput streams with try-with-resources - ASF JIRA",
                "issue_description": "\nHi,\nFirst of all thanks a lot for great library \nI faced with \"Self-suppression not permitted\" issue while using BrokenInputStream & BrokenOutputStream classes with try-with-resources. \nRoot cause of this issue is that these classes always throws same exception instance for all methods.\nThat's how it looks like when javac unfolds try-with-resources: \n\n        InputStream is = new BrokenInputStream();\n        Throwable localThrowable2 = null;\n        try {\n            is.read();\n        } catch (Throwable localThrowable1) {\n            localThrowable2 = localThrowable1;\n            throw localThrowable1;\n        } finally {\n            if (is != null) {\n                if (localThrowable2 != null) {\n                    try {\n                        is.close();\n                    } catch (Throwable x2) {\n                        localThrowable2.addSuppressed(x2);\n                    }\n                } else {\n                    is.close();\n                }\n            }\n        }\n\n\nSo as you can see when close method is invoked resulting exception will be added to itself (first time thrown during read method), this leads to IllegalArgumentException \"Self-suppression not permitted\".\nIt can be easily fixed by omitting throwing of same exception instance for close method. \nIf you don't mind I would attach patch which will fix this issue.  \n"
            },
            "25": {
                "commit_sha_buggy": "9e2b2c09732ca596331f7ca34ba4e0f03d70093d",
                "commit_sha_fixed": "a7bd568249f9ec20b69b2a700da6a0648e93a842",
                "report_id": "IO-483",
                "report_url": "https://issues.apache.org/jira/browse/IO-483",
                "issue_title": "[IO-483] getPrefixLength return -1 if unix file contains colon - ASF JIRA",
                "issue_description": "\nA simple\n\nint prefixLength = FilenameUtils.getPrefixLength(\"/:foo/bar\");\n\n\nreturn -1, but 0 was expected. The path is absolutely valid for unix systems.\n"
            },
            "27": {
                "commit_sha_buggy": "e9eb2d8b5a858bb6810c941ee7891c3adcf9949d",
                "commit_sha_fixed": "a4705cc3c310ffb422336b319891f63eef021f1c",
                "report_id": "IO-535",
                "report_url": "https://issues.apache.org/jira/browse/IO-535",
                "issue_title": "[IO-535] Thread bug in FileAlterationMonitor#stop(int) - ASF JIRA",
                "issue_description": "\nThe thread in FileAlterationMonitor wasn't stopped by the `stop(int)` method, which forbid application to shutdown until all `Thread` are exited (if FileAlterationMonitor is part of a DI managed component).\nThis behavior conflict with the method javadoc `@param stopInterval the amount of time in milliseconds to wait for the thread to finish.`\nSimple example to understand\nBad behavior\n\n    Thread t = new Thread(() -> {\n        try {\n            Thread.sleep(500000);\n        } catch (final InterruptedException e) {\n        }\n    });\n    t.start();\n    t.join(50);\n   // Ok, we reach this point until 500000ms are elapsed, but the thread is still alive.\n   //   because Thread#join(int) does not kill the thread. And the thread remains alive.\n\n\nGood behavior\n\n    Thread t = new Thread(() -> {\n        try {\n            Thread.sleep(500000);\n        } catch (final InterruptedException e) {\n        }\n    });\n    t.start();\n    t.join(50);\n    t.interupt();\n   // Thread is exited\n\n\nIn this case, we waited the given time BEFORE exiting the `Thread`, as described in the javadoc, and the `Thread` is now finished and killed.\n"
            },
            "29": {
                "commit_sha_buggy": "4597f38c3608cfe8ef872144ed4bfe393a05dc84",
                "commit_sha_fixed": "c6b8a383de96cd0a8e94037a04510f162e4bbc68",
                "report_id": "IO-554",
                "report_url": "https://issues.apache.org/jira/browse/IO-554",
                "issue_title": "[IO-554] FileUtils.copyToFile(InputStream source, File destination) should not close input stream - ASF JIRA",
                "issue_description": "\nIn 2.6 this method is closing the input stream, while the javadoc states the opposite.\nThe correct behavior is to leave the stream open, as stated in the javadoc.\nI assigned a high priority because this incorrect behavior breaks existing code, especially when used in combination with ZipInputStream.\n\n\r\n/**\r\n * Copies bytes from an {@link InputStream} <code>source</code> to a file\r\n * <code>destination</code>. The directories up to <code>destination</code>\r\n * will be created if they don't already exist. <code>destination</code>\r\n * will be overwritten if it already exists.\r\n * The {@code source} stream is left open, e.g. for use with {@link java.util.zip.ZipInputStream ZipInputStream}.\r\n * See {@link #copyInputStreamToFile(InputStream, File)} for a method that closes the input stream.\r\n *\r\n * @param source      the <code>InputStream</code> to copy bytes from, must not be {@code null}\r\n * @param destination the non-directory <code>File</code> to write bytes to\r\n *                    (possibly overwriting), must not be {@code null}\r\n * @throws IOException if <code>destination</code> is a directory\r\n * @throws IOException if <code>destination</code> cannot be written\r\n * @throws IOException if <code>destination</code> needs creating but can't be\r\n * @throws IOException if an IO error occurs during copying\r\n * @since 2.5\r\n */\r\npublic static void copyToFile(final InputStream source, final File destination) throws IOException {\r\n\ttry (InputStream in = source;\r\n\t\t OutputStream out = openOutputStream(destination)) {\r\n\t\tIOUtils.copy(in, out);\r\n\t}\r\n}\r\n\n\ninstead it should be:\n\n\r\npublic static void copyToFile(final InputStream source, final File destination) throws IOException {\r\n\ttry (OutputStream out = openOutputStream(destination)) {\r\n\t\tIOUtils.copy(source, out);\r\n\t}\r\n}\n\n"
            },
            "30": {
                "commit_sha_buggy": "58324c1cfb9814b390a8750b0ba97dc5367817a8",
                "commit_sha_fixed": "d463fa0120fc1041729b7a564b2b5f96de9d6ab6",
                "report_id": "IO-625",
                "report_url": "https://issues.apache.org/jira/browse/IO-625",
                "issue_title": "[IO-625] FileUtils.copyDirectoryToDirectory does not reflect srcDir in exception message when srcDir is not a directory - ASF JIRA",
                "issue_description": "\nWhen srcDir parameter to FileUtils.copyDirectoryToDirectory method is not a directory, exception message contains destDir instead of srcDir.\nRelated issue is, that based on Javadocs one would expect IOException instead of IllegalArgumentException. Changing type of the exception would probably break some clients. Fixing message seems reasonable.\n"
            },
            "31": {
                "commit_sha_buggy": "eaa8e0c698f694b7e5fdded5dbb9024c8cf15c4e",
                "commit_sha_fixed": "0a03609ddc6380dd7c9053eb8cb04072baa476a1",
                "report_id": "IO-90",
                "report_url": "https://issues.apache.org/jira/browse/IO-90",
                "issue_title": "[IO-90] Infinite loop in FileSystemUtils.freeSpaceWindows if share directory empty - ASF JIRA",
                "issue_description": "\nWhen using FileSystemUtils.freeSpaceWindows in an empty share directory, the line containing the free space does not exist which causes an infinite loop (the outerloop doesn't decrease the i index).\nIn fact to deal with all possible errors, I propose to test the exitCode of the dir command.\nHere is a proposed new code for this function :\n    /**\n\nFind free space on the Windows platform using the 'dir' command.\n     *\n@param path  the path to get free space for, including the colon\n@return the amount of free drive space on the drive\n@throws IOException if an error occurs\n     */\n    long freeSpaceWindows(String path) throws IOException {\n        path = FilenameUtils.normalize(path);\n        if (path.length() > 2 && path.charAt(1) == ':') \n{\n            path = path.substring(0, 2);  // seems to make it work\n        }\n\n        // build and run the 'dir' command\n        String[] cmdAttrbs = new String[] \n{\"cmd.exe\", \"/C\", \"dir /-c \" + path}\n;\n        // read in the output of the command to an ArrayList\n        BufferedReader in = null;\n        String line = null;\n        ArrayList lines = new ArrayList();\n        int errorLevel = 0;\n        try {\n            Process proc = Runtime.getRuntime().exec(cmdAttrbs);\n            in = new BufferedReader(\n                new InputStreamReader(proc.getInputStream()));\n            line = in.readLine();\n            while (line != null) \n{\n                line = line.toLowerCase().trim();\n                lines.add(line);\n                line = in.readLine();\n            }\n\n            proc.waitFor();\n            errorLevel = proc.exitValue();\n        } finally \n{\n            IOUtils.closeQuietly(in);\n        }\n\n        if (lines.size() == 0) \n{\n            // unknown problem, throw exception\n            throw new IOException(\n                    \"Command line 'dir /-c' did not return any info \" +\n                    \"for command '\" + cmdAttrbs[2] + \"'\");\n        }\n\n        if (errorLevel != 0) {\n            if (errorLevel == 2) \n{\n                // Empty directory : unable to calculate the freeSpace\n                return Integer.MAX_VALUE; // ???\n            }\n else \n{\n                // unknown problem, throw exception\n                throw new IOException(\n                        \"Command line 'dir /-c' error [\" + errorLevel +\n                        \"] for command '\" + cmdAttrbs[2] + \"'\");\n            }\n        }\n        // now iterate over the lines we just read and find the LAST\n        // non-empty line (the free space bytes should be in the last element\n        // of the ArrayList anyway, but this will ensure it works even if it's\n        // not, still assuming it is on the last non-blank line)\n        long bytes = -1;\n        int i = lines.size() - 1;\n        int bytesStart = 0;\n        int bytesEnd = 0;\n        outerLoop: while (i > 0) {\n            line = (String) lines.get;\n            if (line.length() > 0) {\n                // found it, so now read from the end of the line to find the\n                // last numeric character on the line, then continue until we\n                // find the first non-numeric character, and everything between\n                // that and the last numeric character inclusive is our free\n                // space bytes count\n                int j = line.length() - 1;\n                innerLoop1: while (j >= 0) {\n                    char c = line.charAt(j);\n                    if (Character.isDigit(c)) \n{\n                      // found the last numeric character, this is the end of\n                      // the free space bytes count\n                      bytesEnd = j + 1;\n                      break innerLoop1;\n                    }\n                    j--;\n                }\n                innerLoop2: while (j >= 0) {\n                    char c = line.charAt(j);\n                    if (!Character.isDigit(c) && c != ',' && c != '.') \n{\n                      // found the next non-numeric character, this is the\n                      // beginning of the free space bytes count\n                      bytesStart = j + 1;\n                      break innerLoop2;\n                    }\n                    j--;\n                }\n                break outerLoop;\n            } else \n{\n                // If the last line is empty we are unable to parse the freeSpace\n                throw new IOException(\n                        \"Command line 'dir /-c' did not return valid info \" +\n                        \"for command '\" + cmdAttrbs[2] + \"'\");\n            }\n        }\n        // remove commas and dots in the bytes count\n        StringBuffer buf = new StringBuffer(line.substring(bytesStart, bytesEnd));\n        for (int k = 0; k < buf.length(); k++) {\n            if (buf.charAt(k) == ',' || buf.charAt(k) == '.') \n{\n                buf.deleteCharAt(k--);\n            }\n        }\n        bytes = Long.parseLong(buf.toString());\n        return bytes;\n    }\n"
            }
        }
    },
    "JXR": {
        "owner_repo": "apache/maven-jxr",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d5b9c0771d276f9ea0517e211693aa34e896be4f",
                "commit_sha_fixed": "aae189e47b87ca51ef048f851b0241f1dcd69587",
                "report_id": "JXR-18",
                "report_url": "https://issues.apache.org/jira/browse/JXR-18",
                "issue_title": "[JXR-18] JXR Fails with NPE if the .java file is empty (class commented out) - ASF JIRA",
                "issue_description": "\nIf you build a project and one of your java files exists (but is empty / commented out), JXR generates a NPE\n[INFO] Generate \"Source Xref\" report.\n[INFO] Scanning W:\\1244 - Knowledge Management System (KMS)\\dev\\modules\\kms-services\\src\\main\\java\nUnable to processPath W:\\1244 - Knowledge Management System (KMS)\\dev\\modules\\kms-services\\src\\main\\java\\com\\cswgroup\\kms\\services\\cont\nent\\contenthandler\\AddCheckOutMetadataHandler.java => W:\\1244 - Knowledge Management System (KMS)\\dev\\modules\\kms-services\\target/site/\nxref\\com\\cswgroup\\kms\\services\\content\\contenthandler\\AddCheckOutMetadataHandler.html\n[INFO] ------------------------------------------------------------------------\n[ERROR] BUILD ERROR\n[INFO] ------------------------------------------------------------------------\n[INFO] Error during report generation\nEmbedded error: Error while generating the HTML source code of the projet.\n[INFO] ------------------------------------------------------------------------\n[INFO] Trace\norg.apache.maven.lifecycle.LifecycleExecutionException: Error during report generation\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:559)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeStandaloneGoal(DefaultLifecycleExecutor.java:488)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:458)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:306)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:273)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:140)\n        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:322)\n        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:115)\n        at org.apache.maven.cli.MavenCli.main(MavenCli.java:256)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:585)\n        at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)\n        at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)\n        at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)\n        at org.codehaus.classworlds.Launcher.main(Launcher.java:375)\nCaused by: org.apache.maven.plugin.MojoExecutionException: Error during report generation\n        at org.apache.maven.plugins.site.SiteMojo.execute(SiteMojo.java:389)\n        at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:412)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:534)\n        ... 16 more\nCaused by: org.apache.maven.reporting.MavenReportException: Error while generating the HTML source code of the projet.\n        at org.apache.maven.plugin.jxr.JxrReport.generateXrefForSources(JxrReport.java:202)\n        at org.apache.maven.plugin.jxr.JxrReport.executeReport(JxrReport.java:165)\n        at org.apache.maven.reporting.AbstractMavenReport.generate(AbstractMavenReport.java:117)\n        at org.apache.maven.plugins.site.SiteMojo.generateReportsPages(SiteMojo.java:802)\n        at org.apache.maven.plugins.site.SiteMojo.execute(SiteMojo.java:301)\n        ... 18 more\nCaused by: java.lang.NullPointerException\n        at org.apache.maven.jxr.CodeTransform.getHeader(CodeTransform.java:651)\n        at org.apache.maven.jxr.CodeTransform.transform(CodeTransform.java:716)\n        at org.apache.maven.jxr.CodeTransform.transform(CodeTransform.java:787)\n        at org.apache.maven.jxr.JXR.transform(JXR.java:195)\n        at org.apache.maven.jxr.JXR.processPath(JXR.java:114)\n        at org.apache.maven.jxr.JXR.xref(JXR.java:331)\n        at org.apache.maven.plugin.jxr.JxrReport.createXref(JxrReport.java:384)\n        at org.apache.maven.plugin.jxr.JxrReport.generateXrefForSources(JxrReport.java:189)\n        ... 22 more\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1 minute 11 seconds\n[INFO] Finished at: Thu Apr 20 16:02:41 BST 2006\n[INFO] Final Memory: 22M/67M\n[INFO] ------------------------------------------------------------------------\n"
            }
        }
    },
    "MShade": {
        "owner_repo": "apache/maven-shade-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0c1113784feb2a7f3eab7d5f9e768e5ad91e375a",
                "commit_sha_fixed": "1313844ec89701189a87ab629f2d7970bccc57a8",
                "report_id": "MSHADE-19",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-19",
                "issue_title": "[MSHADE-19] static fields are not relocated - ASF JIRA",
                "issue_description": "\neg, static loggers\n"
            },
            "2": {
                "commit_sha_buggy": "8e389707daa75c16ef6aa2112ba3ec9073bc02e8",
                "commit_sha_fixed": "47959bbd73b0aa022ebf32f442e7df6d59fa3ae0",
                "report_id": "MSHADE-26",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-26",
                "issue_title": "[MSHADE-26] Fix case-insensitive string comparisions in resource transformers - ASF JIRA",
                "issue_description": "\nString.toLowerCase() is sensitive to the JVM's default locale and hence platform-dependent, potentially yielding wrong build output. For instance:\n\nLocale.setDefault( new Locale( \"en\" ) );\nSystem.out.println( \"META-INF/NOTICE\".toLowerCase().equals( \"meta-inf/notice\" ) );\nLocale.setDefault( new Locale( \"tr\" ) );\nSystem.out.println( \"META-INF/NOTICE\".toLowerCase().equals( \"meta-inf/notice\" ) );\n\n\nwill print\n\ntrue\nfalse\n\n\nSee also Common Bugs.\n"
            },
            "3": {
                "commit_sha_buggy": "99d436d485e493e5caece022e3f6f9b93e7cf953",
                "commit_sha_fixed": "6ab3cde463cf13f6a21719a0619f62b3fcd3d51d",
                "report_id": "MSHADE-38",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-38",
                "issue_title": "[MSHADE-38] Names of excluded packages are relocated - ASF JIRA",
                "issue_description": "\nFor the configuration\n\n<relocation>\n  <pattern>org.codehaus.plexus.util</pattern>\n  <excludes>\n    <exclude>org.codehaus.plexus.util.xml.pull.*</exclude>\n  </excludes>\n</relocation>\n\n\na source code statement like\n\nchild.getContainerRealm().importFrom(\"plexus.core\", \"org.codehaus.plexus.util.xml.pull\");\n\n\nis erroneously changed to\n\nchild.getContainerRealm().importFrom(\"plexus.core\", \"hidden.org.codehaus.plexus.util.xml.pull\");\n\n\n"
            },
            "4": {
                "commit_sha_buggy": "664a0468c2da9ae52e1db5937b35d153f4eb9ef2",
                "commit_sha_fixed": "65100086a5a51b1ef767b67ac2bfff8b77b573d6",
                "report_id": "MSHADE-70",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-70",
                "issue_title": "[MSHADE-70] Artifact filter does not recognize pattern ending with slash - ASF JIRA",
                "issue_description": "\nA configuration like\n\n<configuration>\n  <filters>\n    <filter>\n      <artifact>foo:bar</artifact>\n      <excludes>\n        <exclude>org/apache/</exclude>\n      </excludes>\n    </filter>\n  </filters>\n</configuration>\n\n\nfails to exclude paths starting with \"org/apache/\". In other words, the pattern \"org/apache/\" is not understood as a shorthand for \"org/apache/**\" (cf. Patterns).\n"
            },
            "6": {
                "commit_sha_buggy": "5217a53bb2bd6569ab8fc23c0e70bc956bfcfc18",
                "commit_sha_fixed": "88f188da5f0d352518d8c1441bac1ee25befcad4",
                "report_id": "MSHADE-101",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-101",
                "issue_title": "[MSHADE-101] ApacheNoticeResourceTransformer NullPointerException for some licenses when no parameters set. - ASF JIRA",
                "issue_description": "\nFor some dependencies, ApacheNoticeResourceTransformer throws a NullPointerException when no parameters are set.\nIncluded in the patch are \n\nan integration test case which demonstrates the problem,\na unit test case (including tests around this problem) and\nmy proposed (narrow) fix for ApacheNoticeResourceTransformer.\n\nATM no parameter is mandatory. This may indicate an intention to support a basic use case without parameters. So this patch opts for a reasonable default.\n"
            },
            "7": {
                "commit_sha_buggy": "088fa83a9fc3dbedf4aa126bed01de79a73079f4",
                "commit_sha_fixed": "bcece7bd4d72f2f980abfd575e5b1afafba7af4c",
                "report_id": "MSHADE-94",
                "report_url": "https://issues.apache.org/jira/browse/MSHADE-94",
                "issue_title": "[MSHADE-94] NullPointerException on empty relocation pattern (default package) - ASF JIRA",
                "issue_description": "\nI need a few classes from a 3rd party jar that are declared in the default package. Since usage of the default package should be avoided, I try to relocate the classes to a named package:\npom.xml\n...\n  <relocation>\n    <pattern />\n    <shadedPattern>org.example.foo.bar</shadedPattern>\n  </relocation>\n\n\nThe Shade Plugin crashes with a NPE:\nStacktrace\nCaused by: org.apache.maven.plugin.MojoExecutionException: Error creating shaded jar: null\n\tat org.apache.maven.plugins.shade.mojo.ShadeMojo.execute(ShadeMojo.java:503)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:107)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)\n\t... 19 more\nCaused by: java.lang.NullPointerException\n\tat org.apache.maven.plugins.shade.relocation.SimpleRelocator.<init>(SimpleRelocator.java:52)\n\tat org.apache.maven.plugins.shade.mojo.ShadeMojo.getRelocators(ShadeMojo.java:616)\n\tat org.apache.maven.plugins.shade.mojo.ShadeMojo.execute(ShadeMojo.java:440)\n\n\n"
            }
        }
    },
    "Tika": {
        "owner_repo": "apache/tika",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "9477c5e4a38dbacf794b663c757617a8ee07432a",
                "commit_sha_fixed": "b12c01d9b56053554cec501aab0530f7f4352daf",
                "report_id": "TIKA-56",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-56",
                "issue_title": "[TIKA-56] Mime type detection fails with upper case file extensions such as \"PDF\". - ASF JIRA",
                "issue_description": "\nMime type detection only seems to work when the file extension is lower case.  Both PDF and DOC extensions failed.\nTo test this, add the following method to TestParsers:\n    public void testGetParsers() throws TikaException, MalformedURLException \n{\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.pdf\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.PDF\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.doc\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.DOC\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.txt\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.TXT\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.html\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.HTML\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.HtMl\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.htm\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.HTM\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.ppt\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.PPT\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.xls\"), tc));\n        assertNotNull(ParseUtils.getParser(new URL(\"file:x.XLS\"), tc));\n        // more?\n    }\n            "
            },
            "2": {
                "commit_sha_buggy": "0dd035b9be57a71ba23a29120f1e2153a3178b5b",
                "commit_sha_fixed": "fa6bb7e3c92145d29cd97820718ece69fd6ffd62",
                "report_id": "TIKA-107",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-107",
                "issue_title": "[TIKA-107] Remove use of assertions for argument checking - ASF JIRA",
                "issue_description": "\nUsing assertions for argument checking is a bad practice since assertions can be enabled/disabled and by default are disabled.\nSee http://java.sun.com/j2se/1.4.2/docs/guide/lang/assert.html#usage\n"
            },
            "5": {
                "commit_sha_buggy": "2699cf47e222d61b5c4f5ab0757c63199e3fd62a",
                "commit_sha_fixed": "dd352d27c1b955103b2be76f2d5bca88f3b8e48b",
                "report_id": "TIKA-189",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-189",
                "issue_title": "[TIKA-189] Text extraction from Excel files juxtaposes cells - ASF JIRA",
                "issue_description": "\nI plan on using Tika to extract text from Excel (both .xls and .xlsx) files for indexing. But, I found that Tika juxtaposes cells on output. The example worksheets are in the attached .zip file.\nI took the time to run Apache POI and it does not have this bug i.e. cells are properly separated.\nWhen I run\n-begin-\njava -jar tika-0.3-SNAPSHOT-standalone.jar --text no_cell_separators_when_extracted.xls\n-end-\nI get the following output:\n-begin-\nPlan1\n    NameEmailSanta Claussanta@claus.org\n    Tooth Fairytooth@fairy.org\n-end-\nSame thing with a .xlxs file:\n-begin-\njava -jar tika-0.3-SNAPSHOT-standalone.jar --text no_cell_separators_when_extracted.xlsx\n-end-\nThe output is:\n-begin-\n[Content_Types].xml\n_rels/.rels\nxl/_rels/workbook.xml.rels\nxl/workbook.xml\nxl/theme/theme1.xml\nxl/worksheets/_rels/sheet1.xml.rels\nxl/worksheets/sheet2.xml\nxl/worksheets/sheet3.xml\nxl/sharedStrings.xml\nNameEmailSanta Claussanta@claus.orgTooth Fairytooth@fairy.org\nxl/styles.xml\nxl/worksheets/sheet1.xml\n012345\ndocProps/core.xml\nGeorgerGeorger2009-01-17T15:29:04Z2009-01-17T15:30:56Z\ndocProps/app.xml\nMicrosoft Excel0falsePlanilhas3Plan1Plan2Plan3falsefalsefalse12.0000\n-end-\nAlso note that the values from docProps/app.xml have been juxtaposed as well.\nThis way, after indexing these files using the output from Tika, a search engine will only find \"Fairy\" when substring matching is used, because \"Tooth Fairy\" becomes \"Tooth Fairytooth@fairy.org\". This is suboptimal and wrong.\nThanks for your attention. Best regards,\nGeorger\n"
            },
            "6": {
                "commit_sha_buggy": "2a77cf379166e9c2e5144d9cafa37a2146563a36",
                "commit_sha_fixed": "f6f9d4fe18590bfd8b03e5e87b75af9a18ee059e",
                "report_id": "TIKA-197",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-197",
                "issue_title": "[TIKA-197] Microsoft Outlook (msg) files get parsed multiple times - ASF JIRA",
                "issue_description": "\nMicrosoft Outlook (msg) files get parsed around 50 times using TikaGUI\n"
            },
            "7": {
                "commit_sha_buggy": "b7e960e5b58a28d67bcda70fb7d455cc0ac4d19b",
                "commit_sha_fixed": "60c9b0e05868fb786180b3d7403537b2e66dce03",
                "report_id": "TIKA-210",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-210",
                "issue_title": "[TIKA-210] html content directly under body node not parsed correctly - ASF JIRA",
                "issue_description": "\nThe html parser does not correctly parse content that is directly under the body node, when passing html like this: <html><body>This is my content</body></html>, an empty string is returned when calling BodyContentHandler#toString()\n"
            }
        }
    },
    "Validator": {
        "owner_repo": "apache/commons-validator",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "603cc5a72bfcac0c4fc0f94422fdcf5522fde50b",
                "commit_sha_fixed": "439d3d5d372887ea92473f50f8b06b501eddf59d",
                "report_id": "VALIDATOR-444",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-444",
                "issue_title": "[VALIDATOR-444] LongValidator: numbers bigger than the maxvalue are Valid - ASF JIRA",
                "issue_description": "\nIf you try to validate\u00a0a Value bigger than\u00a09,223,372,036,854,775,807 it keeps valid.\n\u00a0\u00a0for example with:\n\n\r\nLongValidator longValidator = new LongValidator ( true, AbstractNumberValidator.STANDARD_FORMAT );\r\nlongValidator.isValid(\"9223372036854775808\") // is true should be false max long is 9223372036854775807\r\n\n\neven worse is that:\n\u00a0\n\n\r\nlongValidator.validate ( \"9999999999999999999999999999999999999\")\r\n\n\nwill give you the long maxValue as Result.\nThe IntegerValidator will give you null and nonValid.\u00a0\n\u00a0\n"
            },
            "2": {
                "commit_sha_buggy": "e7ec659df7800aabf6386420f4575f626b19e613",
                "commit_sha_fixed": "e9bda17e9a27e4e8d1b951854baf838f0075619f",
                "report_id": "VALIDATOR-467",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-467",
                "issue_title": "[VALIDATOR-467] URL validator fails if path starts with double slash and has underscores - ASF JIRA",
                "issue_description": "\n\n\r\nimport org.apache.commons.validator.routines.UrlValidator;\r\n...\r\nprivate static final String[] schemes = {\"http\", \"https\"};\r\nprivate static final UrlValidator urlValidator = new UrlValidator(schemes,\r\n        UrlValidator.ALLOW_LOCAL_URLS + UrlValidator.ALLOW_2_SLASHES);\r\n...\r\nurlValidator.isValid(\"https://example.com//some_path/path/\")\r\n\n\nThis returns false. However such URL is valid if authority is not null.\nThe reason it returns false is this code in the validator:\nhttps://github.com/apache/commons-validator/blob/a3771313c9f1833abf32c7c294ad1de4810e532d/src/main/java/org/apache/commons/validator/routines/UrlValidator.java#L452-L461\n\n\r\n        try {\r\n            URI uri = new URI(null,null,path,null);\r\n            String norm = uri.normalize().getPath();\r\n            if (norm.startsWith(\"/../\") // Trying to go via the parent dir \r\n             || norm.equals(\"/..\")) {   // Trying to go to the parent dir\r\n                return false;\r\n            }\r\n        } catch (URISyntaxException e) {\r\n            return false;\r\n        }\r\n\n\nAs far as I understand URI uri = new URI(null,null,path,null); throws URISyntaxException if authority is null and path starts with //.\nI tried running new URI(null, \"example.com\", path, null); and it worked.\nI didn't read RFC but from some googling around I got the following:\n//some_path is invalid if authority is null\n//some_path is valid if authority is not null\nUpdate:\nAnother thing I noticed while testing is that the following actually passes the validation \u2013 \"https://example.com//test\"\nAnd that \"https://example.com//test_test\" fails the validation but URISyntaxException is thrown due to Illegal character in hostname and not due to // at the start.\nSo my original theory behind the failure looks incorrect now, however I still consider this bug as a valid one.\nI guess better description would be \"URL validator incorrectly uses URI uri = new URI(null,null,path,null); check. Due to these nulls in arguments path is validated as a hostname\".\nAnd the simplest URL to test is https://example.com//test_double_slash_and_underscore\n"
            },
            "4": {
                "commit_sha_buggy": "81d60ae98cfd5ae0bff1ccecb7654bdbc6bc2692",
                "commit_sha_fixed": "a3c5da2d0e53003885a6af4875e40565a07b05a4",
                "report_id": "VALIDATOR-302",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-302",
                "issue_title": "[VALIDATOR-302] EMailValidator: Addresses with leading spaces must not be accepted - ASF JIRA",
                "issue_description": "\n    @Test\n    public void testEmailValidatorBug() {\n        // The commons validator class accepts an address with an leading whitespace which seams to be a bug.\n        boolean shouldBe = false;\n        boolean isActual = true;\n        String eMail = \" user@foo.com\";\n        logger.debug(\"{} is {}\", eMail, validator.isValid(eMail) ? \"valid\" : \"invalid\");\n        assertThat(\"Check failed for \" + eMail, validator.isValid(eMail), is(isActual));\n    }\n"
            },
            "6": {
                "commit_sha_buggy": "f8b0a0a96ecc08fef15c2e7e66bf0a62c3616858",
                "commit_sha_fixed": "c547175b4291860bf5e6a52af7e574bc5e214dc0",
                "report_id": "VALIDATOR-240",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-240",
                "issue_title": "[VALIDATOR-240] Support the 65 prefix for Discover Card - ASF JIRA",
                "issue_description": "\nDiscover will be supporting the entire 65 prefix starting October 1st 2007.  The CreditCardValidator should be changed to reflect this update.\n"
            },
            "7": {
                "commit_sha_buggy": "1ed5b4f9b1ae9136b2749fd0ef33f2efefc6762f",
                "commit_sha_fixed": "29db3b8d20363eddc3d63138eb4c171a38026a08",
                "report_id": "VALIDATOR-288",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-288",
                "issue_title": "[VALIDATOR-288] UrlValidator does not validate URL with simple domains (eg: http://hostname ) - ASF JIRA",
                "issue_description": "\nA Url of the form \"http://hostname\" is not validated, when the hostname is simple, i.e does not have any dots.\nI think this is a valid URL and it should pass validation.\nThe bug is in UrlValidator::isValidAuthority(), line 382\n            String topLevel = domainSegment[segmentCount - 1];\n            if (topLevel.length() < 2 || topLevel.length() > 4) \n{\n                return false;\n            }\n\n\nIn this case, topLevel = \"hostname\"\n"
            },
            "8": {
                "commit_sha_buggy": "0456e7a94e139a104f3190e41372511dc82538a5",
                "commit_sha_fixed": "b9f179c29e965eb4e9bf15acb86d56c8d4b51088",
                "report_id": "VALIDATOR-276",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-276",
                "issue_title": "[VALIDATOR-276] isValidURL call returns false for file scheme/protocol when URL is correct - ASF JIRA",
                "issue_description": "\nValidate a URL using the file scheme/protocol for a file on a local Linux filesystem returns false. An extensive set of tests can be found here: URLTest.java.\nThe following code snippet is a quick proof-of-concept:\n\nimport org.apache.commons.validator.UrlValidator;\n\nclass URLTest {\n\n\tpublic static void main(String[] args) {\n\t\tString url = \"file:///etc/hosts\";\n\t\tUrlValidator urlValidator = new UrlValidator(new String[] {\"http\", \"https\", \"ftp\", \"gopher\", \"file\"});\n\t\tboolean result = urlValidator.isValid(url);\n\t\tSystem.out.println(String.format(\"URL '%s' is valid: %s\", url, result));\n\t}\n\n}\n\n\nThis issue occurs whether the scheme String[] constructor or the ALLOW_ALL_SCHEMES equivalent is used.\n"
            },
            "9": {
                "commit_sha_buggy": "9f2301621de691bf98c533708231c9a248c9cb8a",
                "commit_sha_fixed": "7ff07e7799577aecaae22e8a5a9346707e676e3e",
                "report_id": "VALIDATOR-273",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-273",
                "issue_title": "[VALIDATOR-273] EmailValidator does not support mailboxes at TLDs - ASF JIRA",
                "issue_description": "\nAccording to RFC 5321 and 5322, mailboxes at top level domain names are permitted. Thus, the syntax localpart@tld is valid. Explicit text to this topic can be found in RFC 5321:\n2.3.5.  Domain Names\n   A domain name (or often just a \"domain\") consists of one or more\n   components, separated by dots if more than one appears.  In the case\n   of a top-level domain used by itself in an email address, a single\n   string is used without any dots.\nAccordingly, the code\n\t\tEmailValidator ev = EmailValidator.getInstance();\n\t\tSystem.out.println(ev.isValid(\"m@de\"));\nshould output \"true\".\n"
            },
            "11": {
                "commit_sha_buggy": "1f608abd1d869fa4d049482401ad4b901342fd9a",
                "commit_sha_fixed": "9f21a03adeb43b02a548d6fb79984c00ce5cd398",
                "report_id": "VALIDATOR-353",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-353",
                "issue_title": "[VALIDATOR-353] UrlValidator does not allow for optional userinfo in the authority - ASF JIRA",
                "issue_description": "\nThe authority part of a URL includes optional userinfo (name:password@)\nHowever this is not currently permitted\n"
            },
            "13": {
                "commit_sha_buggy": "01fd9c792b8a2f3a7206d43c21d34de8135eaf6e",
                "commit_sha_fixed": "f7c43cd216051aeff62194bfe1b98a7fe7f75c9f",
                "report_id": "VALIDATOR-330",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-330",
                "issue_title": "[VALIDATOR-330] IbanCheckDigit.isValid() returns True for some invalid IBANs - ASF JIRA",
                "issue_description": "\nFor example, isValid() returns True for both of these IBANs; \"IE01AIBK93118702569045\" and \"IE98AIBK93118702569045\".  The \"IE98\" version is the correct one (confirmed with online checkers, which also fail the \"IE01\" version).\ncalculate() correctly returns \"98\".  As a workaround I'm calling calculate() and comparing the result with the checksum in the original IBAN.\n"
            },
            "14": {
                "commit_sha_buggy": "f7c43cd216051aeff62194bfe1b98a7fe7f75c9f",
                "commit_sha_fixed": "03bf0d33143ebd13e4f389cd4ecac8aec17c2057",
                "report_id": "VALIDATOR-363",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-363",
                "issue_title": "[VALIDATOR-363] UrlValidator rejects path having two or more successive dots - ASF JIRA",
                "issue_description": "\nMinmal example:\n\nUrlValidator urlValidator = new UrlValidator();\nboolean isValidOneDot = urlValidator.isValid(\"http://www.example.org/hello.world/\"); // evaluates to true\nboolean isValidTwoDots = urlValidator.isValid(\"http://www.example.org/hello..world/\"); // evaluates to false\n\n\nReal world example:\n\nUrlValidator urlValidator = new UrlValidator();\nboolean isValidRealWord = urlValidator.isValid(\"http://forum.golem.de/sonstiges/trollwiese/apple-bashing-in-3...2...1...go/98,4089549,4089549,read.html#msg-4089549\"); // evaluates to false\n\n\n"
            },
            "15": {
                "commit_sha_buggy": "698b384a95456673fdfaaac2b9b3088dfad6f2a3",
                "commit_sha_fixed": "c45994e38779957dbc09d74831aaa664e7031a46",
                "report_id": "VALIDATOR-364",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-364",
                "issue_title": "[VALIDATOR-364] Email Validator does not support quoted/escaped character in the local part of the email address - ASF JIRA",
                "issue_description": "\nCurrently the email address validator doesn't support to quote (or escape) a character in the local part of the address.\nExamples:\n\nAbc\\@def@example.com\nFred\\ Bloggs@example.com\nJoe.\\\\Blow@example.com\n\n\nSource: RFC 3696 \n"
            },
            "16": {
                "commit_sha_buggy": "f553c9246ace9c4e19ce56ce81ebf90079b210d5",
                "commit_sha_fixed": "a022b47e7808d165401115a1b40fa655acae63f4",
                "report_id": "VALIDATOR-386",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-386",
                "issue_title": "[VALIDATOR-386] org.apache.commons.validator.routines.DomainValidator.ArrayType is not public - ASF JIRA",
                "issue_description": "\nVersion 1.5.0 adds the possibility to override TLDs using: \norg.apache.commons.validator.routines.DomainValidator#updateTLDOverride\nhowever the first parameter to that function is package scoped. This seems like a bug to me, to implement an override I have to create a class in org.apache.commons.validator.routines for me to use this functionality.\n"
            },
            "17": {
                "commit_sha_buggy": "8e4ffb044bc78cb8c317e14e9c25b0affc28df73",
                "commit_sha_fixed": "05de0f3b3b7ef1785c4e80c14c3009d73230c5d5",
                "report_id": "VALIDATOR-359",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-359",
                "issue_title": "[VALIDATOR-359] EmailValidator does not catch invalid email address like dora@.com - ASF JIRA",
                "issue_description": "\nEmailValidator does not catch invalid email address like dora@.com\n"
            },
            "18": {
                "commit_sha_buggy": "05de0f3b3b7ef1785c4e80c14c3009d73230c5d5",
                "commit_sha_fixed": "cb9e256f9e69ebdbccb802fcd890d5d181cdd1d4",
                "report_id": "VALIDATOR-384",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-384",
                "issue_title": "[VALIDATOR-384] EmailValidator does not support escaped quotes in a quoted string - ASF JIRA",
                "issue_description": "\nEmailValidator does not support escaped quotes '\\\"' within a quoted string as specified by RFC5322 section 3.2.4 as well as in the older RFC2822 section 3.2.5.  \nThese sections indicate that a quoted string can contain a quoted pair (escaped characters), where a quoted pair is defined as (in RFC5322):\n\n   quoted-pair     =   (\"\\\" (VCHAR / WSP)) / obs-qp\n   VCHAR = %x21-7E; visible (printing) characters\nThe \" character is %x22 which falls under the definition of VCHAR above.\nExamples: \n\n  \"example\\\"email\"@example.org\n"
            },
            "19": {
                "commit_sha_buggy": "3732ecd015fcc1d094ceffa2c043e7f9a533d4d2",
                "commit_sha_fixed": "c247c6e361bc1ea677526418cbbc2eb5ab2d54b9",
                "report_id": "VALIDATOR-391",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-391",
                "issue_title": "[VALIDATOR-391] UrlValidator.isValid throws exception for FILEURLs - ASF JIRA",
                "issue_description": "\nIn UrlValidator.java from v1.5.0, there is the following section which generates a null pointer exception, rendering isValid unusable for FILE URLs.\norg/apache/commons/validator/routines/UrlValidator.java\nif (\"file\".equals(scheme)) {// Special case - file: allows an empty authority\n            if (!\"\".equals(authority)) {\n                if (authority.contains(\":\")) { // but cannot allow trailing :\n                    return false;\n                }\n            }\n            // drop through to continue validation\n        }\n\n\nIn the case of a file URL given in my example below, authority is null, and thusly doesn't equal a blank string, so it drops down and calls authority.contains, which generates a NullPointerException.\nExample to generate exception\nFile localFile = new File(\"c:\\\\path\\\\to\\\\dir\\\\\");\nURL localURL = localFile.toURI().toURL();\nString urlString = localURL.toString(); // \"file:/C:/path/to/dir/\"\nString[] schemes = {\"file\"};\nUrlValidator urlValidator = new UrlValidator(schemes);\n\nurlValidator.isValid(urlString); // null pointer exception\n\n\n"
            },
            "20": {
                "commit_sha_buggy": "27f1c3badc173b2e739121dce36b3a6634dd3a65",
                "commit_sha_fixed": "b01e9e0720f663f3e4fd0dd0a03e013957998f84",
                "report_id": "VALIDATOR-401",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-401",
                "issue_title": "[VALIDATOR-401] IBANValidator fails for Seychelles and Ukraine - ASF JIRA",
                "issue_description": "\nThe IBANValidator does not validate the IBANs from the Seychelles or Ukraine, even though they are part of IBAN registry.\nSC18SSCB11010000000000001497USD, fails but should pass\nUA213996220000026007233566001, fails but should pass\n"
            },
            "21": {
                "commit_sha_buggy": "8bbbe31ee3f78967ccfd67d2eafe5d5ff58ca8e8",
                "commit_sha_fixed": "4f60e5229d741623257a0053e613f44721418da0",
                "report_id": "VALIDATOR-405",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-405",
                "issue_title": "[VALIDATOR-405] IBANValidator - Costa Rica entry has been updated in SWIFT docs - ASF JIRA",
                "issue_description": "\nThe entry for Costa Rica in version 69 of the PDF file [1] is now:\nCR2!n4!n14!n (length 22)\nIn the previous version (60) it was shown as:\nCR2!n3!n14!n (length 21)\nThe example has likewise been changed to\nCR05015202001026284066\nfrom\nCR0515202001026284066\n[1] https://www.swift.com/standards\nhttps://www.swift.com/file/26766/download?token=JR1P3trU\n"
            },
            "22": {
                "commit_sha_buggy": "322b49f7267ffd5f1f4b7dc46b24912ec66f7d20",
                "commit_sha_fixed": "63a111bcb0d676bea8b2568330aa7c01a1d35c3f",
                "report_id": "VALIDATOR-411",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-411",
                "issue_title": "[VALIDATOR-411] UrlValidator accepts ports above max limit of 16-bit unsigned integer - ASF JIRA",
                "issue_description": "\nSuch a value http://host.organization.com:100000 is gladly accepted because the port ins never parsed and boundaries not checked.\n\npublic static void main(String[] args) {\n  UrlValidator validator = UrlValidator.getInstance();\n  System.out.println(validator.isValid(\"http://host.organization.com:100000\"));\n}\n\n\n"
            },
            "23": {
                "commit_sha_buggy": "2404939a4bfe4681925903bb2d1a0d174217942a",
                "commit_sha_fixed": "ab1f195d44a61b2a01bb4c3f626afcacda978867",
                "report_id": "VALIDATOR-387",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-387",
                "issue_title": "[VALIDATOR-387] Userinfo without colon should be valid in UrlValidator - ASF JIRA",
                "issue_description": "\nUrlValidator does not accept userinfo without \":\".\nThe following code returns false.\n\nUrlValidator validator = new UrlValidator();\nvalidator.isValid(\"http://user@www.apache.org:80/path\")\n\n\nBut it should be accepted.\nRFC of URI allows userinfo without colon.\nhttps://tools.ietf.org/html/rfc3986#section-3.2.1\n\nuserinfo    = *( unreserved / pct-encoded / sub-delims / \":\" )\nRFC of URL also allows it.\nhttps://tools.ietf.org/html/rfc1738#section-3.1\n\n //<user>:<password>@<host>:<port>/<url-path>\n   Some or all of the parts \"<user>:<password>@\", \":<password>\",\n   \":<port>\", and \"/<url-path>\" may be excluded. \nI created Pull Request.\nhttps://github.com/apache/commons-validator/pull/5\n"
            },
            "24": {
                "commit_sha_buggy": "e4a3737c6c07420ee7c27a968c443b04d71c3eaf",
                "commit_sha_fixed": "e2feaed85df37bc91fdeb59220c90fac2d3ade4b",
                "report_id": "VALIDATOR-419",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-419",
                "issue_title": "[VALIDATOR-419] Invalid IPv6 addresses that are IPv4-mapped pass InetAddressValidator validation - ASF JIRA",
                "issue_description": "\n1) InetAddressValidator.getInstance().isValidInet6Address(String inet6Address) returns true for value 0::ffff:192.168.1.1:192.168.1.1\nI believe this is due to wrong comparison operand in line #166 of InetAddressValidator: \n\nif (index > octets.length - 1 || index > 6) {  // CHECKSTYLE IGNORE MagicNumber\n    // IPV4 occupies last two octets\n    return false;\n}\n\n\nindex > octets.length - 1 expression will never be true inside cycle \n\nfor (int index = 0; index < octets.length; index++)\n\n2) According to https://tools.ietf.org/html/rfc4291 IPv6 address that is IPv4-mapped must start with five zero octets followed by one ffff octet. Current implementation of InetAddressValidator does not check this. E.g. 1::2:192.168.1.1 is considered valid.\n"
            },
            "25": {
                "commit_sha_buggy": "e2feaed85df37bc91fdeb59220c90fac2d3ade4b",
                "commit_sha_fixed": "ba559195253cbe42f2f04642e93bcb7e72599005",
                "report_id": "VALIDATOR-420",
                "report_url": "https://issues.apache.org/jira/browse/VALIDATOR-420",
                "issue_title": "[VALIDATOR-420] Query params validator shouldn't accept whitespaces - ASF JIRA",
                "issue_description": "\nI have noticed that query string regex /^(.*)$/ allows to input white space characters. \neg.:\nhttp://example.com/serach?address=Main Avenue\nis a valid url due to validator, but java.net.URI.create will throw java.net.URISyntaxException: Illegal character in query\n"
            }
        }
    },
    "Pool": {
        "owner_repo": "apache/commons-pool",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "498d134dd0bdf10697b5e44365b56519d8eccf76",
                "commit_sha_fixed": "09837736725b4405babcc428ac43816cf77f630b",
                "report_id": "POOL-116",
                "report_url": "https://issues.apache.org/jira/browse/POOL-116",
                "issue_title": "[POOL-116] GenericKeyedObjecPool(factory, Config) constructor ignores minIdle setting in Config - ASF JIRA",
                "issue_description": "\nThe GenericKeyedObjectPool constructor that takes a GenericKeyedObjectPool.Config object as an argument does not use the minIdle field in the Config, resulting in the default value being set.\n"
            },
            "5": {
                "commit_sha_buggy": "9a67df7d74e7db90db0ce714d81b69a4894959ec",
                "commit_sha_fixed": "d08ab23f5d00fb30019827fe5a60e377be408df0",
                "report_id": "POOL-180",
                "report_url": "https://issues.apache.org/jira/browse/POOL-180",
                "issue_title": "[POOL-180] Max active per key can be exceeded by one - ASF JIRA",
                "issue_description": "\nWhen instances in the pool fail validation with high frequency,  maxTotal is less than maxActive times the number of keys, and destroy has latency,  the maxActive contract can be violated (i.e., the number of instances created under a given key minus the number destroyed can exceed maxActive).\nAttaching a test case that fails against POOL_1_X\n"
            },
            "6": {
                "commit_sha_buggy": "d289e4fd31f8d37feda794053d3d1bf58f919052",
                "commit_sha_fixed": "f229ea44e43ac32390a851775a8fba7c192664a4",
                "report_id": "POOL-189",
                "report_url": "https://issues.apache.org/jira/browse/POOL-189",
                "issue_title": "[POOL-189] close() does not release threads blocked on borrowObject() - ASF JIRA",
                "issue_description": "\nHi,\nWhen I call close() and borrowObject() concurrently with no objects in\nthe pool, close() will finish but borrowObject() is blocked forever.\nThe documentation of close() mentions that borrowObject() should fail \nwith IllegalStateException, so I would expect the waiting threads to \nthrow IllegalStateException.\nI will attach a test that exposes this problem. For this test, the \nexpected output is:\n0\n1\n2\n...\n4999\nDONE\nBut when the bug manifests (almost always for this test), the output \nis:\n0\n1\n2\nThe test does not finish, it just gets stuck after printing several \nvalues.\nIs this a bug or am I reading the documentation wrongly? Is there \na patch for this?\nThanks!\nAdrian\n"
            },
            "7": {
                "commit_sha_buggy": "c2ef042a057215aafb73f3e8270780aa135e0d3e",
                "commit_sha_fixed": "90ea8acafa1d8de4af46f2e9e4d7725d22873974",
                "report_id": "POOL-231",
                "report_url": "https://issues.apache.org/jira/browse/POOL-231",
                "issue_title": "[POOL-231] GOP, GKOP invalidateObject is not threadsafe - ASF JIRA",
                "issue_description": "\nThere does not appear to be sufficient sync protection for the destroyCount and createCount counters when destroy is activated by invalidateObject in GOP, GKOP, v2 trunk.  The test below fails when added to GOP tests. The destroyCount is over-incremented due (I think) to the fact that multiple threads can enter destroy before the object being invalidated is removed from allObjects.  This problem was originally reported by Thomas Neidhart in a comment on POOL-213.\n\n@Test\n    public void testConcurrentInvalidate() throws Exception {\n        // Get allObjects and idleObjects loaded with some instances\n        final int nObjects = 1000;\n        pool.setMaxTotal(nObjects);\n        pool.setMaxIdle(nObjects);\n        final Object[] obj = new Object[nObjects];\n        for (int i = 0; i < nObjects; i++) {\n            obj[i] = pool.borrowObject();\n        }\n        for (int i = 0; i < nObjects; i++) {\n            if (i % 2 == 0) {\n                pool.returnObject(obj[i]);\n            }\n        }\n        final int nThreads = 100;\n        final int nIterations = 100;\n        final InvalidateThread[] threads = new InvalidateThread[nThreads];\n        // Randomly generated list of distinct invalidation targets\n        final ArrayList<Integer> targets = new ArrayList<Integer>();\n        final Random random = new Random();\n        for (int j = 0; j < nIterations; j++) {\n            // Get a new invalidation target\n            Integer targ = new Integer(random.nextInt(nObjects));\n            while (targets.contains(targ)) {\n                targ = new Integer(random.nextInt(nObjects));\n            }\n            targets.add(targ);\n            // Launch nThreads threads all trying to invalidate the target\n            for (int i = 0; i < nThreads; i++) {\n                threads[i] = new InvalidateThread(pool, obj[targ]);\n            }\n            for (int i = 0; i < nThreads; i++) {\n                new Thread(threads[i]).start();\n            }\n            boolean done = false;\n            while (!done) {\n                done = true;\n                for (int i = 0; i < nThreads; i++) {\n                    done = done && threads[i].complete();\n                }\n                Thread.sleep(100);\n            }\n        }\n        Assert.assertEquals(nIterations, pool.getDestroyedCount());\n    }\n    \n    static class InvalidateThread implements Runnable {\n        final private Object obj;\n        final private ObjectPool<Object> pool;\n        private boolean done = false;\n        public InvalidateThread(ObjectPool<Object> pool, Object obj) {\n            this.obj = obj;\n            this.pool = pool;\n        }\n        public void run() {\n            try {\n                pool.invalidateObject(obj);\n            } catch (IllegalStateException ex) {\n                // Ignore\n            } catch (Exception ex) {\n                Assert.fail(\"Unexpected exception \" + ex.toString());\n            } finally {\n                done = true;\n            }\n        }\n        public boolean complete() {\n            return done;\n        }\n    }\n\n\n"
            },
            "10": {
                "commit_sha_buggy": "c46bba7d43466dd603b7dc242e1e3d22a694e9c2",
                "commit_sha_fixed": "59fc5a99893c25c3b4f2cc9a4969c0063461ba06",
                "report_id": "POOL-243",
                "report_url": "https://issues.apache.org/jira/browse/POOL-243",
                "issue_title": "[POOL-243] Object creation exception do not decrement createCount in GenericKeyedObjectPool implementation - ASF JIRA",
                "issue_description": "\nWhen KeyedPooledObjectFactory method create(K key), covering the object pool lifecycle, fails to create an object and throws an exception, the created object counter (createCount) of particular ObjectDeque do not gets decremented. As a result, setting the maxTotalPerKey do not work properly, which can cause a serious issue when maxTotalPerKey is set to for example 1.\n"
            },
            "11": {
                "commit_sha_buggy": "0dca56f30dde6b9b935f235e491c1ec6d6516da5",
                "commit_sha_fixed": "163372e76956b447e5bbd18aafcf16e51b70d529",
                "report_id": "POOL-248",
                "report_url": "https://issues.apache.org/jira/browse/POOL-248",
                "issue_title": "[POOL-248] GenericObjectPool.returnObject() is NOT throwing IllegalStateException for object has already been returned - ASF JIRA",
                "issue_description": "\nWhen GenericObjectPool is created using AbandonedConfig, the pool is NOT throwing \"IllegalStateException: Object has already been returned to this pool or is invalid\" for object has already been returned.\nfinal GenericObjectPool<String> pool = new GenericObjectPool<String>(\n\t\t\t\tnew SimpleFactory(), new GenericObjectPoolConfig(),\n\t\t\t\tnew AbandonedConfig());\n\t\tString obj1 = pool.borrowObject();\n\t\tSystem.out.println(\"after borrowing obj1\");\n\t\tSystem.out.println(\"numActive=\" + pool.getNumActive());\n\t\tSystem.out.println(\"numIdle=\" + pool.getNumIdle());\n\t\tSystem.out.println(\"return obj1\");\n\t\tpool.returnObject(obj1);\n\t\tSystem.out.println(\"numActive=\" + pool.getNumActive());\n\t\tSystem.out.println(\"numIdle=\" + pool.getNumIdle());\n\t\tSystem.out.println(\"return obj1 again\");\n\t\tpool.returnObject(obj1);\n\t\tSystem.out.println(\"numActive=\" + pool.getNumActive());\n\t\tSystem.out.println(\"numIdle=\" + pool.getNumIdle());\nOutput:\nafter borrowing obj1\nnumActive=1\nnumIdle=0\nreturn obj1\nnumActive=0\nnumIdle=1\nreturn obj1 again\nnumActive=-1\nnumIdle=2\n"
            },
            "12": {
                "commit_sha_buggy": "d7a18638e896a790215e6333a9f7b2a79a0b71e9",
                "commit_sha_fixed": "a85bc0151aca36475da1ebba67494edae45c19ca",
                "report_id": "POOL-259",
                "report_url": "https://issues.apache.org/jira/browse/POOL-259",
                "issue_title": "[POOL-259] Client wait time is not updated when max wait is configured to be unlimited - ASF JIRA",
                "issue_description": "\nThe local variable waitTime used by borrowObject in both GOP and GKOP is not updated unless borrowMaxWaitMillis is non-negative and blockWhenExhausted is true.  This effectively zeros the JMX client wait time properties for these configurations.  Even when there is a maxWait configured and the pool is set to block when exhausted, what ends up being reported is only the wait time on the instance queue.  Note that this bug is JMX reporting only.\nI am inclined to fix this by setting waitTime at the beginning and updating it at the end (including activate and validate times).  We should also add test cases for this and the other stats exposed via JMX.  Patches welcome, as it may take me a little while to get to this.\n"
            },
            "13": {
                "commit_sha_buggy": "b6e5122f5e85ac3d6b59c04e4e43ab511fa0006f",
                "commit_sha_fixed": "af335b264d5469c07b391bed7f69cb615e12c550",
                "report_id": "POOL-270",
                "report_url": "https://issues.apache.org/jira/browse/POOL-270",
                "issue_title": "[POOL-270] timeBetweenEvictionRunsMillis from config is ignored - ASF JIRA",
                "issue_description": "\nIn the constructor for GenericKeyedObjectPool, the setting for timeBetweenEvictionRunsMillis is always overridden by minEvictableIdleTimeMillis.\nFirst setConfig() is called, which, ends up starting an evictor with a period of timeBetweenEvictionRunsMillis, as expected. but the final line of the constructor calls startEvictor() again with minEvictableIdleTimeMillis, which kills the first timer and starts a new one with the new period. This means effectively the timeBetweenEvictionRunsMillis from the config is not used for anything.\nI want testWhileIdle's verifications to run more often than I want the timeout for evicting idle objects, which does not appear to be possible given this bug.\n"
            },
            "14": {
                "commit_sha_buggy": "2562bd541cf8e9289b7f0892483974970f3c26d8",
                "commit_sha_fixed": "b9b1f5de8f022c6f62343bb29310dde2724318e0",
                "report_id": "POOL-276",
                "report_url": "https://issues.apache.org/jira/browse/POOL-276",
                "issue_title": "[POOL-276] Validation code invoked on unexpected timing. - ASF JIRA",
                "issue_description": "\nI found BasePooledObjectFactory.validateObject() of commons-pool sometimes called on unexpected timing.\nI've configured the pool so as to the validateObject() would be invoked only on instance creation, but sometimes it was invoked for \"non-fresh\" instance on borrowing.\nReproduction code below.\n\nimport java.io.*;\nimport java.util.*;\n\nimport org.apache.commons.pool2.*;\nimport org.apache.commons.pool2.impl.*;\n\npublic class reproduction\n{\n    private static class MyPooledObj\n    {\n        volatile int i = 0;\n        final String uuid = UUID.randomUUID().toString();\n    }\n\n    private static class MyFactory extends BasePooledObjectFactory<MyPooledObj>\n    {\n        @Override\n        public MyPooledObj create() {\n            return new MyPooledObj();\n        }\n\n        @Override\n        public PooledObject<MyPooledObj> wrap(MyPooledObj o) {\n            return new DefaultPooledObject<MyPooledObj>(o);\n        }\n\n        @Override\n        public boolean validateObject(PooledObject<MyPooledObj> o) {\n            MyPooledObj myobj = o.getObject();\n            synchronized (myobj) {\n                myobj.i++;\n            }\n            System.out.println(\"Validated.\");\n            return true;\n        }\n    }\n\n    public static void main(String[] args)\n        throws Exception\n    {\n        GenericObjectPoolConfig poolCfg = new GenericObjectPoolConfig() ;\n        poolCfg.setMaxTotal(1);\n        poolCfg.setMaxIdle(1);\n        poolCfg.setBlockWhenExhausted(true);\n        poolCfg.setMaxWaitMillis(10000);\n\n        poolCfg.setTestOnCreate(true); // should be validated only on creation\n        poolCfg.setTestOnBorrow(false);\n        poolCfg.setTestOnReturn(false);\n        poolCfg.setTestWhileIdle(false);\n\n        final GenericObjectPool<MyPooledObj> pool =\n            new GenericObjectPool<MyPooledObj>(new MyFactory(), poolCfg);\n\n        final MyPooledObj o = pool.borrowObject();\n        System.out.printf(\"%d: %s\\n\", o.i, o.uuid);\n\n        Timer t = new Timer();\n        t.schedule\n            (new TimerTask() {\n                    public void run() {\n                        pool.returnObject(o);\n                    }\n                }, 3000);\n\n        // validation will occur again for non-fresh instance,\n        // confirmed on commons-pool2-2.2 with jdk1.7.0_55\n        MyPooledObj o2 = pool.borrowObject();\n        System.out.printf(\"%d: %s\\n\", o2.i, o2.uuid);\n        pool.returnObject(o2);\n        pool.close();\n\n        t.cancel();\n    }\n}\n\n\n"
            },
            "16": {
                "commit_sha_buggy": "7340c5bb6fb4582afee0cc24219b628e94b3e251",
                "commit_sha_fixed": "cd9365a362b882441d2c8b76d2494a7dc090f262",
                "report_id": "POOL-279",
                "report_url": "https://issues.apache.org/jira/browse/POOL-279",
                "issue_title": "[POOL-279] Thread concurrency issue in DefaultPooledObject.getIdleTimeMillis() - ASF JIRA",
                "issue_description": "\nUnder unlucky thread concurrency the getIdleTimeMillis() method of DefaultPooledObject can return a negative value.\nI have attached a Junit test that fails most of the times and a simple fix, that doesn't use synchronization: with this fix the Junit test always succeed.\n"
            },
            "20": {
                "commit_sha_buggy": "669db17c58795bf8e01c64cb3bf467b4bf1fe42e",
                "commit_sha_fixed": "84069547855364e9efc8a238bcadbc0a8e5a926f",
                "report_id": "POOL-300",
                "report_url": "https://issues.apache.org/jira/browse/POOL-300",
                "issue_title": "[POOL-300] Abandoned object stack traces may not be written - ASF JIRA",
                "issue_description": "\nWhen writing stack traces for abandoned object tracking, DefaultPooledObject does not flush the Printwriter.  The default Printwriter in AbandonedConfig is System.out without autoflush enabled.  This means that stack traces may not be effectively logged (if there is just one, for example).\n"
            },
            "21": {
                "commit_sha_buggy": "a898de843abe44f5f0910b271a89b60e884852a5",
                "commit_sha_fixed": "fa819eb4be47b7078ef973cbc37df38e7df6eb1f",
                "report_id": "POOL-303",
                "report_url": "https://issues.apache.org/jira/browse/POOL-303",
                "issue_title": "[POOL-303] GenericObjectPool's borrowObject may stuck if create() always fail - ASF JIRA",
                "issue_description": "\nIf GenericObjectPool's user use borrowObject() to get the object. The pool will try to pollFirst() first and if there is no idle object it will try to create it. In create()  if createCount > maxTotal, it will not create any object and wait on idleObjects.takeFirst() or idleObjects.pollFirst(borrowMaxWaitMillis, TimeUnit.MILLISECONDS) for other thread return an object. \nIf there are many threads (the number is more than maxTotal) to borrowObject concurrently, there will only maxTotal threads go to create the object, the others will wait on the queue. However, if the factory has some problem that makeObject() always throw Exception, there will not be any object created so no thread will return the object that should send a signal to one waiting thread. The thread wait on idleObjects.takeFirst()  will stuck forever because it has no timeout.\nI think it can be fixed by adding a idleObjects.interuptTakeWaiters(); in create() before it throws the exception and let the waiting threads interrupted and retry to create.  \nIt seems that all 2.x version affected?\n"
            },
            "24": {
                "commit_sha_buggy": "44e087d2977af86dda2677f13d5415371b7be7b1",
                "commit_sha_fixed": "12ba9290e055c2cb86701530b66880e459794ebb",
                "report_id": "POOL-336",
                "report_url": "https://issues.apache.org/jira/browse/POOL-336",
                "issue_title": "[POOL-336] GenericObjectPool's borrowObject lock if create() fails with Error - ASF JIRA",
                "issue_description": "\nWe've spotted exactly the same problem as described in POOL-303 for a pool using mariadb-connector-j-2.1.2 with a pool configured to a size, which exactly reflects the normal quantity of used DB connections. \nAfter weeks of monitoring the situation, we were able to see the same problem as described in POOL-303. After some more drilldown efforts we concluded, that the problem is triggered, because mariadb-connector-j throws instances of Throwables derived from java.lang.Error, which are not instances of java.lang.Execption.\nThis leads to a leak of makeCount in GenericObjectPool.create(), because makeCount is only decremented, when an instance of java.lang.Exception is thrown and not when an instance of java.langError is thrown.\n"
            },
            "26": {
                "commit_sha_buggy": "21831143b35abb156615ac673a95d99d0b7ac601",
                "commit_sha_fixed": "3e02523b6907fb22f3582544fe362c785821bcb8",
                "report_id": "POOL-347",
                "report_url": "https://issues.apache.org/jira/browse/POOL-347",
                "issue_title": "[POOL-347] borrowObject waits for maxWaitMillis over in pool full - ASF JIRA",
                "issue_description": "\nSince\u00a0POOL-303's fix, even if we specify maxWaitMillis, object creation continues waiting for longer time without any hard limit at https://github.com/apache/commons-pool/blob/3e6dfcd61ddcd88b18934738ebda05c84c948a80/src/main/java/org/apache/commons/pool2/impl/GenericObjectPool.java#L848. \nHere's the actual stacktrace:\n\n\r\n   java.lang.Thread.State: WAITING (on object monitor)\r\n\tat java.lang.Object.wait(Native Method)\r\n\t- waiting on <0x0000000741158358> (a java.lang.Object)\r\n\tat java.lang.Object.wait(Object.java:502)\r\n\tat org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:848)\r\n\t- locked <0x0000000741158358> (a java.lang.Object)\r\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:417)\r\n\tat org.apache.commons.pool2.impl.TestGenericObjectPool.testReturnBorrowObjectWithingMaxWaitMillis(TestGenericObjectPool.java:2658)\r\n\n\nAs example of this issue, \nwe use Jedis2.9 with commons-pool 2.4.3 and maxWaitMillis=500ms in our environment.\nHowever, when master node is down and the connection pool for the node is full, succeeding JedisConnections wait there forever until pool is free. \nTherefore, borrowObject (and the aborting) of last connections takes 40 ~ 80 sec at worst case.\nIn order to avoid such situations, we should set hard limit to wait by reusing maxWaitMillis or another value.  \n"
            },
            "27": {
                "commit_sha_buggy": "60a041d393c75035e9a63c33723c382ac6f35c30",
                "commit_sha_fixed": "016a1f67263fe1cde1d910dc7002d972811951c5",
                "report_id": "POOL-356",
                "report_url": "https://issues.apache.org/jira/browse/POOL-356",
                "issue_title": "[POOL-356] deadlock if borrowObject gets called to fast and maxIdle is 0 - ASF JIRA",
                "issue_description": "\nI figured this while creating a unit test for OpenJPA. But also did see this in real production with commons-dbcp2. See DBCP-513 for more info.\nSee this comment for a precise explanation what happens https://issues.apache.org/jira/browse/DBCP-513?focusedCommentId=16660545&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16660545\nThe problem is basically that the logic to immediately destroy a pool object does not notify the DeLinkedQueue:\n\n\r\n        if (isClosed() || maxIdleSave > -1 && maxIdleSave <= idleObjects.size()) {\r\n            try {\r\n                destroy(p);\r\n\n\nBut the borrowObject code is locking on that condition...\n\n\r\n                    if (borrowMaxWaitMillis < 0) {\r\n                        p = idleObjects.takeFirst();\r\n                    } \r\n\n\n"
            },
            "29": {
                "commit_sha_buggy": "11521c1fdbfbb079cc1859034a425191112f5358",
                "commit_sha_fixed": "41f4e410b3e7dc34b294ac9941721073bf5e5271",
                "report_id": "POOL-374",
                "report_url": "https://issues.apache.org/jira/browse/POOL-374",
                "issue_title": "[POOL-374] org.apache.commons.pool2.impl.GenericKeyedObjectPool.returnObject(K, T) should throw IllegalStateException instead of NullPointerException when a key is not found in the pool map - ASF JIRA",
                "issue_description": "\nThe method org.apache.commons.pool2.impl.GenericKeyedObjectPool.returnObject(K, T) should throw IllegalStateException instead of NullPointerException when a key is not found in the pool map.\n"
            },
            "30": {
                "commit_sha_buggy": "cb38a1b69384a3811d50d9eb0145683227fe8d51",
                "commit_sha_fixed": "0cdff0ade7e6a6ae2a48356e55d7549353535043",
                "report_id": "POOL-356",
                "report_url": "https://issues.apache.org/jira/browse/POOL-356",
                "issue_title": "[POOL-356] deadlock if borrowObject gets called to fast and maxIdle is 0 - ASF JIRA",
                "issue_description": "\nI figured this while creating a unit test for OpenJPA. But also did see this in real production with commons-dbcp2. See DBCP-513 for more info.\nSee this comment for a precise explanation what happens https://issues.apache.org/jira/browse/DBCP-513?focusedCommentId=16660545&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16660545\nThe problem is basically that the logic to immediately destroy a pool object does not notify the DeLinkedQueue:\n\n\r\n        if (isClosed() || maxIdleSave > -1 && maxIdleSave <= idleObjects.size()) {\r\n            try {\r\n                destroy(p);\r\n\n\nBut the borrowObject code is locking on that condition...\n\n\r\n                    if (borrowMaxWaitMillis < 0) {\r\n                        p = idleObjects.takeFirst();\r\n                    } \r\n\n\n"
            }
        }
    },
    "Email": {
        "owner_repo": "apache/commons-email",
        "bug_infos": {
            "3": {
                "commit_sha_buggy": "2976dd836797d11f3eb3f4d02d61feb6e7bde2e7",
                "commit_sha_fixed": "b9f88a773c72e590015736edad69181329a43d30",
                "report_id": "EMAIL-116",
                "report_url": "https://issues.apache.org/jira/browse/EMAIL-116",
                "issue_title": "[EMAIL-116] DataSourceCompositeResolver.getDataSourceResolvers() fails to clone DataSourceResolver[] - ASF JIRA",
                "issue_description": "\nThe ctor is careful to clone the provided array, but the getter method fails to clone the array, thus allowing external modification.\nThis is illogical.\n"
            },
            "4": {
                "commit_sha_buggy": "fab97868ec7ffe89e4052a31b22f0a43560c93cb",
                "commit_sha_fixed": "8b9aad8d106f7445495c4d3188424f2bd98294cb",
                "report_id": "EMAIL-124",
                "report_url": "https://issues.apache.org/jira/browse/EMAIL-124",
                "issue_title": "[EMAIL-124] Header values are folded twice and thus creating defective emails - ASF JIRA",
                "issue_description": "\nWith EMAIL-98, header values now are folded by commons-email.\nUnfortunately, they are folded twice: once in \"Mail.addHeader\" or \"Mail.setHeaders\", and once again in \"Mail.buildMimeMessage()\" while iterating over the headers.\nThis results (in our test cases) in corrupted mail header lines having additional blank lines between the first and second line of a folded value - and thus ends in corrupted mails (as all headers after the first blank line are threatened as mail-body-content).\nAs this renders \"additional headers\" useless in commons-mail and corrupts every mail having additionl headers with longer-than-folding-size values, i set the priority to blocker.\nThe fix seems to be easy: just fold either in addHeader and setHeaders, or in buildMimeMessage (but not in both).\nMy preferred solution would be to fold in buildMimeMessage, and to store the values \"as-is\" in addHeader and setHeaders so one is able to work with the plain values (if neccessary) until the mail is actually build and send.\n"
            },
            "5": {
                "commit_sha_buggy": "ed451ccfe82779fbeb1f2bdde9d27ac4c75c7e63",
                "commit_sha_fixed": "f639e15f50e0192187bd77bb63ea5af6fb646a0d",
                "report_id": "EMAIL-124",
                "report_url": "https://issues.apache.org/jira/browse/EMAIL-124",
                "issue_title": "[EMAIL-124] Header values are folded twice and thus creating defective emails - ASF JIRA",
                "issue_description": "\nWith EMAIL-98, header values now are folded by commons-email.\nUnfortunately, they are folded twice: once in \"Mail.addHeader\" or \"Mail.setHeaders\", and once again in \"Mail.buildMimeMessage()\" while iterating over the headers.\nThis results (in our test cases) in corrupted mail header lines having additional blank lines between the first and second line of a folded value - and thus ends in corrupted mails (as all headers after the first blank line are threatened as mail-body-content).\nAs this renders \"additional headers\" useless in commons-mail and corrupts every mail having additionl headers with longer-than-folding-size values, i set the priority to blocker.\nThe fix seems to be easy: just fold either in addHeader and setHeaders, or in buildMimeMessage (but not in both).\nMy preferred solution would be to fold in buildMimeMessage, and to store the values \"as-is\" in addHeader and setHeaders so one is able to work with the plain values (if neccessary) until the mail is actually build and send.\n"
            },
            "6": {
                "commit_sha_buggy": "89ac086217d36a6e9e5d02f3cdc1ee4250b226f0",
                "commit_sha_fixed": "348f4f222f58aadc2a2a079731dbe643bf19c76b",
                "report_id": "EMAIL-131",
                "report_url": "https://issues.apache.org/jira/browse/EMAIL-131",
                "issue_title": "[EMAIL-131] MimeMessageParser not able to read the inline attachments. - ASF JIRA",
                "issue_description": "\nHi All,\nI am trying to extract attachments using MimeMessageParser. But unable to extract the attachment when i have mime part as below \nContent-Type: text/plain; charset=us-ascii;\n        name=\"abc.txt\"\nContent-Transfer-Encoding: 7bit\nContent-Disposition: attachment;\n        filename=\"abc.txt\"\nAfter looking into parse method, \n======\n    protected void parse(Multipart parent, MimePart part)\n        throws MessagingException, IOException\n    {\n        if (part.isMimeType(\"text/plain\") && (plainContent == null))\n        {\n            plainContent = (String) part.getContent();\n        }\n        else\n        {\n            if (part.isMimeType(\"text/html\") && (htmlContent == null))\n            {\n                htmlContent = (String) part.getContent();\n            }\n            else\n            {\n                if (part.isMimeType(\"multipart/*\"))\n                {\n                    this.isMultiPart = true;\n                    Multipart mp = (Multipart) part.getContent();\n                    int count = mp.getCount();\n                    // iterate over all MimeBodyPart\n                    for (int i = 0; i < count; i++)\n                    {\n                        parse(mp, (MimeBodyPart) mp.getBodyPart(i));\n                    }\n                }\n                else\n                {\n                    this.attachmentList.add(createDataSource(parent, part));\n                }\n            }\n        }\n    }\n====\nso attachment is going to plainContent\nCan anybody please let me know. how can this going to work\nDo we need to consider Content-Disposition ? According to java mail documentation\nThanks,\nRaju\n"
            }
        }
    },
    "Graph": {
        "owner_repo": "apache/commons-graph",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3249c5fd606cda769a8c0bbb5788403f57f9d82f",
                "commit_sha_fixed": "808c1c7512778204b72424bb6a72a6181af4176e",
                "report_id": "SANDBOX-334",
                "report_url": "https://issues.apache.org/jira/browse/SANDBOX-334",
                "issue_title": "[SANDBOX-334] [Graph] Bad coloring for crawn graph - ASF JIRA",
                "issue_description": "\nThe graphColoring algorithm fails for crown graph (see http://en.wikipedia.org/wiki/Crown_graph for more details).\n"
            },
            "2": {
                "commit_sha_buggy": "7b6463ac2eeadf3d73d457e8ff18ea444b6159e5",
                "commit_sha_fixed": "8a89bffddac4dd221525ba00b764a66fce9033b2",
                "report_id": "SANDBOX-336",
                "report_url": "https://issues.apache.org/jira/browse/SANDBOX-336",
                "issue_title": "[SANDBOX-336] [Graph] Duplicate Edge   - ASF JIRA",
                "issue_description": "\nThe method  BaseMutableGraph#addEdge does not check if the edge already exists.\n"
            },
            "3": {
                "commit_sha_buggy": "cb0c6b7e7c9316fe89217e40010958e30cd7cfc7",
                "commit_sha_fixed": "28443c5378e12745049f5cca70935a1d7c4e185a",
                "report_id": "SANDBOX-391",
                "report_url": "https://issues.apache.org/jira/browse/SANDBOX-391",
                "issue_title": "[SANDBOX-391] removeEdge method: missing implementation - ASF JIRA",
                "issue_description": "\nIn the BaseMutableGraph  class the implementation of removeEdge method is missing.\n"
            },
            "4": {
                "commit_sha_buggy": "ce874f0ff693f336e33d11c95dcfbb3b1594344c",
                "commit_sha_fixed": "251fd46f717c74dce9297aaa16396af3a7135a33",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fixed unified graph search algorithm in case of non-default visitor implementations",
                "issue_description": "fixed unified graph search algorithm in case of non-default visitor implementations"
            },
            "5": {
                "commit_sha_buggy": "064c0ee082b887fe148d02ccaf3ec11c434115e7",
                "commit_sha_fixed": "cf696dc2366c9ba9595f27e48e9833f172988400",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fixed missing source Vertex in the path vertices list",
                "issue_description": "fixed missing source Vertex in the path vertices list"
            }
        }
    },
    "Net": {
        "owner_repo": "apache/commons-net",
        "bug_infos": {
            "9": {
                "commit_sha_buggy": "2b248a62e4148b5f92ec7c8d10a7eac1184bb015",
                "commit_sha_fixed": "46c9b97454b17150b3ee7b2de973eae4aed8522a",
                "report_id": "NET-268",
                "report_url": "https://issues.apache.org/jira/browse/NET-268",
                "issue_title": "[NET-268] SubnetUtilsTest  does not include any tests for CIDR with /30, /31, /32 - ASF JIRA",
                "issue_description": "\nSubnetUtilsTest  does not include any tests for CIDRs with masks of /30, /31, /32\nIt only includes tests for /8 /16 /24 and /29, plus a test for the (invalid) /0.\n"
            },
            "10": {
                "commit_sha_buggy": "432510450e21779226669b40d0b3531baaf8e27b",
                "commit_sha_fixed": "5278cd419abc3ccaabc352ba67631b1985eb4bed",
                "report_id": "NET-428",
                "report_url": "https://issues.apache.org/jira/browse/NET-428",
                "issue_title": "[NET-428] SubnetUtils throws ArrayIndexOutOfBoundsException for new SubnetUtils( \"1.2.3.4/32\" ).getInfo().getAllAddresses() - ASF JIRA",
                "issue_description": "\nnew SubnetUtils( \"1.2.3.4/32\" ).getInfo().getAllAddresses() throws\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 0\n$SubnetInfo.getAllAddresses(SubnetUtils.java:166)\nSimilarly for /31\nIt would make more sense to return an empty array.\n"
            },
            "12": {
                "commit_sha_buggy": "ceb54335d722859644f74774554a5a02f100aae3",
                "commit_sha_fixed": "9d090d40ef488c6c8e0784da877b93a05034e339",
                "report_id": "NET-511",
                "report_url": "https://issues.apache.org/jira/browse/NET-511",
                "issue_title": "[NET-511] Exception for new SubnetUtils(\"0.0.0.0/0\") - ASF JIRA",
                "issue_description": "\nThe following example in SubnetUtils throws an exception:\n\nSubnetUtils utils = new SubnetUtils(\"0.0.0.0/0\");\n\n\nAs '0.0.0.0/0' is within the IPv4 specification, it should be supported.\n"
            },
            "14": {
                "commit_sha_buggy": "1ab1a17fd37c377d96c8b41f41178ef1498c7fb5",
                "commit_sha_fixed": "717068898a67d03b7c2435e9f16bb65aced68048",
                "report_id": "NET-520",
                "report_url": "https://issues.apache.org/jira/browse/NET-520",
                "issue_title": "[NET-520] SubnetUtils(\"0.0.0.0/0\") does not behave as expected - ASF JIRA",
                "issue_description": "\nSee NET-511 - SubnetUtils(\"0.0.0.0/0\") can now be created, but does not behave as might be expected.\nUnit tests needed which can then drive the fixes\n"
            },
            "15": {
                "commit_sha_buggy": "75129393c169ef25314223d903426c8be0716a77",
                "commit_sha_fixed": "41dd3db34ae2c03f5b5148bcca84653055c0e3eb",
                "report_id": "NET-516",
                "report_url": "https://issues.apache.org/jira/browse/NET-516",
                "issue_title": "[NET-516] parser problem occurs if the filename contains one or more characters of which the second byte of Shift-JIS code is 0x85 - ASF JIRA",
                "issue_description": "\nProblem occurs if the filename contains one or more characters of which the second byte of Shift-JIS code is 0x85, on a windows Japanese machine when listing file names from IIS FTP server.\nThis was working fine in commons-net-1.4.0.jar . \n[This relates to the NTFTPEntryParser]\n"
            },
            "16": {
                "commit_sha_buggy": "061d70dd783a9150601fc884cc93831d39efd751",
                "commit_sha_fixed": "b26a3b41b047cdcc37aa65625075fa621d13f66e",
                "report_id": "NET-539",
                "report_url": "https://issues.apache.org/jira/browse/NET-539",
                "issue_title": "[NET-539] NPE if Threader.thread invoked with empty list or with null array - ASF JIRA",
                "issue_description": "\nThreader.pruneEmptyContainers fails with NPE if Thread.thread is invoked with an empty list\nThe code allows for a null list, but not an empty list.\n"
            },
            "17": {
                "commit_sha_buggy": "c5192345305636887229eb7ae0829d621effc2b4",
                "commit_sha_fixed": "aee94d0b51becdc83ea4a74e86b242d0ca3d6f0a",
                "report_id": "NET-551",
                "report_url": "https://issues.apache.org/jira/browse/NET-551",
                "issue_title": "[NET-551] Util copyReader calls CopyStreamListener.bytesTransferred with the incorrect value for bytesTransferred - ASF JIRA",
                "issue_description": "\nUtil copyReader calls CopyStreamListener.bytesTransferred with the incorrect value for bytesTransferred parameter if it reads a single character.\nIt uses the value of the field chars which at that point contains the character, rather than the number read.\nThe code also re-uses the chars field for both the number of characters read and the single character, which is quite confusing. [The copyStream also re-uses the bytes field, but uses the correct bytesTransferred parameter]\n"
            },
            "18": {
                "commit_sha_buggy": "506d027199a615962ad5df482f077792841a01c1",
                "commit_sha_fixed": "5555226cf8d009ee9fdb9164a919e96d768c529e",
                "report_id": "NET-550",
                "report_url": "https://issues.apache.org/jira/browse/NET-550",
                "issue_title": "[NET-550] Default FTPClient bufferSize results in very slow retrieve transfers - ASF JIRA",
                "issue_description": "\nWhile experimenting with FTPClient, I discovered that if I don't call setBufferSize(), the default value is zero.  This results in retrieveFile() calling the version of InputStream.read() with no parameters, reading one byte at a time.  For comparison, the downloading a CD ISO image of about ~648MB took 18m10s with the default settings.  In contrast, calling setBufferSize(8192) took only 7.9s, an improvement of ~137x.\nHere is some sample code:\n\nFTPClient ftp = new FTPClient();\n// ftp.setBufferSize(8192);\nftp.setControlKeepAliveTimeout(300);\nftp.setCopyStreamListener(new CopyStreamListener() {\n    @Override\n    public void bytesTransferred(long totalBytesTransferred, int bytesTransferred, long streamSize) {\n        System.out.println(\"totalBytesTransferred: \" + totalBytesTransferred\n            + \", bytesTransferred: \" + bytesTransferred + \", streamSize: \" + streamSize);\n    }\n\n    @Override public void bytesTransferred(CopyStreamEvent event) {}\n});\nftp.connect(host);\nftp.login(user, pass);\nftp.retrieveFile(file, outputStream);\n\n\nThe log message from the stream listener printed lots messages \"bytesTransferred: 1\" and totalBytesTransferred incremented by 1 each time.  This corresponds to the part of the code which reads one byte at a time with int inputStream.read().\n"
            },
            "20": {
                "commit_sha_buggy": "1762d632b7c343fc524e1e6495babeaf2b9b8550",
                "commit_sha_fixed": "50a124bf76c36d47d797306ccadcb3d97c43caca",
                "report_id": "NET-566",
                "report_url": "https://issues.apache.org/jira/browse/NET-566",
                "issue_title": "[NET-566] UnixFTPEntryParser Drops Leading Spaces from File Names - ASF JIRA",
                "issue_description": "\nThe UnixFTPEntryParser regular expression  (line 106) consumes all spaces between the timestamp and the file name.\nThe FTPFile.name property ends up getting a value with stripped leading spaces.\nReported by Spring Integration user at https://jira.spring.io/browse/INT-3591\n"
            },
            "21": {
                "commit_sha_buggy": "77a30c218d8b1505a9ed450e62625321bdf000fb",
                "commit_sha_fixed": "e8d76ef9c72325b773b9141a8566ce1147c1ebc6",
                "report_id": "NET-581",
                "report_url": "https://issues.apache.org/jira/browse/NET-581",
                "issue_title": "[NET-581] SimpleSMTPHeader fails to supply the required Date: header - ASF JIRA",
                "issue_description": "\nAccording to RFC 5322 [1] (previously 2822, 822) the message headers MUST include both the From: and Date: (orig-date) fields.\nHowever this is not provided by SimpleSMTPHeader#toString()\nThe code should be amended to generate this if the user has not supplied a Date: header.\n[1] https://tools.ietf.org/html/rfc5322#section-3.6\n"
            },
            "23": {
                "commit_sha_buggy": "ba2886c990242c32e75d94a9d4c7ec9aa2571f10",
                "commit_sha_fixed": "76036954547d0ead559f4e7b258019b3355d05a4",
                "report_id": "NET-624",
                "report_url": "https://issues.apache.org/jira/browse/NET-624",
                "issue_title": "[NET-624] SubnetInfo#toCidrNotation - a wrong format subnet mask is allowed - ASF JIRA",
                "issue_description": "\nAn IPv4 subnet mask, which is also the network mask, must consist of a set of contiguous 1-bits followed by a block of 0-bits (i.e. 255.255.255.0), but it does not check.\n\n/* 255.255.0.1 is 11111111.11111111.00000000.00000001 in  binary */\nSubnetUtils su = new SubnetUtils(\"192.168.0.1\", \"255.255.0.1\"); // expect error\nSubnetInfo si = su.getInfo();\nSystem.out.println(si.getNetmask()); // Expect error or 255.255.0.1\n255.255.128.0\n\n\nhttps://github.com/apache/commons-net/pull/13\n"
            },
            "24": {
                "commit_sha_buggy": "1acb3d3f5f8230e4329be95644c9f433b75bf0cb",
                "commit_sha_fixed": "d8f9af13ba04b2b483f6d441d1c4071174726988",
                "report_id": "NET-631",
                "report_url": "https://issues.apache.org/jira/browse/NET-631",
                "issue_title": "[NET-631] Bug in MVSFTPEntryParser.parseUnixList (FindBugs) - ASF JIRA",
                "issue_description": "\nFindBugs reports a bug in MVSFTPEntryParser#parseUnixList:\n\"Bug: The parameter file to org.apache.commons.net.ftp.parser.MVSFTPEntryParser.parseUnixList(FTPFile, String) is dead upon entry but overwritten\nThe initial value of this parameter is ignored, and the parameter is overwritten here. This often indicates a mistaken belief that the write to the parameter will be conveyed back to the caller.\"\nSince the other parsexxx() methods update the passed FTPFile parameter it looks like it was indeed the intention to update the parameter.\nUnfortunately there are no tests which exercise this code, and I have been unable to find examples of FTP LIST output for MVS in Unix mode. The code in preParse() looks for the string \"total\" at the start of the first line of output. [Presumably subsequent lines look like normal Unix FTP listings.]\n"
            },
            "25": {
                "commit_sha_buggy": "24dd750b5bb142d26d3c74f1d884533f66006346",
                "commit_sha_fixed": "e08fbb9e9adffc54c5ad87ddfd57b590e65ef862",
                "report_id": "NET-639",
                "report_url": "https://issues.apache.org/jira/browse/NET-639",
                "issue_title": "[NET-639] Bug in MVSFTPEntryParser.preParse - MVS, z/OS - ASF JIRA",
                "issue_description": "\nSome PS-files couldn't be retrieved from ftp host (during FTPClient.listFiles(\"xxx\")). After investigation we've noticed, that the file has an unusual large allocation info (reading \n\nVolume Unit    Referred Ext Used Recfm Lrecl BlkSz Dsorg Dsname\n   :     :          :     :   :    :      :    :    :      :\nPEZ320 3390   2017/07/03  215807  FB   29600 29600  PS  'LBP.TX.FTP.LAZAGDOM.WORK.HILF'\n   :     :          :     :   :    :      :    :    :      :\n\n\n\nso the values of ext and used column merged. As a result, the pattern FILE_LIST_REGEX in MVSFTPEntryParser doesn't match -> the file is ignored.\nQuick Fix in Comments described ...\n"
            },
            "26": {
                "commit_sha_buggy": "f38341cab4a20f7f690072f24d648cea8e0f5784",
                "commit_sha_fixed": "2d935482d9b026ccd2cb2b55fcb05380a4466500",
                "report_id": "NET-641",
                "report_url": "https://issues.apache.org/jira/browse/NET-641",
                "issue_title": "[NET-641] SubnetUtils.SubnetInfo.isInRange(\"0.0.0.0\") returns true for CIDR/31, 32 - ASF JIRA",
                "issue_description": "\nCode:\nimport org.apache.commons.net.util.SubnetUtils;\npublic class A {\n  public static void main(String[] args) \n{\n    System.out.println(new SubnetUtils(\"192.168.1.0/30\").getInfo().isInRange(\"0.0.0.0\"));\n    System.out.println(new SubnetUtils(\"192.168.1.0/31\").getInfo().isInRange(\"0.0.0.0\"));\n    System.out.println(new SubnetUtils(\"192.168.1.0/32\").getInfo().isInRange(\"0.0.0.0\"));\n  }\n}\nResult:\nfalse\ntrue\ntrue\nExpected:\nfalse\nfalse\nfalse\n"
            }
        }
    },
    "Numbers_angle": {
        "owner_repo": "apache/commons-numbers",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "463183281c06a2398a70a00651fbb5feab5b0413",
                "commit_sha_fixed": "00b2b5621ed39141d81b92b3fa3ba96a4e54c1c1",
                "report_id": "NUMBERS-94",
                "report_url": "https://issues.apache.org/jira/browse/NUMBERS-94",
                "issue_title": "[NUMBERS-94] PlaneAngle normalize fails for very small numbers. - ASF JIRA",
                "issue_description": "\nWhen the PlaneAngle.normalize() method is called to normalize between 0 and 1 turns and is passed a very small number compared to the 1, then the method returns a number exactly equal to the angle upper bound. This breaks the API contract since the return value must be strictly less than the upper bound. Ex:\n\n\r\nPlaneAngle angle = PlaneAngle.ofTurns(-1e-18);\r\ndouble normalized = angle.normalize(PlaneAngle.PI).toTurns();\r\n// normalized is equal to 1 but it should be 0 since 1 - 1e-18 = 1, which is equivalent to 0 in turns\r\n\n\nPull request: https://github.com/apache/commons-numbers/pull/30\n"
            },
            "2": {
                "commit_sha_buggy": "463183281c06a2398a70a00651fbb5feab5b0413",
                "commit_sha_fixed": "55e07ae99581327c278abc955c7bb3413c285dac",
                "report_id": "NUMBERS-94",
                "report_url": "https://issues.apache.org/jira/browse/NUMBERS-94",
                "issue_title": "[NUMBERS-94] PlaneAngle normalize fails for very small numbers. - ASF JIRA",
                "issue_description": "\nWhen the PlaneAngle.normalize() method is called to normalize between 0 and 1 turns and is passed a very small number compared to the 1, then the method returns a number exactly equal to the angle upper bound. This breaks the API contract since the return value must be strictly less than the upper bound. Ex:\n\n\r\nPlaneAngle angle = PlaneAngle.ofTurns(-1e-18);\r\ndouble normalized = angle.normalize(PlaneAngle.PI).toTurns();\r\n// normalized is equal to 1 but it should be 0 since 1 - 1e-18 = 1, which is equivalent to 0 in turns\r\n\n\nPull request: https://github.com/apache/commons-numbers/pull/30\n"
            }
        }
    },
    "Geometry_core": {
        "owner_repo": "apache/commons-geometry",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2ec5d82d4e8a849fe8eff5083657fbd862db51b7",
                "commit_sha_fixed": "feed702f3266e947835e7685f7b9af30d7849b86",
                "report_id": "GEOMETRY-51",
                "report_url": "https://issues.apache.org/jira/browse/GEOMETRY-51",
                "issue_title": "[GEOMETRY-51] EpsilonDoublePrecisionContext allows negative & NaN epsilon - ASF JIRA",
                "issue_description": "\nEpsilonDoublePrecisionContext does not validate the epsilon to be positive (0 or greater). The comparison is based on Precision.compareTo(double, double, double), which itself calls Precision.equals(double, double, double), which then compares using\u00a0Math.abs(y - x) <= eps. If epsilon is negative or NaN, the comparison is invalid.\n"
            },
            "3": {
                "commit_sha_buggy": "385c02a9b2cc924ebdaacc8ba02f93b76cac31cc",
                "commit_sha_fixed": "fc9272b2366d6b5944e1c1a9ecf568ff89f95a30",
                "report_id": "GEOMETRY-99",
                "report_url": "https://issues.apache.org/jira/browse/GEOMETRY-99",
                "issue_title": "[GEOMETRY-99] Inconsistent equals and hashCode - ASF JIRA",
                "issue_description": "\nThe following classes have inconsistent behavior between equals and hashCode in regard to +0.0 and -0.0:\n\nEpsilonDoublePrecisionContext\nVector1D\nVector2D\nVector2D\nSphericalCoordinates\nPolarCoordinates\nAffineTransformMatrix2D\nAffineTransformMatrix3D\nAxisAngleSequence\n\nThis inconsistency comes from the use of == or Precision.equals to compare doubles in the equals method (which consider +0.0 and -0.0 to be equal) and Double.hashCode in the hashCode method (which returns different hash codes for +0.0 and -0.0). Hence, instances could be considered equal but have different hash codes.\nWe should standardize on the use of Double.compare in equals and Double.hashCode in hashCode.\n"
            }
        }
    },
    "MGpg": {
        "owner_repo": "apache/maven-gpg-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1169a69fcef6204ef9f29a7a3ea50f97fe593aa6",
                "commit_sha_fixed": "cd0f6d394d5ca0cc6bca77928809953dbb0e736b",
                "report_id": "MGPG-78",
                "report_url": "https://issues.apache.org/jira/browse/MGPG-78",
                "issue_title": "[MGPG-78] gpg version parsing failure on Windows - ASF JIRA",
                "issue_description": "\nfound during 3.0.0 release vote: https://lists.apache.org/thread.html/rcab83b862f15ca276aab3fc61cd4192e1a67a35a2a6ce7ad4c7994b1%40%3Cdev.maven.apache.org%3E\n\nCaused by: java.lang.IllegalArgumentException: Can't parse version of\r\ngpg (GnuPG) 2.0.26 (Gpg4win 2.2.3)\r\n    at org.apache.maven.plugins.gpg.GpgVersion.compareTo(GpgVersion.java:60)\r\n    at org.apache.maven.plugins.gpg.GpgVersion.isBefore(GpgVersion.java:101)\r\n    at org.apache.maven.plugins.gpg.GpgSigner.generateSignatureForFile(GpgSigner.java:89)\r\n    at org.apache.maven.plugins.gpg.AbstractGpgSigner.generateSignatureForArtifact(AbstractGpgSigner.java:203)\r\n    at org.apache.maven.plugins.gpg.GpgSignAttachedMojo.execute(GpgSignAttachedMojo.java:178)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)\n\nThe version on the command line:\n\n$ gpg --version\r\ngpg (GnuPG) 2.0.26 (Gpg4win 2.2.3)\r\nlibgcrypt 1.6.2\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\n [show/hide original text] \n\n"
            }
        }
    },
    "Text": {
        "owner_repo": "apache/commons-text",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b11451b26f5145000c71c2191aa306e911e6f12c",
                "commit_sha_fixed": "fe20a173e01a0d73e75d0907fed3a371d34d0f8b",
                "report_id": "TEXT-76",
                "report_url": "https://issues.apache.org/jira/browse/TEXT-76",
                "issue_title": "[TEXT-76] Jaro Winkler implementation is not correct - ASF JIRA",
                "issue_description": "\nUsing 3.5 commons-lang the following call return a distance of 1\nStringUtils.getJaroWinklerDistance(\u201c/opt/software1\u201d,  \u201c/opt/software2\u201d)\nJaro Winkler says that distance of 1 means equal string which is not the case here.\n"
            },
            "2": {
                "commit_sha_buggy": "c71a5cd470d937e270361cf2a379b0f4c3baecc4",
                "commit_sha_fixed": "3f5dfd4b1cc24fa31446a9ea5821cf267375e552",
                "report_id": "TEXT-88",
                "report_url": "https://issues.apache.org/jira/browse/TEXT-88",
                "issue_title": "[TEXT-88] WordUtils.capitalizeFully behaves in a counterintuitive manner with empty delimiter array. - ASF JIRA",
                "issue_description": "\nAs discussed in TEXT-85, it seems that \n\nWordUtils.capitalizeFully(\"i am fine\", new char[]{}) // --> i am fine\n\n\nBoth Sebb and Arun think that this is odd and that the letter \"i\" should have been capitalized resulting in the output I am fine\n"
            },
            "4": {
                "commit_sha_buggy": "804e4599bd63e4bb14c905613711eac8829e54fb",
                "commit_sha_fixed": "c9f92a02f8c0ddfc8e8f30fadf2ac932072ae284",
                "report_id": "TEXT-100",
                "report_url": "https://issues.apache.org/jira/browse/TEXT-100",
                "issue_title": "[TEXT-100] StringEscapeUtils#UnEscapeJson doesn't recognize escape signs correctly - ASF JIRA",
                "issue_description": "\nAs shown in org.apache.commons.text.StringEscapeUtils#testUnescapeJsonFoundBug JSON escape signs do not get treated correctly.\n"
            },
            "5": {
                "commit_sha_buggy": "e55d0ac1c17a7fd71dbb4f65034c7b739be6a35a",
                "commit_sha_fixed": "1596501e610bca7955969bb94fe6c6bad397e361",
                "report_id": "TEXT-106",
                "report_url": "https://issues.apache.org/jira/browse/TEXT-106",
                "issue_title": "[TEXT-106] Exception thrown in ExtendedMessageFormat using quotes with custom registry - ASF JIRA",
                "issue_description": "\nAn exception is thrown when a quote is used just before end brace of format element definition when a custom registry is used.\nThis exception is not thrown when a blank space is added before the end brace.\n\n\r\npublic static void main(String[] args)\r\n{\r\n\tString pattern           = \"TEST: {0,choice,0#0|0<'1'}\";\r\n\tString patternWorkaround = \"TEST: {0,choice,0#0|0<'1' }\"; // a space after quote\r\n\r\n\t// Works fine\r\n\tMessageFormat format0 = new MessageFormat(pattern);\r\n\r\n\tSystem.out.println(format0.format(new Integer[] { 0 })); // \"TEST: 0\"\r\n\tSystem.out.println(format0.format(new Integer[] { 1 })); // \"TEST: 1\"\r\n\r\n\t// Works fine\r\n\tExtendedMessageFormat format1 = new ExtendedMessageFormat(pattern);\r\n\r\n\tSystem.out.println(format1.format(new Integer[] { 0 })); // \"TEST: 0\"\r\n\tSystem.out.println(format1.format(new Integer[] { 1 })); // \"TEST: 1\"\r\n\r\n\t// Works fine\r\n\tExtendedMessageFormat format2 = new ExtendedMessageFormat(patternWorkaround, new HashMap<String, FormatFactory>());\r\n\r\n\tSystem.out.println(format2.format(new Integer[] { 0 })); // \"TEST: 0\"\r\n\tSystem.out.println(format2.format(new Integer[] { 1 })); // \"TEST: 1 \"\r\n\r\n\t// Doesn't work\r\n\tExtendedMessageFormat format3 = new ExtendedMessageFormat(pattern, new HashMap<String, FormatFactory>());\r\n\r\n\tSystem.out.println(format3.format(new Integer[] { 0 })); // Exception in thread \"main\" java.lang.IllegalArgumentException: Unterminated format element at position 9\r\n\tSystem.out.println(format3.format(new Integer[] { 1 }));\r\n}\r\n\n\nExpected behavior: This exception should not be thrown.\n"
            }
        }
    },
    "Tika_core": {
        "owner_repo": "apache/tika",
        "bug_infos": {
            "4": {
                "commit_sha_buggy": "9ba3b5852ece3f19bcc3925d871a327b3501bbf3",
                "commit_sha_fixed": "ed34e70f0ba7fc01769bed8dbf7f65a1a9058ec0",
                "report_id": "TIKA-453",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-453",
                "issue_title": "[TIKA-453] Conflicting Estonian language profile code to ISO 639 - ASF JIRA",
                "issue_description": "\nLanguageIdentifier class adds Estonian language profile with code 'ee' instead of 'et' that should be correct by ISO 639. \nAlso the comment is missing after adding profile.\n"
            },
            "6": {
                "commit_sha_buggy": "3e08e27a6c3f8ac45275823b9120996a416c811d",
                "commit_sha_fixed": "8a5f28845f28f5a5e2debdfc0fa3f89c738cd2fe",
                "report_id": "TIKA-394",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-394",
                "issue_title": "[TIKA-394] Missing spaces on html parsing - ASF JIRA",
                "issue_description": "\nOn parsing such html code:\ntext<p>more<br>yet<select><option>city1<option>city2</select>\nresulting text is:\ntextmore\nyetcity1city2\nBut must be:\ntext\nmore\nyet city1 city2\nCode sample:\nimport java.io.*;\nimport org.apache.tika.metadata.*;\nimport org.apache.tika.parser.*;\npublic class test {\n   public static void main(String[] args) throws Exception {\n      Metadata metadata = new Metadata();\n      metadata.set(Metadata.CONTENT_TYPE, \"text/html\");\n      String content = \"text<p>more<br>yet<select><option>city1<option>city2</select>\";\n      InputStream in = new ByteArrayInputStream(content.getBytes(\"UTF-8\"));\n      AutoDetectParser parser = new AutoDetectParser();\n      Reader reader = new ParsingReader(parser, in, metadata, new ParseContext());\n      char[] buf = new char[10000];\n      int len;\n      StringBuffer text = new StringBuffer();\n      while((len = reader.read(buf)) > 0) \n{\n         text.append(buf, 0, len);\n      }\n      System.out.print(text);\n   }\n}\n"
            },
            "9": {
                "commit_sha_buggy": "e3a183120a7638ccd2093f62a47730e9636ec047",
                "commit_sha_fixed": "48b28a6d31c3afb741ffa5ace4c0c4738101b539",
                "report_id": "TIKA-822",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-822",
                "issue_title": "[TIKA-822] MediaType fails to parse charset that has quoted value - ASF JIRA",
                "issue_description": "\nIf a mime type is\ntext/html; charset=\"UTF-8\"\nthe value is incorrectly \"UTF-8\" not UTF-8\npatch available at https://github.com/osi/tika/commit/b77814874ebff8f412ebb2f2adc52c6465d603c4\ni have a CLA on file.\n"
            },
            "11": {
                "commit_sha_buggy": "eb6207836f8eb7a3353aa6088785d22fd3cd4f64",
                "commit_sha_fixed": "1f16bf8e5ef4848d9d2e91e1566c1cfb5617f311",
                "report_id": "TIKA-866",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-866",
                "issue_title": "[TIKA-866] Invalid configuration file causes OutOfMemoryException - ASF JIRA",
                "issue_description": "\nI tried to override a built-in parser according to the method described in issue TIKA-527. During testing this approach I used an incomplete configuration file (as far as I learned from a discussion on the mailing list also mimetypes and a detector should be specified):\n$ cat tika-config.xml\n<properties>\n<parsers>\n<parser class=\"org.apache.tika.parser.DefaultParser\"/>\n</parsers>\n</properties>\nUsing this configuration file causes an OutOfMemoryException:\n$ java -Dtika.config=tika-config.xml -jar tika-app-1.0.jar --list-parsers\nException in thread \"main\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n        at java.util.Arrays.copyOfRange(Arrays.java:3209)\n        at java.lang.String.<init>(String.java:216)\n        at java.lang.StringBuilder.toString(StringBuilder.java:430)\n        at org.apache.tika.mime.MediaType.toString(MediaType.java:237)\n        at org.apache.tika.detect.MagicDetector.<init>(MagicDetector.java:142)\n        at org.apache.tika.mime.MimeTypesReader.readMatch(MimeTypesReader.java:254)\n        at org.apache.tika.mime.MimeTypesReader.readMatches(MimeTypesReader.java:202)\n        at org.apache.tika.mime.MimeTypesReader.readMagic(MimeTypesReader.java:186)\n        at org.apache.tika.mime.MimeTypesReader.readMimeType(MimeTypesReader.java:152)\n        at org.apache.tika.mime.MimeTypesReader.read(MimeTypesReader.java:124)\n        at org.apache.tika.mime.MimeTypesReader.read(MimeTypesReader.java:107)\n        at org.apache.tika.mime.MimeTypesFactory.create(MimeTypesFactory.java:63)\n        at org.apache.tika.mime.MimeTypesFactory.create(MimeTypesFactory.java:91)\n        at org.apache.tika.mime.MimeTypesFactory.create(MimeTypesFactory.java:147)\n        at org.apache.tika.mime.MimeTypes.getDefaultMimeTypes(MimeTypes.java:455)\n        at org.apache.tika.config.TikaConfig.typesFromDomElement(TikaConfig.java:273)\n        at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:161)\n        at org.apache.tika.config.TikaConfig.getDefaultConfig(TikaConfig.java:237)\n        at org.apache.tika.mime.MediaTypeRegistry.getDefaultRegistry(MediaTypeRegistry.java:42)\n        at org.apache.tika.parser.DefaultParser.<init>(DefaultParser.java:52)\n        at sun.reflect.GeneratedConstructorAccessor4.newInstance(Unknown Source)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n        at java.lang.Class.newInstance0(Class.java:355)\n        at java.lang.Class.newInstance(Class.java:308)\n        at org.apache.tika.config.TikaConfig.parserFromDomElement(TikaConfig.java:288)\n        at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:162)\n        at org.apache.tika.config.TikaConfig.getDefaultConfig(TikaConfig.java:237)\n        at org.apache.tika.mime.MediaTypeRegistry.getDefaultRegistry(MediaTypeRegistry.java:42)\n        at org.apache.tika.parser.DefaultParser.<init>(DefaultParser.java:52)\n        at sun.reflect.GeneratedConstructorAccessor4.newInstance(Unknown Source)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) \nExpected behavior: If the configuration file is not valid, and appropriate exception should be produced.\n"
            },
            "17": {
                "commit_sha_buggy": "aca3dfa1f086d2f6cbd6ebfdccfa9333ab1fbcf1",
                "commit_sha_fixed": "2697354c7e50b9b06c44441accd09f3cff594c6e",
                "report_id": "TIKA-995",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-995",
                "issue_title": "[TIKA-995] XHTMLContentHandler doesn't pass attributes of body element - ASF JIRA",
                "issue_description": "\nXHTMLContentHandler.startElement() uses lazyHead() for the body element because it's defined in the AUTO Set. As a consequence, attributes of the body element are not passed to downstream content handlers. \n"
            },
            "20": {
                "commit_sha_buggy": "63351d11c1778d66826693eb7a97114ab7342e78",
                "commit_sha_fixed": "f43de5a24b56cdd6a3c5abc3e5a38e2410089d69",
                "report_id": "TIKA-1782",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1782",
                "issue_title": "[TIKA-1782] XHTMLContentHandler doesn't pass attributes of html element - ASF JIRA",
                "issue_description": "\nXHTMLContentHandler.startElement() uses lazyHead() for the html element because it's defined in the AUTO Set. As a consequence, attributes of the html element are not passed to downstream content handlers.\n"
            },
            "21": {
                "commit_sha_buggy": "29af90d132752b20e252f2aa275129e343082771",
                "commit_sha_fixed": "62697affaf3fb93c5f667f76fe54deb78003ef4e",
                "report_id": "TIKA-209",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-209",
                "issue_title": "[TIKA-209] Language detection is weak. - ASF JIRA",
                "issue_description": "\nin org.apache.tika.utils.Utils the getUTF8Reader method assigns a language determination without checking the confidence rating from ICU's CharsetDetector.\nPlease add a configurable level (0-100);\nif (language != null && match.getConfidence() > THRESHOLD) {\n  metadata.set(Metadata.CONTENT_LANGUAGE, match.getLanguage());\n  metadata.set(Metadata.LANGUAGE, match.getLanguage());\n}\nObviously using charset to imply language is generally weak but it would be sufficient if the confidence threshold was controlled. Today, the text \"hello\" is tagged as French, for example. \n"
            },
            "22": {
                "commit_sha_buggy": "04d1fb7cc895e054941280e991ef129cde11ab8b",
                "commit_sha_fixed": "4c5599b6694a31e8ce84a1a0d88100827d98490e",
                "report_id": "TIKA-698",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-698",
                "issue_title": "[TIKA-698] \"Invalid UTF-16 surrogate detected:\" parsing PowerPoint 97-2003 - ASF JIRA",
                "issue_description": "\nException when parsing this MS PowerPoint file :  http://jeanferrette.free.fr/MS8.ppt\njava.io.IOException: Substitut UTF-16 non valide d\u00e9tect\u00e9 : db00 bfff ?\n                at com.sun.org.apache.xml.internal.serializer.ToStream.endElement(ToStream.java:2060)\n                at com.sun.org.apache.xalan.internal.xsltc.trax.TransformerHandlerImpl.endElement(TransformerHandlerImpl.java:273)\n                at org.apache.tika.sax.TeeContentHandler.endElement(TeeContentHandler.java:94)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.SecureContentHandler.endElement(SecureContentHandler.java:215)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.XHTMLContentHandler.lazyEndHead(XHTMLContentHandler.java:169)\n                at org.apache.tika.sax.XHTMLContentHandler.startElement(XHTMLContentHandler.java:234)\n                at org.apache.tika.sax.XHTMLContentHandler.startElement(XHTMLContentHandler.java:271)\n                at org.apache.tika.sax.XHTMLContentHandler.element(XHTMLContentHandler.java:308)\n                at org.apache.tika.parser.microsoft.HSLFExtractor.parse(HSLFExtractor.java:41)\n                at org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:201)\n                at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)\n                at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)\n                at org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:129)\n [...]\nParsing this file works fine with tika 0.4.\n"
            },
            "23": {
                "commit_sha_buggy": "57a99d012bc43d04ded8e7d88e056680542b405f",
                "commit_sha_fixed": "edb6775bf356eaaf656730589cc3340a15b602ea",
                "report_id": "TIKA-828",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-828",
                "issue_title": "[TIKA-828] TaggedIOException can be passed non Serializable objects - ASF JIRA",
                "issue_description": "\nTaggedIOException can contain tags. It's used to contain TaggedInputStream which isn't serializable.\nThis can cause the ForkServer to fail when trying to report issues. See TIKA-827\n2 solutions\n\nmake the tag transient\nreplace the InputStream instance in the tag by a serializable object specific to the input stream.\n\nI opt for the first one as I really don't think we need more complexity\n"
            },
            "24": {
                "commit_sha_buggy": "bc0b1f7f7e0b854a119779fc3f806e0d9490c08a",
                "commit_sha_fixed": "b2821d921ac4cfd3be468e8bea9123f5cb627cbf",
                "report_id": "TIKA-1928",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1928",
                "issue_title": "[TIKA-1928] Filename detection misses when a # is in a filename - ASF JIRA",
                "issue_description": "\nIf there is a pound character in a filename it will be detected as application/octet-stream instead of the proper type that is detected without the filename containing the pound.\n\nMetadata metadata = new Metadata();\nTika tika = new Tika();\nmetadata.add(Metadata.RESOURCE_NAME_KEY, \"test#.pdf\");\n// tika uses NameDetector if first parameter == null\nSystem.out.println(tika.detect(null, metadata));\n// prints application/octet-stream instead of application/pdf\n\n\nTested for application/pdf and application/xml.\n"
            },
            "25": {
                "commit_sha_buggy": "d59353ea2ebeb4f0ea81a49bdd79810402f43416",
                "commit_sha_fixed": "7bd88f6eb2eb6035dd20f54364f8eeac7e2df0fd",
                "report_id": "TIKA-2677",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-2677",
                "issue_title": "[TIKA-2677] ConcurrentModificationException in org.apache.tika.mime.MediaTypeRegistry.getAliases - ASF JIRA",
                "issue_description": "\nWhen using Tika parser on multiple threads and calling\u00a0MediaTypeRegistry.getAliases, we get\u00a0ConcurrentModificationException:\n\njava.util.ConcurrentModificationException\r\n at java.util.HashMap$HashIterator.nextNode(HashMap.java:1429)\r\n at java.util.HashMap$EntryIterator.next(HashMap.java:1463)\r\n at java.util.HashMap$EntryIterator.next(HashMap.java:1461)\r\n at org.apache.tika.mime.MediaTypeRegistry.getAliases(MediaTypeRegistry.java:78)\n\nIt will go away, if we use ConcurrentMap here:\nhttps://github.com/apache/tika/blob/master/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java#L49\n\u00a0\nHere is code snippet to recreate the problem:\n\n\r\nstatic boolean stop = false;\r\npublic static void main(String[] args) throws MimeTypeException {\r\n MimeTypes mimeTypes = MimeTypes.getDefaultMimeTypes();\r\n Executors.newSingleThreadExecutor().execute(() -> {\r\n try {\r\n for (int i=0; i < 1000 && !stop; i++) {\r\n System.out.println(mimeTypes.forName(\"abc\" + i + \"/abc\"));\r\n }\r\n } catch (MimeTypeException e) {\r\n e.printStackTrace();\r\n }\r\n });\r\n for (int i=0; i < 1000 && !stop; i++) {\r\n try {\r\n System.out.println(mimeTypes.getMediaTypeRegistry().getAliases(MediaType.APPLICATION_ZIP));\r\n } catch (ConcurrentModificationException ex) {\r\n stop = true;\r\n ex.printStackTrace();\r\n }\r\n }\r\n}\n\n\u00a0\n"
            },
            "26": {
                "commit_sha_buggy": "63e6f31f3893707310b843b8f331a9e8dd494f12",
                "commit_sha_fixed": "0f5c16e57f85cc98ced6b52e52b1e84d53b66ae6",
                "report_id": "TIKA-2955",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-2955",
                "issue_title": "[TIKA-2955] PDF parsing to XHTML results in tika attempting to write invalid HTML characters. - ASF JIRA",
                "issue_description": "\nHi, I am trying to parse: 314.pdf\nwhat is happening when I try to convert it to XHTML is my XML parser fails because:\n\n\r\n14:35:12.876 [main] ERROR com.funnelback.common.filter.TikaFilterProvider - Unable to filter stream with document type '.pdf'\r\norg.xml.sax.SAXException: net.sf.saxon.trans.XPathException: Illegal HTML character: decimal 147\r\n at net.sf.saxon.event.ReceivingContentHandler.endElement(ReceivingContentHandler.java:538) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.SecureContentHandler.endElement(SecureContentHandler.java:256) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.SafeContentHandler.endElement(SafeContentHandler.java:274) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.sax.XHTMLContentHandler.endDocument(XHTMLContentHandler.java:229) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.parser.pdf.AbstractPDF2XHTML.endDocument(AbstractPDF2XHTML.java:556) ~[tika-parsers-1.19.1.jar:1.19.1]\r\n at org.apache.pdfbox.text.PDFTextStripper.writeText(PDFTextStripper.java:267) ~[pdfbox-2.0.12.jar:2.0.12]\r\n at org.apache.tika.parser.pdf.PDF2XHTML.process(PDF2XHTML.java:117) ~[tika-parsers-1.19.1.jar:1.19.1]\r\n at org.apache.tika.parser.pdf.PDFParser.parse(PDFParser.java:172) ~[tika-parsers-1.19.1.jar:1.19.1]\r\n at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:280) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:280) ~[tika-core-1.19.1.jar:1.19.1]\r\n at org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:143) ~[tika-core-1.19.1.jar:1.19.1]\r\n at \r\n[removed section of trace]\r\nCaused by: net.sf.saxon.trans.XPathException: Illegal HTML character: decimal 147\r\n at net.sf.saxon.serialize.HTMLEmitter.writeEscape(HTMLEmitter.java:379) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.serialize.XMLEmitter.characters(XMLEmitter.java:662) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.serialize.HTMLEmitter.characters(HTMLEmitter.java:441) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.serialize.HTMLIndenter.characters(HTMLIndenter.java:216) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.ProxyReceiver.characters(ProxyReceiver.java:193) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.ProxyReceiver.characters(ProxyReceiver.java:193) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.ProxyReceiver.characters(ProxyReceiver.java:193) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.SequenceNormalizer.characters(SequenceNormalizer.java:183) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.ReceivingContentHandler.flush(ReceivingContentHandler.java:646) ~[Saxon-HE-9.9.0-2.jar:?]\r\n at net.sf.saxon.event.ReceivingContentHandler.endElement(ReceivingContentHandler.java:526) ~[Saxon-HE-9.9.0-2.jar:?]\r\n ... 43 more\r\n\n\nIt looks like tika is asking the XML library to handle chracter 147 ie 0x93 which is not allowed in HTML.\nThis saxon XML library is not happy with that, I think the default java one doesn't complain when given the invalid character though, however tika is probably wrong to write out that character when writing XHTML.\n"
            },
            "27": {
                "commit_sha_buggy": "476ed94e935b2dcc1aff977d95a95726a3f1ba7d",
                "commit_sha_fixed": "1798e80d12b57cc7706ff89dc8bb2c740ef09064",
                "report_id": "TIKA-3262",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-3262",
                "issue_title": "[TIKA-3262] Undo reverse ClassLoader sort in Tika 2.0.0 - ASF JIRA",
                "issue_description": "\nWe recently fixed the sort order of loaded classes to be: anything not tika before tika parsers, then in reverse alphabetical order.\nThe problem with this is that we need to have TesseractOCRParser sorted after ImageParser so that if Tesseract is installed, TesseractOCRParser will be called on, for example, .png files.\nOur branch_1x sort works because it did this despite the documentation.  So, let's flip the sort to be alphabetical order?  We'll keep non-Tika parsers first...\nLemme see if there are any other surprises before I commit this.\n"
            },
            "28": {
                "commit_sha_buggy": "15c83430df273aae65170d25ed95f4df62858de2",
                "commit_sha_fixed": "acf76a64d81eb9c901d92fe718c0f0ffb4d14ced",
                "report_id": "TIKA-121",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-121",
                "issue_title": "[TIKA-121] MimeType.clean method no longer exists as a capability - ASF JIRA",
                "issue_description": "\nFor some reason, in r591743 (http://svn.apache.org/viewvc?rev=591743&view=rev), the MimeType.clean functionality was removed and never replaced. This is a problem because that functionality was somewhat necessary as I'm running into the problem of trying to upgrade Nutch to tika-0.1-incubating and Nutch relied on MimeType.clean.\nI've been scratching my head trying to determine an appropriate workaround for the same capability within the tika-0.1-incubating code, but have yet to find one. This functionality needs to be replaced in some form or fashion, or, if someone knows of a simple way to achieve the same functionality, please let me know.\n"
            },
            "29": {
                "commit_sha_buggy": "ed7a1d1bda0d981359261c20e8617a73d7dc482b",
                "commit_sha_fixed": "98eb0b0ec46c8a826a8a76a52636d8cc617d3201",
                "report_id": "TIKA-483",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-483",
                "issue_title": "[TIKA-483] Empty file detected as text/plain - ASF JIRA",
                "issue_description": "\nOur current type detection code returns text/plain for an empty document. A more better return type would be application/octet-stream, to give higher level detectors like filename suffix hints more flexibility.\n"
            },
            "30": {
                "commit_sha_buggy": "9d5cf328f700e655a38cdf547fc86a273b854b78",
                "commit_sha_fixed": "9c9763a5ac67683553f155a33338bdf98e1a6937",
                "report_id": "TIKA-698",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-698",
                "issue_title": "[TIKA-698] \"Invalid UTF-16 surrogate detected:\" parsing PowerPoint 97-2003 - ASF JIRA",
                "issue_description": "\nException when parsing this MS PowerPoint file :  http://jeanferrette.free.fr/MS8.ppt\njava.io.IOException: Substitut UTF-16 non valide d\u00e9tect\u00e9 : db00 bfff ?\n                at com.sun.org.apache.xml.internal.serializer.ToStream.endElement(ToStream.java:2060)\n                at com.sun.org.apache.xalan.internal.xsltc.trax.TransformerHandlerImpl.endElement(TransformerHandlerImpl.java:273)\n                at org.apache.tika.sax.TeeContentHandler.endElement(TeeContentHandler.java:94)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.SecureContentHandler.endElement(SecureContentHandler.java:215)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.ContentHandlerDecorator.endElement(ContentHandlerDecorator.java:136)\n                at org.apache.tika.sax.XHTMLContentHandler.lazyEndHead(XHTMLContentHandler.java:169)\n                at org.apache.tika.sax.XHTMLContentHandler.startElement(XHTMLContentHandler.java:234)\n                at org.apache.tika.sax.XHTMLContentHandler.startElement(XHTMLContentHandler.java:271)\n                at org.apache.tika.sax.XHTMLContentHandler.element(XHTMLContentHandler.java:308)\n                at org.apache.tika.parser.microsoft.HSLFExtractor.parse(HSLFExtractor.java:41)\n                at org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:201)\n                at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)\n                at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)\n                at org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:129)\n [...]\nParsing this file works fine with tika 0.4.\n"
            },
            "31": {
                "commit_sha_buggy": "066f587584998f82e738496cd2906de8ffecb9b4",
                "commit_sha_fixed": "c7d7f66f8c9e389d8654a6a57f0e14040f2e9d51",
                "report_id": "TIKA-1145",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1145",
                "issue_title": "[TIKA-1145] classloaders issue loading resources when extending Tika - ASF JIRA",
                "issue_description": "\nI noticed that ServiceLoader is using different classloader when loading 'services' like Parsers, etc (java.net.FactoryURLClassLoader) than MimeTypesFactory (org.eclipse.jetty.webapp.WebAppClassLoader) when loading mime types definitions. As result - it works completely different:\nWhen jar with custom parser and custom-mimetypes.xml is added to solr.war - both resources are located and loaded (META-INF\\services\\org.apache.tika.parser.Parser and org\\apache\\tika\\mime\\custom-mimetypes.xml) and everything works fine.\nWhen jar with custom parser is in Solr core lib and configured in solrconfig.xml - only META-INF\\services\\org.apache.tika.parser.Parser is loaded, but custom-mimetypes.xml is ignored.\nMimeTypesFactory\u00a0ignores custom classLoader provided in TikaConfig and always using only context provided one:\nClassLoader cl = MimeTypesReader.class.getClassLoader();\n"
            },
            "32": {
                "commit_sha_buggy": "a852c4f55cc320087d4cfa300fca5ffb9c759918",
                "commit_sha_fixed": "22fc879bf987c2ab1fa24d68c10a97cb4797614e",
                "report_id": "TIKA-1146",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1146",
                "issue_title": "[TIKA-1146] MagicDetector don't work for all RFC882 message Types  - ASF JIRA",
                "issue_description": "\nI am trying to use Tika to extract metadata from eml's created via Novell Groupwise. By this I ran into  a problem with the dedection of \"message/rfc822\". The MagicDetector (working with the default tika-mimetypes.xml) compares the \"match\" values binary. RFC822 describes the header attributes are case independent (see http://www.ietf.org/rfc/rfc0822.txt 3.4.7). So MIME-Version is the same than Mime-Version.\n"
            },
            "33": {
                "commit_sha_buggy": "42cebedc5a415b5f9fe32de184ee6dc9e6fab9b9",
                "commit_sha_fixed": "e2293d302bc5f447563c5c6c93907b55bba6e91b",
                "report_id": "TIKA-1459",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1459",
                "issue_title": "[TIKA-1459] Fix write limit bug in BasicContentHandlerFactory for BodyContentHandler - ASF JIRA",
                "issue_description": "\nSmall bug in BasicContentHandlerFactory that does not properly set write limit to -1 when creating a BodyContentHandler.  The result is that BodyContentHandler falls back to default of 100k.  \nThank you, tilman, for your collaboration, without which I wouldn't have found this for a good while!\n"
            },
            "34": {
                "commit_sha_buggy": "5132638ec133b3176d8a49fa3458a32bf71ac738",
                "commit_sha_fixed": "b93a7d267f8d1899354c5e2b8c1c56651e50d99c",
                "report_id": "TIKA-1653",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1653",
                "issue_title": "[TIKA-1653] Tika config xml shouldn't read nested parser definitions as top level - ASF JIRA",
                "issue_description": "\nSpotted while looking at TIKA-1642, if you have some Tika config xml like:\n\n<properties>\n  <parsers>\n    <parser class=\"org.apache.tika.parser.ctakes.CTAKESParser\">\n       <parser class=\"org.apache.tika.parser.DefaultParser\"/>\n    </parser>\n  </parsers>\n</properties>\n\n\nThen because of the way that TikaConfig is fetching the elements, it will process the DefaultParser once as a child of CTakes, then a second time at the top level\n"
            },
            "35": {
                "commit_sha_buggy": "444dadd5eb090f6e2998507e444b2014905cb90f",
                "commit_sha_fixed": "761273f9e69c4a7595e50ccd6a2d9304c398d0b1",
                "report_id": "TIKA-1669",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1669",
                "issue_title": "[TIKA-1669] xpath node test ./node() should match all contained nodes - ASF JIRA",
                "issue_description": "\nPer: https://github.com/apache/tika/pull/52 and Wulf Berschin:\n\nfollowing the w3c spec the xpath node test ./node() should matches all contained nodes (types) but not attributes since attributes are no children. (=> Changes in NodeMatcher)\n\nSo \"/node()\" returns a superset of \"/*\". In XPathParser the latter lead to the construction of \"ChildMatcher(parse(xpath.substring(2)));\" but the first simply returned a \"NodeMatcher.INSTANCE\" what is wrong i.m.o.\n\n\n"
            },
            "36": {
                "commit_sha_buggy": "489ab93c70227da902774badcca54ebb8eeae533",
                "commit_sha_fixed": "fe841bc8760027eae3f9d0105238780815451346",
                "report_id": "TIKA-1835",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1835",
                "issue_title": "[TIKA-1835] LinkContentHandler skips iframe and rel tags - ASF JIRA",
                "issue_description": "\nAs simple as it gets, link and iframe tags were never implemented in LinkContentHandler. NUTCH-1233 kind of requires it.\n"
            },
            "37": {
                "commit_sha_buggy": "8eac1c551fe45d9191a1c5f011f9fdaad1d6c1d3",
                "commit_sha_fixed": "1c5e96cf617b231ce8d902fc86eca84edb9cafe7",
                "report_id": "TIKA-1937",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1937",
                "issue_title": "[TIKA-1937] LinkContentHandler skips script tags - ASF JIRA",
                "issue_description": "\nJust like in TIKA-1835, <script> tags are not collected by LinkContentHandler. The difference between <script> and the other tags is that <script> tags that do not contain a \"src\" attribute are not links.\n"
            },
            "38": {
                "commit_sha_buggy": "cadbc405519e5adbada1ddb6d2d4beff1f953072",
                "commit_sha_fixed": "6a398bd3f6245543091fd7c0e9e4facb34a26882",
                "report_id": "TIKA-1191",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1191",
                "issue_title": "[TIKA-1191] ForkParser / ClassLoaderProxy does not define package - ASF JIRA",
                "issue_description": "\nForkParser will throw an Exception in some cases : \norg.apache.tika.exception.TikaException: Invalid embedded resource\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.handleEmbeddedOfficeDoc(AbstractPOIFSExtractor.java:189)\n\tat org.apache.tika.parser.microsoft.WordExtractor.parse(WordExtractor.java:135)\n\tat org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:186)\n\tat org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:161)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tika.fork.ForkServer.call(ForkServer.java:144)\n\tat org.apache.tika.fork.ForkServer.processRequests(ForkServer.java:124)\n\tat org.apache.tika.fork.ForkServer.main(ForkServer.java:69)\nCaused by: java.lang.NullPointerException\n\tat org.apache.tika.mime.MimeTypesFactory.create(MimeTypesFactory.java:136)\n\tat org.apache.tika.mime.MimeTypes.getDefaultMimeTypes(MimeTypes.java:499)\n\tat org.apache.tika.config.TikaConfig.getDefaultMimeTypes(TikaConfig.java:60)\n\tat org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:169)\n\tat org.apache.tika.config.TikaConfig.getDefaultConfig(TikaConfig.java:268)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.getTikaConfig(AbstractPOIFSExtractor.java:72)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.getDetector(AbstractPOIFSExtractor.java:79)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.handleEmbeddedOfficeDoc(AbstractPOIFSExtractor.java:176)\n\t... 10 more\nA patch will follow\n"
            },
            "39": {
                "commit_sha_buggy": "cadbc405519e5adbada1ddb6d2d4beff1f953072",
                "commit_sha_fixed": "7f6072ca26dccf1d791c426d4c32068535ddae8a",
                "report_id": "TIKA-1191",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-1191",
                "issue_title": "[TIKA-1191] ForkParser / ClassLoaderProxy does not define package - ASF JIRA",
                "issue_description": "\nForkParser will throw an Exception in some cases : \norg.apache.tika.exception.TikaException: Invalid embedded resource\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.handleEmbeddedOfficeDoc(AbstractPOIFSExtractor.java:189)\n\tat org.apache.tika.parser.microsoft.WordExtractor.parse(WordExtractor.java:135)\n\tat org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:186)\n\tat org.apache.tika.parser.microsoft.OfficeParser.parse(OfficeParser.java:161)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tika.fork.ForkServer.call(ForkServer.java:144)\n\tat org.apache.tika.fork.ForkServer.processRequests(ForkServer.java:124)\n\tat org.apache.tika.fork.ForkServer.main(ForkServer.java:69)\nCaused by: java.lang.NullPointerException\n\tat org.apache.tika.mime.MimeTypesFactory.create(MimeTypesFactory.java:136)\n\tat org.apache.tika.mime.MimeTypes.getDefaultMimeTypes(MimeTypes.java:499)\n\tat org.apache.tika.config.TikaConfig.getDefaultMimeTypes(TikaConfig.java:60)\n\tat org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:169)\n\tat org.apache.tika.config.TikaConfig.getDefaultConfig(TikaConfig.java:268)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.getTikaConfig(AbstractPOIFSExtractor.java:72)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.getDetector(AbstractPOIFSExtractor.java:79)\n\tat org.apache.tika.parser.microsoft.AbstractPOIFSExtractor.handleEmbeddedOfficeDoc(AbstractPOIFSExtractor.java:176)\n\t... 10 more\nA patch will follow\n"
            }
        }
    },
    "Tika_app": {
        "owner_repo": "apache/tika",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bf24bc0a11daa83ab707c1576a5605609b35d786",
                "commit_sha_fixed": "8d38e36c861acdfbf6996c924f66e31bbfb01088",
                "report_id": "TIKA-920",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-920",
                "issue_title": "[TIKA-920] iWork Numbers sheetnames not being parsed into metadata - ASF JIRA",
                "issue_description": "\niWork Number's have individual sheetnames.  Currently only the first sheet is going extracted.\n"
            },
            "3": {
                "commit_sha_buggy": "2052fc98acca935fa065ffdca302bc84cfe60ac9",
                "commit_sha_fixed": "39a63cad3ad912f412f75a2dcdca400ab8e37ab6",
                "report_id": "TIKA-725",
                "report_url": "https://issues.apache.org/jira/browse/TIKA-725",
                "issue_title": "[TIKA-725] Empty title element makes Tika-generated HTML documents not open in Chromium - ASF JIRA",
                "issue_description": "\nCurrently when converting Excel sheets (both XLS and XLSX), Tika generates an empty title element as <title/> into the document HEAD section. This causes Chromium not to display the document contents.\nSwitching it to <title></title> fixes this.\n"
            }
        }
    },
    "Shiro_core": {
        "owner_repo": "apache/shiro",
        "bug_infos": {
            "37": {
                "commit_sha_buggy": "aef096afa4348fc70b74ea050ec7cf84992e1cd3",
                "commit_sha_fixed": "dc12c74199ca9f57e7f91d2563e8cb11ceed7dc1",
                "report_id": "SHIRO-156",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-156",
                "issue_title": "[SHIRO-156] SimpleAuthenticationInfo.merge does not merge principals if its internal principal collection is not mutable - ASF JIRA",
                "issue_description": "\nIn SimpleAuthenticationInfo.merge(AuthenticationInfo), there is the following code:\n\n        if (this.principals == null) {\n            this.principals = info.getPrincipals();\n        } else {\n            if (this.principals instanceof MutablePrincipalCollection) {\n                ((MutablePrincipalCollection) this.principals).addAll(info.getPrincipals());\n            } else {\n                this.principals = new SimplePrincipalCollection(this.principals);\n            }\n        }\n\n\nThe logic in the nested else block appears incorrect. If the current \"principals\" collection is not MutablePrincipalCollection, a new SimplePrincipalCollection, which is mutable, is constructed from it. However, it does not copy the principals from other.getPrincipals(), which by that point in the method is known to be non-null and non-empty, after it makes a mutable principal collection.\n"
            },
            "40": {
                "commit_sha_buggy": "afd40920397bc6d85753e6c03c050d370c01cac2",
                "commit_sha_fixed": "8ba8fa115d8d2f18ae64e62f5c10e374c3aee677",
                "report_id": "SHIRO-163",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-163",
                "issue_title": "[SHIRO-163] ModularRealmAuthorizer.setRealms needs to call applyRolePermissionResolverToRealms - ASF JIRA",
                "issue_description": "\nWhen updating the list of realms in ModularRealmAuthorizer.setRealms()  applyRolePermissionResolverToRealms() was not called\nSo this worked if you didn't change your realms.\nAttached patch contains single line fix, and an updated test\n"
            },
            "46": {
                "commit_sha_buggy": "c9a3ff4f843ad87c9efa303ecf8823ccbd07698f",
                "commit_sha_fixed": "776a0a9ab18f5a49de6a0635ac6c6093bfaf876b",
                "report_id": "SHIRO-182",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-182",
                "issue_title": "[SHIRO-182] SimpleSession cannot be deserialized - ASF JIRA",
                "issue_description": "\norg.apache.shiro.session.mgt.SimpleSession fails deserialization with the following error:\n\tat java.io.ObjectInputStream$BlockDataInputStream.readByte(ObjectInputStream.java:2666)\n\tat java.io.ObjectInputStream$BlockDataInputStream.readUTFChar(ObjectInputStream.java:3058)\n\tat java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:2955)\n\tat java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:2764)\n\tat java.io.ObjectInputStream.readUTF(ObjectInputStream.java:1032)\n\tat org.apache.shiro.session.mgt.SimpleSession.readObject(SimpleSession.java:481)\nThere is a problem with the way the 'expired' flag is managed. In writeObject the 'expired' flag is written if it's set:\nif (expired) {\n    out.writeBoolean(expired);\n}\nBut, in getAlteredFieldsBitMask, the bit in the bit mask is only set when the 'exprired' flag is not set:\nbitMask = !expired ? bitMask | EXPIRED_BIT_MASK : bitMask;\nA short test:\nSimpleSession session = new SimpleSession(\"localhost\");\n//  This doesn't work either\n// session.setExpired(true);\nByteArrayOutputStream serialized = new ByteArrayOutputStream();\nObjectOutputStream serializer = new ObjectOutputStream(serialized);\nserializer.writeObject(session);\nserializer.close();\nnew ObjectInputStream(new ByteArrayInputStream(serialized.toByteArray())).readObject();\n"
            },
            "52": {
                "commit_sha_buggy": "0b4151fe49da57c5f7bc855c0d137cce92fd7f6d",
                "commit_sha_fixed": "b45d8573680147c537e4b4e2caac0c6ba1d7b9aa",
                "report_id": "SHIRO-199",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-199",
                "issue_title": "[SHIRO-199] Session Validation thread does not notify SessionListeners or cleans orphans - ASF JIRA",
                "issue_description": "\nThe session validation thread does indeed validate sessions, but we need to verify via a test case that it also cleans up any stopped or expired orphans that may exist as well.\n"
            },
            "98": {
                "commit_sha_buggy": "cb23be1115b5171b2db0b6fc5d5b3f98fa2b1d80",
                "commit_sha_fixed": "604933f08ef6d92dddee422c13eaa175214e858f",
                "report_id": "SHIRO-368",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-368",
                "issue_title": "[SHIRO-368] DomainPermission(string, string) constructor sets targets to the same value as actions - ASF JIRA",
                "issue_description": "\nThe DomainPermission(string, string) constructor incorrectly sets the 'targets' field to the value supplied for 'actions':\n055        public DomainPermission(String actions, String targets) \n{\n056            this.domain = getDomain(getClass());\n057            this.actions = StringUtils.splitToSet(actions, SUBPART_DIVIDER_TOKEN);\n058            this.targets = StringUtils.splitToSet(actions, SUBPART_DIVIDER_TOKEN);\n059            encodeParts(this.domain, actions, targets);\n060        }\n\n            "
            },
            "144": {
                "commit_sha_buggy": "64955340c7f361c529cde7c06d7831bb22d8580f",
                "commit_sha_fixed": "63f2891d48a37c7261c4f7eba7ab0ae5e17cb23a",
                "report_id": "SHIRO-577",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-577",
                "issue_title": "[SHIRO-577] Regression - Unable to set custom SessionValidationScheduler - ASF JIRA",
                "issue_description": "\nThis was introduced by SHIRO-443, while making initialization of the sessionValidationScheulder thread safe.\nReported by user on mailing list:\nhttp://shiro-user.582556.n2.nabble.com/Shiro-443-prevents-custom-Session-Validation-Scheduler-td7581185.html\n"
            },
            "176": {
                "commit_sha_buggy": "89909102182231ce74f66af2ccf8f8fa8e953975",
                "commit_sha_fixed": "49e3132fae55eaa92c9b4c9e0c6cff27c0fb1125",
                "report_id": "SHIRO-660",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-660",
                "issue_title": "[SHIRO-660] Bug in FirstSuccessfulStrategy - ASF JIRA",
                "issue_description": "\nThe '!' lost in the process of migration from 1.3.x to 1.4.0.\n"
            },
            "181": {
                "commit_sha_buggy": "6891aaf74e0b61296e4c47439bf333ada7b0032e",
                "commit_sha_fixed": "d7d33bfbd0a1d3f41b288d1ae8bf8f6fefe35022",
                "report_id": "SHIRO-685",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-685",
                "issue_title": "[SHIRO-685] Potential NullPointerException if PermissionResolver return null/empty string - ASF JIRA",
                "issue_description": "\nReported via email on a private list\nEmail contents:\n\u00a0 When judging whether a person has permission or not, if null or \"\"\nin the permissionSet, it throws new Illegal ArgumentException (\"\nWildcard string cannot be null or empty. Make sure permission strings\nare properly formatted \"). but if null or \"\" in the roleSet, it's no\nproblem\n\u00a0 so i suggest yours to adding a judgement (I'm sorry that I had\ncreate a new file in github because I can't find a page to submit\nissues. I'm sorry for the trouble)\n\u00a0 Here is the code(Code\naddress:org.apache.shiro.realm.AuthorizingRealm, method:private\nCollection<Permission> resolvePermissions(Collection<String>\nstringPerms)):\n\u00a0 --------------------------------------The original\ncode\uff1a--------------------------------------\n\n\r\n\u00a0 private Collection<Permission> resolvePermissions(Collection<String>\r\nstringPerms)\r\n\u00a0 {\r\n\u00a0 \u00a0 Collection<Permission> perms = Collections.emptySet();\r\n\u00a0 \u00a0 PermissionResolver resolver = getPermissionResolver();\r\n\u00a0 \u00a0 if ((resolver != null) && (!CollectionUtils.isEmpty(stringPerms)))\r\n\u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 perms = new LinkedHashSet(stringPerms.size());\r\n\u00a0 \u00a0 \u00a0 for (String strPermission : stringPerms)\r\n\u00a0 \u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 \u00a0 Permission permission = resolver.resolvePermission(strPermission);\r\n\u00a0 \u00a0 \u00a0 \u00a0 perms.add(permission);\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 \u00a0 return perms;\r\n\u00a0 }\r\n\n\n\u00a0 --------------------------------------my code1(I suggest this\nway):--------------------------------------\n\n\r\n\u00a0 private Collection<Permission> resolvePermissions(Collection<String>\r\nstringPerms)\r\n\u00a0 {\r\n\u00a0 \u00a0 Collection<Permission> perms = Collections.emptySet();\r\n\u00a0 \u00a0 PermissionResolver resolver = getPermissionResolver();\r\n\u00a0 \u00a0 if ((resolver != null) && (!CollectionUtils.isEmpty(stringPerms)))\r\n\u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 perms = new LinkedHashSet(stringPerms.size());\r\n\u00a0 \u00a0 \u00a0 for (String strPermission : stringPerms)\r\n\u00a0 \u00a0 \u00a0 {\r\n\u00a0 \u00a0 //\u5bf9\u6570\u636e\u5e93\u4e2d\u7684permission\u8fdb\u884c\u5224\u65ad,\u56e0\u4e3aWildcardPermission\u4e2d\u7684setParts\u91ccStringUtils.clean(wildcardString);\u4f1a\u628a\"\"\u8f6c\u4e3anull\r\n\u00a0 \u00a0 \u00a0if(StringUtils.isBlank(strPermission))\r\n\u00a0 \u00a0 \u00a0continue;\r\n\u00a0 \u00a0 \u00a0 \u00a0 Permission permission = resolver.resolvePermission(strPermission);\r\n\u00a0 \u00a0 \u00a0 \u00a0 perms.add(permission);\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 \u00a0 return perms;\r\n\u00a0 }\r\n\n\n\u00a0 --------------------------------------or my\ncode2--------------------------------------\n\n\r\n\u00a0 private Collection<Permission> resolvePermissions(Collection<String>\r\nstringPerms)\r\n\u00a0 {\r\n\u00a0 \u00a0 Collection<Permission> perms = Collections.emptySet();\r\n\u00a0 \u00a0 PermissionResolver resolver = getPermissionResolver();\r\n\u00a0 \u00a0 //\u6b64\u5904\u8fdb\u884c\u5224\u65ad\uff0c\u5982\u679c\u6570\u636e\u5e93\u4e2d\u7684permission\u96c6\u5408set\u4e2d\u6709null\u5bf9\u8c61\uff0c\u5220\u6389\r\n\u00a0 \u00a0 Collection<String> newStrPerms = new HashSet<String>();\r\n\u00a0 \u00a0 for(String permission : stringPerms)\r\n\u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 if(StringUtils.isBlank(permission))\r\n\u00a0 \u00a0 \u00a0 \u00a0 newStrPerms.add(permission);\r\n\u00a0 \u00a0 }\r\n\u00a0 \u00a0 stringPerms = newStrPerms;\r\n\r\n\u00a0 \u00a0 if ((resolver != null) && (!CollectionUtils.isEmpty(stringPerms)))\r\n\u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 perms = new LinkedHashSet(stringPerms.size());\r\n\u00a0 \u00a0 \u00a0 for (String strPermission : stringPerms)\r\n\u00a0 \u00a0 \u00a0 {\r\n\u00a0 \u00a0 \u00a0 \u00a0 Permission permission = resolver.resolvePermission(strPermission);\r\n\u00a0 \u00a0 \u00a0 \u00a0 perms.add(permission);\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 \u00a0 return perms;\r\n\u00a0 }\r\n\n\n"
            },
            "202": {
                "commit_sha_buggy": "dc380036ddabec2ab0a935e3ae5a9ff0936cc401",
                "commit_sha_fixed": "c7c9c57d69a180dce679c5f26d4f6db64b250a7e",
                "report_id": "SHIRO-747",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-747",
                "issue_title": "[SHIRO-747] FirstSuccessfulStrategy doesn't properly short circuit - ASF JIRA",
                "issue_description": "\nSHIRO-669 supposedly added a method to skip subsequent authentications if one had already succeeded. But it doesn't work; it conditions throwing the ShortCircuitIterationException in beforeAttempt() in part on the PrincipalCollection being empty, which it will (properly) not be if an authentication has succeeded. I believe the check should be that the it is not empty. Was this tested??\n"
            },
            "203": {
                "commit_sha_buggy": "cf986d47c5d7c5ff6c8c3b5126d6dcb0e9ed3014",
                "commit_sha_fixed": "dcd98954b60f57876ba564cb721be54010f27a9c",
                "report_id": "SHIRO-138",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-138",
                "issue_title": "[SHIRO-138] AbstractRememberMeManager attempts to process null/empty byte array - ASF JIRA",
                "issue_description": "\nAbstractRememberMeManager#getRememberedPrincipals will call the 'convertBytesToPrincipals' method even if the 'getRememberedSerializedIdentity' method call returns a null/empty byte array, resulting in the following stack trace.  The 'convertBytesToPrincipals' method should only be called with a non null/empty byte array.\n21419 [btpool0-1] WARN org.apache.shiro.mgt.DefaultSecurityManager -\nDelegate RememberMeManager instance of type\n[org.apache.shiro.web.WebRememberMeManager] threw an exception during\ngetRememberedPrincipals().\njava.lang.IllegalStateException: Unable to crypt bytes with cipher\n[javax.crypto.Cipher@1b951f2].\n       at\norg.apache.shiro.crypto.BlowfishCipher.crypt(BlowfishCipher.java:196)\n       at\norg.apache.shiro.crypto.BlowfishCipher.crypt(BlowfishCipher.java:221)\n       at\norg.apache.shiro.crypto.BlowfishCipher.decrypt(BlowfishCipher.java:143)\n       at\norg.apache.shiro.mgt.AbstractRememberMeManager.decrypt(AbstractRememberMeManager.java:571)\n       at\norg.apache.shiro.mgt.AbstractRememberMeManager.convertBytesToPrincipals(AbstractRememberMeManager.java:512)\n       at\norg.apache.shiro.mgt.AbstractRememberMeManager.getRememberedPrincipals(AbstractRememberMeManager.java:482)\n       at\norg.apache.shiro.mgt.DefaultSecurityManager.getRememberedIdentity(DefaultSecurityManager.java:586)\n       at\norg.apache.shiro.mgt.DefaultSecurityManager.resolvePrincipals(DefaultSecurityManager.java:475)\n       at\norg.apache.shiro.mgt.DefaultSecurityManager.createSubject(DefaultSecurityManager.java:352)\n       at\norg.apache.shiro.subject.Subject$Builder.buildSubject(Subject.java:751)\n       at\norg.apache.shiro.web.subject.WebSubject$Builder.buildWebSubject(WebSubject.java:95)\n       at\norg.apache.shiro.web.servlet.AbstractShiroFilter.bind(AbstractShiroFilter.java:215)\n       at\norg.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:302)\n       at\norg.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81)\n       at\norg.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1084)\n       at\ncom.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:51)\n       at\norg.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1084)\n       at\ncom.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:43)\n       at\norg.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1084)\n       at\ncom.google.appengine.tools.development.StaticFileFilter.doFilter(StaticFileFilter.java:121)\n       at\norg.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1084)\n       at\norg.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:360)\n       at\norg.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n       at\norg.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n       at\norg.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:712)\n       at\norg.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:405)\n       at\ncom.google.apphosting.utils.jetty.DevAppEngineWebAppContext.handle(DevAppEngineWebAppContext.java:70)\n       at\norg.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:139)\n       at\ncom.google.appengine.tools.development.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:352)\n       at\norg.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:139)\n       at org.mortbay.jetty.Server.handle(Server.java:313)\n       at\norg.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:506)\n       at\norg.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:830)\n       at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:514)\n       at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:211)\n       at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:381)\n       at\norg.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:396)\n       at\norg.mortbay.thread.BoundedThreadPool$PoolThread.run(BoundedThreadPool.java:442)\nCaused by: java.lang.IllegalArgumentException: Null input buffer\n       at javax.crypto.Cipher.doFinal(DashoA13*..)\n       at\norg.apache.shiro.crypto.BlowfishCipher.crypt(BlowfishCipher.java:193)\n       ... 37 more\n"
            }
        }
    },
    "Jena_core": {
        "owner_repo": "apache/jena",
        "bug_infos": {
            "2": {
                "commit_sha_buggy": "fc011bd8f3de500549da13ae4747f8eafd745204",
                "commit_sha_fixed": "44b1db2161bef957b147409c2c3e85c82c45da85",
                "report_id": "JENA-1293",
                "report_url": "https://issues.apache.org/jira/browse/JENA-1293",
                "issue_title": "[JENA-1293] Incorrect namespace - ASF JIRA",
                "issue_description": "\nThe namespace given for the vcard ontology (https://github.com/apache/jena/blob/master/jena-core/src/main/java/org/apache/jena/vocabulary/VCARD.java) is\nhttp://www.w3.org/2001/vcard-rdf/3.0#\nThis is deprecated: https://www.w3.org/Submission/vcard-rdf/#Name\n"
            }
        }
    },
    "Shiro_web": {
        "owner_repo": "apache/shiro",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ed8cf1702173302e0f64348ff5cce2141f8c5955",
                "commit_sha_fixed": "786f608fee8426362e8c20ce789e68c74761dbc0",
                "report_id": "SHIRO-190",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-190",
                "issue_title": "[SHIRO-190] PortFilter not accepting custom port - ASF JIRA",
                "issue_description": "\nThe following shiro.ini code no worky. Tomcat running on port 8080, with SSL running on 8443.\n\n[main]\nssl.port = 8443\n\n[urls]\n/admin/** = ssl\n\n\nAccess to http://host:8080/admin/foo redirects to https://host:8080/admin/foo, not https://host:8443/admin/foo.\n(It looks to me like PortFilter.onAccessDenied() appends the request.getServerPort() instead of the port. If I now read this correctly [might not, this is my first foray into Shiro source], it appears that you can only have SSL on 443 or 80, or else it must be on the same port as the request itself )\nAs far as I can tell, this occurs in all versions up until the current trunk.\n"
            },
            "3": {
                "commit_sha_buggy": "9a4de3bba6fa353c3b99f4f1eb127346cfd57e7c",
                "commit_sha_fixed": "96aa7f13532e563ac7e130f93709195cb6e85468",
                "report_id": "SHIRO-421",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-421",
                "issue_title": "[SHIRO-421] Unable to set long timeouts on HttpServletSession - ASF JIRA",
                "issue_description": "\nWhen I set the timeout on a org.apache.shiro.web.session.HttpServletSession to a large value (30 days == 2592000000 milliseconds) using the setTimeout(long) method and then read the timeout with the getTimeout() method, I get -1702967296. I would like to be able to do this in order to have a long-lasting session for users who select \"remember me\" when logging in to a web app.\nI think this may have something to do with the fact that the getTimeout() method is using integer multiplication before converting the javax.servlet.http.HttpSession's max inactive interval from an int to a long.\n"
            },
            "7": {
                "commit_sha_buggy": "9dfed7d2e361faf91ee8ade786e20cf072a38899",
                "commit_sha_fixed": "f782eb1084df73eff3e2ac0f9780cb4a4f429041",
                "report_id": "SHIRO-637",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-637",
                "issue_title": "[SHIRO-637] Refresh cached session in HTTP request after user logs out - ASF JIRA",
                "issue_description": "\nFor native session management in web environments, the ShiroHttpServletRequest caches calls to getSession() by saving a copy of the current subject's session to a member variable. This copy is never updated even when the subject logs out and the session is destroyed.\nWhen the session is accessed again after logout, an UnknownSessionException can be thrown because the session referenced in the request is not physically available anymore (this could be the cause for SHIRO-614).\nThe Shiro HTTP request therefore has to check the state of the cached session and refresh it if necessary, just as the original Jetty Request class does as well.\nPlease see the attached patch for a possible solution that Works For Me\u2122\n"
            },
            "8": {
                "commit_sha_buggy": "7abcba5d18d31a8eec08f76e6f221d64d74aaf66",
                "commit_sha_fixed": "fa34a92fa77943b67e29b9f1c5f30b17abc8915f",
                "report_id": "SHIRO-350",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-350",
                "issue_title": "[SHIRO-350] Creating a subject should not create a session - ASF JIRA",
                "issue_description": "\nWhen the following method is called:\npublic Subject getSubjectByLogin(final String login) \n{\n                PrincipalCollection principals = new SimplePrincipalCollection(login, REALM_NAME);\n                return new Subject.Builder().principals(principals).buildSubject();\n        }\n \nit throws an exception on buildSubject():\nCaused by: java.lang.IllegalArgumentException: SessionContext must be an HTTP compatible implementation.\n        at org.apache.shiro.web.session.mgt.ServletContainerSessionManager.createSession(ServletContainerSessionManager.java:103)\n        at org.apache.shiro.web.session.mgt.ServletContainerSessionManager.start(ServletContainerSessionManager.java:64)\n        at org.apache.shiro.mgt.SessionsSecurityManager.start(SessionsSecurityManager.java:121)\n        at org.apache.shiro.subject.support.DelegatingSubject.getSession(DelegatingSubject.java:336)\n        at org.apache.shiro.subject.support.DelegatingSubject.getSession(DelegatingSubject.java:314)\n        at org.apache.shiro.mgt.DefaultSubjectDAO.mergePrincipals(DefaultSubjectDAO.java:182)\n        at org.apache.shiro.mgt.DefaultSubjectDAO.saveToSession(DefaultSubjectDAO.java:163)\n        at org.apache.shiro.mgt.DefaultSubjectDAO.save(DefaultSubjectDAO.java:144)\n        at org.apache.shiro.mgt.DefaultSecurityManager.save(DefaultSecurityManager.java:383)\n        at org.apache.shiro.mgt.DefaultSecurityManager.createSubject(DefaultSecurityManager.java:350)\n        at org.apache.shiro.subject.Subject$Builder.buildSubject(Subject.java:846) \nIt tries to create a session but really should not.\nPlease see forum http://shiro-user.582556.n2.nabble.com/Subject-being-changed-td7370203.html for more details\nIn our app, in our backoffice area, we display lists of users and their roles, and this functionality is used in this way.\n"
            },
            "9": {
                "commit_sha_buggy": "c4ded8485d4907c98c9aa3a18e414ccb40a94ef7",
                "commit_sha_fixed": "0c48445a23303d1d8f830c40867debbe7fe0856a",
                "report_id": "SHIRO-374",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-374",
                "issue_title": "[SHIRO-374] Session Cookie will not be deleted on subjects logout - ASF JIRA",
                "issue_description": "\nOur web application initializes Shiro through an .ini file. Within the ini file we set the application cookie as following:\n\nCookie Management\ncookie                                                      =       org.apache.shiro.web.servlet.SimpleCookie\ncookie.name                                             =       AppCookie\ncookie.secure                                           =       true\ncookie.httpOnly                                         =       false\nsecurityManager.sessionManager.sessionIdCookie              =       $cookie \n\nShiro runs in \"native\" session mode. When an user enters the application the MyCookie and an JSESSIONID cookie will be created. The session will be authenticated on subject.login(...). Everything works fine until the user log out and we call subject.logout() method. \nIt seems that the JSESSIONID cookie will not be deleted. The value of the cookie stays always the same, while the value(id) of our AppCookie always change. The problem is that the user get the same session again if he log in again. That means that the settings the user made before logout already exists on relogin. \n"
            },
            "10": {
                "commit_sha_buggy": "ea7eb0029660ad437c0c820e3d8f35a49ad81c1e",
                "commit_sha_fixed": "09ebb5ca7f81525cb7da67f2fea29648dc9e3fbd",
                "report_id": "SHIRO-608",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-608",
                "issue_title": "[SHIRO-608] Use a ServiceLoader to discover WebEnvironments - ASF JIRA",
                "issue_description": "\nThe idea here is to lessen the touch points for frameworks when integrating with Shiro. A property file and a WebEnvironment implementation should be all that is needed. The WebEnvironment can then provide additional defaults or customizations specific to that framework.\nPR: https://github.com/apache/shiro/pull/53\n"
            },
            "11": {
                "commit_sha_buggy": "79e596d61e54658696e1cf8773e7ffcb03a91b2c",
                "commit_sha_fixed": "958a8dee1cb0bbb45397c02b3f944e81ceaa573c",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "SHIRO-351: applied fix from 1.2.x branch\n\ngit-svn-id: https://svn.apache.org/repos/asf/shiro/trunk@1468736 13f79535-47bb-0310-9956-ffa450edef68",
                "issue_description": "SHIRO-351: applied fix from 1.2.x branch\n\ngit-svn-id: https://svn.apache.org/repos/asf/shiro/trunk@1468736 13f79535-47bb-0310-9956-ffa450edef68"
            },
            "12": {
                "commit_sha_buggy": "7bf1f98e235ca3622e382a3b270d0694eced0ca4",
                "commit_sha_fixed": "4fa9a677b7c07011c473908c56104ca7f7e888b2",
                "report_id": "SHIRO-375",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-375",
                "issue_title": "[SHIRO-375] Basic authentication issue when using COLON character - ASF JIRA",
                "issue_description": "\nA user with a COLON character in his password cannot connect to a Shiro protected application when using Basic authentication. The problem is in the method that splits the username and password.\n"
            },
            "13": {
                "commit_sha_buggy": "69132cd691ed1b1d5e799747cd323e060f5eef53",
                "commit_sha_fixed": "2b2bdb12ab69feb6db44478a692e7fef497ba6c6",
                "report_id": "SHIRO-825",
                "report_url": "https://issues.apache.org/jira/browse/SHIRO-825",
                "issue_title": "[SHIRO-825] Trailing slash in URI results in \"IllegalArgumentException: There is no configured chain under the name/key\" - ASF JIRA",
                "issue_description": "\nWe recently attempted to upgrade our Dropwizard-based project to 1.7.1 from 1.7.0. We immediately hit a failure in our end-to-end test suite.\nThe case is when the client sends a request URI with trailing slash and it matches one of the patterns we defined in shiro.ini (the pattern does not have a trailing slash).\nThe pattern is:\n\n\r\n/api/models/*/etl/templates\r\n\n\nThe client URI is /api/models/1024831678847123456/etl/templates/\nThe error and stack trace in Shiro 1.7.1:\n\njavax.servlet.ServletException: Filtered request failed.\r\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:384)\r\n\tat \r\n...\r\n...\r\nCaused by: java.lang.IllegalArgumentException: There is no configured chain under the name/key [/api/models/1024831678847123456/etl/templates].\r\n\tat org.apache.shiro.web.filter.mgt.DefaultFilterChainManager.proxy(DefaultFilterChainManager.java:357)\r\n\tat org.apache.shiro.web.filter.mgt.PathMatchingFilterChainResolver.getChain(PathMatchingFilterChainResolver.java:129)\r\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.getExecutionChain(AbstractShiroFilter.java:416)\r\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\r\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\r\n\tat org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\r\n\tat org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\r\n\tat org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387)\r\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\r\n\t... 54 common frames omitted\r\n\n\nThere is no error if the client does not send the trailing slash in the URI. There is also no error with Shiro 1.7.0.\n"
            }
        }
    },
    "Jackrabbit_oak_core": {
        "owner_repo": "apache/jackrabbit-oak",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d2bbdad5b039a31b3c7a8ba1293b195de840b6e4",
                "commit_sha_fixed": "f8be641ad3dcaa45e7d06ded0e3990e039cadff5",
                "report_id": "OAK-1289",
                "report_url": "https://issues.apache.org/jira/browse/OAK-1289",
                "issue_title": "[OAK-1289] Range check fails with IllegalArgumentException - ASF JIRA",
                "issue_description": "\nRange.includes() fails with IllegalArgumentException when provided revision is from another cluster node:\n\njava.lang.IllegalArgumentException: Trying to compare revisions of different cluster ids: r142f43d2f0f-0-2 and r142f43d46fb-0-1\n\tat org.apache.jackrabbit.oak.plugins.mongomk.Revision.compareRevisionTime(Revision.java:84)\n\tat org.apache.jackrabbit.oak.plugins.mongomk.Range.includes(Range.java:55)\n\n\nThe IllegalArgumentException was introduced with OAK-1274.\n"
            },
            "2": {
                "commit_sha_buggy": "badcd98244e480e3ffe4d16a2ad55846f23af031",
                "commit_sha_fixed": "52ffe384db61c423c88634e28fa30cd2c1051465",
                "report_id": "OAK-1297",
                "report_url": "https://issues.apache.org/jira/browse/OAK-1297",
                "issue_title": "[OAK-1297] MoveDetector does not detect moved nodes that have been moved in an earlier commit already - ASF JIRA",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "472c73c19e93a5f5c1c0784a93b623cf67801513",
                "commit_sha_fixed": "dbaf51fbb145ff604e9f75ebde9781186013a4d3",
                "report_id": "OAK-1254",
                "report_url": "https://issues.apache.org/jira/browse/OAK-1254",
                "issue_title": "[OAK-1254] Parallel execution of SimpleSearchTest fails with MongoMK - ASF JIRA",
                "issue_description": "\nAt some point in the benchmark run one MongoMK instance will fail to read a node created by another instance. The exception is very similar to E1 reported in OAK-1204.\n"
            },
            "4": {
                "commit_sha_buggy": "5316521473f74d734a65296e441e5a27b2c94b36",
                "commit_sha_fixed": "a03ebaf5e1b061edafc38d19f8b0e4b96c364113",
                "report_id": "OAK-1348",
                "report_url": "https://issues.apache.org/jira/browse/OAK-1348",
                "issue_title": "[OAK-1348] ACE merging not behaving correctly if not using managed principals - ASF JIRA",
                "issue_description": "\norg.apache.jackrabbit.api.security.JackrabbitAccessControlList#addEntry() does not work correctly, if the given principal is not retrieved from the PrincipalManager.\nException:\n\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakAccessControl0013: Duplicate ACE found in policy\n\tat org.apache.jackrabbit.oak.security.authorization.accesscontrol.AccessControlValidator.accessViolation(AccessControlValidator.java:278)\n\tat org.apache.jackrabbit.oak.security.authorization.accesscontrol.AccessControlValidator.checkValidPolicy(AccessControlValidator.java:188)\n\n\nthis used to work in jackrabbit 2.x.\nthe problem is probably in org.apache.jackrabbit.oak.security.authorization.accesscontrol.ACL#internalAddEntry where the principals are \"equalled\" instead of comparing their names.\nnote, that adding an ACE with such a principal works, just the merging/overwriting detection doesn't.\ntest:\n\n  Principal p1 = new Principal() { getName(){return \"foo\"}};\n  Principal p2 = new Principal() { getName(){return \"foo\"}};\n  acl.addEntry(p1, privileges, true);\n  acl.addEntry(p2, privileges, false);\n  ...\n  save(); // throws\n\n\n"
            },
            "5": {
                "commit_sha_buggy": "8a0c922b570a827bca5e31138302ab893be8fbc4",
                "commit_sha_fixed": "c642f14f0808045f1f59a87725ddd7a2515a99bb",
                "report_id": "OAK-1467",
                "report_url": "https://issues.apache.org/jira/browse/OAK-1467",
                "issue_title": "[OAK-1467] Commit.rollback() may remove changes from other commit - ASF JIRA",
                "issue_description": "\nCommit.rollback() removes documents it previously created. With concurrent commits it may happen that this method removes documents some other commit modified in the meantime.\n"
            }
        }
    },
    "MDeploy": {
        "owner_repo": "apache/maven-deploy-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "271c42bd4478db5a10242e681e7a8fd96a9329d1",
                "commit_sha_fixed": "fa462097bc02d8ca6ca48022dc62f30ef15d45c4",
                "report_id": "MDEPLOY-56",
                "report_url": "https://issues.apache.org/jira/browse/MDEPLOY-56",
                "issue_title": "[MDEPLOY-56] Parent version ignored when deploying file with existing pom - ASF JIRA",
                "issue_description": "\nPom parent version is not used as source for version in deploy-file although deploy allows versionless deployment.\n"
            }
        }
    },
    "Jackrabbit_filevault_vault_validation": {
        "owner_repo": "apache/jackrabbit-filevault",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "60c66c3cb7fe456c6e1fd6599736afdddec862a4",
                "commit_sha_fixed": "9fa6c72bf4bdf36331b50b9370f3ed826a4622e8",
                "report_id": "JCRVLT-354",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-354",
                "issue_title": "[JCRVLT-354] False warnings for files not being included in the package due to being outside of filter roots - ASF JIRA",
                "issue_description": "\nthe new check introduced in JCRVLT-321 produces false warnings in my case - or i do not understand why the warning occurs.\nhere is a sample project:\nhttps://github.com/stefanseifert/filevault-package-maven-plugin-1.0.4-validation-issues/tree/master/content-packages/sample-content\ni can understand these warnings\n\n[WARNING] File content-packages\\sample-content\\jcr_root\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n\n\nalthough it's a pity they are reported because usually these .content.xml files \"above\" the filter paths help creating in between nodes when the package is extracted and the parent paths of the filter do not exist yet.\nbut i do not understand these warnings as the files are definitely included in the filter:\n\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\chicago.jpg\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\chicago.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\chicago.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\chicago.jpg\\_jcr_content\\renditions\\original not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\chicago.jpg\\_jcr_content\\renditions\\original.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\nature.jpg\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\nature.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\nature.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\nature.jpg\\_jcr_content\\renditions\\original not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\nature.jpg\\_jcr_content\\renditions\\original.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\prague.jpg\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\prague.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\prague.jpg\\_jcr_content\\renditions\\cq5dam.web.1280.1280.jpeg.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\prague.jpg\\_jcr_content\\renditions\\original not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\dam\\myproject1\\prague.jpg\\_jcr_content\\renditions\\original.dir\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\myproject1\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n[WARNING] File content-packages\\sample-content\\jcr_root\\content\\myproject1\\en\\.content.xml not covered by a filter rule and therefore not contained in the resulting package\r\n\n\n"
            },
            "2": {
                "commit_sha_buggy": "35a5a7da73c59e66e4301f25e668f040f6aefd84",
                "commit_sha_fixed": "31c150cfa068d0e57281f48efadd07186187c5f0",
                "report_id": "JCRVLT-409",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-409",
                "issue_title": "[JCRVLT-409] Validation: Emit node names in expanded form - ASF JIRA",
                "issue_description": "\nThe node names being emitted via DocumentViewXmlValidator (https://github.com/apache/jackrabbit-filevault/blob/f6762d3807fce27cf5add333c6bf03e92ef81f7d/vault-validation/src/main/java/org/apache/jackrabbit/vault/validation/spi/DocumentViewXmlValidator.java#L50) should have the expanded form to not being forced to make any assumptions about the namespace prefix.\n"
            },
            "3": {
                "commit_sha_buggy": "f29e743aaf94e7e15cec3d96318d3d71ffc3e8cd",
                "commit_sha_fixed": "f94289d10b9ea617b215cee4ad968d3707ac7bda",
                "report_id": "JCRVLT-422",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-422",
                "issue_title": "[JCRVLT-422] filevault-package-maven-plugin 1.1.2: jackrabbit-emptyelements filter fails for nodes starting with numbers - ASF JIRA",
                "issue_description": "\nto reproduce the problem build this sample project:\nhttps://github.com/stefanseifert/filevault-package-maven-plugin-1.1.2-validation-issues/tree/master/content-packages/sample-content\nthis leads (among others) to this error:\n\n[ERROR] ValidationViolation: \"jackrabbit-emptyelements: Found empty node (used for ordering only) without an accompanying folder which are included in the filter with mode=replace. Either remove the empty node or add at least the 'jcr:primaryType' attribute to make this node really get replaced.\", filePath=jcr_root\\content\\dam\\filevaultsample\\.content.xml, nodePath=/content/dam/filevaultsample/_x0030_123_sample.jpg\r\n\n\n\u00a0\nthis is wrong, the node is present. the filter seems to fail due to the escaped node name _x0030_123_sample.jpg, which should map to 0123_sample.jpg in the file system.\nthis problem did not occur with version 1.1.0 of the plugin.\n"
            },
            "4": {
                "commit_sha_buggy": "a3fd7a10abf69d4a4cdbc07cabf49e9e11b425e7",
                "commit_sha_fixed": "9b5655266194b6dd44ea4aae401a539228a08099",
                "report_id": "JCRVLT-423",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-423",
                "issue_title": "[JCRVLT-423] filevault-package-maven-plugin 1.1.2: Validation fails on /content/cq:tags node - ASF JIRA",
                "issue_description": "\ni've encountered another problem, occurs on 1.1.2 and 1.1.3-SNAPSHOT, not with version 1.1.0 of the plugin.\nsample project that contains some content below /content/cq:tags:\nhttps://github.com/stefanseifert/filevault-package-maven-plugin-1.1.2-validation-issues/tree/master/content-packages/sample-content\nleads to validation failures:\n\n[ERROR] ValidationViolation: \"jackrabbit-docviewparser: Invalid XML found: Given root node name 'cq:tags' (implicitly given via filename) cannot be resolved. The prefix used in the filename must be declared as XML namespace in the child docview XML as well!\", filePath=jcr_root\\content\\_cq_tags\\.content.xml\r\n[ERROR] ValidationViolation: \"jackrabbit-filter: Node '/content/cq:tags/.content.xml' is not contained in any of the filter rules\", filePath=jcr_root\\content\\_cq_tags\\.content.xml\r\n\n\nthe package content is exactly that what the package manager produced when downloading the package, so the package data itself is correct.\n"
            },
            "5": {
                "commit_sha_buggy": "f4600dd1d0de2030f51eccf06d32aae8a5c08a56",
                "commit_sha_fixed": "2d6207684fbf78609463feccf0e1afec07ef6a70",
                "report_id": "JCRVLT-482",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-482",
                "issue_title": "[JCRVLT-482] ArrayIndexOutOfBoundsException when validating multivalue property with empty value array - ASF JIRA",
                "issue_description": "\nwhen validating a docview property with an empty value array, e.g.\n\n\r\n    <jcr:content\r\n        cq:tags=\"[]\"\r\n        jcr:primaryType=\"cq:PageContent\"/>\r\n\n\nvalidation fails with an exception\n\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 0\r\n    at org.apache.jackrabbit.vault.validation.spi.impl.nodetype.JcrNodeTypeMetaDataImpl.addProperty (JcrNodeTypeMetaDataImpl.java:537)\r\n    at org.apache.jackrabbit.vault.validation.spi.impl.nodetype.NodeTypeValidator.addProperty (NodeTypeValidator.java:148)\r\n    at org.apache.jackrabbit.vault.validation.spi.impl.nodetype.NodeTypeValidator.validate (NodeTypeValidator.java:128)\r\n    at org.apache.jackrabbit.vault.validation.impl.util.DocumentViewXmlContentHandler.startElement (DocumentViewXmlContentHandler.java:199)\r\n...\r\n\n\n"
            },
            "6": {
                "commit_sha_buggy": "69a5a9e91caec801fbbe96b2328d177229873a1a",
                "commit_sha_fixed": "0fa305d5b0f6dec43e181db3fabeb32603d69501",
                "report_id": "JCRVLT-485",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-485",
                "issue_title": "[JCRVLT-485] Validation fails for nodetypes extending mix:versionable - ASF JIRA",
                "issue_description": "\nwhen validation a content package containing data with a node type extending mix:versionable (and the protected properties are stripped out of the local content) validation failes with:\n\nERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property 'jcr:predecessors' missing in node with types [cq:WorkflowModel] at /var/workflow/models/dam/dam_update_asset1\"\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property 'jcr:baseVersion' missing in node with types [cq:WorkflowModel] at /var/workflow/models/dam/dam_update_asset1\"\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property 'jcr:versionHistory' missing in node with types [cq:WorkflowModel] at /var/workflow/models/dam/dam_update_asset1\"\r\n\n\nsample project to reproduce the problem:\nhttps://github.com/stefanseifert/filevault-package-maven-plugin-validation-issues/tree/master/content-packages/workflow-content\n"
            },
            "7": {
                "commit_sha_buggy": "b60ce9a9ec94832f07b5bfa02e0679ce74b5a0b4",
                "commit_sha_fixed": "3dd6e923bfed0fb3937710e88c5637e2bc279972",
                "report_id": "JCRVLT-489",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-489",
                "issue_title": "[JCRVLT-489] jackrabbit-nodetypes validator errors for cq:WorkflowModel - ASF JIRA",
                "issue_description": "\nUsing the Apache Jackrabbit FileVault Package Maven Plugin 1.1.4 with AEM Node Types and Namespaces 6.5.5.0 and data from a package built from /var/workflow from Adobe Experience Manager 6.5.6, the jackrabbit-nodetypes validator raises errors on nodes of type cq:WorkflowModel. Below is one example of the errors that are raised for one node:\n\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Property 'DocViewProperty [name={http://www.jcp.org/jcr/1.0}uuid, values=[41699399-95fd-444d-ab8c-b9f8e614607e], isMulti=false, type=0, isReferenceProperty=false]' is not allowed in node with types '[cq:WorkflowModel]': Property is protected!\", filePath=jcr_root/var/workflow/models/dam/dynamic-media-encode-video.xml, nodePath=/var/workflow/models/dam/dynamic-media-encode-video, line=8, column=40\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Property 'DocViewProperty [name={http://www.jcp.org/jcr/1.0}isCheckedOut, values=[false], isMulti=false, type=6, isReferenceProperty=false]' is not allowed in node with types '[cq:WorkflowModel]': Property is protected!\", filePath=jcr_root/var/workflow/models/dam/dynamic-media-encode-video.xml, nodePath=/var/workflow/models/dam/dynamic-media-encode-video, line=8, column=40\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property '{http://www.jcp.org/jcr/1.0}predecessors' missing in node with types [cq:WorkflowModel]\", filePath=jcr_root/var/workflow/models/dam/dynamic-media-encode-video.xml, nodePath=/var/workflow/models/dam/dynamic-media-encode-video, line=8, column=40\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property '{http://www.jcp.org/jcr/1.0}baseVersion' missing in node with types [cq:WorkflowModel]\", filePath=jcr_root/var/workflow/models/dam/dynamic-media-encode-video.xml, nodePath=/var/workflow/models/dam/dynamic-media-encode-video, line=8, column=40\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Mandatory property '{http://www.jcp.org/jcr/1.0}versionHistory' missing in node with types [cq:WorkflowModel]\", filePath=jcr_root/var/workflow/models/dam/dynamic-media-encode-video.xml, nodePath=/var/workflow/models/dam/dynamic-media-encode-video, line=8, column=40\r\n\n\nI'm not sure where the issue is, if it's in the data AEM is producing, the Apache Jackrabbit FileVault Validation logic, or the CND provided by the AEM Node Types and Namespaces project.\n"
            },
            "8": {
                "commit_sha_buggy": "51bde3fda90cb3c37e33de2419629bdec3151384",
                "commit_sha_fixed": "9583fd08baf7c3b83797d4348d3ebd15ea156490",
                "report_id": "JCRVLT-497",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-497",
                "issue_title": "[JCRVLT-497] NodeTypeValidator: Incorrect errors emitted for rep:Authorizable nodes - ASF JIRA",
                "issue_description": "\nThe nodes containing rep:Authorizables are first detected as plain nt:folder and only afterwards being converted into the correct node type.\nThe field isAuthenticationOrAuthorizationContext is never adjusted though once the correct node type is detected (https://github.com/apache/jackrabbit-filevault/blob/beb4a72adcf963c1da6ed9604c18b8b5b69ee57c/vault-validation/src/main/java/org/apache/jackrabbit/vault/validation/spi/impl/nodetype/NodeTypeValidator.java#L180). That leads to incorrect validation messages being emitted.\nFor example for https://github.com/Netcentric/accesscontroltool/tree/2.7.1/accesscontroltool-content-package/src/main/jcr_root the following errors are being emitted\n\n\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Node 'actool-service [nt:folder]' is not allowed as child of node with types [rep:AuthorizableFolder]: Node type does not allow arbitrary child nodes and does not allow this specific name and node type either!\", filePath=jcr_root/home/users/system/actool/actool-service, nodePath=/home/users/system/actool/actool-service, line=7, column=6\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Property 'rep:authorizableId' [String] is not allowed in node with types [rep:SystemUser]: Property is protected!\", filePath=jcr_root/home/users/system/actool/actool-service/.content.xml, nodePath=/home/users/system/actool/actool-service, line=7, column=6\r\n[ERROR] ValidationViolation: \"jackrabbit-nodetypes: Property 'rep:principalName' [String] is not allowed in node with types [rep:SystemUser]: Property is protected!\", filePath=jcr_root/home/users/system/actool/actool-service/.content.xml, nodePath=/home/users/system/actool/actool-service, line=7, column=6\r\n\n\n"
            },
            "9": {
                "commit_sha_buggy": "6c1d6a27f2b6685865b93fb244d67c4dd9491ab4",
                "commit_sha_fixed": "9d6e3e101250d543ac9b8e3a2035a0a58907c668",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "JCRVLT-476 fix remaining major bugs",
                "issue_description": "JCRVLT-476 fix remaining major bugs"
            },
            "10": {
                "commit_sha_buggy": "d759ef289e6f46c652288af8ddc6d5cb42da3281",
                "commit_sha_fixed": "3f51305f906a9574644228a2ac29be9a152fa41e",
                "report_id": "JCRVLT-539",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-539",
                "issue_title": "[JCRVLT-539] NodeTypeValidator: more specific jcr:primaryType might be overwritten by generic nt:folder - ASF JIRA",
                "issue_description": "\nIn case the .content.xml is processed first and afterwards there is a folder with the same name as a node in the docview file, the more specific primary node type given in the DocView XML gets overwritten by the more generic implicit primary type nt:folder given by the folder.\n"
            },
            "11": {
                "commit_sha_buggy": "2df498954d708addb027d0d1395a2af2f76b5642",
                "commit_sha_fixed": "58041b7c2c6fd521cf17bd800341ef63c9f0589f",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "JCRVLT-426 fix handling of node types defined in other files\n\nimprove handling of unknown node types",
                "issue_description": "JCRVLT-426 fix handling of node types defined in other files\n\nimprove handling of unknown node types"
            }
        }
    },
    "Doxia_module_apt": {
        "owner_repo": "apache/maven-doxia",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b7c0c112d07d5405b674829d75759d3d0d0df986",
                "commit_sha_fixed": "a213e5d2a7d5e08fedecfa72592ad9ff3494f8fb",
                "report_id": "DOXIA-404",
                "report_url": "https://issues.apache.org/jira/browse/DOXIA-404",
                "issue_title": "[DOXIA-404] Problems using table headers in APT documents - ASF JIRA",
                "issue_description": "\nWhen using the APT enhancement for table header cells the table itself automatically gets a border.\nThis table gets a border:\n\n*-----------+-----------+\n|| Header 1 || Header 2 |\n*-----------+-----------+\n  Cell 1    | Cell 2    |\n*-----------+-----------+\n  Cell 3    | Cell 4    |\n*-----------+-----------+\n\n\nWe need to figure out a way to have table header cells in a table without borders.\nAlso cells 1 and 3 in the example are made into header cells, even though they haven't been specified as such.\n"
            },
            "2": {
                "commit_sha_buggy": "6fedde1a798958cc2dedfaadd1b7eec99ed3c685",
                "commit_sha_fixed": "9f390afa872679939b23cbd9d8a92091650cfee1",
                "report_id": "DOXIA-397",
                "report_url": "https://issues.apache.org/jira/browse/DOXIA-397",
                "issue_title": "[DOXIA-397] Cannot link to javadoc methods - ASF JIRA",
                "issue_description": "\nUsing a link to a javadoc method like\n\n{{{../apidocs/groovyx/net/http/ParserRegistry.html#parseText(org.apache.http.HttpResponse)}ParserRegistry}}\n\n\nthe apt parser removes the brackets of the anchor. The same thing happens with xdocs and probably other formats. Note that non-ascii characters are not legal in anchor names, but they should be replaced by their hex values, see http://www.w3.org/TR/html401/appendix/notes.html#non-ascii-chars.\n"
            }
        }
    },
    "Rdf_jena": {
        "owner_repo": "apache/commons-rdf",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ecc81fa4a1ef959d2f56f249b34eea56123b2eb8",
                "commit_sha_fixed": "895718276b8bba064679b3ee97f95ab2ff70bfc0",
                "report_id": "COMMONSRDF-66",
                "report_url": "https://issues.apache.org/jira/browse/COMMONSRDF-66",
                "issue_title": "[COMMONSRDF-66] JenaDatasetImpl.toString() throws RIOT exception - ASF JIRA",
                "issue_description": "\nOccurs from this method https://github.com/apache/commons-rdf/blob/master/jena/src/main/java/org/apache/commons/rdf/jena/impl/JenaDatasetImpl.java#L152 on instantiation:\nThe exception message is \"No dataset writer for N-Triples/utf-8\".\nThe source is RDFWriterRegistry that builds a registryDataset HashMap of 17 Dataset RDFFormats that does not include this serialization.  The registryGraph HashMap has 25 RDFFormats that does include \"N-Triples/utf-8\".\nNo exception is thrown if Lang.NQUADS is set in the toString() method.\n"
            }
        }
    },
    "Maven_checkstyle_plugin": {
        "owner_repo": "apache/maven-checkstyle-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "25e57176178f5af7da236a88fc7604d0a159813b",
                "commit_sha_fixed": "f54d618b028d59844b09b91ec7c6c10deebbd6e1",
                "report_id": "MCHECKSTYLE-168",
                "report_url": "https://issues.apache.org/jira/browse/MCHECKSTYLE-168",
                "issue_title": "[MCHECKSTYLE-168] checkstyle-aggregate give a wrong file count - ASF JIRA",
                "issue_description": "\nIn a multi-source-directory environment, currently verifiable only with multi-module projects, the total file count is wrong.\n"
            }
        }
    },
    "James_project_core": {
        "owner_repo": "apache/james-project",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cfca550ac4befd4e009aecee04bbecbb2e1672b3",
                "commit_sha_fixed": "ebb749461b5c00f8e77290a2e08dc24c9f4eac34",
                "report_id": "JAMES-2557",
                "report_url": "https://issues.apache.org/jira/browse/JAMES-2557",
                "issue_title": "[JAMES-2557] NULL_SENDER throws an error in Dlp - ASF JIRA",
                "issue_description": "\nWatching Kibana logs I got this recurring error:\n\n\r\n \tException calling dlp.Dlp: NULL sender '<>' do not have domain part\r\njava.lang.IllegalStateException: NULL sender '<>' do not have domain part\r\n\tat org.apache.james.core.MailAddress$1.getDomain(MailAddress.java:87)\r\n\tat org.apache.james.transport.matchers.dlp.Dlp.matchingRule(Dlp.java:76)\r\n\tat org.apache.james.transport.matchers.dlp.Dlp.lambda$findFirstMatchingRule$0(Dlp.java:72)\r\n\tat java.util.Optional.flatMap(Optional.java:241)\r\n\tat org.apache.james.transport.matchers.dlp.Dlp.findFirstMatchingRule(Dlp.java:72)\r\n\tat org.apache.james.transport.matchers.dlp.Dlp.match(Dlp.java:55)\r\n\tat org.apache.james.mailetcontainer.impl.camel.MatcherSplitter.split(MatcherSplitter.java:109)\r\n\tat sun.reflect.GeneratedMethodAccessor70.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.camel.component.bean.MethodInfo.invoke(MethodInfo.java:481)\r\n\tat org.apache.camel.component.bean.MethodInfo$1.doProceed(MethodInfo.java:300)\r\n\tat org.apache.camel.component.bean.MethodInfo$1.proceed(MethodInfo.java:273)\r\n\tat org.apache.camel.component.bean.AbstractBeanProcessor.process(AbstractBeanProcessor.java:187)\r\n\tat org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:109)\r\n\tat org.apache.camel.component.bean.AbstractBeanProcessor.process(AbstractBeanProcessor.java:70)\r\n\tat org.apache.camel.language.bean.BeanExpression.invokeBean(BeanExpression.java:200)\r\n\tat org.apache.camel.language.bean.BeanExpression.evaluate(BeanExpression.java:124)\r\n\tat org.apache.camel.language.bean.BeanExpression.evaluate(BeanExpression.java:135)\r\n\tat org.apache.camel.processor.Splitter.createProcessorExchangePairs(Splitter.java:127)\r\n\tat org.apache.camel.processor.MulticastProcessor.process(MulticastProcessor.java:241)\r\n\tat org.apache.camel.processor.Splitter.process(Splitter.java:122)\r\n\tat org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:548)\r\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\r\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:138)\r\n\tat org.apache.camel.processor.Pipeline.process(Pipeline.java:101)\r\n\tat org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:201)\r\n\tat org.apache.camel.component.direct.DirectBlockingProducer.process(DirectBlockingProducer.java:53)\r\n\tat org.apache.camel.processor.SharedCamelInternalProcessor.process(SharedCamelInternalProcessor.java:186)\r\n\tat org.apache.camel.processor.SharedCamelInternalProcessor.process(SharedCamelInternalProcessor.java:86)\r\n\tat org.apache.camel.impl.ProducerCache$1.doInProducer(ProducerCache.java:541)\r\n\tat org.apache.camel.impl.ProducerCache$1.doInProducer(ProducerCache.java:506)\r\n\tat org.apache.camel.impl.ProducerCache.doInProducer(ProducerCache.java:369)\r\n\tat org.apache.camel.impl.ProducerCache.sendExchange(ProducerCache.java:506)\r\n\tat org.apache.camel.impl.ProducerCache.send(ProducerCache.java:229)\r\n\tat org.apache.camel.impl.DefaultProducerTemplate.send(DefaultProducerTemplate.java:144)\r\n\tat org.apache.camel.impl.DefaultProducerTemplate.sendBody(DefaultProducerTemplate.java:161)\r\n\tat org.apache.camel.impl.DefaultProducerTemplate.sendBody(DefaultProducerTemplate.java:168)\r\n\tat org.apache.james.mailetcontainer.impl.camel.CamelMailetProcessor.service(CamelMailetProcessor.java:68)\r\n\tat org.apache.james.mailetcontainer.lib.AbstractStateCompositeProcessor.service(AbstractStateCompositeProcessor.java:84)\r\n\tat org.apache.james.mailetcontainer.impl.JamesMailSpooler.lambda$run$0(JamesMailSpooler.java:163)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\n\nIt cames from the Dlp part (Dlp.java):\n\n\r\n    private Optional<DLPConfigurationItem.Id> findFirstMatchingRule(Mail mail) {\r\n        return Optional\r\n                .ofNullable(mail.getSender())\r\n                .flatMap(sender -> matchingRule(sender, mail));\r\n    }\r\n\r\n    private Optional<DLPConfigurationItem.Id> matchingRule(MailAddress address, Mail mail) {\r\n        return rulesLoader.load(address.getDomain()).match(mail);\r\n    }\r\n\n\nSince `mail.getSender()` returns a `NULL_SENDER` and not a `null` value, `matchingRule` is executed, since it breaks the LSP, it breaks our code.\nThere are two solutions:\n\nStrengthening `MailAddress`\nChecking `MailAddress.isNullSender()`\n\n"
            },
            "2": {
                "commit_sha_buggy": "ec911c1317aab016e4eb8bc999572e579590f0fd",
                "commit_sha_fixed": "09b5cb567e3292b1739993559bc93d37bd99a478",
                "report_id": "JAMES-2167",
                "report_url": "https://issues.apache.org/jira/browse/JAMES-2167",
                "issue_title": "[JAMES-2167] Serializable attributes are not preserved by enqueue/dequeue on a JMS queue - ASF JIRA",
                "issue_description": "\nA call to toString breaks convertion for generic serializable attributes. \nThe dequeued email will have only a toString version of it. We are expecting the exact same value, just deserialized.\nWe should ensure the value of Serializable attributes gets preserved by enqueue/dequeue operations. We should add a unit test for this, and fix it.\n"
            }
        }
    },
    "Pdfbox_fontbox": {
        "owner_repo": "apache/pdfbox",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c1644feb20e996590167c6c7536b387bccdea632",
                "commit_sha_fixed": "e8ca4741939b7cad993c01c2e762becd48d35d29",
                "report_id": "PDFBOX-2035",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-2035",
                "issue_title": "[PDFBOX-2035] Ignore badly formatted toUnicode CMaps - ASF JIRA",
                "issue_description": "\nCopied from PDFBOX-399:\nSubmitting a patch for ignoring badly-formatted CMap ToUnicode instructions.\nThis allows parsing of some ToUnicode resource streams that would otherwise throw exceptions which were silently consumed. This allows text extraction to get the correctly mapped characters.\nSpecifically parse token<hex> adjacency without whitespace separating them, eat all whitespace within a hex value, and return a partially constructed CMap instead of throwing an exception.\nI don't see a problem with the previous test case example (BlackHat...) but I've modified the test case based on an example from the wild: http://www.itsix.com/media/experienced_java_developer.pdf\nedit: forgot to mention that this patch was designed on 1.8.3, but also worked on trunk.\n"
            },
            "2": {
                "commit_sha_buggy": "211bb5a4cee2573a5afcc8097e8a0466d14c8d32",
                "commit_sha_fixed": "ff02a1b137887523f1051b4bedf8f62579501f4f",
                "report_id": "PDFBOX-2212",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-2212",
                "issue_title": "[PDFBOX-2212] OutOfMemoryError in GlyfCompositeDescrip - ASF JIRA",
                "issue_description": "\nHi All,\nThe application I\u2019m working on is a web service that accepts PDF documents and combines them in a single larger PDF. Client submits a bunch of PDFs and we create a single PDF out of them. In some rare cases one of the PDF documents submitted has a glitch in it that causes Adobe Reader to throw errors when viewing the final document (attached).\nWhen I tried to check the buggy PDF with the approach outlined here:\nhttps://pdfbox.apache.org/cookbook/pdfavalidation.html\nI was getting an OutOfMemoryError in the GlyfCompositeDescrip class, here is the full stack trace:\njava.lang.OutOfMemoryError: Java heap space\n                at org.apache.fontbox.ttf.GlyfCompositeDescript.<init>(GlyfCompositeDescript.java:58)\n                at org.apache.fontbox.ttf.GlyphData.initData(GlyphData.java:62)\n                at org.apache.fontbox.ttf.GlyphTable.initData(GlyphTable.java:69)\n                at org.apache.fontbox.ttf.TrueTypeFont.initializeTable(TrueTypeFont.java:280)\n                at org.apache.fontbox.ttf.AbstractTTFParser.parseTables(AbstractTTFParser.java:128)\n                at org.apache.fontbox.ttf.TTFParser.parseTables(TTFParser.java:80)\n                at org.apache.fontbox.ttf.AbstractTTFParser.parseTTF(AbstractTTFParser.java:109)\n                at org.apache.fontbox.ttf.TTFParser.parseTTF(TTFParser.java:25)\n                at org.apache.fontbox.ttf.AbstractTTFParser.parseTTF(AbstractTTFParser.java:84)\n                at org.apache.fontbox.ttf.TTFParser.parseTTF(TTFParser.java:25)\n                at org.apache.pdfbox.preflight.font.descriptor.TrueTypeDescriptorHelper.processFontFile(TrueTypeDescriptorHelper.java:84)\n                at org.apache.pdfbox.preflight.font.descriptor.FontDescriptorHelper.validate(FontDescriptorHelper.java:97)\n                at org.apache.pdfbox.preflight.font.SimpleFontValidator.processFontDescriptorValidation(SimpleFontValidator.java:82)\n                at org.apache.pdfbox.preflight.font.SimpleFontValidator.validate(SimpleFontValidator.java:55)\n                at org.apache.pdfbox.preflight.process.reflect.FontValidationProcess.validate(FontValidationProcess.java:69)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.callValidation(ContextHelper.java:73)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.validateElement(ContextHelper.java:52)\n                at org.apache.pdfbox.preflight.process.reflect.ResourcesValidationProcess.validateFonts(ResourcesValidationProcess.java:96)\n                at org.apache.pdfbox.preflight.process.reflect.ResourcesValidationProcess.validate(ResourcesValidationProcess.java:74)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.callValidation(ContextHelper.java:73)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.validateElement(ContextHelper.java:52)\n                at org.apache.pdfbox.preflight.xobject.XObjFormValidator.validateXObjectResources(XObjFormValidator.java:178)\n                at org.apache.pdfbox.preflight.xobject.XObjFormValidator.validate(XObjFormValidator.java:75)\n                at org.apache.pdfbox.preflight.process.reflect.GraphicObjectPageValidationProcess.validate(GraphicObjectPageValidationProcess.java:77)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.callValidation(ContextHelper.java:73)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.validateElement(ContextHelper.java:52)\n                at org.apache.pdfbox.preflight.process.reflect.ResourcesValidationProcess.validateXObjects(ResourcesValidationProcess.java:191)\n                at org.apache.pdfbox.preflight.process.reflect.ResourcesValidationProcess.validate(ResourcesValidationProcess.java:78)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.callValidation(ContextHelper.java:73)\n                at org.apache.pdfbox.preflight.utils.ContextHelper.validateElement(ContextHelper.java:52)\n                at org.apache.pdfbox.preflight.xobject.XObjFormValidator.validateXObjectResources(XObjFormValidator.java:178)\n                at org.apache.pdfbox.preflight.xobject.XObjFormValidator.validate(XObjFormValidator.java:75)\nWhile I can\u2019t send on the PDF in question due to the sensitivity of the contents in it, I did a bit of digging and debugging to find out why this is happening.\nIn the GlyfCompositeDescrip classes constructor there is a do \u2026 while loop that is constructing GlyfCompositeComp objects and adding them to the components list of GlyfCompositeDescrip. In the constructor of the GlyfCompositeComp a signed short is read from the TTFDataStream in the flags field, that field in turn is used in the GlyfCompositeDescrip constructor to check if any more components are there to be read. Here is the code in question:\npublic GlyfCompositeDescript(TTFDataStream bais, GlyphTable glyphTable) throws IOException\n    {\n\u2026\n        do\n\n{\n            comp = new GlyfCompositeComp(bais); //This is where the OutOfMemoryError happens\n            components.add(comp);\n        }\n while ((comp.getFlags() & GlyfCompositeComp.MORE_COMPONENTS) != 0); //here the flags are used to check if more components are there\n\u2026\n    }\nprotected GlyfCompositeComp(TTFDataStream bais) throws IOException\n    {\n        flags = bais.readSignedShort();\n\u2026\n}\nIn the case of the corrupted PDF, that we get from time to time, the bais.readSignedShort() call in GlyfCompositeComp results in a value of -1 and once it hits that value the condition in the GlyfCompositeDescript constructor\u2019s loop will always result in 32 (!=0). Basically, it ends up in an infinite loop and keeps constructing GlyfCompositeComp objects until the memory runs out.\nThe main question here is, has anyone ever encountered a PDF corruption that causes this behaviour and how would one have to go about checking the PDF document for this sort of corruptions without causing the application to run out of memory?\nWe\u2019re not required to fix the document, just check if it\u2019s valid. If it\u2019s not valid then we just reject the document. Ideally I\u2019d also like to know what the corruption could be so that I can at least give a hint to the client software as to what is causing this document to be rejected (I do understand that without the actual PDF that\u2019s causing this it might be impossible to tell that).\n"
            },
            "3": {
                "commit_sha_buggy": "9fe43ea4f4be69f8d5e65994300f1a23ca1b7dca",
                "commit_sha_fixed": "392edabe141f43d2f90c570fc6e1e62fd81e7039",
                "report_id": "PDFBOX-2854",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-2854",
                "issue_title": "[PDFBOX-2854] TTFSubsetter NoSuchElementException - ASF JIRA",
                "issue_description": "\nException in thread \"main\" java.util.NoSuchElementException\n\tat java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1113)\n\tat java.util.TreeMap$EntryIterator.next(TreeMap.java:1151)\n\tat java.util.TreeMap$EntryIterator.next(TreeMap.java:1146)\n\tat org.apache.fontbox.ttf.TTFSubsetter.buildOS2Table(TTFSubsetter.java:523)\n\tat org.apache.fontbox.ttf.TTFSubsetter.writeToStream(TTFSubsetter.java:1081)\n        TrueTypeFont x = new TTFParser().parse(\"Uvb_____.TTF\");\n        new TTFSubsetter(x, null).writeToStream(new ByteArrayOutputStream());\n"
            },
            "4": {
                "commit_sha_buggy": "8dfcf094188619831c08cbf1088e4edd86e0365f",
                "commit_sha_fixed": "b9f049e7469ec8ac8399c4a713bcda4450ebb02b",
                "report_id": "PDFBOX-3757",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-3757",
                "issue_title": "[PDFBOX-3757] TTFSubsetter scrambles PostScript names and unicode codepoints when subset contains diaeresis - ASF JIRA",
                "issue_description": "\nI tried to build a standalone FontSubsetter with the great fontbox tools. It works so far for OpenType/TrueType fonts, but when the glyph subset contains characters with diaeresis (like german umlauts \u00e4\u00f6\u00fc), the TTFSubsetter class scrambles PostScript names and unicode codepoints.\nWhen creating a subset from DejaVuSans.ttf for example, with only those two characters \"\u00d6\u200a\" (O umlaut and a hair space \\u200A), the resulting font subset is recognized as a valid font, but the unicode codepoint 200A in the resulting font file has the postscript name \"Dieresis\" and the single dieresis are named \"uni200A\". See screenshot \"fontbox-2.0.5-ttfsubsetter_dieresis-scrambled-names.png\" and the subsetted Font \"Subset-DejaVuSans__dieresis-scrambled-names.ttf\".\nWhen there are more glyphs in the subset, more whitespace, special chars and umlauts, the scrambling goes even further and also scrambles unicode codepoints and not only postscript names:\nglyphs in subset: \"Rabenk\u00f6igKrmloEyGfthsTjHdAu cvF\u00fcD.\u2006w,\u00e4Up:IzWVZSN-\u00dfLC\u2005PB5M\u00ab\u00bbO2013Q\u00a9/;x978-()64XJ'!\u00c4?\u2039\u203a\u00a0...\u00dcqY\u200a&\u00d6\u00e9|_\u2022{}[]>#*$^+\"\nResulting font: \"Subset-DejaVuSans__scrambled-codepoints.ttf\"\nScreenshot: \"fontbox-2.0.5-ttfsubsetter_scrambled-codepoints.png\"\nI considder this a bug, as it does not appear when there are no umlauts or diaeresis in the subset.\n"
            },
            "5": {
                "commit_sha_buggy": "a6b2cf98e431f0815251d2e41a1e61a5e7d5e110",
                "commit_sha_fixed": "40b34e561c78b3b1dea86062376b69d0754fc14b",
                "report_id": "PDFBOX-4242",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-4242",
                "issue_title": "[PDFBOX-4242] Fontbox does not close file descriptor when loading fonts. - ASF JIRA",
                "issue_description": "\nMy app has been getting \"java.io.FileNotFoundException (No file descriptors available)\" and I've confirmed that\u00a0it's because fontbox isn't closing it's file descriptors.\nIn\u00a0org.apache.fontbox.ttf.TTFParser there's this method:\npublic TrueTypeFont parse(File ttfFile) throws IOException {\n\u00a0 RAFDataStream raf = new RAFDataStream(ttfFile, \"r\");\n\u00a0 try {\n\u00a0 \u00a0 return this.parse((TTFDataStream)raf);\n\u00a0 } catch (IOException var4) {\n\u00a0 \u00a0 // close only on error (file is still being accessed later)\n\u00a0 \u00a0 raf.close();\n\u00a0 \u00a0 throw var4;\n}\n}\nI would have expected to see the close() in a finally block so that the file is always closed, not just on exceptions. Presumably, you can keep it in memory without leaving the file descriptor open?\npublic TrueTypeFont parse(File ttfFile) throws IOException {\n\u00a0 RAFDataStream raf = new RAFDataStream(ttfFile, \"r\");\n\u00a0 try {\n\u00a0 \u00a0 return this.parse((TTFDataStream)raf);\n\u00a0 } catch (IOException var4) {\u00a0 \u00a0 raf.close();\n\u00a0 \u00a0 throw var4;\n\u00a0 } finally {\n\u00a0 \u00a0 raf.close();\n}\n}\nI tried performing this in a lazy initialization, but it blew up:\njava.lang.RuntimeException: java.io.IOException: The TrueType font null does not contain a 'cmap' tableCaused by: java.io.IOException: The TrueType font null does not contain a 'cmap' table\n  at org.apache.fontbox.ttf.TrueTypeFont.getUnicodeCmapImpl(TrueTypeFont.java:548)\n  at org.apache.fontbox.ttf.TrueTypeFont.getUnicodeCmapLookup(TrueTypeFont.java:528)\n  at org.apache.fontbox.ttf.TrueTypeFont.getUnicodeCmapLookup(TrueTypeFont.java:514)\n  at org.apache.fontbox.ttf.TTFSubsetter.<init>(TTFSubsetter.java:91)\n  at org.apache.pdfbox.pdmodel.font.TrueTypeEmbedder.subset(TrueTypeEmbedder.java:321)\n  at org.apache.pdfbox.pdmodel.font.PDType0Font.subset(PDType0Font.java:239)\n  at org.apache.pdfbox.pdmodel.PDDocument.save(PDDocument.java:1271)\nThoughts?\nThanks for PDFBox - it's been really helpful!\n"
            },
            "6": {
                "commit_sha_buggy": "21feaee9500aacb0be413dbdb6123b176f19db78",
                "commit_sha_fixed": "8c6f34f495f322378617c6e02a0d4f1a86e1bd55",
                "report_id": "PDFBOX-787",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-787",
                "issue_title": "[PDFBOX-787] CMap parser doesn't work for double byte mappings with values > 255 - ASF JIRA",
                "issue_description": "\nThe CMapParser doesn't work for double byte mappings with values greater than 255 within a \"begincidrange\" block.\n"
            },
            "7": {
                "commit_sha_buggy": "392edabe141f43d2f90c570fc6e1e62fd81e7039",
                "commit_sha_fixed": "aac460ca0be00c4562e8864aa42aa25bda8bd529",
                "report_id": "PDFBOX-2854",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-2854",
                "issue_title": "[PDFBOX-2854] TTFSubsetter NoSuchElementException - ASF JIRA",
                "issue_description": "\nException in thread \"main\" java.util.NoSuchElementException\n\tat java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1113)\n\tat java.util.TreeMap$EntryIterator.next(TreeMap.java:1151)\n\tat java.util.TreeMap$EntryIterator.next(TreeMap.java:1146)\n\tat org.apache.fontbox.ttf.TTFSubsetter.buildOS2Table(TTFSubsetter.java:523)\n\tat org.apache.fontbox.ttf.TTFSubsetter.writeToStream(TTFSubsetter.java:1081)\n        TrueTypeFont x = new TTFParser().parse(\"Uvb_____.TTF\");\n        new TTFSubsetter(x, null).writeToStream(new ByteArrayOutputStream());\n"
            }
        }
    },
    "AaltoXml": {
        "owner_repo": "FasterXML/aalto-xml",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "745ff7facfc5f984b992e9635d770991f6e37751",
                "commit_sha_fixed": "9f4212f37f43bd2913a934269a3dcd7d0b2ef9f4",
                "report_id": "53",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/53",
                "issue_title": "AsyncByteScanner.validPublicIdChar() incorrectly rejects digits",
                "issue_description": "The javadoc for `AsyncByteScanner.validPublicIdChar()` references [PubidLiteral](http://www.w3.org/TR/xml/#NT-PubidLiteral) in the XML 1.0 specification:\r\n\r\n>     PubidLiteral ::= '\"' PubidChar* '\"' | \"'\" (PubidChar - \"'\")* \"'\"\r\n>     PubidChar    ::= #x20 | #xD | #xA | [a-zA-Z0-9] | [-'()+,./:=?;!*#@$_%]\r\n\r\nNote that this includes `[0-9]`. However, the [implementation of the method](https://github.com/FasterXML/aalto-xml/blob/2750fb4be212436ab2cdc5a4d11a0c04baa99451/src/main/java/com/fasterxml/aalto/async/AsyncByteScanner.java#L622-L645) does not:\r\n\r\n```\r\n    protected boolean validPublicIdChar(int c) {\r\n        return\r\n            c == 0xA ||                     //<LF>\r\n            c == 0xD ||                     //<CR>\r\n            c == 0x20 ||                    //<SPACE>\r\n            (c >= '@' && c <= 'Z') ||       //@[A-Z]\r\n            (c >= 'a' && c <= 'z') ||\r\n            c == '!' ||\r\n            (c >= 0x23 && c <= 0x25) ||     //#$%\r\n            (c >= 0x27 && c <= 0x2F) ||     //'()*+,-./\r\n            (c >= ':' && c <= ';') ||\r\n            c == '=' ||\r\n            c == '?' ||\r\n            c == '_';\r\n    }\r\n```\r\n\r\nNote also that [`com.fasterxml.aalto.util.XmlCharTypes.PUBID_CHARS`](https://github.com/FasterXML/aalto-xml/blob/2750fb4be212436ab2cdc5a4d11a0c04baa99451/src/main/java/com/fasterxml/aalto/util/XmlCharTypes.java#L106-L145) correctly includes these digits.\r\n\r\n### Steps to reproduce:\r\n\r\n1. Find or create a document matching the [Encoded Archival Description version 3](https://github.com/saa-ead-roundtable/ead3-toolkit) schema and containing the following `<!DOCTYPE>` declaration (e.g., add it to [this file](https://github.com/saa-ead-roundtable/ead3-toolkit/blob/master/ead3_single_level_minimum.xml)):\r\n\r\n```xml\r\n<!DOCTYPE ead PUBLIC \"+// http://ead3.archivists.org/schema/ //DTD ead3 (Encoded Archival Description (EAD) Version 3)//EN\" \"ead3.dtd\">\r\n```\r\n\r\n2. Attempt to parse it with an `AsyncXMLStreamReader`.\r\n\r\n### Expected:\r\n\r\n- File parses, or at any rate gets past the `<!DOCTYPE>` declaration.\r\n\r\n### Actual:\r\n\r\n- parsing fails with a `WFCException`:\r\n\r\n```java\r\nError parsing XML stream\r\ncom.fasterxml.aalto.WFCException: Unexpected character '3' (code 51) in prolog (not valid in PUBLIC ID)\r\n at [row,col {unknown-source}]: [1,77]\r\n\tat com.fasterxml.aalto.in.XmlScanner.reportInputProblem(XmlScanner.java:1333)\r\n\tat com.fasterxml.aalto.in.XmlScanner.throwUnexpectedChar(XmlScanner.java:1498)\r\n\tat com.fasterxml.aalto.in.XmlScanner.reportPrologUnexpChar(XmlScanner.java:1358)\r\n\tat com.fasterxml.aalto.async.AsyncByteBufferScanner.parseDtdId(AsyncByteBufferScanner.java:1946)\r\n\tat com.fasterxml.aalto.async.AsyncByteBufferScanner.handleDTD(AsyncByteBufferScanner.java:1833)\r\n\tat com.fasterxml.aalto.async.AsyncByteBufferScanner.handlePrologDeclStart(AsyncByteBufferScanner.java:1264)\r\n\tat com.fasterxml.aalto.async.AsyncByteBufferScanner.nextFromProlog(AsyncByteBufferScanner.java:1067)\r\n\tat com.fasterxml.aalto.stax.StreamReaderImpl.next(StreamReaderImpl.java:790)\r\n\tat org.codehaus.stax2.ri.Stax2EventReaderImpl.nextEvent(Stax2EventReaderImpl.java:255)\r\n```\r\n\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "f5c1007442a51696b0ef05937c679422b1420540",
                "commit_sha_fixed": "8940d90adc7ee7efe5884228974f2a29439aa2ee",
                "report_id": "35",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/35",
                "issue_title": "Carriage return (\\r) dropped by `XMLStreamWriter` implementation",
                "issue_description": "I'm using StAX to do some XML processing, reading events and then writing them, sometimes with some changes, etc., as you do, and I've noticed something odd: aalto, given XML containing `&#13;` in a text node will, at the end of this process, produce text with neither the CR nor a newline. This differs from other StAX implementations and appears to be a bug (the handling of this particular case is different across all implementations I know of, but aalto's seems to be the most-wrong).\n\nThis program illustrates:\n\n```\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.nio.charset.StandardCharsets;\n\nimport javax.xml.parsers.DocumentBuilderFactory;\nimport javax.xml.stream.XMLEventFactory;\nimport javax.xml.stream.XMLEventReader;\nimport javax.xml.stream.XMLEventWriter;\nimport javax.xml.stream.XMLInputFactory;\nimport javax.xml.stream.XMLOutputFactory;\nimport javax.xml.stream.events.XMLEvent;\nimport javax.xml.xpath.XPath;\nimport javax.xml.xpath.XPathConstants;\nimport javax.xml.xpath.XPathFactory;\n\nimport org.w3c.dom.Document;\n\n\npublic final class Minimal {\n    /** Enumeration of supported StAX implementations. */\n    public enum StAXImplementation {\n        AALTO(\"com.fasterxml.aalto.stax.InputFactoryImpl\",\n                \"com.fasterxml.aalto.stax.OutputFactoryImpl\",\n                \"com.fasterxml.aalto.stax.EventFactoryImpl\"),\n        /** JDK built in implementation, based on Xerces. */\n        JDK(\"com.sun.xml.internal.stream.XMLInputFactoryImpl\",\n                \"com.sun.xml.internal.stream.XMLOutputFactoryImpl\",\n                \"com.sun.xml.internal.stream.events.XMLEventFactoryImpl\"),\n        WOODSTOX(\"com.ctc.wstx.stax.WstxInputFactory\",\n                \"com.ctc.wstx.stax.WstxOutputFactory\",\n                \"com.ctc.wstx.stax.WstxEventFactory\"),\n        XERCES(JDK.inputFactory,\n                JDK.outputFactory,\n                \"org.apache.xerces.stax.XMLEventFactoryImpl\");\n\n        final String inputFactory;\n        final String outputFactory;\n        final String eventFactory;\n\n        private StAXImplementation(final String inputFactory,\n                final String outputFactory, final String eventFactory) {\n            this.inputFactory = inputFactory;\n            this.outputFactory = outputFactory;\n            this.eventFactory = eventFactory;\n        }\n\n        /**\n         * Tell the JDK to use this StAXImplementation.\n         */\n        public void use() {\n            System.setProperty(\"javax.xml.stream.XMLInputFactory\",\n                    inputFactory);\n            System.setProperty(\"javax.xml.stream.XMLOutputFactory\",\n                    outputFactory);\n            System.setProperty(\"javax.xml.stream.XMLEventFactory\",\n                    eventFactory);\n        }\n    }\n\n\n    static final String CR = new String(Character.toChars(32));\n    static final String TEXT=\"a&#13;a\";\n    static final String EXPANDED_TEXT = \"a\" + CR + \"a\";\n    static final String NEWLINE_TEXT = \"a\\na\";\n    static final String XML = \"<x>\" + TEXT + \"</x>\";\n    static final byte[] XML_BYTES = XML.getBytes(\n            StandardCharsets.UTF_8);\n\n    /** Run some tests for each StAX implementation. */\n    public static void main(final String[] args) throws Exception {\n        for (final StAXImplementation impl : StAXImplementation.values()) {\n            runTest(impl);\n            System.out.println();\n        }\n    }\n\n    private static void runTest(final StAXImplementation impl)\n            throws Exception {\n        impl.use();\n        System.out.println(\"************** Trying \" + impl + \" **************\");\n        final XMLInputFactory inputFactory = XMLInputFactory.newFactory();\n        final XMLOutputFactory outputFactory =\n                XMLOutputFactory.newFactory();\n        final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n        System.out.println(\"-------------- Factory classes:\");\n        printName(\"XMLInputFactory\", inputFactory);\n        printName(\"XMLOutputFactory\", outputFactory);\n        printName(\"XMLEventFactory\", XMLEventFactory.newFactory());\n\n        System.out.println(\"-------------- StAX results:\");\n        final XMLEventReader r = inputFactory.createXMLEventReader(\n                new ByteArrayInputStream(XML_BYTES));\n        final XMLEventWriter w = outputFactory.createXMLEventWriter(baos);\n        final StringBuilder buffer = new StringBuilder();\n        while (r.hasNext()) {\n            final XMLEvent e = r.nextEvent();\n            if (e.isStartDocument()) {\n                // Avoid the XML declaration. Not present in the input.\n                continue;\n            }\n            if (e.isCharacters()) {\n                buffer.append(e.asCharacters().getData());\n            } else {\n                if (buffer.length() > 0) {\n                    testText(buffer.toString());\n                    buffer.setLength(0);\n                }\n            }\n            w.add(e);\n        }\n        r.close();\n        w.flush();\n        w.close();\n        final byte[] resultBytes = baos.toByteArray();\n        System.out.println(\"StAX XML: [\" + new String(resultBytes,\n                StandardCharsets.UTF_8) + \"]\");\n        testDOM(resultBytes);\n    }\n\n    private static void printName(final String name, final Object obj) {\n        System.out.println(name + \"=\" + obj.getClass().getName());\n    }\n\n    private static void testText(final String text) {\n        System.out.println(\"Buffered text: [\" + text + \"]\");\n        System.out.println(\"Code point at index 1: \" +\n                Character.codePointAt(text, 1));\n        System.out.println(\"Buffered text equals input text? \" +\n                TEXT.equals(text));\n        System.out.println(\n                \"Buffered text equals expanded text? \" +\n                        EXPANDED_TEXT.equals(text));\n        System.out.println(\"Buffered text has \\\\n for \\\\r? \" +\n                NEWLINE_TEXT.equals(text));\n    }\n\n    private static void testDOM(final byte[] resultBytes) throws Exception {\n        final DocumentBuilderFactory dbf =\n                DocumentBuilderFactory.newInstance();\n        dbf.setNamespaceAware(true);\n        dbf.setExpandEntityReferences(false);\n        final Document doc = dbf.newDocumentBuilder().parse(\n                new ByteArrayInputStream(resultBytes));\n        final XPath xpath = XPathFactory.newInstance().newXPath();\n        final String domText = (String)xpath.evaluate(\"/x/text()\", doc,\n                XPathConstants.STRING);\n        System.out.println(\"============== DOM results:\");\n        testText(domText);\n    }\n}\n```\n\nIt's pretty straightforward to run if you have all the implementations in your classpath. I use the following pom:\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>foobar</groupId>\n  <artifactId>stax-stuff</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n\n  <dependencies>\n    <dependency>\n      <groupId>com.fasterxml.woodstox</groupId>\n      <artifactId>woodstox-core</artifactId>\n      <version>5.0.1</version>\n    </dependency>\n    <dependency>\n      <groupId>xerces</groupId>\n      <artifactId>xercesImpl</artifactId>\n      <version>2.11.0</version>\n    </dependency>\n    <dependency>\n      <groupId>com.fasterxml</groupId>\n      <artifactId>aalto-xml</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <plugins>\n      <plugin>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <version>3.3</version>\n        <configuration>\n          <source>1.8</source>\n          <target>1.8</target>\n        </configuration>\n      </plugin>\n      </plugins>\n  </build>\n</project>\n```\n\nOutput:\n\n```\n************** Trying AALTO **************\n-------------- Factory classes:\nXMLInputFactory=com.fasterxml.aalto.stax.InputFactoryImpl\nXMLOutputFactory=com.fasterxml.aalto.stax.OutputFactoryImpl\nXMLEventFactory=com.fasterxml.aalto.stax.EventFactoryImpl\n-------------- StAX results:\nBuffered text: [a\na]\nCode point at index 1: 13\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\nStAX XML: [<x>aa</x>]\n============== DOM results:\nBuffered text: [aa]\nCode point at index 1: 97\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\n\n************** Trying JDK **************\n-------------- Factory classes:\nXMLInputFactory=com.sun.xml.internal.stream.XMLInputFactoryImpl\nXMLOutputFactory=com.sun.xml.internal.stream.XMLOutputFactoryImpl\nXMLEventFactory=com.sun.xml.internal.stream.events.XMLEventFactoryImpl\n-------------- StAX results:\nBuffered text: [a\na]\nCode point at index 1: 13\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\nStAX XML: [<x>a\na</x>]\n============== DOM results:\nBuffered text: [a\na]\nCode point at index 1: 10\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? true\n\n************** Trying WOODSTOX **************\n-------------- Factory classes:\nXMLInputFactory=com.ctc.wstx.stax.WstxInputFactory\nXMLOutputFactory=com.ctc.wstx.stax.WstxOutputFactory\nXMLEventFactory=com.ctc.wstx.stax.WstxEventFactory\n-------------- StAX results:\nBuffered text: [a\na]\nCode point at index 1: 13\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\nStAX XML: [<x>a&#xd;a</x>]\n============== DOM results:\nBuffered text: [a\na]\nCode point at index 1: 13\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\n\n************** Trying XERCES **************\n-------------- Factory classes:\nXMLInputFactory=com.sun.xml.internal.stream.XMLInputFactoryImpl\nXMLOutputFactory=com.sun.xml.internal.stream.XMLOutputFactoryImpl\nXMLEventFactory=org.apache.xerces.stax.XMLEventFactoryImpl\n-------------- StAX results:\nBuffered text: [a\na]\nCode point at index 1: 13\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? false\nStAX XML: [<x>a\na</x>]\n============== DOM results:\nBuffered text: [a\na]\nCode point at index 1: 10\nBuffered text equals input text? false\nBuffered text equals expanded text? false\nBuffered text has \\n for \\r? true\n```\n"
            },
            "3": {
                "commit_sha_buggy": "4f4e4b3a0e43bb233e50c9f6d0367879a49f9a5e",
                "commit_sha_fixed": "9b43cf2766b5be1234c0d0bafb07876b773eecec",
                "report_id": "46",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/46",
                "issue_title": "3-byte Unicode character causes an extra character to be appended by `XMLStreamWriter2.writeRaw()`",
                "issue_description": "Consider the following XML fragment `<problem>Left \u2265 Right</problem>.`\r\n\r\nWhen setting the encoding to UTF-8 and using the XmlStreamWrite2.writeRaw method, the result is that the XML output now contains an e following the \"greater than or equal to\" sign: `<problem>Left \u2265e Right</problem>`.\r\n\r\nHere is a unit test to demonstrate the problem. Note that I am using the jdk1.8.0_74 in Windows 10. Also, I am using version 1.0 of aalto, 'com.fasterxml:aalto-xml:1.0.0.'\r\n\r\n``` java\r\n@Test\r\npublic void testSerialization_failsWithUtf8() throws Exception {\r\n\r\n    final String input = \"<problem>Left \u2265 Right</problem>\";\r\n\r\n    final XMLOutputFactory2 outputFactory = new OutputFactoryImpl();\r\n    final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\r\n    final XMLStreamWriter2 xmlStreamWriter =\r\n            (XMLStreamWriter2) outputFactory.createXMLStreamWriter(byteArrayOutputStream, \"utf-8\");\r\n\r\n    xmlStreamWriter.writeStartElement(\"example\");\r\n    xmlStreamWriter.writeRaw(input);\r\n    xmlStreamWriter.writeEndElement();\r\n    xmlStreamWriter.flush();\r\n\r\n    final String result = byteArrayOutputStream.toString(\"utf-8\");\r\n    System.out.print(result);\r\n\r\n    assertThat(result).isEqualToIgnoringCase(\"<example><problem>Left \u2265e Right</problem></example>\");\r\n    // Why is there an e added after the \u2265 character, a valid UTF-8 character (see\r\n    // http://www.fileformat.info/info/unicode/char/2265/index.htm)?\r\n\r\n    byteArrayOutputStream.close();\r\n    xmlStreamWriter.closeCompletely();\r\n}\r\n```\r\n\r\nI wrote 2 additional unit tests to show workarounds I found. The first workaround is to change the encoding to UTF-16.\r\n``` java\r\n@Test\r\npublic void testSerialization_worksWithUtf16() throws Exception {\r\n\r\n    final String input = \"<problem>Left \u2265 Right</problem>\";\r\n\r\n    final XMLOutputFactory2 outputFactory = new OutputFactoryImpl();\r\n    final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\r\n    final XMLStreamWriter2 xmlStreamWriter =\r\n            (XMLStreamWriter2) outputFactory.createXMLStreamWriter(byteArrayOutputStream, \"utf-16\");\r\n\r\n    xmlStreamWriter.writeStartElement(\"example\");\r\n    xmlStreamWriter.writeRaw(input);\r\n    xmlStreamWriter.writeEndElement();\r\n    xmlStreamWriter.flush();\r\n\r\n    final String result = byteArrayOutputStream.toString(\"utf-16\");\r\n    System.out.print(result);\r\n\r\n    assertThat(result).isEqualToIgnoringCase(\"<example><problem>Left \u2265 Right</problem></example>\");\r\n\r\n    byteArrayOutputStream.close();\r\n    xmlStreamWriter.closeCompletely();\r\n}\r\n```\r\n\r\nMy 3rd and final unit test shows that to keep the encoding as UTF-8, I can use a reader and copy the events instead of using the writeRaw string. It's safer, but it's slower too.\r\n``` java\r\n@Test\r\npublic void testSerialization_worksWithUtf8WithReader() throws Exception {\r\n\r\n    final String input = \"<example><problem>Left \u2265 Right</problem></example>\";\r\n    final XMLInputFactory2 inputFactory = new InputFactoryImpl();\r\n    final XMLStreamReader2 xmlStreamReader = (XMLStreamReader2) inputFactory.createXMLStreamReader(\r\n            IOUtils.toInputStream(input, \"utf-8\"));\r\n\r\n    final XMLOutputFactory2 outputFactory = new OutputFactoryImpl();\r\n    final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\r\n    final XMLStreamWriter2 xmlStreamWriter =\r\n            (XMLStreamWriter2) outputFactory.createXMLStreamWriter(byteArrayOutputStream, \"utf-8\");\r\n\r\n    while (xmlStreamReader.hasNext()) {\r\n        xmlStreamReader.next();\r\n        xmlStreamWriter.copyEventFromReader(xmlStreamReader, true);\r\n    }\r\n    xmlStreamWriter.flush();\r\n    xmlStreamReader.closeCompletely();\r\n\r\n    final String result = byteArrayOutputStream.toString(\"utf-8\");\r\n    System.out.print(result);\r\n\r\n    assertThat(result).isEqualToIgnoringCase(\"<example><problem>Left \u2265 Right</problem></example>\");\r\n\r\n    byteArrayOutputStream.close();\r\n    xmlStreamWriter.closeCompletely();\r\n}\r\n```"
            },
            "4": {
                "commit_sha_buggy": "ba4fe1e0e2272ab59a6087b5800ac75b95c25823",
                "commit_sha_fixed": "bb0f5e2448a43ddb29c00073669e39b420976790",
                "report_id": "47",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/47",
                "issue_title": "NPE when trying to parse document with DTD declaration",
                "issue_description": "Currently I get a NPE when I try to do this. I don't need validation, so I can ignore the DTD declarations. Is there a setting for this in aalto-xml?"
            },
            "5": {
                "commit_sha_buggy": "462e2f27898dd4eb597a042fb03c2e0066b99223",
                "commit_sha_fixed": "4f4e4b3a0e43bb233e50c9f6d0367879a49f9a5e",
                "report_id": "45",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/45",
                "issue_title": "Unicode: surrogate pairs encoded invalidly after x number of chars",
                "issue_description": "The problem here is that the character Kappa starts being encoded as xml entities, unfortunately this is an non valid character encoding. I don't understand why this is happening and why it happens after X characters instead of at any point.\r\n\r\n```\r\n@Test\r\npublic void tooManyKappas()\r\n\t throws XMLStreamException\r\n{\r\n\tXMLOutputFactory factory = OutputFactoryImpl.newInstance();\r\n\tif (factory instanceof OutputFactoryImpl) {\r\n\t     ((OutputFactoryImpl) factory).configureForSpeed();\r\n        }\r\n        //loop to find exactly at which point entity encoding kicks in.\r\n\tfor (int j = 0; j < 1000; j++) {\r\n\t\tfinal ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n\t\tXMLStreamWriter writer = factory.createXMLStreamWriter(baos, StandardCharsets.UTF_8.name());\r\n\r\n\t\tfinal String namespace = \"http://example.org\";\r\n\r\n\t\tStringBuilder kappas = new StringBuilder();\r\n\r\n\t\tfor (int i = 0; i < (2000 + j); i++) {\r\n\t\t\tkappas.append(\"\ud835\udf05\");\r\n\t\t}\r\n\t\twriter.writeStartElement(\"\", \"ex\", namespace);\r\n\t\twriter.writeCharacters(kappas.toString());\r\n\t\twriter.writeEndElement();\r\n\t\twriter.close();\r\n\r\n\t\tassertEquals(\"fails at \" + (2000 + j),\r\n\t\t\t    \"<ex>\" + kappas + \"</ex>\",\r\n\t\t\t    new String(baos.toByteArray(), StandardCharsets.UTF_8));\r\n\t}\r\n}\r\n```\r\n\r\nI hope this minimized test case is off help. It's definitely due to something internal to aalto. WSTX does not have this issue (or at a much higher loop number...).\r\n\r\nThe problem really is that aalto-xml reader does not deal with its own output in this case. Which is correct as its the writer that is wrong."
            },
            "6": {
                "commit_sha_buggy": "f5607db7b45d3d70ef2c5db15b1f6c2fe944b109",
                "commit_sha_fixed": "ddeb949017a2832448d7adae56c9bff3af4a96b5",
                "report_id": "78",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/78",
                "issue_title": "Async parsing turns &quot; inside element content into apostrophe",
                "issue_description": "This issue does not occur in 1.2.2. It is present in 1.3.1. I'm told it's also present in 1.3.0, but I haven't confirmed that myself.\r\n\r\nI think I can see the code that's doing this, and that it's been in place for a long time. Wondering if maybe other fixes in 1.3.x have caused this long-standing bug to surface where before it was hidden?\r\n\r\nSee:\r\n* https://github.com/FasterXML/aalto-xml/blob/f5607db7b45d3d70ef2c5db15b1f6c2fe944b109/src/main/java/com/fasterxml/aalto/async/AsyncByteBufferScanner.java#L2401\r\n* https://github.com/FasterXML/aalto-xml/blob/f5607db7b45d3d70ef2c5db15b1f6c2fe944b109/src/main/java/com/fasterxml/aalto/async/AsyncByteBufferScanner.java#L2957\r\n\r\nAlso two locations in `AsyncByteArrayScanner.java`"
            },
            "7": {
                "commit_sha_buggy": "381c2b5f80351c97a88610ebce32f101d550e326",
                "commit_sha_fixed": "f11b1fdd29a2ce1426c45726453bdd49e1a65a78",
                "report_id": "10",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/10",
                "issue_title": "support for capturing  EVENT_INCOMPLETE with XMLEventReader",
                "issue_description": "I have just been trying to use Aalto's parser with Jena's RDF parsers.\nI asked the Jena group what was the best way to do that and we thought that\nadapting the StaX2SAX would probably do it.\n\nhttp://svn.apache.org/viewvc/incubator/jena/Jena2/jena/trunk/src/main/java/com/hp/hpl/jena/rdf/arp/StAX2SAX.java?revision=1198759&view=markup\n\nSo I worked today on this and ended up with this gist\n\n  https://gist.github.com/1713430\n\nIt seems to be close to working.\n\n  but we get an exception on line 82\n\nXMLEvent e = eventReader.nextEvent();\n\njavax.xml.stream.XMLStreamException: Unrecognized event type 257.\n    at org.codehaus.stax2.ri.evt.Stax2EventAllocatorImpl.allocate(Stax2EventAllocatorImpl.java:85)\n    at org.codehaus.stax2.ri.Stax2EventReaderImpl.createStartDocumentEvent(Stax2EventReaderImpl.java:441)\n    at org.codehaus.stax2.ri.Stax2EventReaderImpl.nextEvent(Stax2EventReaderImpl.java:245)\n    at patch.AsyncJenaParser.parse(AsyncJenaParser.java:82)\n\nThis is I suppose because I am transforming the AsyncXMLStreamReader into an\nXMLEventReader as that is the closest to the the way the Jena code was written. You can\nsee this in the constructor \n\n   public AsyncJenaParser(ContentHandler handler, AsyncXMLStreamReader streamReader) throws XMLStreamException {\n        this.handler = handler;\n        this.lhandler = (handler instanceof LexicalHandler) ?\n                (LexicalHandler) handler :\n                NO_LEXICAL_HANDLER ;\n        handler.setDocumentLocator(new LocatorConv(streamReader));\n        final XMLInputFactory xf = InputFactoryImpl.newInstance();\n        this.streamReader = streamReader;\n        this.eventReader = xf.createXMLEventReader(streamReader);\n    }\n\nSo this is not SAX parsing. It is just using an event reader instead of the stream reader. The class is used currently by the following Scala code which extends the com.ning.http.AsyncHandler \n\n  https://gist.github.com/1713663\n"
            },
            "8": {
                "commit_sha_buggy": "9b43cf2766b5be1234c0d0bafb07876b773eecec",
                "commit_sha_fixed": "ead5f2a1710b85cb505d492601d6dafee7d03e1b",
                "report_id": "52",
                "report_url": "https://github.com/FasterXML/aalto-xml/issues/52",
                "issue_title": "Non-informative fail message for multiple root elements, in async parsing mode",
                "issue_description": "(as per #48 and #49)\r\n\r\nIt looks like error message given when trying to parser non-well-formed XML content, consisting of more than one root element, is not giving much usable information. It seems like this particular case could and should be improved to help developers more easily detect issues.\r\n\r\n"
            },
            "9": {
                "commit_sha_buggy": "10189114db1cc327aa3ecd82e73843fcb63a0394",
                "commit_sha_fixed": "0f801121285205eaefcc3c00ad243c6e680ed02b",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix of https://github.com/FasterXML/aalto-xml/issues/40",
                "issue_description": "Fix of https://github.com/FasterXML/aalto-xml/issues/40"
            }
        }
    },
    "HttpClient5": {
        "owner_repo": "apache/httpcomponents-client",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a2cc0a511bb2a38cc37a0f351944d6b19036fa67",
                "commit_sha_fixed": "56cc24525e5ba2a5ef8fa0de2385687e83589a71",
                "report_id": "HTTPCLIENT-1906",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-1906",
                "issue_title": "[HTTPCLIENT-1906] HttpClient rejects valid certificates with subjectAltNames - ASF JIRA",
                "issue_description": "\nA certificate containing only an email address (declared as rfc822Name) in subjectAltName gets rejected. This change was introduced with\u00a0HTTPCLIENT-1802.\nHttpClient should fall back onto CN for hostname verification instead of rejecting the certificate as invalid.\nExample certificate which gets rejected:\n\n-----BEGIN CERTIFICATE-----\r\nMIIDpTCCAo2gAwIBAgIJANqkMEtlkelbMA0GCSqGSIb3DQEBCwUAMHAxCzAJBgNV\r\nBAYTAlVTMQswCQYDVQQIDAJWQTERMA8GA1UEBwwIU29tZUNpdHkxEjAQBgNVBAoM\r\nCU15Q29tcGFueTETMBEGA1UECwwKTXlEaXZpc2lvbjEYMBYGA1UEAwwPd3d3LmNv\r\nbXBhbnkuY29tMB4XDTE4MDIxNTA3MjkzMFoXDTIwMDIxNTA3MjkzMFowcDELMAkG\r\nA1UEBhMCVVMxCzAJBgNVBAgMAlZBMREwDwYDVQQHDAhTb21lQ2l0eTESMBAGA1UE\r\nCgwJTXlDb21wYW55MRMwEQYDVQQLDApNeURpdmlzaW9uMRgwFgYDVQQDDA93d3cu\r\nY29tcGFueS5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC4v6Oq\r\nUa0goRVn1cmT7MOpJhXFm3A70bTpvJIRpEjtGIz99hb34/9r5AYyf1VhKyWmBq24\r\nXNcOJ59XOlyjjbm2Tl811ufTOdcNbPadoVBmMt4039OSUFpVb4wAw2XPWLTCG2h1\r\nHNj9GuFHmwcDsg5EiIRrhDGQm2LLLAGoe5PdReoMZCeeWzNWvKTCV14pyRzwQhJL\r\nF1OmzLYzovbPfB8LZVhQgDbLsh034FScivf2oKDB+NEzAEagNpnrFR0MFLWGYsu1\r\nnWD5RiZi78HFGiibmhH7QrEPfGlo2eofuUga6naoBUROqkmMCIL8n1HZ/Ur0oGny\r\nvQCj1AyrfOhuVC53AgMBAAGjQjBAMAsGA1UdDwQEAwIEMDATBgNVHSUEDDAKBggr\r\nBgEFBQcDATAcBgNVHREEFTATgRFlbWFpbEBleGFtcGxlLmNvbTANBgkqhkiG9w0B\r\nAQsFAAOCAQEAZ0IsqRrsEmJ6Fa9Yo6PQtrKJrejN2TTDddVgyLQdokzWh/25JFad\r\nNCMYPH5KjTUyKf96hJDlDayjbKk1PMMhSZMU5OG9NOuGMH/dQttruG1ojse7KIKg\r\nyHDQrfq5Exxgfa7CMHRKAoTCY7JZhSLyVbTMVhmGfuUDad/RA86ZisXycp0ZmS97\r\nqDkAmzFL0sL0ZUWNNUh4ZUWvCUZwiuN08z70NjGqXMTDCf68p3SYxbII0xTfScgf\r\naQ/A/hD7IbGGTexeoTwpEj01DNvefbQV6//neo32/R5XD0D5jn3TCgZcMThA6H3a\r\nVkEghVg+s7uMfL/UEebOBQWXQJ/uVoknMA==\r\n-----END CERTIFICATE-----\n\nA unit test demonstrating\u00a0the issue: https://github.com/asigner/httpcomponents-client/commit/e2e5c422ad201fc4a4df07e05ffda522ed626008\nSee http://mail-archives.apache.org/mod_mbox/hc-httpclient-users/201802.mbox/%3cCAG5G_q+fh1p54gOO=_kLN09+9RizCfXGpmfEvUE3iQ3rp8ifxg@mail.gmail.com%3e\n"
            },
            "2": {
                "commit_sha_buggy": "50e7dd51e06b877c9378846e980b99cbef2eafbb",
                "commit_sha_fixed": "7824d98d0ca8aa4bed14d70c01c544ac544d4170",
                "report_id": "HTTPCLIENT-1958",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-1958",
                "issue_title": "[HTTPCLIENT-1958] Thread interrupt flag leaking when aborting httpRequest during connection leasing stage - ASF JIRA",
                "issue_description": "\nWhen calling HttpRequestBase#abort during the leasing connection phase, the thread is being interrupted and `RequestAbortedException`\u00a0will be thrown.\nIt\u00a0is an unexpected behavior that aborting the http request would cause the interrupt flag to be set on\u00a0the caller thread.\nHere is what happened looking from the source code of 4.5.5,\u00a0\n\nAborting the request invokes future.cancel(true) and it throws InterruptedException https://github.com/apache/httpcomponents-client/blob/4.5.5/httpclient/src/main/java/org/apache/http/impl/conn/PoolingHttpClientConnectionManager.java#L272\u00a0\nInterruptedException is caught in MainClientExec\u00a0and then it re-interrupts the thread and throws RequestAbortedException\n\nThe second step is expected and the first step seems to be the root cause.\u00a0Should we use `future.cancel(false)` instead as it causes the side effect for a simple httprequest#abort to interrupt the caller's thread?\n\u00a0\nCode to reproduce:\nScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(1);\ntry (\n\u00a0 \u00a0 \u00a0PoolingHttpClientConnectionManager poolingHttpClientConnectionManager = new PoolingHttpClientConnectionManager();\n\u00a0 \u00a0 \u00a0 CloseableHttpClient httpclient = HttpClients.custom().setConnectionManager(poolingHttpClientConnectionManager).build()) \n{\r\n\u00a0 \u00a0 \u00a0\r\n\r\n\u00a0 \u00a0 HttpGet httpGet = new HttpGet(\"https://somehost.com\");\r\n\r\n\u00a0 \u00a0// Aborting the request when it's getting a connection from the connection pool\r\n\u00a0 \u00a0 \u00a0 scheduledExecutorService.schedule(httpGet::abort, 40, TimeUnit.MILLISECONDS);\r\n\u00a0 \u00a0 \u00a0 CloseableHttpResponse response = httpclient.execute(httpGet);\r\n\r\n\u00a0 \u00a0 \u00a0 HttpEntity entity = response.getEntity();\r\n\u00a0 \u00a0 \u00a0 EntityUtils.consume(entity);\r\n\u00a0 \u00a0}\n catch (Exception e) \n{\r\n\u00a0 \u00a0 \u00a0 \u00a0e.printStackTrace();\r\n\u00a0 \u00a0}\n finally \n{\r\n\u00a0 \u00a0scheduledExecutorService.shutdown();\r\n\u00a0 \u00a0}\n\nSystem.out.println(\"Interrupted ?\" + Thread.currentThread().isInterrupted());\n\u00a0\n"
            },
            "4": {
                "commit_sha_buggy": "3575cff3dc77f80557e9a2264ffa38a696379743",
                "commit_sha_fixed": "4401991d93e1c4979cf8931e343323f97c335608",
                "report_id": "HTTPCLIENT-2047",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-2047",
                "issue_title": "[HTTPCLIENT-2047] Regression in default HTTP Client construction for non-public hostnames - ASF JIRA",
                "issue_description": "\nI believe that the result of:\n\u00a0\nhttps://github.com/apache/httpcomponents-client/commit/b184b244ad9342a384ba87f48c6b48805a3b0f1f\nand:\nhttps://github.com/apache/httpcomponents-client/commit/e0416f07c344929699a2bc303eb3a049c62bd979\n\u00a0\nCaused a regression which prevents non-public hostnames from validating, resulting in errors like (I have redacted hostnames as possible):\n\n\r\n\r\nCertificate for <hostname-workspace-1.ops.domain.local> doesn't match any of the subject alternative names: [user-id-60662, hostname-workspace-1.ops.domain.local, 127.0.0.1, 10.2.243.75]\r\n\r\n \n\nThis is because the default value of ICANN is now supplied to the PublicSuffixMatcher, which causes it to only accept publicly accessible hostnames now (or so it seems).\n"
            },
            "5": {
                "commit_sha_buggy": "3e484c083064c7718f694d870aca2448e40adcc5",
                "commit_sha_fixed": "12ec6f15ea30cfa8e7a1b59f143adde3b175fcaf",
                "report_id": "HTTPCLIENT-2076",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-2076",
                "issue_title": "[HTTPCLIENT-2076] LaxExpiresHandler throws NullPointerException when a value is null. - ASF JIRA",
                "issue_description": "\nHi. I'm using RFC6265LaxSpec and would like to report two issues.\n1. LaxExpiresHandler throws NullPointerException when a value is null.\nThis line line is causing NPE.\nYou can easily reproduce this, with the following Set-Cookie string.\nSet-Cookie: gtinfo=info; Expires; domain=.webmd.com; path=/\nI think We need to check whether value is blank just like how LaxMaxAgeHandler is doing.\nhttps://github.com/apache/httpcomponents-client/blob/master/httpclient5/src/main/java/org/apache/hc/client5/http/impl/cookie/LaxMaxAgeHandler.java#L60\n2. We need to 'ignore' invalid attributes only.\nLaxExpiresHandler throws MalformedCookieException when attribute is not valid, so the cookie with invalid Expires attributes is ignored entirely. But\u00a0RFC 6265 says, 'If the attribute-value failed to parse as a cookie date, ignore the cookie-av.'\u00a0\nI think we should not throw MalformedCookieException but just ignore invalid attributes only. LaxMaxAgeHandler is also already doing this.\nhttps://github.com/apache/httpcomponents-client/blob/master/httpclient5/src/main/java/org/apache/hc/client5/http/impl/cookie/LaxMaxAgeHandler.java#L69\nhttps://github.com/apache/httpcomponents-client/blob/master/httpclient5/src/main/java/org/apache/hc/client5/http/impl/cookie/LaxMaxAgeHandler.java#L61\nFollowings are the classes needs to be considered.\n\nBasicExpiresHandler\nBasicMaxAgeHandler\nLaxExpiresHandler\n\nThanks.\n"
            },
            "6": {
                "commit_sha_buggy": "e26d5376587a6c9873bd8d45a18b3d4d4ac10052",
                "commit_sha_fixed": "76a12fc4c680b25b1c3820b78069967fd0901a22",
                "report_id": "HTTPCLIENT-2077",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-2077",
                "issue_title": "[HTTPCLIENT-2077] Migration from HttpClient v4.5.x to v5.0 causes NTLM proxy authentication failure - ASF JIRA",
                "issue_description": "\nUpgrade of HttpClient from v4.5.x to v5.0 causes a NTLM proxy authentication failure (s. attached test class\u00a0NtlmProxyAuthenticationTest.java\u00a0with generated\u00a0log file\u00a0NtlmProxyAuthenticationTest.log).\nError logged:\u00a0\n\n\r\n01:27:20.360 [main] DEBUG org.apache.hc.client5.http.impl.auth.HttpAuthenticator - Authentication failed\r\n----------------------------------------\r\n407 authenticationrequired\r\n\u00a0\r\n\n\n\u00a0\nThe same class implemented with HttpClient v4.5.x does not have any proxy issues and connects to the target as expected.\n\u00a0\n"
            },
            "7": {
                "commit_sha_buggy": "5bdcb242f0297c9dca8f6284ed5a4dd062a210b7",
                "commit_sha_fixed": "ff6308a69fe2d0db8342c2962a910fee6ff698fc",
                "report_id": "HTTPCLIENT-2100",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-2100",
                "issue_title": "[HTTPCLIENT-2100] MultipartEntityBuilder would not support HttpRFC6532Multipart - ASF JIRA",
                "issue_description": "\nIn HttpClient 5.0.1\ni read the\u00a0MultipartEntityBuilder's source code,\n\n\r\ncase EXTENDED:\r\n    if (ContentType.MULTIPART_FORM_DATA.isSameMimeType(ContentType.MULTIPART_FORM_DATA)) {\r\n        if (charsetCopy == null) {\r\n            charsetCopy = StandardCharsets.UTF_8;\r\n        }\r\n        form = new HttpRFC7578Multipart(charsetCopy, boundaryCopy, multipartPartsCopy);\r\n    } else {\r\n        form = new HttpRFC6532Multipart(charsetCopy, boundaryCopy, multipartPartsCopy);\r\n    }\r\n    break;\r\n\n\nso, the\u00a0HttpRFC6532Multipart would never be used,\nbecause of\u00a0ContentType.MULTIPART_FORM_DATA == ContentType.MULTIPART_FORM_DATA!?\n"
            },
            "8": {
                "commit_sha_buggy": "c6a4a9b376c4366c85e04f7c233828a154831488",
                "commit_sha_fixed": "a22d889807eb74a0d4b8dd8d6360802a391a6eb3",
                "report_id": "HTTPCLIENT-2083",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCLIENT-2083",
                "issue_title": "[HTTPCLIENT-2083] HttpClientBuilder addExecInterceptorFirst and addExecInterceptorLast NPE - ASF JIRA",
                "issue_description": "\nCalling HttpClientBuilder.addExecInterceptorFirst or HttpClientBuilder.addExecInterceptorLast without first using addExecInterceptorBefore, addExecInterceptorBefore, or replaceExecInterceptor results in a NullPointerException.\nUnlike other builder methods addExecInterceptorFirst and addExecInterceptorLast do not first do a null check to conditionally initialize the interceptors list.\n"
            }
        }
    },
    "jackson_modules_java8_datetime": {
        "owner_repo": "FasterXML/jackson-modules-java8",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2ef7c25e933f2386b7f540266f61fd8714bce2fb",
                "commit_sha_fixed": "22acd5953ba95face689346420906d5762bb37e2",
                "report_id": "148",
                "report_url": "https://github.com/FasterXML/jackson-modules-java8/issues/148",
                "issue_title": "Allow strict `LocalDate` parsing",
                "issue_description": "Per default `LocalDateDeserializer` deserializes local dates using `DateTimeFormatter.ISO_LOCAL_DATE` formatter. This formatter uses `ResolverStyle.STRICT`. \r\n\r\n```\r\n    /**\r\n     * Style to resolve dates and times strictly.\r\n     * <p>\r\n     * Using strict resolution will ensure that all parsed values are within\r\n     * the outer range of valid values for the field. Individual fields may\r\n     * be further processed for strictness.\r\n     * <p>\r\n     * For example, resolving year-month and day-of-month in the ISO calendar\r\n     * system using strict mode will ensure that the day-of-month is valid\r\n     * for the year-month, rejecting invalid values.\r\n     */\r\n    STRICT,\r\n```\r\n\r\nIf I use `@JsonFormat` (i.e. `@JsonFormat(pattern = \"yyyy-MM-dd\", lenient = OptBoolean.FALSE)`) the created DateTimeFormatter uses `ResolverStyle.SMART`. It accepts invalid dates like `2019-11-31`. \r\nThe default formatter does not accept such dates and throws an error.\r\n\r\nTo make the behaviour consistent, I suggest setting the `DateTimeFormatter` to use `ResolverStyle.STRICT` if the lenient attribute is set to `false`."
            },
            "2": {
                "commit_sha_buggy": "bc966f9622861758cb4da58aa7924c644086d7b7",
                "commit_sha_fixed": "3d20752aa23eb5fa7f89bd8def4576741b52fa14",
                "report_id": "196",
                "report_url": "https://github.com/FasterXML/jackson-modules-java8/issues/196",
                "issue_title": "`@JsonFormat` overriden features don't apply when there are no other options while deserializing ZonedDateTime ",
                "issue_description": "After deserializing a following class:\r\n```\r\n    static class WrapperWithFeatures {\r\n        @JsonFormat(without = JsonFormat.Feature.ADJUST_DATES_TO_CONTEXT_TIME_ZONE)\r\n        public ZonedDateTime value;\r\n\r\n        public WrapperWithFeatures() { }\r\n        public WrapperWithFeatures(ZonedDateTime v) { value = v; }\r\n    }\r\n```\r\n`value` field should preserve timezone from the source - but it doesn't. Following test fails:\r\n```\r\n    @Test\r\n    public void testDeserializationWithZonePreserved() throws Throwable\r\n    {\r\n        WrapperWithFeatures wrapper = JsonMapper.builder()\r\n                .addModule(new JavaTimeModule())\r\n                .build()\r\n                .readerFor(WrapperWithFeatures.class)\r\n                .readValue(\"{\\\"value\\\":\\\"2000-01-01T12:00+01:00\\\"}\");\r\n        assertEquals(\"Timezone should be preserved.\",\r\n                ZonedDateTime.of(2000, 1, 1, 12, 0, 0 ,0, ZoneOffset.ofHours(1)),\r\n                wrapper.value);\r\n    }\r\n```"
            },
            "3": {
                "commit_sha_buggy": "9532f8f4e1ce975b9b43f63fbfae55ccfece46e6",
                "commit_sha_fixed": "ed2155003869c59dfc79ee4392376ce2bdfa11f4",
                "report_id": "127",
                "report_url": "https://github.com/FasterXML/jackson-modules-java8/issues/127",
                "issue_title": "ZonedDateTime in map keys ignores option to write Zone IDs ",
                "issue_description": "As of v2.9.9, the following fails:\r\n\r\n```java\r\nclass Sample {\r\n    private Map<ZonedDateTime, ZonedDateTime> map;\r\n    private ZonedDateTime dateTime;\r\n\r\n    public Sample() {\r\n    }\r\n\r\n    public ZonedDateTime getDateTime() {\r\n        return dateTime;\r\n    }\r\n\r\n    public void setDateTime(ZonedDateTime dateTime) {\r\n        this.dateTime = dateTime;\r\n    }\r\n\r\n    public Map<ZonedDateTime, ZonedDateTime> getMap() {\r\n        return map;\r\n    }\r\n\r\n    public void setMap(Map<ZonedDateTime, ZonedDateTime> map) {\r\n        this.map = map;\r\n    }\r\n}\r\n\r\npublic class JacksonTest {\r\n\r\n    @Test\r\n    public void shouldSerializeZoneIdInMapKeys() throws IOException {\r\n        // given\r\n        final ObjectMapper objectMapper = new ObjectMapper();\r\n        objectMapper.registerModule(new Jdk8Module());\r\n        objectMapper.registerModule(new JavaTimeModule());\r\n        objectMapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\r\n        objectMapper.enable(SerializationFeature.WRITE_DATES_WITH_ZONE_ID);\r\n\r\n        final ZonedDateTime datetime = ZonedDateTime.parse(\"2007-12-03T10:15:30+01:00[Europe/Warsaw]\");\r\n        final HashMap<ZonedDateTime, ZonedDateTime> map = new HashMap<>();\r\n        map.put(datetime, datetime);\r\n        final Sample sample = new Sample();\r\n        sample.setMap(map);\r\n        sample.setDateTime(datetime);\r\n\r\n        // when\r\n        final String value = objectMapper.writeValueAsString(sample);\r\n\r\n        // then\r\n        assertThat(value).isEqualTo(\"{\\\"map\\\":\" +\r\n                \"{\\\"2007-12-03T10:15:30+01:00[Europe/Warsaw]\\\":\\\"2007-12-03T10:15:30+01:00[Europe/Warsaw]\\\"},\" +\r\n                \"\\\"dateTime\\\":\\\"2007-12-03T10:15:30+01:00[Europe/Warsaw]\\\"\" +\r\n                \"}\");\r\n    }\r\n}\r\n```\r\n\r\nI'd expect that Zone ID is written not only in map keys but also in map values. \r\nCurrently `SerializationFeature.WRITE_DATES_WITH_ZONE_ID` has no impact on map keys.\r\n\r\nSample project:\r\n[test.zip](https://github.com/FasterXML/jackson-modules-java8/files/3491978/test.zip)\r\n\r\n\r\n\r\n"
            },
            "4": {
                "commit_sha_buggy": "4ecf483af6efa49a7d4b3558d8bf49692e84a5c6",
                "commit_sha_fixed": "05d87805757fe8837834a4b6c2b587b93d851071",
                "report_id": "78",
                "report_url": "https://github.com/FasterXML/jackson-modules-java8/issues/78",
                "issue_title": "Year deserialization ignores `@JsonFormat` pattern",
                "issue_description": "Jackson version: 2.9.3\r\nJackson datatype version: 2.9.6\r\n\r\nExample of the `@JsonFormat` definition:\r\n```java\r\npublic class ObjectTest {\r\n   @JsonFormat(shape = JsonFormat.Shape.STRING, pattern = \"'Y'yyyy\")\r\n    private Year customYear;\r\n   // Getters and setters\r\n}\r\n```\r\n\r\nTest example:\r\n```java\r\nObjectTest object = new ObjectTest();\r\nobject.setCustomYear(Year.of(2018));\r\nObjectMapper objectMapper = new ObjectMapper().registerModule(new JavaTimeModule());\r\nString json = objectMapper.writeValueAsString(object); // OK -> \"{\\\"customYear\\\":\\\"Y2018\\\"}\";\r\nobject = objectMapper.readValue(json, ObjectTest.class); // ERROR -> Throws exception\r\n```\r\n\r\n**Possibly related to**: https://github.com/FasterXML/jackson-modules-java8/issues/51\r\n\r\nStack trace:\r\n```java\r\ncom.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.time.Year` from String \"Y2018\": Failed to deserialize java.time.Year: (java.time.format.DateTimeParseException) Text 'Y2018' could not be parsed at index 0\r\n at [Source: (String)\"{\"customYear\":\"Y2018\"}\"; line: 1, column: 15] (through reference chain: com.devdevx.examples.jackson.domain.javatime.JavaTime[\"customYear\"])\r\n\r\n\tat com.fasterxml.jackson.databind.exc.InvalidFormatException.from(InvalidFormatException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.weirdStringException(DeserializationContext.java:1548)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleWeirdStringValue(DeserializationContext.java:910)\r\n\tat com.fasterxml.jackson.datatype.jsr310.deser.JSR310DeserializerBase._handleDateTimeException(JSR310DeserializerBase.java:80)\r\n\tat com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer.deserialize(YearDeserializer.java:64)\r\n\tat com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer.deserialize(YearDeserializer.java:34)\r\n\tat com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:127)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:287)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:151)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4001)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2992)\r\n\tat com.devdevx.examples.jackson.domain.JsonTest.toObject(JsonTest.java:38)\r\n\tat com.devdevx.examples.jackson.domain.javatime.JavaTimeTest.customYearJsonToObject(JavaTimeTest.java:279)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:515)\r\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:115)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:170)\r\n\tat org.junit.jupiter.engine.execution.ThrowableCollector.execute(ThrowableCollector.java:40)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:166)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:113)\r\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:58)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:134)\r\n\tat org.junit.platform.engine.support.hierarchical.SingleTestExecutor.executeSafely(SingleTestExecutor.java:66)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:128)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:109)\r\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:138)\r\n\tat org.junit.platform.engine.support.hierarchical.SingleTestExecutor.executeSafely(SingleTestExecutor.java:66)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:128)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:109)\r\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:138)\r\n\tat org.junit.platform.engine.support.hierarchical.SingleTestExecutor.executeSafely(SingleTestExecutor.java:66)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:128)\r\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:109)\r\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32)\r\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:49)\r\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:47)\r\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:170)\r\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:154)\r\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:90)\r\n\tat com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:62)\r\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\r\nCaused by: java.time.format.DateTimeParseException: Text 'Y2018' could not be parsed at index 0\r\n\tat java.time.format.DateTimeFormatter.parseResolved0(DateTimeFormatter.java:1949)\r\n\tat java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1851)\r\n\tat java.time.Year.parse(Year.java:292)\r\n\tat java.time.Year.parse(Year.java:277)\r\n\tat com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer.deserialize(YearDeserializer.java:60)\r\n\t... 45 more\r\n```\r\n\r\n"
            },
            "5": {
                "commit_sha_buggy": "0e6702c5d8f31ccbab320e1903a4d5bf7c205864",
                "commit_sha_fixed": "67e06eec44ed94e6eeaf84e7eaca334120136141",
                "report_id": "166",
                "report_url": "https://github.com/FasterXML/jackson-modules-java8/issues/166",
                "issue_title": "Cannot deserialize `OffsetDateTime.MIN` or `OffsetDateTime.MAX` with `ADJUST_DATES_TO_CONTEXT_TIME_ZONE` enabled",
                "issue_description": "This probably relates to #124.\r\n\r\nI cannot deserialize `OffsetDateTime.MIN` and `OffsetDateTime.MAX`.\r\n\r\nWith `jackson-databind` and `jackson-datatype-jsr310` (both 2.10.3) on my class path the following works:\r\n```\r\nObjectMapper o = new ObjectMapper();\r\no.findAndRegisterModules();\r\no.readValue(\"\\\"\" + OffsetDateTime.now().toString() + \"\\\"\", OffsetDateTime.class);\r\n```\r\nThe following does __not__ work:\r\n```\r\n// (OffsetDateTime.MIN is -999999999-01-01T00:00+18:00)\r\no.readValue(\"\\\"\" + OffsetDateTime.MIN.toString() + \"\\\"\", OffsetDateTime.class);\r\n// Or:\r\n// (OffsetDateTime.MAX is +999999999-12-31T23:59:59.999999999-18:00)\r\no.readValue(\"\\\"\" + OffsetDateTime.MAX.toString() + \"\\\"\", OffsetDateTime.class);\r\n```\r\nRemoving the offset or shifting the time by the respective amount of hours seems to work again:\r\n```\r\no.readValue(\"\\\"-999999999-01-01T00:00+18:00\\\"\", OffsetDateTime.class); // doesn't work\r\no.readValue(\"\\\"-999999999-01-01T18:00+18:00\\\"\", OffsetDateTime.class); // works\r\no.readValue(\"\\\"-999999999-01-01T00:00+00\\\"\", OffsetDateTime.class); // works\r\n```"
            }
        }
    },
    "Pdfbox_pdfbox": {
        "owner_repo": "apache/pdfbox",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "23a065c36099ae20a70b54d2e6cb854d79eb7972",
                "commit_sha_fixed": "f1ea96656c68e261d81d2c60e627916a1125d1f4",
                "report_id": "PDFBOX-821",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-821",
                "issue_title": "[PDFBOX-821] RandomAccessBuffer returns wrong values for single byte reads, patch attached - ASF JIRA",
                "issue_description": "\nRandomAccessBuffer contains a critical bug which had no effect so far since this class is currently not used. The problem is in method read() (single byte read). If the byte read is larger than 127 the method returns the signed byte value instead of the unsigned values 128-255. Thus a component using this method will assume end-of-stream.\nThe solution is to 'AND' the value with 0xff. Patch is attached.\n"
            },
            "2": {
                "commit_sha_buggy": "e73268b0809f8eb26fbb15df1c89e2bf40756962",
                "commit_sha_fixed": "aa35407128337055e41844f69b7d2a55d86dbe77",
                "report_id": "PDFBOX-1469",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-1469",
                "issue_title": "[PDFBOX-1469] [PATCH] PDPageContentStream incorrectly sets colors in CMYK color space - ASF JIRA",
                "issue_description": "\nI have a program that reads graphic commands from a postscript file and draws a logo on existing PDF pages.\nPDF commands are written using PDPageContentStream which works OK except when I pass colors in CMYK color space - in this case the colors are \"off\". \nIt appears that setStrokingColor(Color color) and setNonStrokingColor(Color color) set the magenta component wrong, they pass yellow instead. \nHere is the problematic line. Notice the second argument, it should be colorComponents[1], not colorComponents[2]\n\n\n  setStrokingColor( colorComponents[0], colorComponents[2], colorComponents[2], colorComponents[3] );\n\n\n\nThe patch and a unit test are attached.\nRegards,\nYegor\n"
            },
            "3": {
                "commit_sha_buggy": "2f5a3237200566c049cd4cead01f403879a04f4b",
                "commit_sha_fixed": "5694d51c17ff27343602387d0751fa58a1eba59e",
                "report_id": "PDFBOX-1047",
                "report_url": "https://issues.apache.org/jira/browse/PDFBOX-1047",
                "issue_title": "[PDFBOX-1047] PDPageLabels with Junks in Particular Pdf - ASF JIRA",
                "issue_description": "\nHi all.\nWhile extracting Page number with particular PDF, the last page number was with Junk values which is also extracted.\nHere by I attaching the particular PDF and kindly guide me in that particular issue.\nHere by I show my snippet of code which is working fine in all PDF but adding junk values with the particular PDF.\nCODE:\n  PDDocumentCatalog cat = pd.getDocumentCatalog();\n  String[] labels = cat.getPageLabels().getLabelsByPageIndices();\n  System.out.println(\"Hi\"+labels[0] +\"Hi\");\n   System.out.println(\"Hi\"  +labels[labels.length - 1] + \"Hi\");\nOUTPUT\nHi1Hi  Correct Output for First Page\nHi3   Orginal output for Last Page(bug)\nHi3Hi Expected output for Last Page\nKindly guide me in this issue .i attach the sample PDF with this file.\nThank you\nRegards\nKarthick.g\n"
            }
        }
    },
    "Storm_client": {
        "owner_repo": "apache/storm",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bfd10066cc86b66fe7e71c7c09b33d628bd3d20e",
                "commit_sha_fixed": "2aa415498df01b450562368d7c38643a3456189f",
                "report_id": "STORM-2511",
                "report_url": "https://issues.apache.org/jira/browse/STORM-2511",
                "issue_title": "[STORM-2511] Submitting a topology with name containing unicode getting failed. - ASF JIRA",
                "issue_description": "\nBelow error occurs when a topology name contains  unicode characters.\n\n$ storm jar WordCountTopology-1.0-SNAPSHOT.jar examples.WordCountTopology \"wordcount-\u4e2d\u6587topology\"\n2624 [main] INFO  o.a.s.StormSubmitter - Submitting topology wordcount-\u4e2d\u6587topology in distributed mode with conf \nUnknown macro: {\"storm.zookeeper.topology.auth.scheme\"} \nException in thread \"main\" java.lang.RuntimeException: AuthorizationException(msg:wordcount-\u4e2d\u6587topology-4-1483689231-stormconf.ser does not appear to be a valid blob key)\n        at org.apache.storm.StormSubmitter.submitTopologyAs(StormSubmitter.java:255)\n        at org.apache.storm.StormSubmitter.submitTopology(StormSubmitter.java:310)\n        at org.apache.storm.StormSubmitter.submitTopologyWithProgressBar(StormSubmitter.java:346)\n        at org.apache.storm.StormSubmitter.submitTopologyWithProgressBar(StormSubmitter.java:327)\n        at com.microsoft.example.KafkaReaderTop.main(KafkaReaderTop.java:39)\nCaused by: AuthorizationException(msg:wordcount-\u4e2d\u6587topology-4-1483689231-stormconf.ser does not appear to be a valid blob key)\n        at org.apache.storm.generated.Nimbus$submitTopology_result$submitTopology_resultStandardScheme.read(Nimbus.java:7628)\n        at org.apache.storm.generated.Nimbus$submitTopology_result$submitTopology_resultStandardScheme.read(Nimbus.java:7596)\n        at org.apache.storm.generated.Nimbus$submitTopology_result.read(Nimbus.java:7530)\n        at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86)\n        at org.apache.storm.generated.Nimbus$Client.recv_submitTopology(Nimbus.java:294)\n        at org.apache.storm.generated.Nimbus$Client.submitTopology(Nimbus.java:278)\n        at org.apache.storm.StormSubmitter.submitTopologyAs(StormSubmitter.java:243)\n        ... 4 more\n"
            }
        }
    },
    "James_mime4j_core": {
        "owner_repo": "apache/james-mime4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e6e5ce9ae8e5c6504482bbbc38c352864ba359ea",
                "commit_sha_fixed": "be831dff83e23a64b2393cef2fe09a94b7e53834",
                "report_id": "MIME4J-177",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-177",
                "issue_title": "[MIME4J-177] The parser invoke preamble token/event even when no preamble exists in the message - ASF JIRA",
                "issue_description": "\nThe token stream sends T_PREAMBLE tokens even when there is no preamble in the message making impossible to distinguish between messages with no preamble and messages with an empty preamble.\nT_PREAMBLE should be called only when a preamble exists:\nThe rfc define multipart-body as:\n     multipart-body := [preamble CRLF]\n                       dash-boundary transport-padding CRLF\n                       body-part *encapsulation\n                       close-delimiter transport-padding\n[CRLF epilogue] \nSo preamble is optional (if the is a CRLF before the first boundary then you have a preamble).\n"
            },
            "2": {
                "commit_sha_buggy": "a07f3a0ade43404dd814d7da4d973c9a65680661",
                "commit_sha_fixed": "9d26d3d5a807a2b59d1bf254f8a7e7d314f77b9c",
                "report_id": "MIME4J-187",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-187",
                "issue_title": "[MIME4J-187] Inconsistency in handling of empty preambles and epilogues - ASF JIRA",
                "issue_description": "\nThe handling of empty preambles and epilogues is not consistent. Empty preambles do not trigger a parsing event, empty epilogues do.\n"
            },
            "3": {
                "commit_sha_buggy": "1384bb96aee71e4f1561b301b21503edcebb73ba",
                "commit_sha_fixed": "280a2c9a1f688f8bd7eefc0b794d7e72a9aae3a2",
                "report_id": "MIME4J-189",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-189",
                "issue_title": "[MIME4J-189] Problems with content type header when the boundary contains a space and it is folded - ASF JIRA",
                "issue_description": "\nI guess this is a regression introduced with MIME4J-145.\n"
            },
            "4": {
                "commit_sha_buggy": "28f70e83eee11063653ce86d5daa05662bb76922",
                "commit_sha_fixed": "8ab9362b799f4fe44cb250bcd7a132f07dff8c40",
                "report_id": "MIME4J-209",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-209",
                "issue_title": "[MIME4J-209] Problem decoding quoted-printable question mark in subject - ASF JIRA",
                "issue_description": "\nWhen a subject contains only \"Subject: =?ISO-8859-1?Q?=\" MIME4j doesn't decode it. It simply returns \"=?ISO-8859-1?Q?=\". The encoding is however legal with regards to RFC2045:\n6.7  2)   (Literal representation) Octets with decimal values of\n          33 through 60 inclusive, and 62 through 126, inclusive,\n          MAY be represented as the US-ASCII characters which\n          correspond to those octets (EXCLAMATION POINT through\n          LESS THAN, and GREATER THAN through TILDE,\n          respectively).\nExample message:\nFrom: John Doe <example@example.com>\nMIME-Version: 1.0\nContent-Type: multipart/mixed;\n        boundary=\"XXXXboundary text\"\nSubject: =?ISO-8859-1?Q???=\nThis is a multipart message in MIME format.\n--XXXXboundary text\nContent-Type: text/plain\nthis is the body text\n--XXXXboundary text\nContent-Type: text/plain;\nContent-Disposition: attachment;\n        filename=\"test.txt\"\nthis is the attachment text\n-XXXXboundary text-\nExample code fragment:\nMessageBuilder builder = new DefaultMessageBuilder();\nMessage message = builder.parseMessage(in);\nSystem.out.println(\"Subject: \" + message.getSubject());\nThis outputs \"Subject: =?ISO-8859-1?Q???=\" but should output \"Subject: ?\".\n"
            },
            "5": {
                "commit_sha_buggy": "0d5247fed64edf0494362b72ee52aa5ec5012592",
                "commit_sha_fixed": "2ae2cb54a1cfa1ca17e70487eb91c65752a7c962",
                "report_id": "MIME4J-218",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-218",
                "issue_title": "[MIME4J-218] Content-Type Fallback Character Set - ASF JIRA",
                "issue_description": "\nWould it be possible to add a feature that would allow for specifying a fallback character set to use when the character set in a 'Content-Type' header is not recognized by Java? In the old 0.6.2 version, that we used before, the character set 'ISO-8859-1' was used as a fallback but in the 0.7.2 version an UnsupportedEncodingException is thrown when the parser encounters an unknown character set in a Content-Type header.\nHere is the relevant part of the exception stack trace:\nCaused by: java.io.UnsupportedEncodingException: x-user-defined\nat sun.nio.cs.StreamDecoder.forInputStreamReader(StreamDecoder.java:52)\nat java.io.InputStreamReader.<init>(InputStreamReader.java:83)\nat org.apache.james.mime4j.message.BasicTextBody.getReader(BasicTextBody.java:49)\nWe receive, parse and archive a vast number of confidential e-mail messages (for which we use Mime4J) and every now and then we get an e-mail message that contains a non-standard character encoding name (in this case 'x-user-defined'). With the old (0.6) Mime4J version we were still able to parse and read most of those e-mail messages because of the fallback character set in the parser.\nI can unfortunately not post the entire message here but the content-type header that caused the above exception looks like this:\nContent-Type: text/plain; charset=\"x-user-defined\" \n"
            },
            "6": {
                "commit_sha_buggy": "d924dcb518f4aa85a7e7ff21920a472251345c0d",
                "commit_sha_fixed": "03c1f6fcb5e1fc0d78371d03af5310a5c6cb1f98",
                "report_id": "MIME4J-273",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-273",
                "issue_title": "[MIME4J-273] Update EncoderUtil#encodeB encoding string splitting point - ASF JIRA",
                "issue_description": "\nSee https://github.com/apache/james-mime4j/pull/16\n"
            },
            "7": {
                "commit_sha_buggy": "c33617db27d2c31825946706c91843f3cfbadce5",
                "commit_sha_fixed": "db390c15702eff7ba6b0cdb5855ffc5503bb9b5c",
                "report_id": "MIME4J-263",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-263",
                "issue_title": "[MIME4J-263] DecoderUtil.decodeEncodedWords() doesn't decode an encoded empty string - ASF JIRA",
                "issue_description": "\nDecoderUtil.decodeEncodedWords() returns an unencoded string if the word to decode is empty.\nFor example\nDecoderUtil.decodeEncodedWords(\"=?utf-8?Q??=\", DecodeMonitor.SILENT)\nreturns\n\"=?utf-8?Q??=\"\ninstead of empty string (or perhaps null)\nThe problem lies in the regexp that is used behind the scenes that requires at least one character:\n\nprivate static final Pattern PATTERN_ENCODED_WORD = Pattern.compile(\n            \"(.*?)=\\\\?(.+?)\\\\?(\\\\w)\\\\?(.+?)\\\\?=\", Pattern.DOTALL);\n\n\n"
            },
            "8": {
                "commit_sha_buggy": "fefae5a68b1f70f495dcfa6aa5adacb5c8f8f8b8",
                "commit_sha_fixed": "6ec1135e813fc845875cfae3c1055ad534a418b9",
                "report_id": "MIME4J-273",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-273",
                "issue_title": "[MIME4J-273] Update EncoderUtil#encodeB encoding string splitting point - ASF JIRA",
                "issue_description": "\nSee https://github.com/apache/james-mime4j/pull/16\n"
            },
            "9": {
                "commit_sha_buggy": "8a8942badaf4d7dc574130e74a9c7892a09bd1a9",
                "commit_sha_fixed": "68bc1194428d9cf057e60a0178469821d49d1d42",
                "report_id": "MIME4J-203",
                "report_url": "https://issues.apache.org/jira/browse/MIME4J-203",
                "issue_title": "[MIME4J-203] RawField parsing problem in case of '\\t' delimiter - ASF JIRA",
                "issue_description": "\nRawField doesn't drop '\\t' char between field header and body, so body starts from LWSP-char that should be ignored by RFC822 (see 3.4.2 in spec) because date field is structured. So date isn't extracted.\n"
            }
        }
    },
    "JacksonDataformatsText_yaml": {
        "owner_repo": "FasterXML/jackson-dataformats-text",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "67ce0ac3005c0163496a19266c6301a6f738252d",
                "commit_sha_fixed": "db4cb8a0dc4585f5dd2236814e8dbcf371396d42",
                "report_id": "34",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/34",
                "issue_title": "Problem with `YAMLGenerator.Feature.INDENT_ARRAYS`, nested Objects",
                "issue_description": "(see https://github.com/FasterXML/jackson-dataformat-yaml/issues/67 reported by @ondrej-kvasnovsky for discussion)\r\n\r\nLooks like SnakeYAML (1.18 and below) have an issue with indentation, causing generation of invalid YAML in cases where array values are not scalars.\r\n"
            },
            "2": {
                "commit_sha_buggy": "220203d4e6d65e3640f759c9c48d156775ac5ffd",
                "commit_sha_fixed": "97952f006486bd4066aec9d4ad7c30f62458d712",
                "report_id": "99",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/99",
                "issue_title": "`YamlGenerator` closes the target stream when configured not to ",
                "issue_description": "### Bug description\r\nYamlGenerator closes the target stream when configured not to.\r\n\r\n### Versions used\r\njackson-dataformat-yaml 2.9.2\r\njackson-databind 2.9.6\r\n\r\n### Expected result\r\nThe target stream not closed when writing a value. No output when running reproduction script/program.\r\n\r\n### Actual result\r\nThe target stream is closed when using the YamlGenerator, with the following output when running the reproduction script/program.\r\n```\r\nYaml test failed: Stream was closed.\r\nYaml2 test failed: Stream was closed.\r\n```\r\n\r\n### Steps to reproduce\r\n```java\r\npackage com.spotify;\r\n\r\nimport com.fasterxml.jackson.core.JsonGenerator;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport com.fasterxml.jackson.dataformat.yaml.YAMLFactory;\r\nimport java.io.IOException;\r\nimport java.io.OutputStream;\r\n\r\npublic class YamlBug {\r\n\r\n  static final Pojo pojo = new Pojo(\"bar\");\r\n\r\n  public static void main(String[] args) throws IOException {\r\n    try {\r\n      jsonTest();\r\n    } catch (AssertionError e) {\r\n      System.out.println(\"Json test failed: \" + e.getMessage());\r\n    }\r\n\r\n    try {\r\n      yamlTest();\r\n    } catch (AssertionError e) {\r\n      System.out.println(\"Yaml test failed: \" + e.getMessage());\r\n    }\r\n\r\n    try {\r\n      yamlTest2();\r\n    } catch (AssertionError e) {\r\n      System.out.println(\"Yaml2 test failed: \" + e.getMessage());\r\n    }\r\n\r\n  }\r\n\r\n  static void jsonTest() throws IOException {\r\n    final ThrowingOutputStream jsonOutputStream = new ThrowingOutputStream();\r\n    final ObjectMapper jsonMapper = new ObjectMapper()\r\n        .disable(JsonGenerator.Feature.AUTO_CLOSE_TARGET);\r\n    jsonMapper.writeValue(jsonOutputStream, pojo);\r\n  }\r\n\r\n  static void yamlTest() throws IOException {\r\n    final ThrowingOutputStream yamlOutputStream = new ThrowingOutputStream();\r\n    final ObjectMapper yamlMapper = new ObjectMapper(\r\n        new YAMLFactory()\r\n            .disable(JsonGenerator.Feature.AUTO_CLOSE_TARGET)\r\n    );\r\n    yamlMapper.writeValue(yamlOutputStream, pojo);\r\n  }\r\n\r\n  static void yamlTest2() throws IOException {\r\n    final ThrowingOutputStream yamlOutputStream = new ThrowingOutputStream();\r\n    final ObjectMapper yamlMapper =\r\n        new ObjectMapper(\r\n            new YAMLFactory()\r\n        ).disable(JsonGenerator.Feature.AUTO_CLOSE_TARGET);\r\n    yamlMapper.writeValue(yamlOutputStream, pojo);\r\n  }\r\n\r\n  static class ThrowingOutputStream extends OutputStream {\r\n\r\n    @Override\r\n    public void write(final int b) throws IOException {\r\n\r\n    }\r\n\r\n    @Override\r\n    public void close() throws IOException {\r\n      throw new AssertionError(\"Stream was closed.\");\r\n    }\r\n  }\r\n\r\n  static class Pojo {\r\n\r\n    public final String foo;\r\n\r\n    Pojo(final String foo) {this.foo = foo;}\r\n  }\r\n}\r\n```"
            },
            "4": {
                "commit_sha_buggy": "f5bf7a425e208fa22986a3aec8746c715051f79e",
                "commit_sha_fixed": "24edc02b8389e06669fb8cb99abd800e6acba2f3",
                "report_id": "83",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/83",
                "issue_title": "(yaml) Update index of sequence context",
                "issue_description": "I've a problem with a custom deserializer which relies on `JsonStreamContext.getCurrentIndex()` to reflect the current collection index. The YAMLParser fails to update the `_index` field and thus the following fails for YAML but completes successfully for JSON:\r\n\r\n```\r\nimport com.fasterxml.jackson.annotation.JsonProperty;\r\nimport com.fasterxml.jackson.core.JsonParser;\r\nimport com.fasterxml.jackson.databind.DeserializationContext;\r\nimport com.fasterxml.jackson.databind.JsonDeserializer;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\r\nimport com.fasterxml.jackson.dataformat.yaml.YAMLFactory;\r\nimport org.junit.Test;\r\n\r\nimport java.io.IOException;\r\n\r\nimport static org.junit.Assert.assertArrayEquals;\r\n\r\npublic class Sequence2Test {\r\n    private static class IdDeser extends JsonDeserializer<Integer> {\r\n        @Override\r\n        public Integer deserialize(JsonParser p, DeserializationContext ctxt) {\r\n            return p.getParsingContext().getCurrentIndex();\r\n        }\r\n    }\r\n\r\n    private static class MySequence {\r\n        @JsonProperty @JsonDeserialize(contentUsing = IdDeser.class)\r\n        Integer[] myList;\r\n    }\r\n\r\n    @Test\r\n    public void testSequenceIteratorYaml() throws IOException {\r\n        testSequence(new ObjectMapper(new YAMLFactory()));\r\n    }\r\n\r\n    @Test\r\n    public void testSequenceIteratorJson() throws IOException {\r\n        testSequence(new ObjectMapper());\r\n    }\r\n\r\n    private void testSequence(ObjectMapper mapper) throws IOException {\r\n        MySequence seq = mapper.readValue(\"{\\\"myList\\\": [9,8,7]}\", MySequence.class);\r\n        assertArrayEquals(new Integer[] { 0, 1, 2 }, seq.myList);\r\n    }\r\n}\r\n```\r\nI guess it's a bit awkward to detect start of a new item (which might be scalar or object), but maybe someone more familiar with how this works for JSON can suggest a fix? Or is this working as intended?"
            },
            "5": {
                "commit_sha_buggy": "580159d35721926d31ddae29016bb3fb7b7bc6bc",
                "commit_sha_fixed": "14da25652fac0c7e0ef7b1b8fe2b8cdd6d58af39",
                "report_id": "182",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/182",
                "issue_title": "Negative numbers not quoted correctly wrt `ALWAYS_QUOTE_NUMBERS_AS_STRINGS`",
                "issue_description": "When initializing a `YamlFactory` as follows, negative numbers are not quoted correctly.\r\n\r\n```\r\nYAMLFactory factory = new YAMLFactory();\r\nfactory.enable(YAMLGenerator.Feature.MINIMIZE_QUOTES);\r\nfactory.enable(YAMLGenerator.Feature.ALWAYS_QUOTE_NUMBERS_AS_STRINGS);\r\n```\r\n\r\nSerializing `60` currently results in `\"60\"`.\r\nSerializing `-14` currently results in `14`."
            },
            "6": {
                "commit_sha_buggy": "f52abd9275bb2a981f722b8da80f47d1cbdb9347",
                "commit_sha_fixed": "a2b3d2eab48aec82e54a25feaad198bcd1b5831b",
                "report_id": "51",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/51",
                "issue_title": "Set of custom objects with `IGNORE_UNKNOWN` brokes silently csv",
                "issue_description": "When I use a Set (but I think a Collection) of objects with feature `JsonGenerator.Feature.IGNORE_UNKNOWN` extra line separators are added.\r\nI paste the code to reproduce it:\r\n\r\n```\r\n    protected static class Person\r\n    {\r\n        private String name;\r\n        private String surname;\r\n\r\n        public Person()\r\n        {\r\n        }\r\n\r\n        public Person( String name, String surname )\r\n        {\r\n            this.name = name;\r\n            this.surname = surname;\r\n        }\r\n\r\n        public String getName()\r\n        {\r\n            return name;\r\n        }\r\n\r\n        public void setName( String name )\r\n        {\r\n            this.name = name;\r\n        }\r\n\r\n        public String getSurname()\r\n        {\r\n            return surname;\r\n        }\r\n\r\n        public void setSurname( String surname )\r\n        {\r\n            this.surname = surname;\r\n        }\r\n    }\r\n\r\n    protected static class MyClass\r\n    {\r\n        private Set<Person> people;\r\n        private String address;\r\n        private String phoneNumber;\r\n\r\n        public MyClass()\r\n        {\r\n        }\r\n\r\n        public Set<Person> getPeople()\r\n        {\r\n            return people;\r\n        }\r\n\r\n        public void setPeople( Set<Person> people )\r\n        {\r\n            this.people = people;\r\n        }\r\n\r\n        public String getAddress()\r\n        {\r\n            return address;\r\n        }\r\n\r\n        public void setAddress( String address )\r\n        {\r\n            this.address = address;\r\n        }\r\n\r\n        public String getPhoneNumber()\r\n        {\r\n            return phoneNumber;\r\n        }\r\n\r\n        public void setPhoneNumber( String phoneNumber )\r\n        {\r\n            this.phoneNumber = phoneNumber;\r\n        }\r\n    }\r\n\r\n    public void testEmbeddedObjects() throws Exception\r\n    {\r\n        CsvMapper mapper = mapperForCsv();\r\n        mapper.configure( JsonGenerator.Feature.IGNORE_UNKNOWN, true );\r\n        CsvSchema schema = CsvSchema.builder()\r\n                .addColumn( \"people\" ) // here I'm skipping phoneNumber so I need to use IGNORE_UNKNOWN feature\r\n                .addColumn( \"address\" )\r\n                .build()\r\n                .withHeader();\r\n\r\n        Person firstPerson = new Person( \"Barbie\", \"Benton\" );\r\n        Person secondPerson = new Person( \"Veltto\", \"Virtanen\" );\r\n        Set<Person> people = new HashSet<>();\r\n        people.add( firstPerson );\r\n        people.add( secondPerson );\r\n        MyClass myClass = new MyClass();\r\n        myClass.setPeople( people );\r\n        myClass.setAddress( \"AAA\" );\r\n        myClass.setPhoneNumber( \"123\" );\r\n\r\n        String result = mapper.writer( schema ).writeValueAsString( myClass );\r\n        int numberOfLines = result.split( \"\\n\" ).length;\r\n        assertEquals( 2, numberOfLines ); // header and data (here fails with 3)\r\n    }\r\n```\r\n\r\nVersion is 2.9.0\r\nA workaround would be to write a custom serializer, but with a class with a lot of fields it was very hard to find which field has broken silently the csv.\r\nIs there any way to use the toString rappresentation for cases like this one?\r\nIf you prefer I can open a PR with that code instead of paste it here."
            },
            "7": {
                "commit_sha_buggy": "810772312735f1fb89d6fa37dd70e150e9cc783b",
                "commit_sha_fixed": "fc1ee688c05d4814dfbd4d55afa32ff030acc0f9",
                "report_id": "226",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/226",
                "issue_title": "Quote 'y'/'Y'/'n'/'N' as names too (to avoid problems with Boolean keys)",
                "issue_description": "(note: replacement of #225 targeting 2.12 branch)\r\n\r\nLooks like #68 left out single-letter boolean values (\"Y\"/\"y\"/\"N\"/\"n\") wrt quoting of names, presumable for aesthetic reasons.\r\nIt seems better to quote these, however, since they are already quoted when output as values (see `MUST_QUOTE_VALUES` in `YAMLGenerator`).\r\nChange is planned for 2.12.0; we can still revisit this after 2.12.0-rc1 if there are actual problems introduced (and if so possibly add Yet Another `YAMLGenerator.Feature` if need be).\r\n\r\n"
            }
        }
    },
    "JacksonDataformatsText_properties": {
        "owner_repo": "FasterXML/jackson-dataformats-text",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "50da8132111d18316d03efa09fad2c4a8250632e",
                "commit_sha_fixed": "36f2f2a17a2463ac995bf29a661ad8225c30d7f9",
                "report_id": "74",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/74",
                "issue_title": "`JavaPropsMapper` issue deserializing multiple byte array properties",
                "issue_description": "Hi,\r\n\r\nI've found an issue: byte array values look not correctly set when having multiple `byte[]` in a data model. When it happens, the same byte array content is set to ALL of the bean `byte[]` (or ByteBuffer) properties. I even have a more complex use case where an object property is set with the deserialized value of another different object `byte[]` property.\r\n\r\nPlease see the simple test case attached.\r\nFabrice\r\n\r\n[MyBean.java.zip](https://github.com/FasterXML/jackson-dataformats-text/files/1747744/MyBean.java.zip)"
            },
            "2": {
                "commit_sha_buggy": "3e481c65e50cdacd41c97ffc17e8187245f9e09d",
                "commit_sha_fixed": "580159d35721926d31ddae29016bb3fb7b7bc6bc",
                "report_id": "179",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-text/issues/179",
                "issue_title": "`JavaPropsMapper` doesn't close the .properties file properly after reading",
                "issue_description": "When I read an object from a .properties file I can't delete the file, access is held by the JVM. The input stream isn't closed properly unlike the regular JSON parser which does close.\r\n\r\nThis came up in a scenario when we read a properties file to create the object and later needed to delete the file.\r\n\r\nOnly seems to happen under Windows 10 (Linux is NOT impacted). Java version is 8 using Open JDK 8 u242 b08. \r\n\r\nAttached a zip file with a small maven project created in IntelliJ demonstrating the issue. Run \"compile\" to ensure the resources (.json, .properties files) are copied to the target folder before each run. \r\n\r\n[jackson-testing.zip](https://github.com/FasterXML/jackson-dataformats-text/files/4325288/jackson-testing.zip)\r\n"
            }
        }
    },
    "JacksonDataformatBinary_avro": {
        "owner_repo": "FasterXML/jackson-dataformats-binary",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "57f811b8dbf944f6e52aeb7235492ec6622d1bb6",
                "commit_sha_fixed": "a837a64be4f1e93545bef21de0219415d930b26f",
                "report_id": "39",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/39",
                "issue_title": "Problem decoding Maps with union values",
                "issue_description": "(reported by a user)\r\n\r\nLooks like Avro codec (version 2.7.8) writes nested Maps correctly, but has some issues with decoding, such that entries (of the outermost Map) after first one are dropped. That is, only the first key/value pair seems to be exposed.\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "4ac24abb78201b411213f483b7e6582ba4eded17",
                "commit_sha_fixed": "8a0df0a0cc37aec3021808e29614f3fdba24e2e9",
                "report_id": "161",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/161",
                "issue_title": "[avro] Deserialize from newer version to older one throws NullPointerException",
                "issue_description": "Version `2.9.0` and `2.9.8`\r\n\r\nTest to reproduce 07da0ea27aafa2598066298af2adc70bf7fd1042\r\n\r\nI have event in newer version of schema and I want to deserialize it with older version. Newer schema has additional field which might be null. During deserialization there is `NullPointerException` :\r\n```\r\njava.lang.NullPointerException\r\n\tat com.fasterxml.jackson.dataformat.avro.deser.UnionReader._decodeIndex(UnionReader.java:63)\r\n\tat com.fasterxml.jackson.dataformat.avro.deser.UnionReader.skipValue(UnionReader.java:45)\r\n\tat com.fasterxml.jackson.dataformat.avro.deser.AvroFieldReader$Structured.skipValue(AvroFieldReader.java:61)\r\n\tat com.fasterxml.jackson.dataformat.avro.deser.RecordReader$Resolving.nextFieldName(RecordReader.java:222)\r\n\tat com.fasterxml.jackson.dataformat.avro.deser.AvroParserImpl.nextFieldName(AvroParserImpl.java:110)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:294)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:151)\r\n\tat com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1608)\r\n\tat com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1185)\r\n\tat com.fasterxml.jackson.dataformat.avro.schemaev.ErrorReproduceTest.testShouldDeserialize(ErrorReproduceTest.java:72)\r\n```\r\nNullPointer occures when new field has UnionType `null` and one of`(Record, Map, Array)`. \r\n\r\nNewer schema which has additional field:\r\n```\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"V1\",\r\n  \"namespace\": \"test\",\r\n  \"doc\": \"simple schema version 2 testing compatibility\",\r\n  \"fields\": [\r\n    {\r\n      \"name\": \"name\",\r\n      \"type\": \"string\",\r\n      \"doc\": \"object name\"\r\n    },\r\n    {\r\n      \"name\": \"label\",\r\n      \"type\": \r\n      [\r\n        \"null\",\r\n        {\r\n          \"type\" : \"array\",\r\n          \"items\" : \"string\"\r\n        }\r\n      ],\r\n      \"doc\": \"object label\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nOlder Schema:\r\n```\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"V1\",\r\n  \"namespace\": \"test\",\r\n  \"doc\": \"simple schema testing compatibility\",\r\n  \"fields\": [\r\n    {\r\n      \"name\": \"name\",\r\n      \"type\": \"string\",\r\n      \"doc\": \"object name\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nI serialize event with newer schema and later I want to deserialize with older schema\r\n```\r\n{\r\n\"name\" : \"test\",\r\n\"label\": null\r\n}\r\n```\r\n\r\nDo you have any idea how can I configure mapper to avoid this problem or it has to be fixed?"
            }
        }
    },
    "JacksonDataformatBinary_cbor": {
        "owner_repo": "FasterXML/jackson-dataformats-binary",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d3c419806b80c825a668857fd3e574e679c6580c",
                "commit_sha_fixed": "a91c2591a9d65e5d84cf846ec546247c961f50f9",
                "report_id": "31",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/31",
                "issue_title": "Exception serializing double[][]",
                "issue_description": "To reproduce it (v. 2.8.3):\n\n```\n        ObjectMapper mapper = new ObjectMapper(new CBORFactory());\n        byte[] cborBytes = mapper.writeValueAsBytes(new double[][]{ {1.2323132131} });\n\n```\n\nI suspect that the problem is in CBORGenerator the line 678, the call to  _verifyValueWrite(\"\") has been already performed in the parent method, line 601, but I'm not familiar with the code, maybe there is another cause.\n\n```\n    private final void _writeNumberNoCheck(double d) throws IOException {\n        _verifyValueWrite(\"write number\");\n        _ensureRoomForOutput(11);\n\n```\n\nThe exception log trace:\n\n```\nException in thread \"main\" com.fasterxml.jackson.core.JsonGenerationException: Array size mismatch: number of element encoded is not equal to reported array/map size.\n    at com.fasterxml.jackson.core.JsonGenerator._reportError(JsonGenerator.java:1897)\n    at com.fasterxml.jackson.dataformat.cbor.CBORGenerator._failSizedArrayOrObject(CBORGenerator.java:1089)\n    at com.fasterxml.jackson.dataformat.cbor.CBORGenerator._verifyValueWrite(CBORGenerator.java:1080)\n    at com.fasterxml.jackson.dataformat.cbor.CBORGenerator._writeNumberNoCheck(CBORGenerator.java:678)\n    at com.fasterxml.jackson.dataformat.cbor.CBORGenerator.writeArray(CBORGenerator.java:604)\n    at com.fasterxml.jackson.databind.ser.std.StdArraySerializers$DoubleArraySerializer.serialize(StdArraySerializers.java:686)\n    at com.fasterxml.jackson.databind.ser.std.StdArraySerializers$DoubleArraySerializer.serialize(StdArraySerializers.java:620)\n    at com.fasterxml.jackson.databind.ser.std.ObjectArraySerializer.serializeContents(ObjectArraySerializer.java:256)\n    at com.fasterxml.jackson.databind.ser.std.ObjectArraySerializer.serialize(ObjectArraySerializer.java:216)\n    at com.fasterxml.jackson.databind.ser.std.ObjectArraySerializer.serialize(ObjectArraySerializer.java:26)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:292)\n    at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3672)\n    at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsBytes(ObjectMapper.java:3072)\n\n```\n"
            },
            "2": {
                "commit_sha_buggy": "8a1866e8204ad1ba13de0ed4fc3afc78f30b7949",
                "commit_sha_fixed": "7d26d7b805ba72ce4600aec1e6938f0ee6497c8e",
                "report_id": "93",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/93",
                "issue_title": "`CBORParser` does not accept \"undefined value\"",
                "issue_description": "I'm trying to use the CBORParser to parse a byte stream but the method nextToken() throws JsonParseException when the stream contains \"undefined value\" (Major Type: 7, Additional info: 23).\r\n\r\nI guess it is because there in no equivalent for this datatype in JSON.\r\n\r\nIs it possible to use the CBORParser when input stream contain \"undefined value\"?\r\n\r\nWould that be a good idea to modify the CBORParser class to add a new method \"nextCborToken\" to add support for \"undefined value\"?"
            },
            "3": {
                "commit_sha_buggy": "0efa55d3639bb35e4b26e75bc9a3fefc3ef5a8b3",
                "commit_sha_fixed": "9b66e84747131113529f6c59fcc68f27ca33331b",
                "report_id": "139",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/139",
                "issue_title": "Incorrect `BigDecimal` fraction representation (2.9 -> 2.10 change)",
                "issue_description": "According to the spec, decimal fractions (tag 4) of value m * 10^e should be represented as a tagged array containing the exponent e and the mantissa m. However, Jackson writes BigDecimals as tagged arrays containing their scale and unscaled value. The difference being that the value of BigDecimal is unscaled value * 10^-scale, which means the scale is the opposite of the exponent e.\r\n\r\nThe spec gives an example how 273.15 should be represented:\r\n\r\n    C4             -- Tag 4\r\n       82          -- Array of length 2\r\n          21       -- -2\r\n          19 6AB3  -- 27315\r\n\r\nHere is the actual representation:\r\n\r\n    C4             -- Tag 4\r\n       82          -- Array of length 2\r\n          02       -- 2\r\n          19 6AB3  -- 27315"
            },
            "4": {
                "commit_sha_buggy": "82b282d1fa51468d1fbe493bb92291bf0b8f8897",
                "commit_sha_fixed": "a99037f4a8dcf5221c1f0a7ed02760434c55361d",
                "report_id": "155",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/155",
                "issue_title": "Inconsistent support for `StreamWriteFeature.FLUSH_PASSED_TO_STREAM`",
                "issue_description": "Cbor and Smile serializers attempt to flush streams on close when AUTO_CLOSE_TARGET is disabled, even if FLUSH_PASSED_TO_STREAM is also disabled."
            },
            "5": {
                "commit_sha_buggy": "47daf9cd8545297f173400dcc7589429e0fe6bee",
                "commit_sha_fixed": "09c18b1c401ae3e2537801e43c9bc8f4494d0eb8",
                "report_id": "178",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/pull/178",
                "issue_title": "Fix issue wit input offsets when parsing CBOR from `InputStream`",
                "issue_description": "This fixes an issue I discovered where CBORParser#_loadToHaveAtLeast didn't increment _currInputProcessed pointer if array move didn't occur.  Observed because calling CBORParser#getCurrentLocation after CBORParser#finishToken returned offsets smaller than expected if a token spanned between two chunks read from the stream."
            }
        }
    },
    "JavaClassmate": {
        "owner_repo": "FasterXML/java-classmate",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "de71348de04e2116087ba6f272c99edc523b74d2",
                "commit_sha_fixed": "fecf425daa3385f18c6a56e6bf6af0562d732bf9",
                "report_id": "34",
                "report_url": "https://github.com/FasterXML/java-classmate/pull/34",
                "issue_title": "test and fix for issue #33: \"ghost\" type parameter in field",
                "issue_description": "I punted on the \"primitive\" bit since it seems the ResolvedPrimitiveType wasn't intended for object primitives like `Integer.class`\n"
            },
            "2": {
                "commit_sha_buggy": "fecf425daa3385f18c6a56e6bf6af0562d732bf9",
                "commit_sha_fixed": "db5b52602eedbdf36a080c84f6bed6417d04605f",
                "report_id": "33",
                "report_url": "https://github.com/FasterXML/java-classmate/issues/33",
                "issue_title": "\"ghost\" type parameter in field",
                "issue_description": "I have found an issue that at first I thought was related to Issue #28 but is specific to fields so maybe is different. I've pasted a test showing the issue below:\n\n``` java\npackage com.fasterxml.classmate.members;\n\nimport java.util.List;\n\nimport junit.framework.TestCase;\n\nimport com.fasterxml.classmate.*;\nimport java.math.BigInteger;\n\n// for issue \"ghost\" type parameter in field:\npublic class GhostTypeParameterInFieldTest\n    extends TestCase\n{\n    public static class A<T extends Number> {\n        public Integer i;\n        public BigInteger bigI;\n    }\n\n    ResolvedField[] fields;\n\n    @Override\n    protected void setUp() throws Exception {\n        TypeResolver resolver = new TypeResolver();\n        ResolvedType resolvedType = resolver.resolve(A.class, Integer.class);\n        MemberResolver memberResolver = new MemberResolver(resolver);\n        ResolvedTypeWithMembers resolvedTypeWithMembers = memberResolver.resolve(resolvedType, null, null);\n        fields = resolvedTypeWithMembers.getMemberFields();\n    }\n\n    public void testPrimitive()\n    {\n        // test fields\n        assertEquals(2, fields.length);\n\n        // field Integer i\n        ResolvedField iField = fields[0];\n        assertEquals(\"i\", iField.getName());\n        ResolvedType iArg = iField.getType();\n        assertEquals(Integer.class, iArg.getErasedType());\n        assertTrue(\"i should be a primitive\", iArg.isPrimitive());\n\n        // field BigInteger bigI \n        ResolvedField bigIField = fields[1];\n        assertEquals(\"bigI\", bigIField.getName());\n        ResolvedType bigIArg = bigIField.getType();\n        assertEquals(BigInteger.class, bigIArg.getErasedType());\n        assertFalse(\"bigI should not be a primitive\", bigIArg.isPrimitive());\n    }\n\n    public void testGhostTypeParameterInField()\n    {\n        // test fields\n        assertEquals(2, fields.length);\n\n        // field Integer i\n        ResolvedField iField = fields[0];\n        assertEquals(\"i\", iField.getName());\n        ResolvedType iArg = iField.getType();\n        assertEquals(Integer.class, iArg.getErasedType());\n        List<ResolvedType> iTypeParams = iArg.getTypeParameters();\n        if (iTypeParams.size() != 0) {\n            fail(\"Expected 0 type parameters for Integer i, got \"+iTypeParams.size()+\": \"+iTypeParams);\n        }\n\n        // field BigInteger bigI \n        ResolvedField bigIField = fields[1];\n        assertEquals(\"bigI\", bigIField.getName());\n        ResolvedType bigIArg = bigIField.getType();\n        assertEquals(BigInteger.class, bigIArg.getErasedType());\n        List<ResolvedType> bigITypeParams = bigIArg.getTypeParameters();\n        if (bigITypeParams.size() != 0) {\n            fail(\"Expected 0 type parameters for BigInteger bigI, got \"+bigITypeParams.size()+\": \"+bigITypeParams);\n        }\n    }\n\n}\n```\n\nThis fails with\n\n```\nFailed tests: \n  GhostTypeParameterInFieldTest.testPrimitive:40 i should be a primitive\n  GhostTypeParameterInFieldTest.testGhostTypeParameterInField:62 Expected 0 type parameters for Integer i, got 1: [java.lang.Integer]\n```\n\nAssuming this is a real problem, I think I've traced it to [TypeResolver._fromClass](https://github.com/FasterXML/java-classmate/blob/master/src/main/java/com/fasterxml/classmate/TypeResolver.java#L336). There may be multiple things going on here, but here are my two suspicions:\n- The Integer type should be a primitive but the ClassKey that is built for Integer.class is not matching on [line 339](https://github.com/FasterXML/java-classmate/blob/master/src/main/java/com/fasterxml/classmate/TypeResolver.java#L339)\n- The type construction is incorrectly associating the type bindings to the Integer type (resulting in an Integer with a parameterized type) on [line 368](https://github.com/FasterXML/java-classmate/blob/master/src/main/java/com/fasterxml/classmate/TypeResolver.java#L368)\n\n(accidentally pasted in the wrong test before. edited with correct test that also uses static inner class and tests both for primitive and \"ghost\" parameters)\n"
            }
        }
    },
    "JacksonModuleJsonSchema": {
        "owner_repo": "FasterXML/jackson-module-jsonSchema",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "10692e81f9d1d5cb5a37f013fc1c34391f18ad96",
                "commit_sha_fixed": "d924e7fd9f8f62c7af380cedd7fc19687452b38b",
                "report_id": "47",
                "report_url": "https://github.com/FasterXML/jackson-module-jsonSchema/issues/47",
                "issue_title": "VisitorContext results in incomplete json schema output",
                "issue_description": "In version 2.4.1, VisitorContext was added, which keeps track of visited JavaTypes in a static HashSet, with static methods to add to and get from the static HashSet. Because of this, if you use SchemaFactoryWrapper to generate json schema multiple times during a given run of the JVM, you may get references along the lines of \"$ref\" : \"urn:jsonschema:test:JsonSchemaTest:Bar\" when no such id exists in the json schema document generated. To make matters worse, because VisitorContext is all static, there's no way to work around the problem.\n\nhere's a quick test case that produces the issue:\n\n```\npackage test;\n\nimport java.io.StringWriter;\n\nimport org.junit.Test;\n\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.module.jsonSchema.factories.SchemaFactoryWrapper;\n\npublic class JsonSchemaTest {\n\n\n    class Foo {\n        private String fooProp1;\n        private int fooProp2;\n        private Bar fooProp3;\n\n        public String getFooProp1() {\n            return fooProp1;\n        }\n\n        public void setFooProp1(String fooProp1) {\n            this.fooProp1 = fooProp1;\n        }\n\n        public int getFooProp2() {\n            return fooProp2;\n        }\n\n        public void setFooProp2(int fooProp2) {\n            this.fooProp2 = fooProp2;\n        }\n\n        public Bar getFooProp3() {\n            return fooProp3;\n        }\n\n        public void setFooProp3(Bar fooProp3) {\n            this.fooProp3 = fooProp3;\n        }\n    }\n\n    class Bar {\n        private String barProp1;\n        private int barProp2;\n\n        public String getBarProp1() {\n            return barProp1;\n        }\n\n        public void setBarProp1(String barProp1) {\n            this.barProp1 = barProp1;\n        }\n\n        public int getBarProp2() {\n            return barProp2;\n        }\n\n        public void setBarProp2(int barProp2) {\n            this.barProp2 = barProp2;\n        }\n    }\n\n    class Qwer {\n        private String qwerProp1;\n        private Bar qwerProp2;\n\n        public String getQwerProp1() {\n            return qwerProp1;\n        }\n\n        public void setQwerProp1(String qwerProp1) {\n            this.qwerProp1 = qwerProp1;\n        }\n\n        public Bar getQwerProp2() {\n            return qwerProp2;\n        }\n\n        public void setQwerProp2(Bar qwerProp2) {\n            this.qwerProp2 = qwerProp2;\n        }\n    }\n\n    @Test\n    public void testSchemaGeneration() throws Exception {\n        printJsonSchema(Foo.class);\n        printJsonSchema(Qwer.class);\n    }\n\n    private void printJsonSchema(Class<?> clazz) throws Exception {\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.configure(SerializationFeature.INDENT_OUTPUT, true);\n        SchemaFactoryWrapper visitor = new SchemaFactoryWrapper();\n        mapper.acceptJsonFormatVisitor(\n                mapper.constructType(\n                        clazz), visitor);\n        StringWriter sr = new StringWriter();\n        mapper.writeValue(sr, visitor.finalSchema());\n        System.out.println(sr.toString());\n    }\n\n}\n```\n\noutput:\n\n``` javascript\n{\n  \"type\" : \"object\",\n  \"id\" : \"urn:jsonschema:test:JsonSchemaTest:Foo\",\n  \"properties\" : {\n    \"fooProp3\" : {\n      \"type\" : \"object\",\n      \"id\" : \"urn:jsonschema:test:JsonSchemaTest:Bar\",\n      \"properties\" : {\n        \"barProp1\" : {\n          \"type\" : \"string\"\n        },\n        \"barProp2\" : {\n          \"type\" : \"integer\"\n        }\n      }\n    },\n    \"fooProp2\" : {\n      \"type\" : \"integer\"\n    },\n    \"fooProp1\" : {\n      \"type\" : \"string\"\n    }\n  }\n}\n{\n  \"type\" : \"object\",\n  \"id\" : \"urn:jsonschema:test:JsonSchemaTest:Qwer\",\n  \"properties\" : {\n    \"qwerProp2\" : {\n      \"type\" : \"object\",\n      \"$ref\" : \"urn:jsonschema:test:JsonSchemaTest:Bar\"\n    },\n    \"qwerProp1\" : {\n      \"type\" : \"string\"\n    }\n  }\n}\n```\n\nNote that the second object in the output is incomplete.\"$ref\" : \"urn:jsonschema:test:JsonSchemaTest:Bar\" refers to an id from the prior schema generation operation that got statically cached.\n"
            }
        }
    },
    "JacksonDatatypeJoda": {
        "owner_repo": "FasterXML/jackson-datatype-joda",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4e6c26633974375e34bbc9152a952284ce4fead6",
                "commit_sha_fixed": "86c640298c85092631054b0ce0ad79d1dc24e3ca",
                "report_id": "60",
                "report_url": "https://github.com/FasterXML/jackson-datatype-joda/issues/60",
                "issue_title": "Configured date/time format not considered when serializing Joda Instant ",
                "issue_description": "The configured date/time format is not considered for org.joda.time.Instant since version 2.4.4 and newer. In earlier versions Instants were serialized using the configured formatter.\n\nReproduce with the follwing code snippet:\n\n``` java\n  @Test\n  public void testInstantConversion() throws Exception {\n    ObjectMapper om = new ObjectMapper();\n    om.registerModule(new JodaModule());\n\n    // Configure Date Formatting\n    om.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\n    om.setDateFormat(new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss'Z'\"));\n\n    // Create an instant and serialize and additonally serialize the instant as DateTime to demonstrate the difference\n    org.joda.time.Instant now = new Instant();\n    String jsonInstant = om.writeValueAsString(now);\n    String jsonDateTime = om.writeValueAsString(now.toDateTime());\n\n    // just to show the version that was used when running the demo\n    System.out.println(\"packageVersion: \" + com.fasterxml.jackson.datatype.joda.PackageVersion.VERSION);\n\n    System.out.println(\"jsonInstant: \" + jsonInstant);\n    System.out.println(\"jsonDateTime: \" + jsonDateTime);\n\n    assertThat(jsonInstant).isEqualTo(jsonDateTime); // will fail for jackson-datatype-joda > 2.4.4\n  }\n```\n\nOutput using v2.4.3:\n\n```\npackageVersion: 2.4.3\njsonInstant: \"2015-05-11T13:40:14.541Z\"\njsonDateTime: \"2015-05-11T13:40:14.541Z\"\n```\n\nOutput using v2.4.4:\n\n```\npackageVersion: 2.4.4\njsonInstant: \"2015-05-11T13:46:41.081Z\"\njsonDateTime: \"2015-05-11T13:46:41.081Z\"\n```\n\nOutput using v2.5.0:\n\n```\npackageVersion: 2.5.0\njsonInstant: 1431352169061\njsonDateTime: \"2015-05-11T13:49:29.061Z\"\n\norg.junit.ComparisonFailure: \nExpected :'[\"2015-05-11T13:49:29.061Z\"]'\nActual   :'[1431352169061]':\n```\n\nOutput using v2.5.3:\n\n```\npackageVersion: 2.5.3\njsonInstant: 1431352294592\njsonDateTime: \"2015-05-11T13:51:34.592Z\"\n\norg.junit.ComparisonFailure: \nExpected :'[\"2015-05-11T13:51:34.592Z\"]'\nActual   :'[1431352294592]'\n```\n"
            },
            "2": {
                "commit_sha_buggy": "c9340a90096269975640cc9989526d829aba2de9",
                "commit_sha_fixed": "a24ccc2211ea6c9af0bd731d6824536193b0ee41",
                "report_id": "70",
                "report_url": "https://github.com/FasterXML/jackson-datatype-joda/issues/70",
                "issue_title": "Default DateTime parser format is stricter than previous versions, causing incompatibility",
                "issue_description": "In this commit, for DateTimeSerializer:\nhttps://github.com/FasterXML/jackson-datatype-joda/commit/cf2f4c282c3eb4048ca501e6af21948afb447913#diff-86756f80e06fe3b0a847c963534b14baR55\n\n`DateTime.parse()` is replaced by using the `JacksonJodaDateFormat`, which defaults to `FormatConfig.DEFAULT_DATETIME_FORMAT`, which is defined as `new JacksonJodaDateFormat(ISODateTimeFormat.dateTime().withZoneUTC())`.\n\n`DateTime.parse()` uses `ISODateTimeFormat.dateTimeParser().withOffsetParsed()`:\nhttp://www.joda.org/joda-time/apidocs/org/joda/time/DateTime.html#parse-java.lang.String-\n\nSo ultimately, the default date time parser format has changed from `ISODateTimeFormat.dateTimeParser()` to `ISODateTimeFormat.dateTime()`. Although similar, `ISODateTimeFormat.dateTimeParser()` is much less restrictive:\nhttp://www.joda.org/joda-time/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTime--\nhttp://www.joda.org/joda-time/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTimeParser--\n\nAs an example, the datetime \"2015-07-27T08:11:07-07:00\" is missing the `.SSS` milliseconds value, so it fails in 2.6.0 but works in 2.5.4:\n\n```\nCaused by: java.lang.IllegalArgumentException: Invalid format: \"2015-07-27T08:11:07-07:00\" is malformed at \"-07:00\"\n    at org.joda.time.format.DateTimeFormatter.parseDateTime(DateTimeFormatter.java:899) ~[joda-time-2.8.1.jar:2.8.1]\n    at com.fasterxml.jackson.datatype.joda.deser.DateTimeDeserializer.deserialize(DateTimeDeserializer.java:90) ~[jackson-datatype-joda-2.6.0.jar:2.6.0]\n    at com.fasterxml.jackson.datatype.joda.deser.DateTimeDeserializer.deserialize(DateTimeDeserializer.java:22) ~[jackson-datatype-joda-2.6.0.jar:2.6.0]\n    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:520) ~[jackson-databind-2.6.0.jar:2.6.0]\n    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101) ~[jackson-databind-2.6.0.jar:2.6.0]\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:256) ~[jackson-databind-2.6.0.jar:2.6.0]\n```\n\nA workaround in this situation is to add a `@JsonFormat` annotation to the property specifying the specific format, e.g: `@JsonFormat(pattern=\"yyyy-MM-dd'T'HH:mm:ssZZ\")`\n"
            },
            "3": {
                "commit_sha_buggy": "7a34a40c561321e04da1fb33eaabf33e4e50e902",
                "commit_sha_fixed": "cf110c7da6d49a138d5ea11c914df15faf11a52d",
                "report_id": "113",
                "report_url": "https://github.com/FasterXML/jackson-datatype-joda/issues/113",
                "issue_title": "`ObjectMapper.setDefaultLeniency()` is causing `NullPointerException` in `JacksonJodaDateFormat`",
                "issue_description": "(Jackson version: `2.10.1`)\r\n\r\nConsider the following example:\r\n```\r\nObjectMapper mapper = new ObjectMapper();\r\nmapper.registerModule(new JodaModule());\r\nmapper.setDefaultLeniency(false);\r\nmapper.writeValueAsString(new org.joda.time.DateTime());\r\n```\r\nThis code raises the following exception:\r\n```\r\njava.lang.NullPointerException\r\n\tat com.fasterxml.jackson.datatype.joda.cfg.JacksonJodaDateFormat.with(JacksonJodaDateFormat.java:123)\r\n\tat com.fasterxml.jackson.datatype.joda.ser.JodaDateSerializerBase.createContextual(JodaDateSerializerBase.java:94)\r\n\tat com.fasterxml.jackson.databind.SerializerProvider.handleSecondaryContextualization(SerializerProvider.java:1004)\r\n\tat com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:524)\r\n\tat com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:713)\r\n\tat com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:308)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:4094)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:3404)\r\n...\r\n```\r\n\r\nThis is caused by `JsonFormat.Value#getPattern()` returning `null` at line https://github.com/FasterXML/jackson-datatype-joda/blob/master/src/main/java/com/fasterxml/jackson/datatype/joda/cfg/JacksonJodaDateFormat.java#L123.\r\n\r\nNote that `getPattern` returns an empty string when `JsonFormat` comes from an annotation, but `null` when created because of `ObjectMapper.setDefaultLenciency()`.\r\n"
            }
        }
    },
    "Bcel": {
        "owner_repo": "apache/commons-bcel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e103eea0addbbe3781775ac714c89473086d1ad7",
                "commit_sha_fixed": "8dab4e845ccbdb0a0f287c38ceafd7d15e417c06",
                "report_id": "BCEL-186",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-186",
                "issue_title": "[BCEL-186] Performance degradation with the UTF8 cache - ASF JIRA",
                "issue_description": "\nI'd love to see 6.0 released.\nHere was the last vote:\nhttp://apache-commons.680414.n4.nabble.com/VOTE-Release-BCEL-6-0-based-on-RC3-td4667129.html\nKonstantin Kolinko reported some issues with caching that blocked the release:\nI noted new methods that introduced caching into classfile.ConstantUtf8 class. BCEL_DONT_CACHE should at least have static setter, or a static setter for a cache instance / a factory class. RELEASE-NOTES.txt describes this change as BCEL-163 Incorporate patch file from Findbugs which does not say much about this change. Actually this change introduced caching for ConstantUtf8 and ObjectType instances.\nEmmanuel Bourg did some investigation and testing and reported back:\nIf nobody object I'll remove this cache, the impact on the performance is too important to enable it by default, and the static state smells like a quick and dirty implementation. This feature could return as a pluggable cache if someone wants to provide a patch.\ngarydgregory suggested adding a flush method to clear the cache in ObjectType\n"
            },
            "2": {
                "commit_sha_buggy": "101996e7ade8d700263b6fc7504ccfcae4884ef6",
                "commit_sha_fixed": "c070c23750e4720fe44b92237b2b55559619e8ac",
                "report_id": "BCEL-207",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-207",
                "issue_title": "[BCEL-207] RemoveLocalVariable(s) doesn't remove the associated Targetters. - ASF JIRA",
                "issue_description": "\nRemoveLocalVariable(s) doesn't remove the associated Targetters.\n"
            },
            "3": {
                "commit_sha_buggy": "d24936191391128db30ff49e298e2b31aa643d3a",
                "commit_sha_fixed": "5f029f691332139ea0bb0e938b90799d74806a93",
                "report_id": "BCEL-184",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-184",
                "issue_title": "[BCEL-184] JustIce verifier does not check correctly the returned value of a method - ASF JIRA",
                "issue_description": "\nDefining a areturn opcode (return object) in a void method is accepted by the bytecode verifier.\nThis must not be allowed.\nHere is an example of a non-valid bytecode for a void method:\n\n       BB 0003      // 0   : new java/lang/Object\n       59           // 3   : dup \n       B7 0008      // 4   : invokespecial java/lang/Object.<init>()V\n       00           // 7   : nop \n       B0           // 8   : areturn (Not allowed in a void method)\n\n\n"
            },
            "4": {
                "commit_sha_buggy": "5865fdde89b92235cb080637810e178f21bbfc11",
                "commit_sha_fixed": "2f2698fa5739eba1cdc3bdf8299a754fb98ae871",
                "report_id": "BCEL-243",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-243",
                "issue_title": "[BCEL-243] Type.getType() needs to understand TypeVariableSignature(s) - ASF JIRA",
                "issue_description": "\nCorrect Type.getType() to use the updated Type support added as part of BCEL-197.\n"
            },
            "5": {
                "commit_sha_buggy": "8df53e2ef1866726bba923d064319f050413fa49",
                "commit_sha_fixed": "7ceb5a6b8236517d708d7965f4873344c5630969",
                "report_id": "BCEL-277",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-277",
                "issue_title": "[BCEL-277] Resolving the String representation of a constant throws NoSuchElementException in case of CONSTANT_NameAndType constant. - ASF JIRA",
                "issue_description": "\nA method that constantToString of ConstantPool class always occur NoSuchElementException when face with costant type of CONSTANT_NameAndType.\nA reason is invalid separator for StringTokenizer that colon. It should be replaced to empty string.\nI had pull request include ConstantPoolTestCase.\n"
            },
            "6": {
                "commit_sha_buggy": "5f5fa24f351870d57a196a2280ae7a0b668f26c7",
                "commit_sha_fixed": "e74df2c0e90e5e4ee92a0d45fcc6f5db5958861a",
                "report_id": "BCEL-289",
                "report_url": "https://issues.apache.org/jira/browse/BCEL-289",
                "issue_title": "[BCEL-289] Crash when parsing constructor of inner classes with parameters annotated - ASF JIRA",
                "issue_description": "\nBCEL crashes when parsing the constructor of an inner class whose parameters are annotated. For instance, when parsing the jar obtained from the following classes:\n\npublic @interface A {}\npublic @interface B {}\npublic class Test {\n    public class Inner {\n\tpublic Inner(@A Object a, @B Object b) {}\n    }\n}\n\n\nIn particular:\n\n\t\tClassParser cp = new ClassParser(args[0]);\n\t\tClassGen cg = new ClassGen(cp.parse());\n\t\tMethodGen mg = new MethodGen(cg.getMethodAt(0), cg.getClassName(), cg.getConstantPool());\n\t\tmg.getAnnotationsOnParameter(0);\n\n\n(where args[0] points to Test$Inner.class)\nyou get\n\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 2\n\tat org.apache.bcel.generic.MethodGen.ensureExistingParameterAnnotationsUnpacked(MethodGen.java:1120)\n\tat org.apache.bcel.generic.MethodGen.getAnnotationsOnParameter(MethodGen.java:1073)\n\n\n"
            }
        }
    },
    "JacksonDataformatBinary_protobuf": {
        "owner_repo": "FasterXML/jackson-dataformats-binary",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "9f792202770c0e2823332c01a879de8127db7d70",
                "commit_sha_fixed": "39ff81e6a118212a514c5c20d7a6a9ba2376a84d",
                "report_id": "79",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/79",
                "issue_title": "Fix wire type for packed arrays",
                "issue_description": "(note: see #76 for background)\r\n\r\nLooks like generator is writing wrong wire type for packed arrays: it should use type `2` (length prefixed) and NOT wire type of elements contained.\r\n"
            },
            "2": {
                "commit_sha_buggy": "78bd410affb13482d86e33d770d83ea08e6e1fe5",
                "commit_sha_fixed": "1a53cd5b6ce3b856f68badc944248b170bf212ac",
                "report_id": "85",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/85",
                "issue_title": "[protobuf] _decode32Bits() bug in ProtobufParser",
                "issue_description": "```java\r\nprotected final int _decode32Bits() throws IOException {\r\n    int ptr = this._inputPtr;\r\n    if(ptr + 3 >= this._inputEnd) {\r\n      return this._slow32();\r\n    } else {\r\n      byte[] b = this._inputBuffer;\r\n      int v = (b[ptr] & 255) + (b[ptr + 1] << 8) + ((b[ptr + 2] & 255) << 16) + (b[ptr + 3] << 24);\r\n      this._inputPtr = ptr + 4;\r\n      return v;\r\n    }\r\n  }\r\n```\r\nbug in the following line\r\nint v = (b[ptr] & 255) + (b[ptr + 1] << 8) + ((b[ptr + 2] & 255) << 16) + (b[ptr + 3] << 24);\r\n\r\nIf b[prt+1] or b[ptr+3] is negative, << will preserve sign and the overall plus operation will corrupt. Float values like 123.456f will be incorrectly decoded.\r\n\r\n_decode64Bits()'s logic is correct.\r\n"
            },
            "3": {
                "commit_sha_buggy": "0a870e1389400852f8b5c0588a93b8d89dfeaabf",
                "commit_sha_fixed": "6d0a2df0e14627591461c5bb67511dbcb08dbb19",
                "report_id": "94",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/94",
                "issue_title": "Should _ensureRoom in ProtobufGenerator.writeString()?",
                "issue_description": "With version 2.9.0.pr3, we encounter a ArrayIndexOutOfBoundsException\r\n\r\n```\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 8000\r\n         at com.fasterxml.jackson.dataformat.protobuf.ProtobufUtil.appendLengthLength(ProtobufUtil.java:73)\r\n         at com.fasterxml.jackson.dataformat.protobuf.ProtobufGenerator._writeLengthPrefixed(ProtobufGenerator.java:1293)\r\n         at com.fasterxml.jackson.dataformat.protobuf.ProtobufGenerator._encodeLongerString(ProtobufGenerator.java:1286)\r\n         at com.fasterxml.jackson.dataformat.protobuf.ProtobufGenerator.writeString(ProtobufGenerator.java:729)\r\n         at com.fasterxml.jackson.databind.ser.std.StringSerializer.serialize(StringSerializer.java:41)\r\n         at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:727)\r\n         at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:716)\r\n         ... 104 more\r\n```\r\n\r\nOccurs once every few hours, so not easily reproduced. Shall we call _ensureRoom when _encodeLongerString?"
            },
            "4": {
                "commit_sha_buggy": "ba93ae2107254b89bec81cb2af463cf1b0e59fb8",
                "commit_sha_fixed": "f1ddf07ae892a84df7787f935ce8228071c0dfa4",
                "report_id": "135",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/135",
                "issue_title": "Infinite sequence of `END_OBJECT` tokens returned at end of streaming read",
                "issue_description": "Jackson version: 2.9.4\r\nI'm trying to use streaming JsonParser to parse protobuf binary data according to your example, however the nextToken method keep returning \"END_OBJECT\" token in the end of parsing. You can reproduce this issue by following code:\r\n```java\r\n        ObjectMapper mapper = new ProtobufMapper();\r\n        String protobuf_str = \"message Employee {\\n\"\r\n                + \" required string name = 1;\\n\"\r\n                + \" required int32 age = 2;\\n\"\r\n                + \" repeated string emails = 3;\\n\"\r\n                + \" optional Employee boss = 4;\\n\"\r\n                + \"}\\n\";\r\n        final ProtobufSchema schema = ProtobufSchemaLoader.std.parse(protobuf_str);\r\n\r\n        Employee empl = new Employee();\r\n        empl.age = 30;\r\n        empl.emails = new String[]{\"foo@gmail.com\"};\r\n        empl.name = \"foo\";\r\n\r\n        byte[] protobufData = mapper.writer(schema)\r\n                .writeValueAsBytes(empl);\r\n\r\n        JsonParser jsonParser = new ProtobufFactory().createParser(new ByteArrayInputStream(protobufData));\r\n        jsonParser.setSchema(schema);\r\n        JsonToken token;\r\n        while ((token = jsonParser.nextToken()) != null) {\r\n            System.out.println(token.id());\r\n        }\r\n```\r\noutput:\r\n```\r\n1\r\n5\r\n6\r\n5\r\n7\r\n5\r\n3\r\n6\r\n4\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n2\r\n...endless\r\n```"
            }
        }
    },
    "Jackrabbit_filevault_vault_core": {
        "owner_repo": "apache/jackrabbit-filevault",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "35a9089daf47581c45f5664660e54231ef817fbd",
                "commit_sha_fixed": "87a0f33a57757437dd20b6a25451f9111e3c692f",
                "report_id": "JCRVLT-117",
                "report_url": "https://issues.apache.org/jira/browse/JCRVLT-117",
                "issue_title": "[JCRVLT-117] Potential XSS problem in org.apache.jackrabbit.vault.util.HtmlProgressListener - ASF JIRA",
                "issue_description": "\nthe org.apache.jackrabbit.vault.util.HtmlProgressListener should escape the arguments before it streams them to the stream. the users of the progress listener should not care about the intended output medium.\n"
            }
        }
    },
    "JacksonDatatypeJsr310": {
        "owner_repo": "FasterXML/jackson-datatype-jsr310",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0104604c9160ad34876fd57441c867a5f219eeb4",
                "commit_sha_fixed": "ae8d8356f009b6875439b0bfd37f6677f54ed953",
                "report_id": "27",
                "report_url": "https://github.com/FasterXML/jackson-datatype-jsr310/pull/27",
                "issue_title": "Also accept ISO strings with time-component when deserializing LocalDate",
                "issue_description": "In JavaScript, we only have a single Date type, whose `toJSON` serializes it as ISO8601 string (e.g. `2015-01-01T12:33:44`. It always includes the time component, even when using it only for the date-component:\n\n```\nvar mydate = new Date(\"2015-01-01\");\nmydate.toJSON(); // results in \"2015-01-01T00:00:00.000Z\"\n```\n\nIf you deserialize this into a Java `LocalDate`, the current implementation blows up since it specifies the ISO format without time-component for parsing. This PR ignores the time-component from the serialized string when deserializing into a `LocalDate`, making it more broadly useable.\n"
            },
            "2": {
                "commit_sha_buggy": "ae8d8356f009b6875439b0bfd37f6677f54ed953",
                "commit_sha_fixed": "8f3a0440d52ae658eb63b70fb8b2ceb1866e2205",
                "report_id": "32",
                "report_url": "https://github.com/FasterXML/jackson-datatype-jsr310/pull/32",
                "issue_title": "Support WRITE_DATES_WITH_ZONE_ID",
                "issue_description": "Solves issue #30\n"
            },
            "3": {
                "commit_sha_buggy": "34f2c209d052be549f1725f012e6d81ad26bd70c",
                "commit_sha_fixed": "e74927b0fc1e2b140b6e7b31a423ea2dd18f5f8a",
                "report_id": "56",
                "report_url": "https://github.com/FasterXML/jackson-datatype-jsr310/pull/56",
                "issue_title": "Handle JSON serialized Dates from JavaScript in LocalDateDeserializer",
                "issue_description": "I've been at this before (#28), however, during the review phase of the PR I accidentally borked my own use-case. Unfortunately I only found out after we switched from our internally patched version to the current 2.7 release. \n\nIt's now possible to parse a date and time (\"2016-01-18T15:41:32.232\") as LocalDate. However, what I needed was to be able to parse this, coming from JavaScript:\n\n```\nnew Date().toJSON()\n\"2016-01-18T14:09:30.163Z\"\n```\n\n(notice the trailing Z, which is currently not accepted)\n\nJavaScript generates an ISO instant string when serialising a JavaScript Date [1]. It seems I am not the only one running into this issue [2]. I think it would be great to revise my original PR to allow for this.  That way, it works for many people doing Java/JS interop without having to override the pattern on each usage of a LocalDate field. The check for custom formatter (https://github.com/FasterXML/jackson-datatype-jsr310/issues/37) is obviously still in place. I also made the check for the presence of the time component a bit more robust.\n\nThanks for considering this PR. My CLA is already in place, so that should not be an issue.\n\n[1] https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toJSON & https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toISOString\n[2] http://stackoverflow.com/questions/26233882/javascript-date-to-java-time-localdate & http://stackoverflow.com/questions/5591967/how-to-deserialize-js-date-using-jackson\n"
            },
            "4": {
                "commit_sha_buggy": "f85c7085e5d1b77bafb58c4f40b78a6e8368a12c",
                "commit_sha_fixed": "0b37e347adb70f469e3d4808f9108ff0ab5c09d2",
                "report_id": "70",
                "report_url": "https://github.com/FasterXML/jackson-datatype-jsr310/pull/70",
                "issue_title": "Fix issue #69 by making formatters aware of the time zone",
                "issue_description": "Formatters are now aware of time zone specified in @JsonFormat\n"
            }
        }
    },
    "JacksonDataformatBinary_smile": {
        "owner_repo": "FasterXML/jackson-dataformats-binary",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7fc8d59a999343ad900b91135cd2e6adf1dcfea2",
                "commit_sha_fixed": "155ec35e351a4b6d8a0aa428082866a292a30a22",
                "report_id": "153",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/153",
                "issue_title": "Unable to set a compression input/output decorator to a `SmileFactory`",
                "issue_description": "I have a special need for the `riak-java-client` which only allows me to use an `ObjectMapper` to serialize/deserialize key-values, I would like to decorate a `SmileFactory` with compressors like LZ4, Snappy or GZip but at the moment this is not possible, when I try a mapper like the following:\r\n```\r\npublic static final Charset UTF8=Charset.forName(\"UTF-8\");\r\n\r\npublic static final ObjectMapper GZIP_JSON_MAPPER=new ObjectMapper(new SmileFactory().disable(ENCODE_BINARY_AS_7BIT)\r\n   .setInputDecorator(new InputDecorator()\r\n   {\r\n     @Override\r\n     public InputStream decorate(IOContext context,InputStream inputStream) throws IOException\r\n     {\r\n       return new GZIPInputStream(inputStream);\r\n     }\r\n\r\n     @Override\r\n     public InputStream decorate(IOContext context,byte[] bytes,int offset,int length) throws IOException\r\n     {\r\n       return new GZIPInputStream(new ByteArrayInputStream(bytes,offset,length));\r\n     }\r\n\r\n     @Override\r\n     public Reader decorate(IOContext context,Reader reader) throws IOException\r\n     {\r\n       return new InputStreamReader(new GZIPInputStream(new ReaderInputStream(reader)),UTF8);\r\n     }\r\n   })\r\n   .setOutputDecorator(new OutputDecorator()\r\n   {\r\n     @Override\r\n     public OutputStream decorate(IOContext context,OutputStream outputStream) throws IOException\r\n     {\r\n       return new GZIPOutputStream(outputStream);\r\n     }\r\n\r\n     @Override\r\n     public Writer decorate(IOContext context,Writer writer) throws IOException\r\n     {\r\n       return new OutputStreamWriter(new GZIPOutputStream(new WriterOutputStream(writer,UTF8)));\r\n     }\r\n   }))\r\n   .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\r\n   .disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\r\n   .setSerializationInclusion(JsonInclude.Include.NON_NULL)\r\n   .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\r\n```\r\n\r\n**This is the exception I get:**\r\n```\r\nException in thread \"main\" java.util.zip.ZipException: Not in GZIP format\r\n\tat java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:165)\r\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:79)\r\n\tat java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:91)\r\n\tat ...JsonUtils$4.decorate(JsonUtils.java:162)\r\n\tat com.fasterxml.jackson.core.JsonFactory._decorate(JsonFactory.java:1459)\r\n\tat com.fasterxml.jackson.dataformat.smile.SmileFactory.createParser(SmileFactory.java:330)\r\n\tat com.fasterxml.jackson.dataformat.smile.SmileFactory.createParser(SmileFactory.java:320)\r\n\tat com.fasterxml.jackson.dataformat.smile.SmileFactory.createParser(SmileFactory.java:29)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091)\r\n```\r\n\r\nI used Gzip as an example, in reality I'm using both LZ4 and Gzip and both throw exceptions when I try with a `SmileFactory`, this works perfectly with a `JsonFactory`, the reason for me to prefer a `SmileFactory` over a `JsonFactory` is because it is notice-able faster than the `JsonFactory` so basically it'll help compensate the price I pay for compression."
            },
            "2": {
                "commit_sha_buggy": "82b282d1fa51468d1fbe493bb92291bf0b8f8897",
                "commit_sha_fixed": "a99037f4a8dcf5221c1f0a7ed02760434c55361d",
                "report_id": "155",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/155",
                "issue_title": "Inconsistent support for `StreamWriteFeature.FLUSH_PASSED_TO_STREAM`",
                "issue_description": "Cbor and Smile serializers attempt to flush streams on close when AUTO_CLOSE_TARGET is disabled, even if FLUSH_PASSED_TO_STREAM is also disabled."
            },
            "3": {
                "commit_sha_buggy": "f798cedc2aa2d6f23a4b22f6475d5503946d1a23",
                "commit_sha_fixed": "01fe76a596bb204d72de54c73772d675156a7b07",
                "report_id": "257",
                "report_url": "https://github.com/FasterXML/jackson-dataformats-binary/issues/257",
                "issue_title": "Uncaught validation problem wrt Smile \"BigDecimal\" type (found by OSS-Fuzzer)",
                "issue_description": "(note: offshoot of this finding https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=32168)\r\n\r\nLooks like following 7-byte document encoding a single \"BigInteger\" value:\r\n\r\n```\r\n0x3A 0x29 0x0A  0x08  // 4 byte header (note, 0x8 specifies unused bit that... maybe should error)\r\n0x2A // Number, BigDecimal\r\n0xFF // scale; zigzag value of -32,\r\n   // HOWEVER, not actually legal as second-most-significant-bit SHOULD be zero\r\n   // (should this be caught, reported?)\r\n   // -- should be 0xBF\r\n0xC0 // length of payload, zigzag of 0 but similarly invalid represention\r\n   // -- should be 0x80\r\n```\r\n\r\ncauses an exception within `BigInteger`, attempting to pass 0-byte array to construct `BigInteger` (to further create `BigDecimal`). That is not a valid value and needs to be specifically checked against, reported.\r\n\r\n\r\n"
            }
        }
    },
    "JacksonModuleAfterburner": {
        "owner_repo": "FasterXML/jackson-module-afterburner",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "563520be197b509fa04301741357818b4797756f",
                "commit_sha_fixed": "aac3e8afd50fd7ac70de4ec4803350ca315e5dfe",
                "report_id": "43",
                "report_url": "https://github.com/FasterXML/jackson-module-afterburner/issues/43",
                "issue_title": "IllegalStateException: Afterburner internal error: BeanDeserializer for [simple type, class Envelope] has no properties that match expected ordering -- can not create optimized deserializer",
                "issue_description": "Hi,\n\nEncountering the following problem with:\njackson-module-afterburner:jar:2.3.2\n\nAnd the following code:\n\n```\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.annotation.JsonTypeInfo;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.module.afterburner.AfterburnerModule;\nimport org.junit.Test;\n\nimport java.io.IOException;\n\n\nclass Envelope {\n    @JsonTypeInfo(use= JsonTypeInfo.Id.CLASS, include= JsonTypeInfo.As.EXTERNAL_PROPERTY, property=\"class\")\n    private Object payload;\n\n\n    public Envelope(@JsonProperty(\"payload\") Object payload) {\n        this.payload = payload;\n    }\n\n    @JsonProperty\n    public Object getPayload() {\n        return payload;\n    }\n}\n\nclass Payload {\n    private String something;\n\n    public Payload(@JsonProperty(\"something\") String something) {\n        this.something = something;\n    }\n    @JsonProperty\n    public Object getSomething() {\n        return something;\n    }\n}\n\n\npublic class AfterBurnerTest {\n    @Test\n    public void testAfterburner() throws IOException {\n\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.registerModule(new AfterburnerModule());\n        Envelope envelope = new Envelope(new Payload(\"test\"));\n        String json = mapper.writeValueAsString(envelope);\n        System.err.println(json);\n        Envelope envelope1 = mapper.readValue(json, Envelope.class);\n        System.err.println(mapper.writeValueAsString(envelope1));\n    }\n}\n```\n\nResults in:\n\n```\n{\"payload\":{\"something\":\"test\"},\"class\":\"Payload\"}\n\njava.lang.IllegalStateException: Afterburner internal error: BeanDeserializer for [simple type, class Envelope] has no properties that match expected ordering -- can not create optimized deserializer\n    at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.resolve(SuperSonicBeanDeserializer.java:97)\n    at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:292)\n    at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:241)\n    at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\n    at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:381)\n    at com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:3154)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3047)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2146)\n    at AfterBurnerTest.testAfterburner(AfterBurnerTest.java:49)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:160)\n        ...\n```\n\nOnly happens with Afterburner, and seems to be due to Envelope only having one property, as adding another property to Envelope seems to fix it.\n"
            },
            "2": {
                "commit_sha_buggy": "2390aad0c2526df536204c8bdc2758ea7764e974",
                "commit_sha_fixed": "7a81b2ceb5efcb95f72fd37e503e2f608d3c7220",
                "report_id": "52",
                "report_url": "https://github.com/FasterXML/jackson-module-afterburner/issues/52",
                "issue_title": "Invalidating SerializationInclusion.NON_NULL of other modules",
                "issue_description": "https://github.com/zapodot/jackson-databind-java-optional/issues/2\n#### tl;dr\n\nIf a different module with custom SerializationInclusion handling is registered after AfterBurnerModule, nulls are de/serialized still as nulls, ignoring the other module. The workaround is to\n- Register the other module first. Not possible when one uses dropwizard for example.\n- Add @JsonProperty to those specific fields. Not pretty when one has many of those.\n\nUnit tests are available in the issue above.\n"
            },
            "3": {
                "commit_sha_buggy": "d68ed5e4e86d3f7174b8ea0604d6710ee99fb0cd",
                "commit_sha_fixed": "bda2f9b194e7b5e0d1f001e1aaf951504f96f1c9",
                "report_id": "57",
                "report_url": "https://github.com/FasterXML/jackson-module-afterburner/issues/57",
                "issue_title": "@JsonAppend causes NullPointerException",
                "issue_description": "Afterburner does not seem to work with `@JsonAppend`. The following code reproduces the issue:\n\n``` java\n  @Test\n  public void testJsonAppendWithAfterburner() throws Exception {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.registerModule(new AfterburnerModule());\n    String json = mapper.writeValueAsString(new Pojo(\"foo\"));\n    assertEquals(\"{\\\"name\\\":\\\"foo\\\",\\\"virtual\\\":\\\"bar\\\"}\", json);\n  }\n\n\n  @JsonAppend(props = @Prop(name = \"virtual\", value = MyVirtualPropertyWriter.class))\n  public static class Pojo {\n    private final String name;\n    public Pojo(String name) {\n      this.name = name;\n    }\n    public String getName() {\n      return name;\n    }\n  }\n\n  public static class MyVirtualPropertyWriter extends VirtualBeanPropertyWriter {\n    public MyVirtualPropertyWriter() {\n    }\n    protected MyVirtualPropertyWriter(BeanPropertyDefinition propDef, Annotations contextAnnotations,\n        JavaType declaredType) {\n      super(propDef, contextAnnotations, declaredType);\n    }\n    @Override\n    protected Object value(Object bean, JsonGenerator jgen, SerializerProvider prov) throws Exception {\n      return \"bar\";\n    }\n    @Override\n    public VirtualBeanPropertyWriter withConfig(MapperConfig<?> config, AnnotatedClass declaringClass,\n        BeanPropertyDefinition propDef, JavaType type) {\n      return new MyVirtualPropertyWriter(propDef, declaringClass.getAnnotations(), type);\n    }\n  }\n```\n\nRunning the test results in:\n\n```\njava.lang.NullPointerException\n    at com.fasterxml.jackson.module.afterburner.ser.SerializerModifier.findProperties(SerializerModifier.java:82)\n    at com.fasterxml.jackson.module.afterburner.ser.SerializerModifier.changeProperties(SerializerModifier.java:49)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.constructBeanSerializer(BeanSerializerFactory.java:374)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.findBeanSerializer(BeanSerializerFactory.java:272)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._createSerializer2(BeanSerializerFactory.java:225)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.createSerializer(BeanSerializerFactory.java:153)\n    at com.fasterxml.jackson.databind.SerializerProvider._createUntypedSerializer(SerializerProvider.java:1199)\n    at com.fasterxml.jackson.databind.SerializerProvider._createAndCacheUntypedSerializer(SerializerProvider.java:1153)\n    at com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:481)\n    at com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:679)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:107)\n    at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3525)\n    at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2915)\n    at com.bitlok.JsonAppendTest.testJsonAppendWithAfterburner(JsonAppendTest.java:26)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n```\n\nI've tested this with 2.6.1. Without the AfterburnerModule it works as expected.\n"
            }
        }
    },
    "Woodstox": {
        "owner_repo": "FasterXML/woodstox",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4debd108e9a9e8423ddb489dee4fe6230bbde761",
                "commit_sha_fixed": "db22adc6efa9c99814466f8a9dc19e3a3f25136b",
                "report_id": "13",
                "report_url": "https://github.com/FasterXML/woodstox/issues/13",
                "issue_title": "BasicStreamReader.getElementText() behavior doesn't match Java documentation",
                "issue_description": "The [documentation for XMLStreamReader](https://docs.oracle.com/javase/8/docs/api/javax/xml/stream/XMLStreamReader.html#getElementText--) suggests that `getElementText()` return all valid text between a `START_ELEMENT` and `END_ELEMENT`.  \n\nWith 5.0.1 and 5.0.2 woodstox, this doesn't happen for an element that contains text and then CDATA.  \nExample:\n`\"<tag>foo<![CDATA[bar]]></tag>\"`, calling `getElementText()` while at `tag` will return `\"foo\"`, while the example implementation from the doc comments suggests it should be `\"foobar\"`.\n\nI linked the documentation from Java 8, but it's the same blurb given for previous versions as well.\n"
            },
            "2": {
                "commit_sha_buggy": "c2ffc0f55315d03d86eee23317541e3aeb19fd31",
                "commit_sha_fixed": "87e136dd23ad0ddc7dfb524ac5f5b4ab9520926f",
                "report_id": "43",
                "report_url": "https://github.com/FasterXML/woodstox/issues/43",
                "issue_title": "`CompactStartElement` appears to incorrectly classify attributes as default",
                "issue_description": "When reading and writing XML via `WstxInputFactory` and `DefaultEventAllocator`, attributes appear to be classed as default/unspecified incorrectly.\r\n\r\nThis appears to be caused by `CompactStartElement.constructAttr`; this method passes `isDef` (presumably \"is default\"?) to `AttributeEventImpl`'s `wasSpecified` parameter directly. If an attribute is default, shouldn't that mean it wasn't specified?\r\n\r\nPlease let me know if I'm misinterpreting this behaviour.\r\n\r\nTest case:\r\n```java\r\nimport java.io.ByteArrayInputStream;\r\nimport java.io.StringWriter;\r\nimport javax.xml.stream.XMLEventFactory;\r\nimport javax.xml.stream.XMLStreamException;\r\nimport javax.xml.stream.XMLStreamReader;\r\nimport javax.xml.stream.events.StartElement;\r\nimport javax.xml.stream.events.XMLEvent;\r\n\r\nimport com.ctc.wstx.evt.DefaultEventAllocator;\r\nimport com.ctc.wstx.stax.WstxEventFactory;\r\nimport com.ctc.wstx.stax.WstxInputFactory;\r\n\r\npublic class Main {\r\n\r\n    public static void main(String[] args) throws XMLStreamException {\r\n        String xml = \"<?xml version=\\\"1.0\\\" ?><a b=\\\"c\\\"></a>\";\r\n        WstxInputFactory inputFactory = new WstxInputFactory();\r\n        XMLStreamReader stream = inputFactory.createXMLStreamReader(new ByteArrayInputStream(xml.getBytes()));\r\n        DefaultEventAllocator allocator = DefaultEventAllocator.getDefaultInstance();\r\n        XMLEventFactory eventFactory = new WstxEventFactory();\r\n        StringWriter writer = new StringWriter();\r\n        while(stream.hasNext()) {\r\n            XMLEvent event = allocator.allocate(stream);\r\n            if(event.isStartElement()) {\r\n                // Force parsing of attributes\r\n                StartElement start = event.asStartElement();\r\n                event = eventFactory.createStartElement(start.getName(), start.getAttributes(), start.getNamespaces());\r\n            }\r\n            event.writeAsEncodedUnicode(writer);\r\n            stream.next();\r\n        }\r\n        System.out.println(\"Expected: \" + xml);\r\n        System.out.println(\"Actual:   \" + writer.toString());\r\n    }\r\n}\r\n```"
            },
            "3": {
                "commit_sha_buggy": "bae0330b0c2895b4aeb35ac83aa961d7f29bfa66",
                "commit_sha_fixed": "3175647b0eba4289369e296171dee5ad11444261",
                "report_id": "47",
                "report_url": "https://github.com/FasterXML/woodstox/issues/47",
                "issue_title": "Validation error due to white-space being handled as CData by `BaseStreamWriter`",
                "issue_description": "Hello,\r\n\r\nI've found a bug in the way white-space is handled by the BaseStreamWriter when using validation with release 5.1.0\r\n\r\nThe exception we get is the following:\r\n`Exception in thread \"main\" com.ctc.wstx.exc.WstxValidationException: Element <Document> has non-mixed content specification; can not contain non-white space text, or any CDATA sections\r\n at [row,col {unknown-source}]: [1,49]\r\n\tat com.ctc.wstx.exc.WstxValidationException.create(WstxValidationException.java:50)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportProblem(BaseStreamWriter.java:1248)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportValidationProblem(BaseStreamWriter.java:1739)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportInvalidContent(BaseStreamWriter.java:1691)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.verifyWriteCData(BaseStreamWriter.java:1516)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.writeCData(BaseStreamWriter.java:331)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.copyEventFromReader(BaseStreamWriter.java:806)\r\n\tat Converter.main(Converter.java:34)`\r\n\r\nThis happens because white-space events copied to the BaseStreamWriter, at BaseStreamWriter:806, are handled by writeCData() and therefore treated as a CDATA block for validation purposes."
            },
            "4": {
                "commit_sha_buggy": "100eee2930648867a4846a4ca5903b243eaa2e0d",
                "commit_sha_fixed": "6adeaa7a5f30452e638b65b12855a3e20831b83f",
                "report_id": "47",
                "report_url": "https://github.com/FasterXML/woodstox/issues/47",
                "issue_title": "Validation error due to white-space being handled as CData by `BaseStreamWriter`",
                "issue_description": "Hello,\r\n\r\nI've found a bug in the way white-space is handled by the BaseStreamWriter when using validation with release 5.1.0\r\n\r\nThe exception we get is the following:\r\n`Exception in thread \"main\" com.ctc.wstx.exc.WstxValidationException: Element <Document> has non-mixed content specification; can not contain non-white space text, or any CDATA sections\r\n at [row,col {unknown-source}]: [1,49]\r\n\tat com.ctc.wstx.exc.WstxValidationException.create(WstxValidationException.java:50)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportProblem(BaseStreamWriter.java:1248)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportValidationProblem(BaseStreamWriter.java:1739)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.reportInvalidContent(BaseStreamWriter.java:1691)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.verifyWriteCData(BaseStreamWriter.java:1516)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.writeCData(BaseStreamWriter.java:331)\r\n\tat com.ctc.wstx.sw.BaseStreamWriter.copyEventFromReader(BaseStreamWriter.java:806)\r\n\tat Converter.main(Converter.java:34)`\r\n\r\nThis happens because white-space events copied to the BaseStreamWriter, at BaseStreamWriter:806, are handled by writeCData() and therefore treated as a CDATA block for validation purposes."
            },
            "5": {
                "commit_sha_buggy": "e5433fbedf06e19d10137822915a58d10008ba87",
                "commit_sha_fixed": "09f310b910afe074b493dc6ba2a70a6ae8939c1e",
                "report_id": "104",
                "report_url": "https://github.com/FasterXML/woodstox/issues/104",
                "issue_title": "`NullPointerException` in `DTDValidator.validateElementEnd()` for element undefined in DTD",
                "issue_description": "The DTDValidator class is throwing a NullPointerException when processing invalid XML.  To reproduce, use this catalog: https://github.com/oasis-tcs/dita/tree/v1.3/doctypes\r\n\r\ntest.xml\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<!DOCTYPE map PUBLIC \"-//OASIS//DTD DITA Map//EN\" \"map.dtd\">\r\n<map>\r\n  <topicref>\r\n    <ditavalref>\r\n      <val><!-- This is invalid -->\r\n        <prop att=\"product\" val=\"win\" action=\"flag\" color=\"black\"/>\r\n      </val>\r\n    </ditavalref>\r\n  </topicref>\r\n</map>\r\n```\r\n\r\nWstxValidatorTest.java\r\n```java\r\nimport com.ctc.wstx.stax.WstxInputFactory;\r\nimport java.io.File;\r\nimport java.nio.file.Paths;\r\nimport javax.xml.catalog.CatalogFeatures;\r\nimport javax.xml.catalog.CatalogManager;\r\nimport javax.xml.stream.XMLInputFactory;\r\nimport javax.xml.stream.XMLStreamException;\r\n\r\npublic class WstxValidatorTest {\r\n  public static void main(String[] args) throws XMLStreamException {\r\n    var catalog =\r\n        CatalogManager.catalogResolver(\r\n            CatalogFeatures.defaults(), Paths.get(\"path/to/catalog.xml\").toUri());\r\n    var factory = new WstxInputFactory();\r\n    factory.setProperty(XMLInputFactory.IS_VALIDATING, true);\r\n    factory.setProperty(XMLInputFactory.RESOLVER, catalog);\r\n\r\n    var reader = factory.createXMLStreamReader(new File(\"path/to/test.xml\"));\r\n    reader.setValidationProblemHandler(p -> System.out.println(p.getMessage()));\r\n\r\n    while (reader.hasNext()) {\r\n      reader.next();\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```\r\nUndefined element <val> encountered\r\nUndefined element <prop> encountered\r\nException in thread \"main\" java.lang.NullPointerException\r\n\tat com.ctc.wstx.dtd.DTDValidator.validateElementEnd(DTDValidator.java:362)\r\n\tat com.ctc.wstx.sr.InputElementStack.validateEndElement(InputElementStack.java:560)\r\n\tat com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2730)\r\n\tat com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1122)\r\n\tat WstxValidatorTest.main(WstxValidatorTest.java:22)\r\n```\r\n\r\n"
            },
            "6": {
                "commit_sha_buggy": "913c115e829ffd11bbe082baa70014db5ea7cc95",
                "commit_sha_fixed": "6d25170c25025ce1bf6b140deb594b4da7abd49b",
                "report_id": "122",
                "report_url": "https://github.com/FasterXML/woodstox/issues/122",
                "issue_title": "Expected either attr limit (2147483647) >= currAttrSize (0) OR >= outBuf.length (96)",
                "issue_description": "After upgrading my application to woodstock v6.2.x, importing xml failed with this exception :\r\n\r\n```\r\nCaused by: java.lang.RuntimeException: Internal error: Expected either attr limit (2147483647) >= currAttrSize (0) OR >= outBuf.length (96)\r\n\tat com.ctc.wstx.util.ExceptionUtil.throwInternal(ExceptionUtil.java:69) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader._checkAttributeLimit(BasicStreamReader.java:2056) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.parseAttrValue(BasicStreamReader.java:2038) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.handleNsAttrs(BasicStreamReader.java:3144) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.handleStartElem(BasicStreamReader.java:3042) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.handleRootElem(BasicStreamReader.java:2188) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.nextFromProlog(BasicStreamReader.java:2168) ~[?:?]\r\n\tat com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1180) ~[?:?]\r\n```\r\n\r\ndowngrading to v6.0.2 fixes it.\r\n\r\nI don't really understand what the message means.. ;)\r\n\r\nThe code looks like the following : \r\n\r\n```java\r\npublic static void checkSVG(final String svg) {\r\n\tboolean allowed = true;\r\n\r\n\tXMLInputFactory factory = XMLInputFactory.newInstance();\r\n\tfactory.setProperty(XMLInputFactory.SUPPORT_DTD, Boolean.FALSE);\r\n\tfactory.setProperty(XMLInputFactory.IS_SUPPORTING_EXTERNAL_ENTITIES, Boolean.FALSE);\r\n\tfactory.setProperty(\"com.ctc.wstx.maxAttributeSize\", Integer.MAX_VALUE);\r\n\r\n\tXMLStreamReader reader = factory.createXMLStreamReader(new StringReader(svg))\r\n\ttry {\r\n\t\twhile (reader.hasNext()) {\r\n\t\t\tif (reader.next() == XMLEvent.START_ELEMENT) {\r\n\r\n\t\t\t\tif (!WHITELIST_ELEMENTS.contains(reader.getLocalName())) {\r\n\t\t\t\t\tallowed = false;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tint attcount = reader.getAttributeCount();\r\n\t\t\t\tfor (int i = 0; i < attcount; ++i) {\r\n\t\t\t\t\tString attName = reader.getAttributeLocalName(i); \r\n\t\t\t\t\tif (!WHITELIST_ATTRIBUTES.contains(attName)) {\r\n\t\t\t\t\t\tallowed = false;\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t} catch (final XMLStreamException e) {\r\n\t\tExceptionUtils.throwRuntimeException(e);\r\n\t}\r\n\t\r\n\tif (!allowed) {\r\n\t\tthrow new SecurityException(\"xxx\");\r\n\t}\r\n}\r\n``` \r\n"
            },
            "7": {
                "commit_sha_buggy": "ff6ad89934de20cab36fbd8395dd774d68f4783d",
                "commit_sha_fixed": "5fd55bec8bc92a7855b08633da0906942b4a7e33",
                "report_id": "124",
                "report_url": "https://github.com/FasterXML/woodstox/issues/124",
                "issue_title": "ArrayIndexOutOfBoundsException for 4-byte UTF-8 character at end of CDATA",
                "issue_description": "(note: from Ossfuzz issue 32906: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=32906)\r\n\r\nLooks like there is another rare boundary condition found by Ossfuzz.\r\n"
            }
        }
    },
    "MetaModel_core": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "979ac783553cd98ec257437d011cd19a9807103e",
                "commit_sha_fixed": "f1ca2be89aeb0fff790f9fa7de28c7ca579be032",
                "report_id": "METAMODEL-58",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-58",
                "issue_title": "[METAMODEL-58] ColumnBuilder.asPrimaryKey() not respected when using CreateTable class - ASF JIRA",
                "issue_description": "\nIf I create a table like this:\nDataContext dc = ...\ndc.executeUpdate(new CreateTable(...).withColumn(\"foo\").asPrimaryKey()...);\nthen the \"foo\" column's primary key aspect is not respected and the table gets created without any PK.\nI found the issue to be that CreateTable is using this method:\nAbstractColumnBuilder.like(Column)\nAnd in this method we do not properly check the primary key flag and set it if appropriate.\nIt should be easy to fix, and quite important!\n"
            },
            "2": {
                "commit_sha_buggy": "a395c5f8023700c2ef47fbb542dd3bf8b88a6ee3",
                "commit_sha_fixed": "48db730750cc907ec53858be2d567c89fff9a2f0",
                "report_id": "METAMODEL-69",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-69",
                "issue_title": "[METAMODEL-69] Deserializing legacy ColumnType is not working - ASF JIRA",
                "issue_description": "\nBecause the old ColumnType was an enum and the new one is an interface, we cannot currently deserialize an old schema structure into the new class format. To fix, we need an enum implementation of the new interface and make the LegacyDeserializationObjectInputStream port the old objects into instances from this new enum.\n"
            },
            "3": {
                "commit_sha_buggy": "796c00aa69e00717260ab5a915ffe37278f8628b",
                "commit_sha_fixed": "f87201ce9f1114bb0b047e02cf6f13dc30b957b4",
                "report_id": "METAMODEL-100",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-100",
                "issue_title": "[METAMODEL-100] AbstracColumn.equals(..) does not take into account the column number - ASF JIRA",
                "issue_description": "\nI ran into a rare issue the other day: While reading a CSV file that had duplicate column names, doing a subselection on the table caused the values at the position of the duplicated column names to be duplicated values instead of the values really at the records.\nThe table layout would be like:\n\nfoo,foo,bar\n1,2,3\n4,5,6\n\n\nBut while selecting \"foo\", \"foo\" and \"bar\" it emitted records:\n\n1,1,3\n4,4,6\n\n\nAfter some debugging it seems that the indexOf(...) calls on the DataSetHeader is eventually delegating to an equals(..) call on AbstractColumn. This equals method does not take into account the column number and thus the columns are deemed equal although they are not.\n"
            },
            "4": {
                "commit_sha_buggy": "491ab5161b6b9fa7f2357b88ca1749a2cc1c4dd2",
                "commit_sha_fixed": "c1cc5d803f4cc9579d87c5f257d2072a855d12d3",
                "report_id": "METAMODEL-138",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-138",
                "issue_title": "[METAMODEL-138] Not capable of parsing queries with more than 2 empty spaces before \"AS\" - ASF JIRA",
                "issue_description": "\nAdding more than 2 spaces before the \"AS\" keyword prevent the QueryParser to parse the query properly. This test does not pass:\npublic void testSelectEmptySpacesBeforeAs() throws Exception \n{\n        Query q = MetaModelHelper.parseQuery(dc, \"SELECT tbl.foo     AS alias FROM sch.tbl\");\n        assertEquals(\"SELECT tbl.foo AS alias FROM sch.tbl\", q.toSql());\n    }\n\nWe have found out that the parsing problem starts when you add more than 2 empty spaces before the \"AS\" keyword.\n"
            },
            "5": {
                "commit_sha_buggy": "d17a10dd01a5e22b8d9c3f5511c553d97e0c5098",
                "commit_sha_fixed": "b95d74f1fe51ade825a0369fdc56d11b726fc884",
                "report_id": "METAMODEL-194",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-194",
                "issue_title": "[METAMODEL-194] Max rows property of query cannot be 0 - ASF JIRA",
                "issue_description": "\nQuery.setMaxRows(Integer) has a check to see that the value is correct. But for some reason it does not allow max rows = 0. In my opinion it should be possible to define and execute a query with max rows = 0. It would just always return an empty DataSet. But from our perspective we shouldn't prohibit it becuase the query may be created by some tool or dynamic code in which case allowing 0 may make sense.\n"
            },
            "6": {
                "commit_sha_buggy": "9553357cd5b1b8e38b774c283d859f6b6f8c62ed",
                "commit_sha_fixed": "9de5b7711d36470cd6b88f6d037e0bab46b8147a",
                "report_id": "METAMODEL-199",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-199",
                "issue_title": "[METAMODEL-199] QueryParser fails to parse \"WHERE (x='1') AND (y='2')\" style where clause - ASF JIRA",
                "issue_description": "\nWe encountered a query that was expressed like this, that was not parseable:\nSELECT COUNT FROM table WHERE (col1='1') AND (col2='2')\nIt seems that it works if we remove the parentheses around the where items. But it should rather be able to parse something like this I think...\n"
            },
            "7": {
                "commit_sha_buggy": "4f4cefdbbe890291def12107b1b20ca6a5b96141",
                "commit_sha_fixed": "67a0c96c8f849e112b57ce0cc3e99667e0145384",
                "report_id": "METAMODEL-228",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-228",
                "issue_title": "[METAMODEL-228] ColumnTypeImpl.convertColumnType(...) does not support Number.class - ASF JIRA",
                "issue_description": "\nCalling ColumnTypeImpl.convertColumnType(...) does not yield ColumnType.NUMBER as I would expect it to.\nSimilarly I would also expect it to return ColumnType.STRING instead of VARCHAR when invoked with String.class.\n"
            },
            "8": {
                "commit_sha_buggy": "250b12dbf5ed5f3620cdd693c67ffedc1e82ac1b",
                "commit_sha_fixed": "1910d56f40bd5b4cd6a10b1b312d763059dfc8bd",
                "report_id": "METAMODEL-1103",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-1103",
                "issue_title": "[METAMODEL-1103] WildcardPattern not anchored to beginning of string. - ASF JIRA",
                "issue_description": "\nWhen filtering using LIKE in FilterItem.evaluate() (really WildcardPattern) is not properly anchored to the beginning of the string, which is not consistent with SQL LIKE\nGiven the table:\n\n\n\nname\n\n\nfoobar\n\n\nbar\n\n\noba\n\n\n\nAnd the queries:\n\nSELECT * FROM liketest WHERE name LIKE 'oba%'\nSELECT * FROM liketest WHERE name LIKE 'bar'\n\n\nPostgreSQL and MS SQL will return the results:\n\n\n\nname\n\n\noba\n\n\n\nand \n\n\n\nname\n\n\nbar\n\n\n\nBut MetaModel (on a QueryPostprocessDataContext based source) will return the results:\n\n\n\nname\n\n\nfoobar\n\n\noba\n\n\n\nand \n\n\n\nname\n\n\nfoobar\n\n\noba\n\n\n\n(Marked critical since it is means errors that are easily missed when looking the results over, but can sneak corruptions in later)\n"
            },
            "9": {
                "commit_sha_buggy": "88b537c200d3d4606abd467faf60d9d375726386",
                "commit_sha_fixed": "6fc258f8e5a812156b710193a2a06cfa7e2122cc",
                "report_id": "METAMODEL-1171",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-1171",
                "issue_title": "[METAMODEL-1171] FormatHelper cannot parse time value that was formatted by himself - ASF JIRA",
                "issue_description": ""
            }
        }
    },
    "MetaModel_csv": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8a17fbfbb4c37c702fd362a25bc401268a08e3f1",
                "commit_sha_fixed": "9c8f0b9d100853431f20b5761b4364c04276452b",
                "report_id": "METAMODEL-1113",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-1113",
                "issue_title": "[METAMODEL-1113] Column naming strategy doesn't work in csv datastore - ASF JIRA",
                "issue_description": "\nMETAMODEL-244 introduces the ability to define column names for csv, fixed-width and excel datastores. For csv datastores this doesn't work however, because the CsvConfiguration constructor which takes ColumnNamingStrategy as an argument doesn't actually assign it to its columnNamingStrategy field.\n"
            }
        }
    },
    "MetaModel_excel": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8156d76fd10a9ccc3ae88563e417b9c8700f22a3",
                "commit_sha_fixed": "3c4c1267309475a185d103508b63921f61ceef57",
                "report_id": "METAMODEL-152",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-152",
                "issue_title": "[METAMODEL-152] DataContext.refreshSchemas() not respected by QueryPostprocessDataContext - ASF JIRA",
                "issue_description": "\nI've just realized that we have a (probably quite old) critical bug in the sense of QueryPostprocessDataContext doing dirty caching of the main schema. The refreshSchemas() method on the DataContext interface is there to clear any cached schemas but it seems that the main schema is always going to be reused in QueryPostprocessDataContext - a kinda big breach of contract and it impacts a lot of implementations since this class is superclass of many DataContext implementations.\n"
            }
        }
    },
    "MetaModel_jdbc": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "496a839a26add619dbc27adb5431acacfa025078",
                "commit_sha_fixed": "8ea5ef52659abee313957fa7164c1b3f55a31674",
                "report_id": "METAMODEL-239",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-239",
                "issue_title": "[METAMODEL-239] DB2 query rewriting fails when first row = 1 and maxRows = null - ASF JIRA",
                "issue_description": "\nIn DB2 when firstRow is set as 1 but the maxRows is set to null then the queryRewriting generates a query like this and in DB2 the query does not get executed.\nSELECT table.col1, table.col2 \nFROM table FETCH FIRST null ROWS ONLY\n"
            },
            "2": {
                "commit_sha_buggy": "3949af857282f7c17a9be279e333348c5d3a0196",
                "commit_sha_fixed": "5f09375ff7197545f67e9f64982921bfdb8354d7",
                "report_id": "METAMODEL-1123",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-1123",
                "issue_title": "[METAMODEL-1123] Salesforce.com data type 'currency' is treated as a String, not a Number - ASF JIRA",
                "issue_description": "\nSee https://github.com/apache/metamodel/pull/132\n"
            },
            "3": {
                "commit_sha_buggy": "7ea316f97f579143debcdcba37b9632b4adfc9e6",
                "commit_sha_fixed": "88b537c200d3d4606abd467faf60d9d375726386",
                "report_id": "METAMODEL-1169",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-1169",
                "issue_title": "[METAMODEL-1169] MS Sql and queries with WHERE part on datetime or timestamp columns lost milliseconds precision - ASF JIRA",
                "issue_description": "\nAn example, where a query is constructed that compares some `datetime` column with a value.\n\n\r\nQuery q = ...\r\njava.util.Date datetimeValue = createDatetime('2017-01-01 12:00:00.500');\r\nq.where(column, OperatorType.GREATER_THAN, datetimeValue);\r\n\n\nIf there is a row with  the appropriate column value for example `2017-01-01 12:00:00.157`, this row should NOT be selected, but currently it IS, since the milliseconds are trimmed to 0 in the query operand.\nOnly on MS SQL database. The problem is probably in `SQLServerQueryRewriter.rewriteFilterItem` class & method.\n"
            }
        }
    },
    "MetaModel_pojo": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "85e457f3cb05975d9bf832deba589c93e346e3d6",
                "commit_sha_fixed": "39c4a391b55e360eaa4132c598648e0b27563756",
                "report_id": "METAMODEL-70",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-70",
                "issue_title": "[METAMODEL-70] Some unittests are depending on Java 6 specifics - ASF JIRA",
                "issue_description": "\nI've just noticed that when I switch to JDK 7, some unittests fail. This looks to be because of different HashMap.toString() implementations in JDK6 and JDK7... Should be made deterministic instead of depending on the (unspecified) behaviour of a particular JDK.\n"
            }
        }
    },
    "MetaModel_salesforce": {
        "owner_repo": "apache/metamodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a2f97111044949998005b049bb375682cd9b262e",
                "commit_sha_fixed": "fff3a930dc2ab6c4540cc22e96ef4c019f8e290b",
                "report_id": "METAMODEL-95",
                "report_url": "https://issues.apache.org/jira/browse/METAMODEL-95",
                "issue_title": "[METAMODEL-95] Salesforce - Query for column of type double always return value 1 - ASF JIRA",
                "issue_description": "\nI performed a query for a table, which contains columns of type double.\nThe result for these columns was always 1, regardless of the actual value.\nI verified the actual value by using Salesforce developer console.\nI tracked the bug to SalesforceDataSet:111\n            if (columnType.isNumber()) \n{\n                return NumberComparator.toNumber(columnType.isNumber());\n            }\n\nshould be:\n            if (columnType.isNumber()) \n{\n                return NumberComparator.toNumber(value);\n            }\n\nAnother option for a fix is to use the ColumnType.\n"
            }
        }
    },
    "Wink_common": {
        "owner_repo": "apache/wink",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "88a88652981fc1510d8505be4287d0f016e634da",
                "commit_sha_fixed": "84c82d3bc2e6f159bd33aff349185a429c19d85a",
                "report_id": "WINK-123",
                "report_url": "https://issues.apache.org/jira/browse/WINK-123",
                "issue_title": "[WINK-123] Error reading an Atom feed - ASF JIRA",
                "issue_description": "\nI tried consuming the Atom feed available at http://www.snellspace.com/wp/wp-atom1.php in a Java application as below:\n        RestClient client = new RestClient();\n        //String url = \"http://alexharden.org/blog/atom.xml\"; //this feed can be read\n        String url = \"http://www.snellspace.com/wp/wp-atom1.php\"; //this feed cannot be read!\n        //but http://feedvalidator.org/ says it is a valid Atom 1.0 feed\n        Resource resource = client.resource(url);\n        AtomFeed feed = resource.accept(MediaType.APPLICATION_ATOM_XML).get(AtomFeed.class);\nIt however fails with the below error:\nException in thread \"main\" java.lang.RuntimeException: Illegal atom content: must contain a single child element\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils$AtomUnmarshallingListener$SpecialContentHandler.getResult(AtomJAXBUtils.java:714)\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils$AtomUnmarshallingListener$AtomUnmarshallerHandler.endSpecialContent(AtomJAXBUtils.java:527)\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils$AtomUnmarshallingListener.afterUnmarshal(AtomJAXBUtils.java:469)\n\tat com.sun.xml.bind.v2.runtime.unmarshaller.Loader.fireAfterUnmarshal(Loader.java:221)\n\tat com.sun.xml.bind.v2.runtime.unmarshaller.StructureLoader.leaveElement(StructureLoader.java:267)\n\tat com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallingContext.endElement(UnmarshallingContext.java:474)\n\tat com.sun.xml.bind.v2.runtime.unmarshaller.InterningXmlVisitor.endElement(InterningXmlVisitor.java:77)\n\tat com.sun.xml.bind.v2.runtime.unmarshaller.SAXConnector.endElement(SAXConnector.java:145)\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils$AtomUnmarshallingListener$AtomUnmarshallerHandler.endElement(AtomJAXBUtils.java:549)\n\tat org.apache.xerces.parsers.AbstractSAXParser.endElement(Unknown Source)\n\tat org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanEndElement(Unknown Source)\n\tat org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)\n\tat org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)\n\tat org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)\n\tat org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)\n\tat org.apache.xerces.parsers.XMLParser.parse(Unknown Source)\n\tat org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils.saxParse(AtomJAXBUtils.java:127)\n\tat org.apache.wink.common.model.atom.AtomJAXBUtils.unmarshal(AtomJAXBUtils.java:149)\n\tat org.apache.wink.common.internal.providers.entity.atom.AbstractAtomFeedProvider.readFeed(AbstractAtomFeedProvider.java:94)\n\tat org.apache.wink.common.internal.providers.entity.atom.AtomFeedProvider.readFrom(AtomFeedProvider.java:59)\n\tat org.apache.wink.common.internal.providers.entity.atom.AtomFeedProvider.readFrom(AtomFeedProvider.java:43)\n\tat org.apache.wink.client.internal.handlers.ClientResponseImpl.readEntity(ClientResponseImpl.java:116)\n\tat org.apache.wink.client.internal.handlers.ClientResponseImpl.getEntity(ClientResponseImpl.java:60)\n\tat org.apache.wink.client.internal.handlers.ClientResponseImpl.getEntity(ClientResponseImpl.java:47)\n\tat org.apache.wink.client.internal.ResourceImpl.invoke(ResourceImpl.java:178)\n\tat org.apache.wink.client.internal.ResourceImpl.get(ResourceImpl.java:267)\n\tat myPackage.ConsumeAtomUsingWink.main(ConsumeAtomUsingWink.java:19)\n"
            },
            "2": {
                "commit_sha_buggy": "29169e26a730a43c193d20fb539384e54a023dad",
                "commit_sha_fixed": "f656b3be94bbeaa1bb07a1e8ce36352427f30fe0",
                "report_id": "WINK-249",
                "report_url": "https://issues.apache.org/jira/browse/WINK-249",
                "issue_title": "[WINK-249] Fix issue in UriBuilder where not throwing IllegalArgumentException - ASF JIRA",
                "issue_description": "\nIn UriBuilder's host/port, there can be illegal values given to it which are not checked.  (i.e. empty hostname / illegal port).  Do a pre-emptive throw on the values just to produce an error a lot earlier than currently given.\n"
            },
            "3": {
                "commit_sha_buggy": "70a39906eb9ae8b2af7f39d995f8ccc87a6210c2",
                "commit_sha_fixed": "8730a3d190b74fd038cf19c7c22877bf02865954",
                "report_id": "WINK-264",
                "report_url": "https://issues.apache.org/jira/browse/WINK-264",
                "issue_title": "[WINK-264] Problem to construct a link using the LinkBuilders for a resource with a path param that contains \":\" - ASF JIRA",
                "issue_description": "\nAssuming we got a resource \"MyResource\" with the path template:\n\n\"/myResource/{entity_id: [0-9]+}\"\n\nWhen coming to use the LinkBuilders and build a link for this resource (code example):\n\n@Context\nprivate LinkBuilders linkBuilders;\nlinkBuilders.createSingleLinkBuilder().resource(myResource).pathParam(\"entity_id\",\"3\").rel(\"myRel\").build(syndLinks);\n\n\nWe will get the exception:\n\njava.lang.IllegalArgumentException: Syntax error: '/myResource/{entity_id:/' contains invalid template form\n\tat org.apache.wink.common.internal.uritemplate.UriTemplateProcessor$Literal.assertValid(UriTemplateProcessor.java:379)\n\tat org.apache.wink.common.internal.uritemplate.UriTemplateProcessor$Literal.<init>(UriTemplateProcessor.java:368)\n\tat org.apache.wink.common.internal.uritemplate.UriTemplateProcessor$AbstractPatternBuilder.literal(UriTemplateProcessor.java:601)\n\tat org.apache.wink.common.internal.uritemplate.JaxRsUriTemplateProcessor$JaxRsPatternBuilder.literal(JaxRsUriTemplateProcessor.java:239)\n\tat org.apache.wink.common.internal.uritemplate.UriTemplateProcessor$AbstractPatternBuilder.endCompile(UriTemplateProcessor.java:609)\n\tat org.apache.wink.common.internal.uritemplate.JaxRsUriTemplateProcessor.compile(JaxRsUriTemplateProcessor.java:138)\n\tat org.apache.wink.common.internal.uritemplate.JaxRsUriTemplateProcessor.compile(JaxRsUriTemplateProcessor.java:92)\n\tat org.apache.wink.common.internal.uritemplate.JaxRsUriTemplateProcessor.<init>(JaxRsUriTemplateProcessor.java:81)\n\tat org.apache.wink.common.internal.UriBuilderImpl.getVariableNamesList(UriBuilderImpl.java:144)\n\tat org.apache.wink.common.internal.UriBuilderImpl.buildFromMap(UriBuilderImpl.java:402)\n\tat org.apache.wink.common.internal.UriBuilderImpl.buildFromEncodedMap(UriBuilderImpl.java:394)\n\tat org.apache.wink.server.internal.utils.SingleLinkBuilderImpl.build(SingleLinkBuilderImpl.java:86)\n\tat org.apache.wink.server.internal.utils.SingleLinkBuilderImpl.build(SingleLinkBuilderImpl.java:76)\n\tat...\n\n\nAfter debugging the framework I found out that the core problem is in UrlBuilderImpl.path(String path).\nThis method tries to extract the schema from the path (although that in the above case the path is relative), and that's by looking for \":\", in the case above we've got the \":\" but as part of the \"path param\" and not as the schema delimiter...\n"
            },
            "4": {
                "commit_sha_buggy": "4196874d5e855d3c0ff1aa2c4fdabf8cffc40f29",
                "commit_sha_fixed": "673ccfcff5a704aaf80830caf1f0f6b9e686e55b",
                "report_id": "WINK-275",
                "report_url": "https://issues.apache.org/jira/browse/WINK-275",
                "issue_title": "[WINK-275] When trying to register interface, the registration fails with NullPointerException - ASF JIRA",
                "issue_description": "\nWhen registering interface \n\n@Path(\"/\")\npublic interface Interface {\n\n    @GET\n    @Produces(\"text/plain\")\n    public String method();\n\n}\n\nthe following exception is thrown:\n\njava.lang.NullPointerException\n\tat org.apache.wink.common.internal.registry.metadata.ProviderMetadataCollector.isProvider(ProviderMetadataCollector.java:64)\n\tat org.apache.wink.common.internal.application.ApplicationValidator.isValidClass(ApplicationValidator.java:102)\n\tat org.apache.wink.common.internal.application.ApplicationValidator.isValidResource(ApplicationValidator.java:60)\n\tat org.apache.wink.server.internal.registry.ResourceRegistry.addResource(ResourceRegistry.java:148)\n\tat org.apache.wink.server.internal.application.ApplicationProcessor.processClasses(ApplicationProcessor.java:143)\n\tat org.apache.wink.server.internal.application.ApplicationProcessor.process(ApplicationProcessor.java:85)\n\tat org.apache.wink.server.internal.DeploymentConfiguration.addApplication(DeploymentConfiguration.java:273)\n\tat org.apache.wink.server.internal.servlet.RestServlet.createRequestProcessor(RestServlet.java:118)\n\tat org.apache.wink.server.internal.servlet.RestServlet.init(RestServlet.java:92)\n\tat javax.servlet.GenericServlet.init(GenericServlet.java:212)\n\tat org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1173)\n\tat org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:993)\n\tat org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:4149)\n\tat org.apache.catalina.core.StandardContext.start(StandardContext.java:4458)\n\tat org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045)\n\tat org.apache.catalina.core.StandardHost.start(StandardHost.java:722)\n\tat org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045)\n\tat org.apache.catalina.core.StandardEngine.start(StandardEngine.java:443)\n\tat org.apache.catalina.core.StandardService.start(StandardService.java:516)\n\tat org.apache.catalina.core.StandardServer.start(StandardServer.java:710)\n\tat org.apache.catalina.startup.Catalina.start(Catalina.java:583)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.lang.reflect.Method.invoke(Unknown Source)\n\tat org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:288)\n\tat org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:413)\n\n\n"
            }
        }
    },
    "Xbean_naming": {
        "owner_repo": "apache/geronimo-xbean",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "eca2eb51cb3b3109e3af90874ea321ce1518f41f",
                "commit_sha_fixed": "8de3134fc19784a716a0df750ed6e2afbe9aabf7",
                "report_id": "XBEAN-122",
                "report_url": "https://issues.apache.org/jira/browse/XBEAN-122",
                "issue_title": "[XBEAN-122] Object cannot be removed from context in many circumstances - ASF JIRA",
                "issue_description": "\nSee https://issues.apache.org/jira/browse/GERONIMO-4549\n"
            }
        }
    },
    "James_project_server_container_core": {
        "owner_repo": "apache/james-project",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0e5872cdff268f7e0271930c2ba79910f4683cf6",
                "commit_sha_fixed": "b7cdb8809354100d21d0dc265e2c695d627db048",
                "report_id": "JAMES-2163",
                "report_url": "https://issues.apache.org/jira/browse/JAMES-2163",
                "issue_title": "[JAMES-2163] Passing null parameters to Mail seems possible - ASF JIRA",
                "issue_description": "\nAs reported by @arpitsriv on Gitter, it seems possible to write an email with possibly null parameters.\nThis causes defacts later on, for instance in his case when enqueing the email.\nWe need upfront null value rejection on the MailImpl object, via Preconditions. This will bring the error closer to the code causing the defect, and makes debugging easier.\nUnit tests should be provided on the MailImpl object.\nThanks to @arpitsriv for his time spotting and understanding this issue.\n"
            }
        }
    },
    "Johnzon_core": {
        "owner_repo": "apache/johnzon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c0ebe9d2acbd8515a6169e7c1c80ecbe3ae67988",
                "commit_sha_fixed": "b5b99cf4046bb73e37cd6921417a20deea2fd921",
                "report_id": "JOHNZON-18",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-18",
                "issue_title": "[JOHNZON-18] JsonStreamParserImpl not filling up buffer consistently - ASF JIRA",
                "issue_description": "\nThis is related to the issue discussed here. Basically, the \"read\" method might not read all the bytes at once. We need to make sure to read at least one until we reach the value \"-1\".\n"
            },
            "2": {
                "commit_sha_buggy": "f283c1e896526c136afbba5fc07faf657a40fb32",
                "commit_sha_fixed": "f6979d363c18fed6ce06f42b635f673e65225b07",
                "report_id": "JOHNZON-122",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-122",
                "issue_title": "[JOHNZON-122] JSONP spec compliance: JsonNumber equality not spec compliant - ASF JIRA",
                "issue_description": "\nAccording to the JSONP spec:\n\nCompares the specified object with this JsonNumber object for equality. Returns true if and only if the type of the specified object is also JsonNumber and their bigDecimalValue() objects are equal\n\n\nyet johnzon considers \"unequal\" values to be equal\nSample application:\n\npublic final class Main {\n    public static void main(String[] args) {\n        JsonNumber a = Json.createObjectBuilder().add(\"a\", 1).build().getJsonNumber(\"a\");\n        JsonNumber b = Json.createObjectBuilder().add(\"b\", 1.1).build().getJsonNumber(\"b\");\n\n        System.out.println(\"EQUALS: \" + a.equals(b));\n        System.out.println(\"BigDecimal EQUALS: \" + a.bigDecimalValue().equals(b.bigDecimalValue()));\n    }\n}\n\n\nActual output:\n\nEQUALS: true\nBigDecimal EQUALS: false\n\n\nExpected output:\n\nEQUALS: false\nBigDecimal EQUALS: false\n\n\n[1] http://docs.oracle.com/javaee/7/api/javax/json/JsonNumber.html#equals-java.lang.Object-\n"
            },
            "4": {
                "commit_sha_buggy": "05effff6e0a555d1a2c62e65d1891745df028ea7",
                "commit_sha_fixed": "d455deafbf01675b5c607a8241adfde56ea11a6f",
                "report_id": "JOHNZON-139",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-139",
                "issue_title": "[JOHNZON-139] JohnzonJsonParser + Wrapper do not implement the new JSON-P-1.1 features - ASF JIRA",
                "issue_description": "\nJohnzonJsonParser\nJohnzonJsonParserWrapper\nJsonInMemoryParserImpl\nJsonStreamParserImpl\ndo not implement getObject() and other new JSON-P-1.1 features.\n"
            },
            "5": {
                "commit_sha_buggy": "3c28e350141d12a0bac3f7ceaf66352261caca5d",
                "commit_sha_fixed": "b594980702cb9ce0f7814ebee1e1bf603775c9ae",
                "report_id": "JOHNZON-172",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-172",
                "issue_title": "[JOHNZON-172] JsonPatchBuilder issue for a partcuilar scenario - ASF JIRA",
                "issue_description": "\nI am adding a failing test. org.apache.johnzon.core.JsonPointerImpl line 361 is causing the issue.\n\n\r\n@Test\r\nvoid test1() {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 JsonProvider json = JsonProvider.provider();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 JsonObject jsonObject = json.createReader(new StringReader(\"{\" +\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"\u00a0\u00a0\u00a0 \\\"request\\\" : {\" +\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \\\"test\\\" : {}\" +\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"\u00a0\u00a0\u00a0 }\" +\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"}\")).readObject();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 JsonPatchBuilder patchBuilder = json.createPatchBuilder();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 JsonObject result = patchBuilder.add(\"/name\", \"ravi\").build().apply(jsonObject);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 assertEquals(\"{\\\"request\\\":{\\\"test\\\":{}},\\\"name\\\":\\\"ravi\\\"}\", result.toString());\r\n\u00a0\u00a0\u00a0 }\r\n\n\n"
            },
            "6": {
                "commit_sha_buggy": "297654206d56de2dd7b2de11e9de1f1eb7a81d41",
                "commit_sha_fixed": "b2d205738c65fb53e768fca445fa611515417c19",
                "report_id": "JOHNZON-193",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-193",
                "issue_title": "[JOHNZON-193] Johnzon is keeping the reference for map/values from JsonObjectBuilder. - ASF JIRA",
                "issue_description": "\nIf you try the follow code:\n\n\r\nfinal JsonObjectBuilder jsonObjectBuilder = Json.createObjectBuilder();\r\nfinal JsonArrayBuilder jsonArrayBuilder = Json.createArrayBuilder();\r\nIntStream.range(1, 10).forEach(numer -> {\r\n\u00a0\u00a0\u00a0 jsonObjectBuilder.add(\"key\", String.format(\"Key %d\", numer)); \r\n\u00a0\u00a0\u00a0 jsonObjectBuilder.add(\"value\", String.format(\"Value %d\", numer)); \r\n\u00a0\u00a0\u00a0 jsonArrayBuilder.add(jsonObjectBuilder);\r\n});\r\nfinal String message = jsonArrayBuilder.build().toString();\n\nit is retuning:\n\n\r\n[{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"}]\n\n But we expect to see:\n\n\r\n[{\"key\":\"Key 1\",\"value\":\"Value 1\"},{\"key\":\"Key 2\",\"value\":\"Value 2\"},{\"key\":\"Key 3\",\"value\":\"Value 3\"},{\"key\":\"Key 4\",\"value\":\"Value 4\"},{\"key\":\"Key 5\",\"value\":\"Value 5\"},{\"key\":\"Key 6\",\"value\":\"Value 6\"},{\"key\":\"Key 7\",\"value\":\"Value 7\"},{\"key\":\"Key 8\",\"value\":\"Value 8\"},{\"key\":\"Key 9\",\"value\":\"Value 9\"}]\n\n"
            },
            "7": {
                "commit_sha_buggy": "78ad82adb99fc9083506dca9afc5fb3089bbf37c",
                "commit_sha_fixed": "54c0b11ab8d84fceff6547612d54b2849fecc3a6",
                "report_id": "JOHNZON-195",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-195",
                "issue_title": "[JOHNZON-195] JsonWriter.write(JsonValue) fails with simple values (strings, numbers, booleans) - ASF JIRA",
                "issue_description": "\nThe following code snipped fails with a JsonGenerationException(\"Invalid json\").\n{{ try (JsonWriter jsonWriter = Json.createWriter(System.out))}}\n {{ {}}\n\u00a0 \u00a0jsonWriter.write(Json.createValue(\"hello\"));\n {{ }}}\nI would have expected this code to write just the value to the output stream, e.g. \"hello\" in the above example. Reading such values via JsonReader.readValue() works fine and I wanted to write out any kind of values that have been read before.\nAs a workaround, I'm currently using the JsonWriter only for types ARRAY and OBJECT and otherwise just use JsonValue.toString(), but I want to get rid of such ugly code.\nTo fix the issue,\u00a0I have created this pull request: https://github.com/apache/johnzon/pull/32\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n"
            },
            "8": {
                "commit_sha_buggy": "67b761c40f6e6ad0d16ed82313915166afffad31",
                "commit_sha_fixed": "4d6c30df35b6edbfaf8465ed73aceab836667601",
                "report_id": "JOHNZON-217",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-217",
                "issue_title": "[JOHNZON-217] Allow to plugin a custom BufferStrategy - ASF JIRA",
                "issue_description": "\nBufferStrategy is right now an enum which contains a few pre-defined buffer strategies.\nFor allowing custom BufferStrategies we should extract an interface out of it and have a lookup with the current enum constants.\nAlternatively one could also configure a fully qualified class name of a custom BufferStrategy which would be created via newInstance().\n"
            },
            "9": {
                "commit_sha_buggy": "c159515c7c34c3e8f930cccc3b8c2f1bf93de590",
                "commit_sha_fixed": "51b120fa031524623715704560780e3468529de7",
                "report_id": "JOHNZON-267",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-267",
                "issue_title": "[JOHNZON-267] Prevent to call writeEnd() if already called - ASF JIRA",
                "issue_description": "\n\u00a0\nThis is invalid:\n\n\r\nwriteEnd().writeEnd()\n\n"
            },
            "10": {
                "commit_sha_buggy": "1dfbf224c920872cfee892dc8684d8e1e9100258",
                "commit_sha_fixed": "5a55c6677a6749eff4d4ddb11cd818a6e1cbd2ee",
                "report_id": "JOHNZON-265",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-265",
                "issue_title": "[JOHNZON-265] BigInteger/BigDecimal value can be lost (JSON-P) - ASF JIRA",
                "issue_description": ""
            },
            "11": {
                "commit_sha_buggy": "b836513b68d94f4f7f97a0477f67ee9c047486c2",
                "commit_sha_fixed": "48c34e68c51791b0aea15b94cb013ea8586e29da",
                "report_id": "JOHNZON-346",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-346",
                "issue_title": "[JOHNZON-346] ArrayBoundException when an overflow happens from an escaped character - ASF JIRA",
                "issue_description": ""
            },
            "12": {
                "commit_sha_buggy": "5852983bbc16c0c07c60d30fcd39fd6c308d48bd",
                "commit_sha_fixed": "17fdff13f3a65695ede0faab9db48ea42235ff09",
                "report_id": "JOHNZON-111",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-111",
                "issue_title": "[JOHNZON-111] readObject throws ClassCastException if json array is passed - ASF JIRA",
                "issue_description": "\nthe javax.json.JsonReader.readObject() method implementation in org.apache.johnzon.core.JsonReaderImpl.readObject() throws ClassCastException if a json array like \"[]\" is passed to it, instead it should throw JsonParsingException if the JsonStructure returned by org.apache.johnzon.core.JsonReaderImpl.read() is not a JsonObject\n"
            }
        }
    },
    "Nifi_mock": {
        "owner_repo": "apache/nifi",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8abf330328953022c6506c173a11e12bde1abd64",
                "commit_sha_fixed": "39a258dc38f9b037bb0ee75c8f9a3da2b12b0946",
                "report_id": "NIFI-6727",
                "report_url": "https://issues.apache.org/jira/browse/NIFI-6727",
                "issue_title": "[NIFI-6727] MockProcessContext.decrypt() Removes An Extra Character - ASF JIRA",
                "issue_description": "\nThe `MockProcessContext.decrypt()` method removes one too many characters from the passed in 'encrypted' string.\u00a0\n"
            },
            "2": {
                "commit_sha_buggy": "7e5e332842685fc2cd222a60b75d1ea8506023b9",
                "commit_sha_fixed": "fe416d1ea0e1b7f15c1fdf8884d10f280d126f4e",
                "report_id": "NIFI-6064",
                "report_url": "https://issues.apache.org/jira/browse/NIFI-6064",
                "issue_title": "[NIFI-6064] MockComponentLog misplaces reported exceptions - ASF JIRA",
                "issue_description": "\nWhen MockComponentLog.error(String, Throwable) is called, the message is forwarded to CapturingLogger.error(String, Object, Object), which treats the Throwable passed as the last parameter as a regular message parameter and passes it as such to the LogMessage constructor. As the result, the Throwable ends up as the last element in LogMessage.args, instead of the LogMessage.throwable field, where it would be more appropriate.\nNote: I have only tested this with 1.8.0, but the relevant code in the master branch is the same, so I assume the issue applies to the latest version as well.\n"
            }
        }
    },
    "Rat_core": {
        "owner_repo": "apache/creadur-rat",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "95c0c4cd7832869b190c9205e22ce57240e7a3b3",
                "commit_sha_fixed": "378376d7247b572cad489a4a17bf868489801fee",
                "report_id": "RAT-159",
                "report_url": "https://issues.apache.org/jira/browse/RAT-159",
                "issue_title": "[RAT-159] Detect OpenOffice documents as being archives - ASF JIRA",
                "issue_description": "\nRat currently does not recognize OpenOffice documents. This means that they will be flagged as not having a license header. They are in fact archives, so Rat should detect them as such.\n"
            }
        }
    },
    "Rat_plugin": {
        "owner_repo": "apache/creadur-rat",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c210f773daef6f5664136ecc6fab127dfb35c6fa",
                "commit_sha_fixed": "25d23c9387d98027602ebe030294f65b6c15ed6c",
                "report_id": "RAT-160",
                "report_url": "https://issues.apache.org/jira/browse/RAT-160",
                "issue_title": "[RAT-160] Fails to ignore build.log created by maven-invoker-plugin - ASF JIRA",
                "issue_description": "\nWhen using maven-invoker-plugin to run integration-tests for a maven plugin project, maven-invoker-plugin creates a build.log file in the basedir for the project.\nThis may be a bug in maven-invoker-plugin. Perhaps it'd be better to put this file in its build directory, rather than its basedir. Regardless, the apache-rat-plugin should ignore this build.log file.\n"
            }
        }
    },
    "Tez_common": {
        "owner_repo": "apache/tez",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1ae62421aa6c3d9131e1673615b1c94c8e7011aa",
                "commit_sha_fixed": "fd9c015750c320a9a70b917cf22f993cf144e89e",
                "report_id": "TEZ-3937",
                "report_url": "https://issues.apache.org/jira/browse/TEZ-3937",
                "issue_title": "[TEZ-3937] Empty partition BitSet to byte[] conversion creates one extra byte in rounding error - ASF JIRA",
                "issue_description": "\nByte array length calculation is defined as (bitset.length / 8) + 1 which has off by one errors on byte boundaries. For example, BitSet of length 0 is converted to a byte array of length 1. This was introduced as part of TEZ-972 since BitSet.toByteArray and valueOf were not supported as Tez supported Java 6 at the time and API was introduced in Java 7.\n"
            }
        }
    },
    "Tinkerpop_gremlin_core": {
        "owner_repo": "apache/tinkerpop",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bce33476a035a1de77ca2d5116b6871e8692f788",
                "commit_sha_fixed": "5165d0d94a6717aa4a57e70f4e4818be2699f0b1",
                "report_id": "TINKERPOP-1215",
                "report_url": "https://issues.apache.org/jira/browse/TINKERPOP-1215",
                "issue_title": "[TINKERPOP-1215] Labeled a SideEffectCapStep cause problems.  - ASF JIRA",
                "issue_description": "\n\ngremlin> g.V().hasLabel(\"person\").aggregate(\"x\").by(\"age\").cap(\"x\").as(\"y\",\"z\").select(\"x\",\"y\",\"z\")\n==>[x:[29, 27, 32, 35], y:[[29, 27, 32, 35], [29, 27, 32, 35]], z:[[29, 27, 32, 35], [29, 27, 32, 35]]] // BAD\ngremlin> g.V().hasLabel(\"person\").aggregate(\"x\").by(\"age\").cap(\"x\").filter{true}.as(\"y\",\"z\").select(\"x\",\"y\",\"z\")\n==>[x:[29, 27, 32, 35], y:[29, 27, 32, 35], z:[29, 27, 32, 35]] // GOOD\n\n\nThis only seems to be an issue with AggregateStep\n\ngremlin> g.V().hasLabel(\"person\").groupCount(\"a\").cap(\"a\").as(\"b\",\"c\").select(\"a\",\"b\",\"c\")\n==>[a:[v[1]:1, v[2]:1, v[4]:1, v[6]:1], b:[v[1]:1, v[2]:1, v[4]:1, v[6]:1], c:[v[1]:1, v[2]:1, v[4]:1, v[6]:1]]\ngremlin> g.V().hasLabel(\"person\").aggregate(\"a\").cap(\"a\").as(\"b\",\"c\").select(\"a\",\"b\",\"c\")\n==>[a:[v[1], v[2], v[4], v[6]], b:[[v[1], v[2], v[4], v[6]], [v[1], v[2], v[4], v[6]]], c:[[v[1], v[2], v[4], v[6]], [v[1], v[2], v[4], v[6]]]]\n\n\n"
            }
        }
    },
    "Webbeans_web": {
        "owner_repo": "apache/openwebbeans",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "56f696e97728532584c367905b3e0d2d35295460",
                "commit_sha_fixed": "432ced2c015c5a6b4fc404a538d53ee23cba6e6c",
                "report_id": "OWB-1223",
                "report_url": "https://issues.apache.org/jira/browse/OWB-1223",
                "issue_title": "[OWB-1223] WebContextsService does not fire BeforeDestroyed(ApplicationScoped.class) event - ASF JIRA",
                "issue_description": "\nWhile we fire the BeforeDestroyedEvent in the DefaultContextsService we seems to have missed to also enable this in the WebContextsService.\n"
            }
        }
    },
    "Hono_client": {
        "owner_repo": "eclipse/hono",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e317e2298dc6aff6349ec64275087d3fea94d4b5",
                "commit_sha_fixed": "c1550b3e8b39f061226873d180eb14ec52bb8e20",
                "report_id": "231",
                "report_url": "https://github.com/eclipse/hono/issues/231",
                "issue_title": "Protocol Adapters can reach state where re-creation of message sender fails",
                "issue_description": "In our Hono setup we have reached a state where the Protocol Adapters can't re-create a message sender.\r\n\r\nREST Adapter log excerpt:\r\n```\r\n05:03:24.641 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.AbstractSender - sender [telemetry/DEFAULT_TENANT] closed: Error{condition=hono:no-downstream-consumer, description='no downstream consumer available for data', info=null}\r\n05:03:27.319 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - creating new message sender for telemetry/DEFAULT_TENANT\r\n05:03:27.319 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:27.347 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-23, status: 200]\r\n05:03:27.841 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:27.841 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:27.841 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:27.869 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-24, status: 200]\r\n05:03:37.118 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:37.118 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:37.118 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:37.147 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-25, status: 200]\r\n05:03:47.206 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:47.206 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:47.206 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:47.235 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-26, status: 200]\r\n05:03:51.731 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:51.731 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:51.731 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:51.759 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-27, status: 200]\r\n05:03:56.738 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:56.738 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:56.738 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:56.766 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-28, status: 200]\r\n05:03:57.297 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:57.297 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:57.297 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:03:57.325 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-29, status: 200]\r\n05:04:07.401 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:04:07.401 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:04:07.401 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:04:07.429 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-30, status: 200]\r\n05:04:07.673 [vert.x-eventloop-thread-0] INFO o.e.hono.client.impl.HonoClientImpl - Hono server [hono.hono:5671] closed connection with error condition: Error{condition=amqp:resource-limit-exceeded, description='local-idle-timeout expired', info=null}\r\n05:04:07.673 [vert.x-eventloop-thread-0] INFO o.e.hono.client.impl.HonoClientImpl - lost connection to Hono server [hono.hono:5671]\r\n05:04:07.674 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:04:07.674 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - scheduling re-connect attempt ...\r\n05:04:07.674 [vert.x-eventloop-thread-0] WARN o.e.hono.client.impl.HonoClientImpl - cannot handle failure of unknown connection\r\n05:04:08.175 [vert.x-eventloop-thread-0] INFO o.e.hono.client.impl.HonoClientImpl - attempting to re-connect to Hono server [hono.hono:5671]\r\n05:04:08.175 [vert.x-eventloop-thread-0] INFO o.e.h.c.ConnectionFactoryImpl - connecting to AMQP 1.0 container [amqps://hono.hono:5671]\r\n05:04:08.301 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:04:08.301 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:04:08.301 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n05:04:08.329 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-31, status: 200]\r\n05:04:08.345 [vert.x-eventloop-thread-0] INFO o.e.h.c.ConnectionFactoryImpl - connected to AMQP 1.0 container [amqps://hono.hono:5671], opening connection ...\r\n05:04:08.346 [vert.x-eventloop-thread-0] INFO o.e.h.c.ConnectionFactoryImpl - connection to container [Hono-0.0.0.0:5671] at [amqps://hono.hono:5671] open\r\n05:04:09.072 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:04:09.072 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:04:09.072 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.h.AbstractVertxBasedHttpProtocolAdapter - Service unavailable: null\r\n```\r\n\r\nMQTT Adapter log:\r\n```\r\n05:03:24.642 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.AbstractSender - sender [telemetry/DEFAULT_TENANT] closed: Error{condition=hono:no-downstream-consumer, description='no downstream consumer available for data', info=null}\r\n05:03:26.402 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.600194195a1b\r\n05:03:26.445 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:26.445 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - creating new message sender for telemetry/DEFAULT_TENANT\r\n05:03:26.474 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-23, status: 200]\r\n05:03:26.846 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.5ccf7f9509f1\r\n05:03:26.897 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:26.897 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:26.897 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: esp8266.5ccf7f9509f1, topic: telemetry/DEFAULT_TENANT/esp8266.5ccf7f9509f1, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:03:26.897 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: esp8266.5ccf7f9509f1]\r\n05:03:26.926 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-24, status: 200]\r\n05:03:36.408 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.600194195a1b\r\n05:03:36.452 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:36.452 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:36.452 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: esp8266.600194195a1b, topic: telemetry/DEFAULT_TENANT/esp8266.600194195a1b, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:03:36.452 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: esp8266.600194195a1b]\r\n05:03:36.481 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-25, status: 200]\r\n05:03:46.500 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.600194195a1b\r\n05:03:46.543 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:46.543 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:46.543 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: esp8266.600194195a1b, topic: telemetry/DEFAULT_TENANT/esp8266.600194195a1b, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:03:46.543 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: esp8266.600194195a1b]\r\n05:03:46.572 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-26, status: 200]\r\n05:03:51.736 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client HealthCheck_c8ca8231-a348-4d58-b135-1c24883611d8_mqtt\r\n05:03:51.739 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:51.739 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:51.739 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: HealthCheck_c8ca8231-a348-4d58-b135-1c24883611d8_mqtt, topic: telemetry/DEFAULT_TENANT/HealthCheck_c8ca8231-a348-4d58-b135-1c24883611d8_mqtt, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:03:51.739 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: HealthCheck_c8ca8231-a348-4d58-b135-1c24883611d8_mqtt]\r\n05:03:51.767 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-27, status: 200]\r\n05:03:56.585 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.600194195a1b\r\n05:03:56.629 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:03:56.629 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:03:56.629 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: esp8266.600194195a1b, topic: telemetry/DEFAULT_TENANT/esp8266.600194195a1b, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:03:56.629 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: esp8266.600194195a1b]\r\n05:03:56.661 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-28, status: 200]\r\n05:04:06.689 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client esp8266.600194195a1b\r\n05:04:06.732 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:04:06.733 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:04:06.733 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: esp8266.600194195a1b, topic: telemetry/DEFAULT_TENANT/esp8266.600194195a1b, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:04:06.733 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: esp8266.600194195a1b]\r\n05:04:06.762 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-29, status: 200]\r\n05:04:08.305 [vert.x-eventloop-thread-0] INFO o.e.h.a.m.VertxBasedMqttProtocolAdapter - Connection request from client HealthCheck_1467bc4a-e738-45ab-9390-cd590e9532bc_mqtt\r\n05:04:08.308 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - reusing existing registration client for [DEFAULT_TENANT]\r\n05:04:08.308 [vert.x-eventloop-thread-0] DEBUG o.e.hono.client.impl.HonoClientImpl - already trying to create a message sender for telemetry/DEFAULT_TENANT\r\n05:04:08.308 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - cannot process message [client ID: HealthCheck_1467bc4a-e738-45ab-9390-cd590e9532bc_mqtt, topic: telemetry/DEFAULT_TENANT/HealthCheck_1467bc4a-e738-45ab-9390-cd590e9532bc_mqtt, QoS: AT_MOST_ONCE]: sender link not established yet\r\n05:04:08.308 [vert.x-eventloop-thread-0] DEBUG o.e.h.a.m.VertxBasedMqttProtocolAdapter - closing connection with client [client ID: HealthCheck_1467bc4a-e738-45ab-9390-cd590e9532bc_mqtt]\r\n05:04:08.337 [vert.x-eventloop-thread-0] DEBUG o.e.h.c.i.AbstractRequestResponseClient - received response [correlation ID: reg-client-30, status: 200]\r\n```\r\n\r\nNotice the recurring output of\r\n\r\n> already trying to create a message sender for telemetry/DEFAULT_TENANT"
            },
            "2": {
                "commit_sha_buggy": "9d59a1023976f84b503513c2c761afefbb373bf9",
                "commit_sha_fixed": "43468221cbef4a3fbbc48849791c8b32b1b65777",
                "report_id": "232",
                "report_url": "https://github.com/eclipse/hono/issues/232",
                "issue_title": "Consumer doesn't get messages anymore",
                "issue_description": "In our Hono setup we have a consumer connected to the dispatch router. There is no log output indicating a lost connection.\r\nAt one point, the consumer didn't get messages anymore.\r\n\r\nLogs from the Hono server/messaging component show that the connection to QPid was lost and re-established in-between:\r\n```\r\n05:03:24.641 [vert.x-eventloop-thread-1] WARN o.e.h.t.i.ForwardingTelemetryDownstreamAdapter - lost connection to downstream container [Hono.Example.Router], closing upstream receivers ...\r\n05:03:24.641 [vert.x-eventloop-thread-1] WARN o.e.h.e.i.ForwardingEventDownstreamAdapter - lost connection to downstream container [Hono.Example.Router], closing upstream receivers ...\r\n05:03:25.142 [vert.x-eventloop-thread-1] INFO o.e.h.t.i.ForwardingTelemetryDownstreamAdapter - attempting to re-connect to downstream container\r\n05:03:25.142 [vert.x-eventloop-thread-1] INFO o.e.h.s.DownstreamClientConfigProperties - using certificates from file [/run/secrets/trusted-certs.pem] as trust anchor\r\n05:03:25.142 [vert.x-eventloop-thread-1] INFO o.e.h.s.DownstreamClientConfigProperties - using key & certificate from PKCS12 key store [/run/secrets/honoKeyStore.p12] for identity\r\n05:03:25.142 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connecting to AMQP 1.0 container [amqps://qdrouter.hono:5673]\r\n05:03:25.149 [vert.x-eventloop-thread-1] INFO o.e.h.e.i.ForwardingEventDownstreamAdapter - attempting to re-connect to downstream container\r\n05:03:25.149 [vert.x-eventloop-thread-1] INFO o.e.h.s.DownstreamClientConfigProperties - using certificates from file [/run/secrets/trusted-certs.pem] as trust anchor\r\n05:03:25.149 [vert.x-eventloop-thread-1] INFO o.e.h.s.DownstreamClientConfigProperties - using key & certificate from PKCS12 key store [/run/secrets/honoKeyStore.p12] for identity\r\n05:03:25.149 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connecting to AMQP 1.0 container [amqps://qdrouter.hono:5673]\r\n05:03:25.272 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connected to AMQP 1.0 container [amqps://qdrouter.hono:5673], opening connection ...\r\n05:03:25.274 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connection to container [Hono.Example.Router] at [amqps://qdrouter.hono:5673] open\r\n05:03:25.277 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connected to AMQP 1.0 container [amqps://qdrouter.hono:5673], opening connection ...\r\n05:03:25.278 [vert.x-eventloop-thread-1] INFO o.e.h.c.ConnectionFactoryImpl - connection to container [Hono.Example.Router] at [amqps://qdrouter.hono:5673] open\r\n```\r\nMore log output here:\r\n[Hono_messaging.txt](https://github.com/eclipse/hono/files/1097407/Hono_messaging.txt)\r\n\r\nA 2nd consumer didn't show this behaviour, it still got messages."
            },
            "3": {
                "commit_sha_buggy": "7b8bb1b7de6d4e165f67fb45a270723d96dca4a2",
                "commit_sha_fixed": "9f8536476182f48a97219edb3e50c75dc3ea49f9",
                "report_id": "380",
                "report_url": "https://github.com/eclipse/hono/issues/380",
                "issue_title": "Status is reported as \"String\" instead of \"int\"",
                "issue_description": "The Hono documentation states that the \"status\" response will be reported as \"int\" [1]. However, looking inside the application properties of the AMQP message it actually is a \"String\".\r\n\r\n![image](https://user-images.githubusercontent.com/202474/31818740-b3fc1f20-b599-11e7-85d2-231307f773ea.png)\r\n\r\n\r\n[1] https://www.eclipse.org/hono/api/Device-Registration-API/#standard-response-properties"
            },
            "4": {
                "commit_sha_buggy": "44f266c226de8470cb173871974259127919082a",
                "commit_sha_fixed": "d28707b75a197c4484beee6295b42090ae81cac5",
                "report_id": "1073",
                "report_url": "https://github.com/eclipse/hono/issues/1073",
                "issue_title": "Potentially competing receiver links when using command and control API",
                "issue_description": "Command and control API uses address `control/${tenant_id}/${reply_id}` for receiving responses in consumer applications. Users are free to choose `${reply_id}`. If an application wants to receive all responses of one tenant, hono docs recommend to use an arbitrary (short) string as `${reply_id}` without `${device_id}` and to keep the receiver link open. \r\n\r\nHowever, protocol adapters use a very similar addressing scheme to receive commands from applications in the form of `control/${tenant_id}/${device_id}`. If `${device_id}` == `${reply_id}` we now have two competing receiver links and messaging network can not distinguish if a message should be sent to protocol adapter or to the application.\r\n\r\nOne possible solution would be to change addressing scheme for responses to \r\n`response/${tenant_id}/${reply_id}`. Of course this would require an API change.\r\n\r\nWDYT?"
            }
        }
    },
    "Httpcomponents_core_h2": {
        "owner_repo": "apache/httpcomponents-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "00926e8bcd358fc7c5beeb6a8e8864aa4821fe7c",
                "commit_sha_fixed": "784878de35003c414a620f27538614558d0398a4",
                "report_id": "HTTPCORE-648",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCORE-648",
                "issue_title": "[HTTPCORE-648] Session buffers should respect buffer arrayOffset - ASF JIRA",
                "issue_description": "\nImpacted classes: SessionInputBufferImpl, SessionOutputBufferImpl, HPackDecoder,\u00a0HPackEncoder\n"
            }
        }
    },
    "Httpcomponents_core_httpcore5": {
        "owner_repo": "apache/httpcomponents-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "18cc4df6ca82e4d248de47126e2627435a3ac785",
                "commit_sha_fixed": "029fdfe9b9c7f5147d57244984613857174b9f2a",
                "report_id": "HTTPCORE-559",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCORE-559",
                "issue_title": "[HTTPCORE-559] The DefaultBHttpClientConnection will not read a simple end-of-stream terminated HTTP response body - ASF JIRA",
                "issue_description": "\nWhen you use the Classic HttpClient to execute a GET request for a resource which is returned with no Content-Length or Transfer-Encoding header then the response body (which should be now terminated by the closing of the stream) is not read.\u00a0 Instead the client returns an empty response with no attempt made to read from the stream.\nI realize that virtually no responses are ever sent this way, they almost always either have a content length or use chunked transfer encoding, but it is still legal as per the HTTP spec to return a response without using either of these and relying on the end-of-stream to terminate the response body.\u00a0 Currently if a server is doing this, the HttpClient won't receive the response.\nI found this problem testing the HttpClient, but I believe the root source of the problem is in the DefaultBHttpClientConnection implementation.\n"
            },
            "2": {
                "commit_sha_buggy": "589fe21a0bd3481431f08d296fff1e323a8f497d",
                "commit_sha_fixed": "7068d0c3750cd54a136df7fadb1dbbac9cd3e201",
                "report_id": "HTTPCORE-573",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCORE-573",
                "issue_title": "[HTTPCORE-573] FileContentDecoder don't always enforce the maximum number of bytes to transfer - ASF JIRA",
                "issue_description": "\nThe FileContentDecoder.transfer function has the 'count' parameter indicating the maximum number of bytes to transfer.\n Implementations (LengthDelimitedDecoder and IdentityDecoder) don't respect this parameter when getting the data from the internal buffer: in practice the whole buffer content is transferred, thus the actual number of bytes transferred may exceed the maximum requested by caller.\nSince the way data are read from the buffer can be limited, it is possible to respect the requested 'count'.\n"
            },
            "3": {
                "commit_sha_buggy": "964775edb9cbe4095964f038b2aa088ac6393624",
                "commit_sha_fixed": "41ff6a8f1f4d20e1233fdc3df543f921f41d856e",
                "report_id": "HTTPCORE-638",
                "report_url": "https://issues.apache.org/jira/browse/HTTPCORE-638",
                "issue_title": "[HTTPCORE-638] SharedOutputBuffer calls endStream multiple times - ASF JIRA",
                "issue_description": "\nUsing `SharedOutputBuffer` in conjunction with `ContentOutputStream` can cause `endStream` to be called multiple times on the `DataStreamChannel`. I've noticed this happening in my code where I'm using something nearly identical `AbstractClassicEntityProducer` (only difference is that I use my own thread to produce the data). When this happens, the `HttpAsyncMainClientExec`'s `messageCountDown` goes to zero and the exchange is considered completed but since no response was processed, it results in a `cancel` callback. I should note that this does not happen all the time but frequently enough when I'm calling into a local web server.\nHere's how `endStream` ends up being called twice:\n\nOnce from the producer thread when it calls close on the `ContentOutputStream`\none from the call to `SharedOutputBuffer.flush` from `OutputStreamClassicEntityProducer.produce`.\n\nFrom my understanding, this sequence is legitimate as `OutputStreamClassicEntityProducer.produce` is called repeatedly, and it can hold on to the DataStreamChannel to call into asynchronously (from the comment in `AsyncDataProducer`). When I've seen this happen, both calls to `endStream` happen within one or two milliseconds of each other.\nThere is no guard in SharedOutputBuffer to ensure that `endStream` is called only once. Is this the correct fix? I'm happy to submit a PR if this the right solution.\nThank you!\n"
            }
        }
    },
    "Johnzon_jsonb": {
        "owner_repo": "apache/johnzon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "919fa53dacc2c1c51a356ca6dd76da3a71af670d",
                "commit_sha_fixed": "df0560a116be4e0ffc86e6c8e00b06831e94479c",
                "report_id": "JOHNZON-187",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-187",
                "issue_title": "[JOHNZON-187] [JSONB] User adapters dont override default adapters - ASF JIRA",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "1176a1d7e002d241b3143174e94cf1136ce83efd",
                "commit_sha_fixed": "5892a84e61ee6c4c0dab3773ebfb8317d23a3cea",
                "report_id": "JOHNZON-211",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-211",
                "issue_title": "[JOHNZON-211] Serialization context with a key ignores the key - ASF JIRA",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "2807054bcc9ae43ebdfe73b0846d6b9515eef21e",
                "commit_sha_fixed": "2f56ba6e7dbecff45fbd4c37df84e33b916ec4aa",
                "report_id": "JOHNZON-222",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-222",
                "issue_title": "[JOHNZON-222] jsonb.fromJson(..., JsonArray.class) fails - ASF JIRA",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "323c72328a8b0e6e6fc3bf477b189fbbcf41c09c",
                "commit_sha_fixed": "589fb9e2b8732a0033f99d162b1209082d0de019",
                "report_id": "JOHNZON-277",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-277",
                "issue_title": "[JOHNZON-277] Fails to deserialize inner empty JSON block {} at OBJECT_START - ASF JIRA",
                "issue_description": "\nJohnzon fails to derserialize inner empty JSON block {} if the cursor of the JSON parser stands at the beginning of the inner object, i. e. after it already provided OBJECT_START. This Github Pull Request proofs the failure:\u00a0https://github.com/apache/johnzon/pull/45. rmannibucau confirmed this is a bug.\n"
            },
            "5": {
                "commit_sha_buggy": "d0a20025554ca5234120d735f5c04f9e5299eeb9",
                "commit_sha_fixed": "12c168722a27c6d334249f6456043a8300b82f78",
                "report_id": "JOHNZON-326",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-326",
                "issue_title": "[JOHNZON-326] Primitive arrays not written correctly by JohnzonJsonB - ASF JIRA",
                "issue_description": "\nWhen serializing a primitive array (e.g. int[]) a ClassCastException occurs as the Johnzon attempts to cast to Object[].\n"
            },
            "6": {
                "commit_sha_buggy": "d8d09dd61c95785019f03200e9c739b48c5619fd",
                "commit_sha_fixed": "14393f00a7c520b85d4e8c1e09e05e140929a111",
                "report_id": "JOHNZON-325",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-325",
                "issue_title": "[JOHNZON-325] JSON Pointer using \"-\" (last index) not properly handled for arrays - ASF JIRA",
                "issue_description": "\nAs per spec, \"-\" always points to the first index after the last element.\nAs the arrays are zero based in terms of index. \"-\" is always equals to the size of the array.\n\u00a0\nWhen adding to \"-\" it basically adds at the tail of the array.\n\u00a0\nAny other operation must result in a JSonException (getValue, replace and remove)\n"
            }
        }
    },
    "Johnzon_jaxrs": {
        "owner_repo": "apache/johnzon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b41dd5782a165bbd1f3ac2479e3f6c230ed2e4b6",
                "commit_sha_fixed": "9391718099778416ad205cc96285bd4f49275f9b",
                "report_id": "JOHNZON-67",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-67",
                "issue_title": "[JOHNZON-67] JohnzonProvider doesn't support collection serialization without generics - ASF JIRA",
                "issue_description": ""
            }
        }
    },
    "Hbase_common": {
        "owner_repo": "apache/hbase",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e153a0c9ac987adb9a4b637f4587ca7100124a63",
                "commit_sha_fixed": "0c13da349bd12bbf2568b69a22d73dd1cbe01798",
                "report_id": "HBASE-6518",
                "report_url": "https://issues.apache.org/jira/browse/HBASE-6518",
                "issue_title": "[HBASE-6518] Bytes.toBytesBinary() incorrect trailing backslash escape - ASF JIRA",
                "issue_description": "\nBytes.toBytesBinary() converts escaped strings to byte arrays. When encountering a '\\' character, it looks at the next one to see if it is an 'x', without checking if it exists.\n"
            }
        }
    },
    "Incubator_tamaya_api": {
        "owner_repo": "apache/incubator-retired-tamaya",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "db56ee2264f79bb939cb4117c26d3d48d618f1d4",
                "commit_sha_fixed": "135792e9f649693684d85d68b83a6a258e782a10",
                "report_id": "TAMAYA-326",
                "report_url": "https://issues.apache.org/jira/browse/TAMAYA-326",
                "issue_title": "[TAMAYA-326] ServiceContextManager picks second available service provider even if the ordinal is lower - ASF JIRA",
                "issue_description": "\nWhile adding some test coverage on the api, I found that org.apache.tamaya.spi.ServiceContextManager has a bug as it searches for the default service provider in loadDefaultServiceProvider.\u00a0 Namely, the \"highestOrdinal\" is not set after the first service provider is found, so any following service provider with an ordinal higher than 0 will be used, even if that ordinal is lower than the first one's.\nI modified the test ServiceContext to demonstrate the bug, as well as fixed the logic on my branch in github.\u00a0 Note that if you run the tests against the ServiceContextManager as-is, they will fail.\nhttps://github.com/peculater/incubator-tamaya/commit/320d018566b5f32afecb79d33109e3c4606ba782 is the commit\nhttps://github.com/peculater/incubator-tamaya/tree/TAMAYA-326 is the branch\n\u00a0\n"
            },
            "2": {
                "commit_sha_buggy": "135792e9f649693684d85d68b83a6a258e782a10",
                "commit_sha_fixed": "ca4de3dc49fefa020e89073b8032be7de20ab27d",
                "report_id": "TAMAYA-327",
                "report_url": "https://issues.apache.org/jira/browse/TAMAYA-327",
                "issue_title": "[TAMAYA-327] Inconsistent signature for creating ConversionContext - ASF JIRA",
                "issue_description": "\nDuring some additional testing in the API added as part of TAMAYA-288, I came across an inconsistency between the ConversionContext and the ConversionContext.Builder.\u00a0 Namely, the comments say that supportedFormats have their order maintained, which is consistent with the use of an ArrayList here https://github.com/apache/incubator-tamaya/blob/master/code/api/src/main/java/org/apache/tamaya/spi/ConversionContext.java#L42 .\u00a0 The builder, however implements the same supportedFormats with a HashSet, which does not ensure order.\u00a0 See https://github.com/apache/incubator-tamaya/blob/master/code/api/src/main/java/org/apache/tamaya/spi/ConversionContext.java#L148 .\nI'm planning on creating a pull request with the additional tests for that object as well as a patch to more consistently maintain order (all ArrayLists).\u00a0 Please let me know if the better answer is to more consistently leave order unspecified (all HashSets).\n"
            }
        }
    },
    "James_project_mailet_standard": {
        "owner_repo": "apache/james-project",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5a781fb1a72e97234159a1831f57c60a6f561c74",
                "commit_sha_fixed": "6e6fdae820ebba821bc2850eba066bbf71aa13a7",
                "report_id": "JAMES-2015",
                "report_url": "https://issues.apache.org/jira/browse/JAMES-2015",
                "issue_title": "[JAMES-2015] Vacation mailet does not work for mail that come from external domain - ASF JIRA",
                "issue_description": "\nWhen a user that set is vacation on receive a email from a external domain, the email is not sent because of an authentication issue.\n"
            }
        }
    },
    "Johnzon_jsonschema": {
        "owner_repo": "apache/johnzon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1aea0bbf4a01de4b131ff21f743d9e744c937e1f",
                "commit_sha_fixed": "297654206d56de2dd7b2de11e9de1f1eb7a81d41",
                "report_id": "JOHNZON-191",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-191",
                "issue_title": "[JOHNZON-191] [Schema] \"patternProperties\" does not correctly handle related property type - ASF JIRA",
                "issue_description": "\nIn Apache Sling we have been developing a draft-07 compliant schema to define Sling Feature files, which are in JSON format, and of course Johnzon is the de-facto standard choice to work with JSON structures.\nIf you want to have a look at the initial draft, have a look at https://gist.github.com/simonetripodi/c69d2ffebdbd2c4b1355df60568f1ab5\nSo, in our Feature we have so called extensions where users can define a custom data set, extensions keys are defined by patternProperties which related type, I noticed, are not correctly handled by the JsonSchemaValidator: the expected behaviour is that for an input like the one below:\n\n{\r\n  \"id\":\"test/artifacts-extension/1.0.0\",\r\n  \"my-extension1:TEXT|false\":{}\r\n}\r\n\n\nan error is detected since type is invalid, string or array is expected but  but got object, tested on https://www.jsonschemavalidator.net/, but JsonSchemaValidator passes all verifications.\nI noticed that this behaviour is even present in Johnzon tests , i.e.JsonSchemaValidatorTest.java#L572 where number type is expected for keys identified by [0-9]+, but it succeeds for string type as well.\nI think it is a bug, unless I misconfigured something, follows below a snippet of code where the validator is created:\n\n    private final JsonSchemaValidator validator;\r\n\r\n    private FeatureSchemaValidatorProvider() {\r\n        JsonReader reader = null;\r\n        JsonSchemaValidatorFactory factory = null;\r\n        try (InputStream schemaInput = FeatureJSONReader.class.getResourceAsStream(\"/META-INF/feature/Feature-1.0.0.schema.json\")) {\r\n            reader = Json.createReader(schemaInput);\r\n            JsonObject schema = reader.readObject();\r\n            factory = new JsonSchemaValidatorFactory();\r\n            factory.setRegexFactory(JavaRegex::new);\r\n            validator = factory.newInstance(schema);\r\n        } catch (IOException ioe) {\r\n            // should not happen, /META-INF/feature/Feature-1.0.0.schema.json is in the classpath\r\n            throw new UncheckedIOException(ioe);\r\n        } finally {\r\n            if (reader != null) {\r\n                reader.close();\r\n            }\r\n            if (factory != null) {\r\n                factory.close();\r\n            }\r\n        }\r\n    }\r\n\n\nCould you kindly help us? Many thanks in advance!\n"
            },
            "2": {
                "commit_sha_buggy": "b1c44d56f764d32f2500f3438689b19ddfedde3a",
                "commit_sha_fixed": "5ac4924ac45f2985673ab048f650b33b7b81e81b",
                "report_id": "JOHNZON-322",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-322",
                "issue_title": "[JOHNZON-322] johnzon-jsonschema: BaseNumberValidation cannot support negative numbers - ASF JIRA",
                "issue_description": "\nBaseNumberValidation is the parent class of all number validations and such validations need to support negative numbers.\n For instance, trying to validate with a -1 MinimumValidation will fail when val is -1 or 0.\nRelated code:\u00a0\nhttps://github.com/apache/johnzon/blob/master/johnzon-jsonschema/src/main/java/org/apache/johnzon/jsonschema/spi/builtin/BaseNumberValidation.java#L40-L42\n"
            }
        }
    },
    "Johnzon_mapper": {
        "owner_repo": "apache/johnzon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5a4857421e6e42af701cf2e1ada61842f67b502d",
                "commit_sha_fixed": "4b8c93a797088872843e191a3eb43ae038146135",
                "report_id": "JOHNZON-28",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-28",
                "issue_title": "[JOHNZON-28] Bad numeric conversion - ASF JIRA",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "8a6fc5946399b264155900346eb0fdbe60f6d5a0",
                "commit_sha_fixed": "3d5ebbf7a29d1d9d223a2b7cb1bde0d793fb3e70",
                "report_id": "JOHNZON-25",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-25",
                "issue_title": "[JOHNZON-25] Map<String, Object> with nested objects - ASF JIRA",
                "issue_description": "\nNo time to work on it now so opening a ticket for version > next release.\nJOHNZON-20 solved a part of it but we still don't handle Object everywhere (basically we have the json event so we have the type so we just need to default to the type we want (JsonString -> String, JsonArray -> List<Object>, JsonObject -> Map<String, Obejct>, ...).\nMain cases to fix and test: nested list/map.\n"
            },
            "3": {
                "commit_sha_buggy": "bcab1c842ba89c450d70931e7966384cb13dada2",
                "commit_sha_fixed": "32d0715dfbf7de615005a51efa862c159d94ba2e",
                "report_id": "JOHNZON-35",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-35",
                "issue_title": "[JOHNZON-35] Mapper fails on short and byte array - ASF JIRA",
                "issue_description": "\nshort[] numShortA = new short[]\n{(short)1,(short)2,(short)3,(short)4,(short)5,(short)-7,(short)-8}\n;\n(same for byte[])\nfails with a \nException in thread \"main\" java.lang.ClassCastException: Cannot cast java.lang.Short to java.lang.Integer\n\tat java.lang.Class.cast(Class.java:3176)\n\tat org.apache.johnzon.mapper.Mapper.writePrimitives(Mapper.java:110)\n\tat org.apache.johnzon.mapper.Mapper.writeItem(Mapper.java:421)\n\tat org.apache.johnzon.mapper.Mapper.writeValue(Mapper.java:395)\n\tat org.apache.johnzon.mapper.Mapper.doWriteObjectBody(Mapper.java:346)\n\tat org.apache.johnzon.mapper.Mapper.doWriteObject(Mapper.java:313)\n\tat org.apache.johnzon.mapper.Mapper.writeItem(Mapper.java:423)\n\tat org.apache.johnzon.mapper.Mapper.writeValue(Mapper.java:395)\n\tat org.apache.johnzon.mapper.Mapper.doWriteObjectBody(Mapper.java:346)\n\tat org.apache.johnzon.mapper.Mapper.doWriteObject(Mapper.java:313)\n\tat org.apache.johnzon.mapper.Mapper.doWriteHandlingNullObject(Mapper.java:292)\n\tat org.apache.johnzon.mapper.Mapper.writeObject(Mapper.java:269)\n"
            },
            "4": {
                "commit_sha_buggy": "70a77af7f4271e06f6295d5b6b50070ae0e12d73",
                "commit_sha_fixed": "cc1053463d05b181edffae10936f534420a6110e",
                "report_id": "JOHNZON-48",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-48",
                "issue_title": "[JOHNZON-48] Complex types in collection with converter - ASF JIRA",
                "issue_description": "\nComplex objects in a list get serialized as json object without using registered converters. This leads to malformed json strings which can't be deserialized if there is no default constructor available (as is the case with enums). \n"
            },
            "5": {
                "commit_sha_buggy": "9330cea8c8752f3e9048cb579910104af0398737",
                "commit_sha_fixed": "d858d3dd461bc1b4dc98b789366a1a68673733b0",
                "report_id": "JOHNZON-150",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-150",
                "issue_title": "[JOHNZON-150] Incorrect Mapping of EnumSet Field - ASF JIRA",
                "issue_description": "\nIf i try to serialize and deserialize an object with a field of type EnumSet i get an argument type mismatch. The reason is, that in this case Johnzon deserializes the field as type HashSet an throws an error when trying to set the field value.\nI think the problem is in the method createCollectionMapping of the class Mappings.  \n"
            },
            "6": {
                "commit_sha_buggy": "014ef1e19b25a327c3c7108bab9358ca36bca98c",
                "commit_sha_fixed": "a9b615331b1e9830b8ce3b01ea2ec996c7f7c60b",
                "report_id": "JOHNZON-206",
                "report_url": "https://issues.apache.org/jira/browse/JOHNZON-206",
                "issue_title": "[JOHNZON-206] toStructure of arrray of JsonObjects serializes JsonObjectImpl like an arbitrary Object - ASF JIRA",
                "issue_description": "\nI'm not sure this is really a bug or more a feature request/improvement/misunderstanding on my side.\nCalling toStructure with an javax.json.JsonObject works fine.\n Calling it with an JsonArray of JsonObjects works fine.\n Calling it with an java.langObject[]-Array of Objects works fine.\n Calling it with an Object[]-Array of JsonObjects treats the JsonObjects as arbitrary Objects resulting in an serialized form of their internals:\n\n{\"integral\":true,\"valueType\":\"NUMBER\",\"value\":1}\n\nI\u00a0would have expected this special treatment of JsonX classes to work on all nesting levels, not only on the top level. What do you think?\n"
            }
        }
    },
    "Karaf_main": {
        "owner_repo": "apache/karaf",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "be6b7e845dc7975acc5cb8e5b2668dd0e9920e35",
                "commit_sha_fixed": "79922932e922943eaa43710cf0dc755ae202f03a",
                "report_id": "KARAF-335",
                "report_url": "https://issues.apache.org/jira/browse/KARAF-335",
                "issue_title": "[KARAF-335] The lib folder should be optional - ASF JIRA",
                "issue_description": "\nThe main class throws a NPE if the lib folder does not exist.\n"
            }
        }
    },
    "Appformer_uberfire_commons_editor_backend": {
        "owner_repo": "kiegroup/appformer",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5a109336dbc8c6f71b0ab08aaecf42bf80d43a19",
                "commit_sha_fixed": "f115f62f72638f390a398f1cd373a5adb177a0cc",
                "report_id": "AF-2341",
                "report_url": "https://issues.redhat.com/browse/AF-2341",
                "issue_title": "AppFormerAF-2341Not able to restore files where dot file (metadata) has been edited",
                "issue_description": "\nNot able to restore any file where metadata has been edited. The editors edit two files: the actual file and the dot file for the actual file. Currently restore menu item only restores the dot file if the dot file has been edited. \n"
            }
        }
    },
    "Kie_pmml_commons": {
        "owner_repo": "kiegroup/drools",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "fdccf1829fbc8e7f6fcb9ee5af45a70d3de916b6",
                "commit_sha_fixed": "eac2a63b7414aba00fcfedd0ba162e31d1f8131f",
                "report_id": "DROOLS-6094",
                "report_url": "https://issues.redhat.com/browse/DROOLS-6094",
                "issue_title": "DroolsDROOLS-6094Fix package name declaration from files containing dash in the name",
                "issue_description": "\nRefer to RHPAM-3521.\nFix:  \norg.kie.pmml.commons.utils.KiePMMLModelUtils.getSanitizedPackageName(String):\nadd \".replace(\"-\", \"\").\"\n"
            },
            "2": {
                "commit_sha_buggy": "e05cd7b388c4b0255d41e00f17d3c98065fbfc41",
                "commit_sha_fixed": "d96410478c3dd359c303f6b3d2b760bdf411e1f9",
                "report_id": "DROOLS-6235",
                "report_url": "https://issues.redhat.com/browse/DROOLS-6235",
                "issue_title": "DroolsDROOLS-6235Fix path/packagename management in Windows",
                "issue_description": "\nPMMLAssemblerService.getFactoryClassNamePackageName does not convert windows path to unis one.\nFix it to have correct folder separators (\"/\" instead of \"\\\")\nFix also \nKiePMMLModelUtils.getSanitizedPackageName to remove \":\"\nfix both KiePMMLModelUtils to use a smarter way (regex ?) for replacement\n"
            },
            "3": {
                "commit_sha_buggy": "a608f8741b31314d30551495d9cac14c56f73bb3",
                "commit_sha_fixed": "9c95403195e6d000f45837d022e9683fa524f5fc",
                "report_id": "DROOLS-6272",
                "report_url": "https://issues.redhat.com/browse/DROOLS-6272",
                "issue_title": "DroolsDROOLS-6272Fix package generation in pmml codegen",
                "issue_description": "\nLook inside generated kjar - packages are not nested anymore but they should to avoid name/class clashes\n"
            }
        }
    },
    "Kie_memory_compiler": {
        "owner_repo": "kiegroup/drools",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e33abb6536b1b7cfe83df79bd1109a4fbcf40b4f",
                "commit_sha_fixed": "2b65d147e6c244d7eab6f2af4f625c33350518a7",
                "report_id": "DROOLS-5932",
                "report_url": "https://issues.redhat.com/browse/DROOLS-5932",
                "issue_title": "DroolsDROOLS-5932NullPointerException at NativeJavaCompiler when using JRE ",
                "issue_description": "\nIf you use JRE instead of JDK, ToolProvider.getSystemJavaCompiler() returns null and will result in NPE later.\nhttps://github.com/kiegroup/drools/blob/996e8f40dec9f25650dfb0457eb09bad3b1cebc7/kie-memory-compiler/src/main/java/org/kie/memorycompiler/jdknative/NativeJavaCompiler.java#L88\nProbably should add a null check and throw an error message, something like \"Cannot perform native java compilation: could not find the System's Java compiler. Maybe install a JDK?\"\nFYI)\nhttps://groups.google.com/g/optaplanner-dev/c/2UkiCjPua5w/m/BebSTW0zCAAJ\nhttps://stackoverflow.com/questions/2543439/null-pointer-exception-while-using-java-compiler-api/2543485#2543485\nhttps://stackoverflow.com/questions/65682295/course-timetabling-and-conference-scheduling-examples-are-broken-in-optaplanner\n"
            }
        }
    },
    "Jbpm_human_task_workitems": {
        "owner_repo": "kiegroup/jbpm",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "dd4432e65155e512c8f8fe81c046a99994d6c8ec",
                "commit_sha_fixed": "b4a68043351dde7f564016bc1e525739984eb417",
                "report_id": "JBPM-7356",
                "report_url": "https://issues.redhat.com/browse/JBPM-7356",
                "issue_title": "jBPMJBPM-7356Task assignment failing if actor contains variable with empty string",
                "issue_description": "\nThe actors assignment for a task is defined as a combination of fixed string and a variable. During process execution, the var1 variable could be set to an empty String due to business logic. Depending on the order of the string/variable in the actors assignment, this could work or lead to a failure during process execution:\n\nThis works:\n\t\nbpmsAdmin,#{var1}\n\n\nThis fails:\n\t\n#{var1},bpmsAdmin\n\n\n\nExample failure when using Oracle:\n\n12:28:11,344 WARN  [org.hibernate.engine.jdbc.spi.SqlExceptionHelper] (http-10.213.29.102:8080-3) SQL Error: 1400, SQLState: 23000\n12:28:11,344 ERROR [org.hibernate.engine.jdbc.spi.SqlExceptionHelper] (http-10.213.29.102:8080-3) ORA-01400: cannot insert NULL into (\"PEOPLEASSIGNMENTS_POTOWNERS\".\"ENTITY_ID\")\n\n12:28:11,344 INFO  [org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl] (http-10.213.29.102:8080-3) HHH000010: On release of batch it still contained JDBC statements\n12:28:11,344 WARN  [org.jbpm.services.task.persistence.TaskTransactionInterceptor] (http-10.213.29.102:8080-3) Could not commit session: javax.persistence.PersistenceException: org.hibernate.exception.ConstraintViolationException: could not execute statement\n\n\n"
            }
        }
    },
    "Drools_traits": {
        "owner_repo": "kiegroup/drools",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "93d74a23981fa8dd6aa6830048913637f46e7766",
                "commit_sha_fixed": "1d92caebdcf73f786f19f9404a49831564e385bb",
                "report_id": "DROOLS-5721",
                "report_url": "https://issues.redhat.com/browse/DROOLS-5721",
                "issue_title": "DroolsDROOLS-5721Ruleflow group rule does not fire when drools-traits is on classpath",
                "issue_description": "\nWhen drools-traits is added on the classpath, the provided tests fails on fireAllRules() returning 0 instead of expected 1. The test passes in RHDM/RHPAM 7.8.1 and earlier, the problem was reproduced on master.\nIf the test describes a behaviour which is now not supported, please let us know, thanks! Otherwise, it seems to be a regression.\nI have set the priority to Critical in order to investigate what is going on (if the regression might cause more serious unexpected behaviour), it can be deprioritized if we are sure what it affects.\n"
            }
        }
    },
    "Drools_model_compiler": {
        "owner_repo": "kiegroup/drools",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7e1bad83d6023b7790bcb1698817d643a32edac3",
                "commit_sha_fixed": "d1b864df4fb9d6d3cb098c84f36a5d05f424b5cd",
                "report_id": "DROOLS-2625",
                "report_url": "https://issues.redhat.com/browse/DROOLS-2625",
                "issue_title": "DroolsDROOLS-2625Executable model - AccumulateTest and other tests fail with the model",
                "issue_description": "\nTests from these test classes from drools-compiler module fail (350 out of 1014 cases) with the executable model:\n\nAccumulateTest\nAlphaNetworkModifyTest\nAlphaTest\nAnnotationsTest\nArrayTest\nBackwardChainingTest\n\nPR with tests: https://github.com/kiegroup/drools/pull/1941\n"
            }
        }
    },
    "Appformer_uberfire_security_management_client": {
        "owner_repo": "kiegroup/appformer",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0df68ea67304750409a1fb1a375c2cc2d426526d",
                "commit_sha_fixed": "e9ef4b415905a1e85184b0a4eda2b8c858c04270",
                "report_id": "AF-483",
                "report_url": "https://issues.redhat.com/browse/AF-483",
                "issue_title": "AppFormerAF-483[Security management] ClientResponseFailure when User without sufficient client-roles opens Security management perspective",
                "issue_description": "\nIf you open Security management perspective (Roles, Groups, Users) as admin user without realm-management client roles, you will get ClientResponseFailure error because you don't have required permissions. This is not user friendly and it should be replaced with other message or the security management should be disabled for the user.\n"
            }
        }
    },
    "Appformer_uberfire_workbench_client": {
        "owner_repo": "kiegroup/appformer",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b78f362d6fbcbd4b908149a888eeb5fb8e8e6170",
                "commit_sha_fixed": "36a46f606add71baa13e4074925268feba601e80",
                "report_id": "AF-900",
                "report_url": "https://issues.redhat.com/browse/AF-900",
                "issue_title": "AppFormerAF-900Pages are incorrectly named in the security settings UI",
                "issue_description": "\nPages created in the Dashboards perspective are incorrectly named in the Settings. For example, a page called \"Page no. 1\" is displayed only as \"1\". See the attached screenshots.\n\u2014\nMentioning david.magallanes just so he is aware of this. We were dealing with the same issue in the CMS perspective not that long ago.\n"
            },
            "2": {
                "commit_sha_buggy": "90b39c4da20941c7695e63c220091cfc7fd6a987",
                "commit_sha_fixed": "20554d6e00cd4a1c8d0516f1fbe907e24cf1fe58",
                "report_id": "AF-1252",
                "report_url": "https://issues.redhat.com/browse/AF-1252",
                "issue_title": "AppFormerAF-1252Notification event throws NPE in standalone mode when using IE",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "16e1858ef23192abdb03142cb095e52170f8c619",
                "commit_sha_fixed": "60ef2272a0c2296e5aa3b945b045d84425f7d49b",
                "report_id": "AF-2232",
                "report_url": "https://issues.redhat.com/browse/AF-2232",
                "issue_title": "AppFormerAF-2232IllegalStateException displayed briefly in the UI when logging out from business-central",
                "issue_description": "\nWhen clicking the Log Out button in business-central, an overlay error panel is displayed for a short period of time during the redirection to the login page. Different error messages have been observed, such as:\n\nLibraryPerspectiveActivity failed in SHUTDOWN: java.lang.IllegalStateException: Activity org.kie.workbench.common.screens.library.client.perspective.LibraryPerspectiveActivity for PlaceRequest[\"LibraryPerspective\" {}] is open\n\n\nor\n\nHomePerspectiveActivity failed in SHUTDOWN: java.lang.IllegalStateException: Activity org.kie.workbench.common.screens.home.client.perspective.HomePerspectiveActivity for PlaceRequest[\"HomePerspective\" {}] is open\n\n\nThe error can be seen at  ~0:08s in the attached screencast.\nWhile this appears to have no functional impact, it gives the impression that something is incorrect.\n"
            }
        }
    },
    "Deltaspike_api": {
        "owner_repo": "apache/deltaspike",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "6e62f8eb3048fdffd2ce5fef53d6e338d4c05747",
                "commit_sha_fixed": "b4dd2ba9c18de97a70bda142d4dcb1adee3792fc",
                "report_id": "DELTASPIKE-781",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-781",
                "issue_title": "[DELTASPIKE-781] AnnotatedTypeImpl doesn't work for Annotation AnnotatedType - ASF JIRA",
                "issue_description": "\nI needed to create AnnotatedType for Annotation to register it as an interceptor binding with BeforeBeanDiscovery#addInterceptorBinding and realised that the builded AnnotatedType thru AnnotatedTypeBuilder contained all the Annotation class methods where it should have contained none. That makes the container (Weld or OWB) crash.  \n"
            },
            "2": {
                "commit_sha_buggy": "07f5199529a0e2cdb6dfbda20e4b16f060378b84",
                "commit_sha_fixed": "e60776cc76c12e10b214db5950fcbf0d80f883e3",
                "report_id": "DELTASPIKE-1139",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-1139",
                "issue_title": "[DELTASPIKE-1139] TypedResolver might prematurely return null under high load - ASF JIRA",
                "issue_description": "\nif the caching logic gets used we reset the reload-timer a tad too early. This might result in returning null if the first access is performed in a highly concurrent way.\n"
            },
            "3": {
                "commit_sha_buggy": "138eec6167cf7cfa428d3dab78a7b870eb72920d",
                "commit_sha_fixed": "c25a89f1dd0ab8654396acedb60e1e1975386a41",
                "report_id": "DELTASPIKE-1147",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-1147",
                "issue_title": "[DELTASPIKE-1147] TypedResolver behaves different than ConfigResolver - ASF JIRA",
                "issue_description": "\nWe have some cases where the TypedResolver return different values than performing the same operation via the legacy ConfigResolver API.\n1.) default values of 'null' get handled different\n2.) ProjectStage specific empty values abort the resolver chain in older versions. In 1.6.1 it continues the evaluation. This leads to different values.\n"
            },
            "4": {
                "commit_sha_buggy": "0596f9db2cc9344ab76a9cbc610f2f527e4e3373",
                "commit_sha_fixed": "7215f7b7fdea436017c8a331d5468dc8fc5c7145",
                "report_id": "DELTASPIKE-1208",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-1208",
                "issue_title": "[DELTASPIKE-1208] deltaspike configuration: Variable Replacement in Configured Values is NOT fully stage aware - ASF JIRA",
                "issue_description": "\nusing the following apache-deltaspike.properties \n\nsome-service-url=${edge-server-url}/some-service\nedge-server-url=undefined\nedge-server-url.Development=http://development:8081\nedge-server-url.Staging=http://staging:8081\nedge-server-url.Production=http://prod:8081\n\n\nand executing the following code:\n\nSystem.out.println(\"some-service-url=\"+ConfigResolver.getProjectStageAwarePropertyValue(\"some-service-url\"));\n\n\nhaving the following java VM arg set:\n\n-Dorg.apache.deltaspike.ProjectStage=Staging\n\n\nshould result in the output: \nsome-service-url=http://staging:8081/some-service\nI have already contributed a bug fix for DELTASPIKE-1167 - unfortunately that didn't fully solve the issue.\nI plan to provide a fix for this soon. [UPDATE] patch added\n"
            },
            "5": {
                "commit_sha_buggy": "618dd99b6861c80250d2724208e77807c14b5f32",
                "commit_sha_fixed": "651c9a56937f8da2f92859bf5720362459bc3202",
                "report_id": "DELTASPIKE-1287",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-1287",
                "issue_title": "[DELTASPIKE-1287] asList() getValue() fails with a NPE if no configured value exists - ASF JIRA",
                "issue_description": "\nWe currently blow up with a NullPointerException if a List gets resolved and no value was actually configured.\n"
            },
            "6": {
                "commit_sha_buggy": "1af137d843c9ba2e07015e654a4d84b59fc2a738",
                "commit_sha_fixed": "b5f94113b15716e7fed81ea643f3948040079422",
                "report_id": "DELTASPIKE-1317",
                "report_url": "https://issues.apache.org/jira/browse/DELTASPIKE-1317",
                "issue_title": "[DELTASPIKE-1317] AnnotatedCallableImpl blows up with ArrayOutofBounds when parsing enums - ASF JIRA",
                "issue_description": "\nIt seems like constructor#getParameterTypes() and getGenericParameterTypes() return a different number of parameters for enums.\n\u00a0\nThere is already a rudimentary workaround in place, but that seems not to be enough.\n\u00a0\nWe need to dig deeper why this happens.\n"
            }
        }
    },
    "Flume_ngcore": {
        "owner_repo": "apache/flume",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e6c64a8e3fd4d2ffe5d8505041738bdd4cc3f667",
                "commit_sha_fixed": "c2bcda202e24c426329425a11623946c9df0b102",
                "report_id": "FLUME-1470",
                "report_url": "https://issues.apache.org/jira/browse/FLUME-1470",
                "issue_title": "[FLUME-1470] Syslog source does not parse facility correctly - ASF JIRA",
                "issue_description": "\nFacility is specified as priority / 8 but it's currently implemented as priority - 8\n"
            },
            "2": {
                "commit_sha_buggy": "d5ce8af76d40e75624a2efe88e5aeb58146bda10",
                "commit_sha_fixed": "c145b2b8c1ed7bc04e1b018085c519555cf61a21",
                "report_id": "FLUME-1683",
                "report_url": "https://issues.apache.org/jira/browse/FLUME-1683",
                "issue_title": "[FLUME-1683] Fix Time Granularity Bug in SpoolingFileLineReader - ASF JIRA",
                "issue_description": "\nThis patch fixes a test in the SpoolingFileLineReader, and a bug associated with that test:\nThe issue is related to the way that the source sorts files which are candidates for ingestion. It sorts the files by timestamp, and the unit test assumes that if it creates two files:\nx = new File()\nFiles.write(\"something\", x)\ny = new File() \nFiles.write(\"something\", y)\n// Read from files\nthat x will be processed before y. In my filesystem, the time granularity is only 1 second, so these files were actually processed in a non-deterministic order. On your filesystem, they were processed in the correct order, and the test (correctly) failed.\nI didn't notice that the test was mixed up because it was passing for me due to this issue.\nI updated the sorting order to take into account filename when there is a tie in the timestamp, so at least we have a consistent ordering we can test.\n"
            }
        }
    },
    "Jandex": {
        "owner_repo": "wildfly/jandex",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c05209a900c5920e56250cf25ea27d2fa55bede4",
                "commit_sha_fixed": "c5e3a883eb5a2af392419bfed869c197e5a953b2",
                "report_id": "JANDEX-20",
                "report_url": "https://issues.redhat.com/browse/JANDEX-20",
                "issue_title": "JandexJANDEX-20DotName.isComponentized() returns the inverted value of the componentized member",
                "issue_description": "\nSo that it returns true for simple variant and false for componentized variant. The member componentized has the right value initialized so the problem is only in the isComponentized() method.\n"
            },
            "2": {
                "commit_sha_buggy": "c05209a900c5920e56250cf25ea27d2fa55bede4",
                "commit_sha_fixed": "c412a714421597ae671a3d92ec58bf1fedd67d99",
                "report_id": "JANDEX-20",
                "report_url": "https://issues.redhat.com/browse/JANDEX-20",
                "issue_title": "JandexJANDEX-20DotName.isComponentized() returns the inverted value of the componentized member",
                "issue_description": "\nSo that it returns true for simple variant and false for componentized variant. The member componentized has the right value initialized so the problem is only in the isComponentized() method.\n"
            },
            "3": {
                "commit_sha_buggy": "9930fcb9b573f4c692cb7f859d62744fb8e8021c",
                "commit_sha_fixed": "c682961a725d1b0507aae1ed6053737be280bc7f",
                "report_id": "JANDEX-35",
                "report_url": "https://issues.redhat.com/browse/JANDEX-35",
                "issue_title": "JandexJANDEX-35Failure to resolve method type variable when using class-level bounded wildcard generics",
                "issue_description": "\nWhen indexing class file data, the signatures along with its targets are processed in an order they arrived from an input stream, which might lead to method-level signatures being processed before class-level, thus leading to unresolved type variables and incorrect resulting indexes. No exceptions raised.\n"
            },
            "4": {
                "commit_sha_buggy": "d72291d5dd408f1c85817b81ecb707051555799e",
                "commit_sha_fixed": "8996177aea4e0626f849ead5f9ab110383d70d79",
                "report_id": "JANDEX-37",
                "report_url": "https://issues.redhat.com/browse/JANDEX-37",
                "issue_title": "JandexJANDEX-37ClassInfo does not distinguish between inner and static nested classes",
                "issue_description": "\nInner classes are non-static nested classes. But ClassInfo.NestingType.INNER is also returned for static nested classes and that's quite confusing. The same probably applies to org.jboss.jandex.DotName.isInner(). Fortunately, ClassInfo.flags() can be used to identify static nested classes.\nClassInfo.NestingType.INNER should be either called NESTED or a special value for static nested classes should be added. \n"
            },
            "5": {
                "commit_sha_buggy": "d72291d5dd408f1c85817b81ecb707051555799e",
                "commit_sha_fixed": "7d69a7ffe4586f6e376f74b442ec08122a37016b",
                "report_id": "JANDEX-37",
                "report_url": "https://issues.redhat.com/browse/JANDEX-37",
                "issue_title": "JandexJANDEX-37ClassInfo does not distinguish between inner and static nested classes",
                "issue_description": "\nInner classes are non-static nested classes. But ClassInfo.NestingType.INNER is also returned for static nested classes and that's quite confusing. The same probably applies to org.jboss.jandex.DotName.isInner(). Fortunately, ClassInfo.flags() can be used to identify static nested classes.\nClassInfo.NestingType.INNER should be either called NESTED or a special value for static nested classes should be added. \n"
            },
            "6": {
                "commit_sha_buggy": "c107579771ec68a32d8267cc64ac25eb8888d678",
                "commit_sha_fixed": "5d55ee3fdfe011b967bb37628c2bf6b63b7a495d",
                "report_id": "JANDEX-47",
                "report_url": "https://issues.redhat.com/browse/JANDEX-47",
                "issue_title": "JandexJANDEX-47DotName value class is violating the Comparator contract",
                "issue_description": "\nThe DotName class is a \"value object\" but some of its methods are tricky to implement since it can represent the value in different formats (\"simple\" and \"componentized\").\nIn particular the compareTo method has a fallback on the String comparator for certain cases; the main implementation though isn't consistent with the fallback implementation when inner classes are involved. This can lead to issues when relying on the sort order, e.g. with TreeSet and similar.\nSending a fix with tests.\n"
            }
        }
    },
    "Kogito_editors_java_kie_wb_common_stunner_widgets": {
        "owner_repo": "kiegroup/kogito-editors-java",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e8c9b3f8e82b481c1f1643b439acf180268b5c1c",
                "commit_sha_fixed": "d4086c191abb368179ac7d4b97e9e669630f7280",
                "report_id": "KOGITO-1014",
                "report_url": "https://issues.redhat.com/browse/KOGITO-1014",
                "issue_title": "KogitoKOGITO-1014[DMN Designer] ACE Editor is not shown for invalid DMN content",
                "issue_description": "\nWhen opening an invalid DMN file with the most recent DMN editor, it's expected that Ace editor shows up and displays the contents as text. However, due to a recently discovered bug, probably originated by this commit, an empty diagram shows and no error messages are displayed.\nAcceptance criteria:\nAce editor should show DMN contents as text on invalid DMN file input\n"
            }
        }
    },
    "Ognl": {
        "owner_repo": "apache/commons-ognl",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "dc8d1a5f2959d8ca84cba8ce9d70a79674c57b92",
                "commit_sha_fixed": "6587abc4cb8d9c0481c3a5eb57b74162f2134378",
                "report_id": "OGNL-9",
                "report_url": "https://issues.apache.org/jira/browse/OGNL-9",
                "issue_title": "[OGNL-9] Cannot handle hivemind's messages.format - ASF JIRA",
                "issue_description": "\nA way to reproduce is\n<span jwcid=\"@Insert\" value=\"ognl:messages.format('page-title', partners.size)\"/>\nwhere partners.size returns an int... \nError compiling expression on object $OurPartners_82@3c1[member/ourpartners/OurPartners] with expression node messages.format(\"page-title\", partners.size) getter body: \n{ return ((org.apache.hivemind.impl.AbstractMessages)(($OurPartners_82)$2).getMessages()).format(\"page-title\", ((java.util.AbstractCollection)(($OurPartners_82)$2).getPartners()).size());}\n setter body: nullUnable to add method java.lang.Object get(ognl.OgnlContext, java.lang.Object) to class ognl.ASTChain10373568Accessor: [source error] format(java.lang.String,int) not found in org.apache.hivemind.impl.AbstractMessages\norg.apache.tapestry.services.impl.HiveMindExpressionCompiler.compileExpression(HiveMindExpressionCompiler.java:258)\nognl.OgnlRuntime.compileExpression(OgnlRuntime.java:384)\nognl.Ognl.compileExpression(Ognl.java:123)\norg.apache.tapestry.services.impl.ExpressionCacheImpl.parse(ExpressionCacheImpl.java:129)\norg.apache.tapestry.services.impl.ExpressionCacheImpl.getCompiledExpression(ExpressionCacheImpl.java:91)\n$ExpressionCache_1112fc97cc3.getCompiledExpression($ExpressionCache_1112fc97cc3.java)\norg.apache.tapestry.binding.ExpressionBinding.resolveExpression(ExpressionBinding.java:121)\norg.apache.tapestry.binding.ExpressionBinding.getObject(ExpressionBinding.java:112)\norg.apache.tapestry.binding.AbstractBinding.getObject(AbstractBinding.java:84)\n$Border_22.getTitle($Border_22.java)\nognl.ASTProperty31122047Accessor.get(ASTProperty31122047Accessor.java)\norg.apache.tapestry.services.impl.ExpressionEvaluatorImpl.read(ExpressionEvaluatorImpl.java:131)\n$ExpressionEvaluator_1112fc97cc1.read($ExpressionEvaluator_1112fc97cc1.java)\norg.apache.tapestry.binding.ExpressionBinding.resolveExpression(ExpressionBinding.java:127)\norg.apache.tapestry.binding.ExpressionBinding.getObject(ExpressionBinding.java:112)\norg.apache.tapestry.binding.AbstractBinding.getObject(AbstractBinding.java:84)\n$Insert_6.getValue($Insert_6.java)\norg.apache.tapestry.components.Insert.renderComponent(Insert.java:48)\norg.apache.tapestry.AbstractComponent.render(AbstractComponent.java:708)\n\norg.apache.tapestry.services.impl.DefaultResponseBuilder.render(DefaultResponseBuilder.java:184)\norg.apache.tapestry.AbstractComponent.renderBody(AbstractComponent.java:521)\norg.apache.tapestry.html.Body.renderComponent(Body.java:38)\n\n"
            }
        }
    },
    "Qpid_client": {
        "owner_repo": "apache/qpid-jms",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "52b170c72372cb39393293871d07157a4db78d42",
                "commit_sha_fixed": "f2181f997ec2cb38dacc7c603c00c0b4e424d752",
                "report_id": "QPIDJMS-116",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-116",
                "issue_title": "[QPIDJMS-116] make behaviour of receive and receiveNoWait consistent when consumer closes due to a problem - ASF JIRA",
                "issue_description": "\nCurrently, if a consumer clsoes due to a problem, recieveNoWait will throw an exception, but a blocking receive in progress will return null. The behaviour should be consistent, and throwing the exception seems reasonable given that returning null would likely just lead to future use of the consumer which will itself then throw an exception.\n"
            },
            "2": {
                "commit_sha_buggy": "2f97ccb04b19b9203c7a7b1e42513152c65d5508",
                "commit_sha_fixed": "5a55b46e6593f32113f6c69bdf21b0e91b6945ac",
                "report_id": "QPIDJMS-114",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-114",
                "issue_title": "[QPIDJMS-114] When failover.initialReconnectDelay is set, client cannot connect - ASF JIRA",
                "issue_description": "\nWhen option failover.initialReconnectDelay is set to other value than 0, client hangs up during creating a session.\n\nInitialContext ctx = new InitialContext(properties);\nConnection connection = ((ConnectionFactory) ctx.lookup(\"connection\")).createConnection();\nSession session = connection.createSession(false, Session.CLIENT_ACKNOWLEDGE);\nConnection string used:\nconnectionfactory.connection=failover:(amqp://server:21415?amqp.saslMechanisms=PLAIN)?failover.initialReconnectDelay=1&failover.maxReconnectAttempts=5&failover.reconnectDelay=60000&jms.username=admin&jms.password=admin&jms.forceAsyncSend=false&jms.alwaysSyncSend=true&jms.sendAcksAsync=false\nBroker was started day before test and broker still is running. In broker logs there are no signs about connection (trace level) and client is just stuck (i waited for 10 minutes and still no error message).\nBroker is qpidd - the Qpid AMQP Message Broker Daemon, versions of qpidd and mrg-m below.\n\n$ qpidd --version\nqpidd (qpid-cpp) version 0.22\n$ rpm -qa | grep mrg-m\nmrg-messaging-release-3.0.0-3.el6.noarch\n$ rpm -qa | grep qpid\nqpid-cpp-server-0.22-52.el6.x86_64\nqpid-cpp-server-linearstore-0.22-52.el6.x86_64\nqpid-proton-c-0.7-4.el6.x86_64\nqpid-tools-0.22-16.el6.noarch\npython-qpid-qmf-0.22-41.el6.x86_64\nqpid-cpp-client-devel-0.22-52.el6.x86_64\nqpid-cpp-client-devel-docs-0.22-52.el6.noarch\npython-qpid-0.22-19.el6.noarch\nqpid-cpp-server-devel-0.22-52.el6.x86_64\nqpid-qmf-0.22-41.el6.x86_64\nqpid-cpp-client-0.22-52.el6.x86_64\nqpid-cpp-server-ha-0.22-52.el6.x86_64\nqpid-tests-0.22-16.el6.noarch\n"
            },
            "3": {
                "commit_sha_buggy": "5a55b46e6593f32113f6c69bdf21b0e91b6945ac",
                "commit_sha_fixed": "12e77cac7f84d0059010c21efe5e39a5f5733c9b",
                "report_id": "QPIDJMS-117",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-117",
                "issue_title": "[QPIDJMS-117] dont apply the initialReconnectDelay to the first attempt to connect - ASF JIRA",
                "issue_description": "\nDont apply the initialReconnectDelay to the first attempt to connect, only the subsequent attempts to reconnect.\n"
            },
            "4": {
                "commit_sha_buggy": "12e77cac7f84d0059010c21efe5e39a5f5733c9b",
                "commit_sha_fixed": "689bd88b78a6cdaa17a88fe7f8e38544db0877a8",
                "report_id": "QPIDJMS-115",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-115",
                "issue_title": "[QPIDJMS-115] Repetitive reconnections when wrong password set - ASF JIRA",
                "issue_description": "\nWhen I supply wrong password in connection string, client tries connect again immediately after failure. These reconnection will happen until I stop the client.\n2015-09-22 12:36:08 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:08 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:09 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n2015-09-22 12:36:10 +0200 INFO org.apache.qpid.jms.sasl.SaslMechanismFinder - Best match for SASL auth was: SASL-CRAM-MD5\n...\nThis is happening during creating session.\nsession = connection.createSession(false, Session.CLIENT_ACKNOWLEDGE);\nUsed connection string:\nfailover:(amqp://cbgc01:21415)?jms.username=admin&jms.password=admin2\nAMQP 0-10 client prints out an exception and quits when wrong password supplied, is same behavior expected here?\n"
            },
            "5": {
                "commit_sha_buggy": "a76b51ac1a0f4cc8ac0734e982ec861d67a830a3",
                "commit_sha_fixed": "03b491240d88ff5dde1b3759d000e7963ee1492d",
                "report_id": "QPIDJMS-116",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-116",
                "issue_title": "[QPIDJMS-116] make behaviour of receive and receiveNoWait consistent when consumer closes due to a problem - ASF JIRA",
                "issue_description": "\nCurrently, if a consumer clsoes due to a problem, recieveNoWait will throw an exception, but a blocking receive in progress will return null. The behaviour should be consistent, and throwing the exception seems reasonable given that returning null would likely just lead to future use of the consumer which will itself then throw an exception.\n"
            },
            "6": {
                "commit_sha_buggy": "f82bf5032bceab98d87f9ac5c8a5a9c3163d112c",
                "commit_sha_fixed": "301e32d69552bc183fadee471c45a1717a6347f1",
                "report_id": "QPIDJMS-118",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-118",
                "issue_title": "[QPIDJMS-118] timed dequeue calls on the local queue can return before they should - ASF JIRA",
                "issue_description": "\nThe client uses a local queue in each consumer to hold messages prior to receive/onMessage processing using them. When a timed dequeue is performed, it is currently possible for the dequeue call to erroneously return early before they should have, prior to the timeout expiring (excepting the desired  cases such a message arriving or the queue being been closed etc) because the method does not ensure it has actually waited for the requested time.\n"
            },
            "7": {
                "commit_sha_buggy": "bb56d0ffd2a415447249a5edc19803451e841a10",
                "commit_sha_fixed": "26f881bf3be693b4734a52aedd26f12357549e97",
                "report_id": "QPIDJMS-130",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-130",
                "issue_title": "[QPIDJMS-130] clearing the properties of a received message should make them writable again - ASF JIRA",
                "issue_description": "\nJMS requries that recieved messages have read-only properties and bodies (but not headers) that can be independently cleared, which makes them writable again.\nOur clearProperties implementation is currently only clearing the existing properties and is not marking them writable, so it isnt possible to set new property values after performing the clear operation.\n"
            },
            "8": {
                "commit_sha_buggy": "974a8510bf95d48fe9174c25ad178198145771e1",
                "commit_sha_fixed": "c4c79e5c549e643fb5bcc03222ffbf955b6b8da1",
                "report_id": "QPIDJMS-126",
                "report_url": "https://issues.apache.org/jira/browse/QPIDJMS-126",
                "issue_title": "[QPIDJMS-126] Handle tx coordinator link being closed by the transactional resource - ASF JIRA",
                "issue_description": "\nOne outcome of discharging a transaction is that the transacted resource could close the coordinator link.  We currently don't handle this and will get into a bad state if it happens.   \n"
            }
        }
    },
    "Switchyard_admin": {
        "owner_repo": "jboss-switchyard/core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a8a9431e2d847917d78016e59c92a1befeb78c19",
                "commit_sha_fixed": "d8ded8d2801d1aff5aed554d0dc97012b4cdaeaa",
                "report_id": "SWITCHYARD-697",
                "report_url": "https://issues.redhat.com/browse/SWITCHYARD-697",
                "issue_title": "SWITCHYARD-640: Create web app demo that showcases switchyard bpm task api",
                "issue_description": "SWITCHYARD-640: Create web app demo that showcases switchyard bpm task api"
            }
        }
    },
    "Weld_se_core": {
        "owner_repo": "weld/core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d69174bbf1485759699956183438d17657fd3c3d",
                "commit_sha_fixed": "e0a65e37efc380d87a9632042cb57db080b6525f",
                "report_id": "WELD-798",
                "report_url": "https://issues.redhat.com/browse/WELD-798",
                "issue_title": "WeldWELD-798Typesafe resolver performs poorly on startup",
                "issue_description": "\nFiring the ProcessBean events at startup has now become a massive hotspot when portable extensions are installed that inject the bean manager. The TypeSafeBeanResolver cache gets cleared and re-created between each firing, which is very expensive. The beansByType cache which provides a big performance boost when no portable extensions are installed appears to be the main culprit.\n"
            }
        }
    },
    "Jboss_modules": {
        "owner_repo": "jboss-modules/jboss-modules",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "862464701cd9210d7e1629575497058059bec91b",
                "commit_sha_fixed": "6812cc2fef35b3453587eec9023d182080502c2c",
                "report_id": "MODULES-237",
                "report_url": "https://issues.redhat.com/browse/MODULES-237",
                "issue_title": "JBoss ModulesMODULES-237Setting maven.repo.local to \"\" causes / to be used as the repo",
                "issue_description": "\nIt should instead fall back to ${user.home}/.m2/repository, as it does when maven.repo.local is null, or when local.maven.repo.path is null or empty.\n"
            },
            "3": {
                "commit_sha_buggy": "3a82b3f06f7c233ee3876d034f1947d8b65d98b9",
                "commit_sha_fixed": "8825165cd5d7d7161b466e045254fed440f97473",
                "report_id": "MODULES-378",
                "report_url": "https://issues.redhat.com/browse/MODULES-378",
                "issue_title": "JBoss ModulesMODULES-378Resource in modules.xml that references a directory link ignored when loading a resource bundle with ModuleClassLoader",
                "issue_description": "\nIf a module is created with a file resource\n\n<module xmlns=\"urn:jboss:module:1.0\" name=\"org.wf.test\">\n  <resources>\n    <resource-root path=\"/opt/properties\" name=\"properties\" />\n\n\nand that path resource references a link to another filesystem directory, then that link is not read when attempting to load resources with a ModuleClassLoader\n"
            },
            "4": {
                "commit_sha_buggy": "48e8b865992c51b0dd23ef0959062a8d3d65aa9f",
                "commit_sha_fixed": "2ce0bf3dffd831e7d7a5f6d5afa712abb59dc48b",
                "report_id": "MODULES-378",
                "report_url": "https://issues.redhat.com/browse/MODULES-378",
                "issue_title": "JBoss ModulesMODULES-378Resource in modules.xml that references a directory link ignored when loading a resource bundle with ModuleClassLoader",
                "issue_description": "\nIf a module is created with a file resource\n\n<module xmlns=\"urn:jboss:module:1.0\" name=\"org.wf.test\">\n  <resources>\n    <resource-root path=\"/opt/properties\" name=\"properties\" />\n\n\nand that path resource references a link to another filesystem directory, then that link is not read when attempting to load resources with a ModuleClassLoader\n"
            },
            "5": {
                "commit_sha_buggy": "a498bc6609965135beb9593bf33b90eaefe22643",
                "commit_sha_fixed": "ca2210e244350e2dc20ccf46febe937a150a7a37",
                "report_id": "MODULES-377",
                "report_url": "https://issues.redhat.com/browse/MODULES-377",
                "issue_title": "JBoss ModulesMODULES-377Getting 'IllegalArgumentException: moduleLoader is null' when iterating modules and module.xml contains a permissions markup",
                "issue_description": "\nIf we are executing the following code and there is a module.xml that contains a permission markup, we get an IllegalArgumentException: moduleLoader is null:\n\nIterator<String> stringIterator = ml.iterateModules((String) null, true);\n        while (stringIterator.hasNext()){\n            ...\n        }\n\n\nThe exception is:\n\nException in thread \"main\" java.lang.IllegalArgumentException: moduleLoader is null\n        at org.jboss.modules.security.ModularPermissionFactory.<init>(ModularPermissionFactory.java:69)\n        at org.jboss.modules.xml.ModuleXmlParser.expandName(ModuleXmlParser.java:1464)\n        at org.jboss.modules.xml.ModuleXmlParser.parseGrant(ModuleXmlParser.java:1386)\n        at org.jboss.modules.xml.ModuleXmlParser.parsePermissions(ModuleXmlParser.java:1352)\n        at org.jboss.modules.xml.ModuleXmlParser.parseModuleContents(ModuleXmlParser.java:681)\n        at org.jboss.modules.xml.ModuleXmlParser.parseDocument(ModuleXmlParser.java:440)\n        at org.jboss.modules.xml.ModuleXmlParser.parseModuleXml(ModuleXmlParser.java:311)\n        at org.jboss.modules.xml.ModuleXmlParser.parseModuleXml(ModuleXmlParser.java:269)\n        at org.jboss.modules.LocalModuleFinder$3.hasNext(LocalModuleFinder.java:299)\n        at org.jboss.modules.ModuleLoader$2.hasNext(ModuleLoader.java:345)\n        at local.tests.Main.main(Main.java:12)\n        at org.jboss.modules.Module.run(Module.java:352)\n        at org.jboss.modules.Module.run(Module.java:320)\n        at org.jboss.modules.Main.main(Main.java:593)\n\n\nIt seems jboss modules is unable to parse a module.xml under those circustances and when we are iteraing over the available modules.\nSource of the problem could be LocalModuleFinder:299, where the moduleLoader argument for parseModuleXml() is explicitely set to null.\n"
            },
            "6": {
                "commit_sha_buggy": "eb309b6f83ed89dc6171c8d6c675151041837530",
                "commit_sha_fixed": "0399324741a77001a751b293625bab733847300a",
                "report_id": "MODULES-405",
                "report_url": "https://issues.redhat.com/browse/MODULES-405",
                "issue_title": "JBoss ModulesMODULES-405System property 'maven.repo.local' must have preference over localRepository definition in settings.xml",
                "issue_description": "\nSee Ricardo proper analysis in https://issues.redhat.com/browse/WFLY-14244\n"
            }
        }
    },
    "Jboss_threads": {
        "owner_repo": "jbossas/jboss-threads",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "076592d052758904ad377fa86c1c815f7f9e2dc8",
                "commit_sha_fixed": "41e3577057cbe84ed7f2eb07a498a6a2c7acaf56",
                "report_id": "JBTHR-87",
                "report_url": "https://issues.redhat.com/browse/JBTHR-87",
                "issue_title": "Merge pull request #79 from dmlloyd/restore-cl\n\nRestore previous class loader after safeRun",
                "issue_description": "Merge pull request #79 from dmlloyd/restore-cl\n\nRestore previous class loader after safeRun"
            }
        }
    },
    "Minaftp_api": {
        "owner_repo": "apache/mina-ftpserver",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "184b641cb9e6e128c9c2187d8dc93d568809c172",
                "commit_sha_fixed": "c0394d584ba148f7e92c52097a0455e19933b668",
                "report_id": "FTPSERVER-383",
                "report_url": "https://issues.apache.org/jira/browse/FTPSERVER-383",
                "issue_title": "[FTPSERVER-383] STAT command does not work as LIST - ASF JIRA",
                "issue_description": "\nSTAT command does not work as LIST.\nquoting rfc959:\nSTATUS (STAT)\n...\nIf the argument is a pathname, the command\nis analogous to the \"list\" command except that data shall be\ntransferred over the control connection.\nSeems like current STAT impl ignores pathname arg.\n"
            }
        }
    },
    "Sling_validation": {
        "owner_repo": "apache/sling-org-apache-sling-validation-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "9a603e4605faa771417759cd1fc67210d92751f5",
                "commit_sha_fixed": "10c2515830fe0b05e9ce01a517725665ca674703",
                "report_id": "SLING-7289",
                "report_url": "https://issues.apache.org/jira/browse/SLING-7289",
                "issue_title": "[SLING-7289] Sling Validator Service does not free Validators correctly - ASF JIRA",
                "issue_description": "\nWhen a bundle that contains Sling Validators is removed. the Sling Validation Service does not correctly free them.\nThe problem is in the ValidatorMap, which fails to remove the service from the map in \nhttps://github.com/apache/sling-org-apache-sling-validation-core/blob/master/src/main/java/org/apache/sling/validation/impl/ValidatorMap.java#L225\n"
            }
        }
    },
    "Switchyard_config": {
        "owner_repo": "jboss-switchyard/core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e35de16bfbd6e3af2d3c866e7e079a696a326459",
                "commit_sha_fixed": "f506c5ff34f507fecfdc24c89b065525a1cfa424",
                "report_id": "SWITCHYARD-980",
                "report_url": "https://issues.redhat.com/browse/SWITCHYARD-980",
                "issue_title": "SWITCHYARD-976 Customizable activator list for standalone SwitchYard runtime",
                "issue_description": "SWITCHYARD-976 Customizable activator list for standalone SwitchYard runtime"
            }
        }
    },
    "Switchyard_validate": {
        "owner_repo": "jboss-switchyard/core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "eca6325658757e50a54cbaf70022e85b21c39c04",
                "commit_sha_fixed": "4e9f783aab5593b85cb4bbb745d45ad57bd5f280",
                "report_id": "SWITCHYARD-894",
                "report_url": "https://issues.redhat.com/browse/SWITCHYARD-894",
                "issue_title": "SWITCHYARD-886 Provide transaction mixin for integration tests",
                "issue_description": "SWITCHYARD-886 Provide transaction mixin for integration tests"
            }
        }
    },
    "Wildfly_naming_client": {
        "owner_repo": "wildfly/wildfly-naming-client",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7f62895ecf728e64a73d63d8038968e34f1246d9",
                "commit_sha_fixed": "583bbe256eeb9e3b3ca2eb0e66063f4102c65527",
                "report_id": "WFNC-56",
                "report_url": "https://issues.redhat.com/browse/WFNC-56",
                "issue_title": "WildFly Naming ClientWFNC-56Naming client - env property takes no effect when value is an Integer rather than String",
                "issue_description": "\n\nProperties jndiProps = new Properties();\njndiProps.put(Context.INITIAL_CONTEXT_FACTORY, \"org.jboss.naming.remote.client.InitialContextFactory\");\njndiProps.put(Context.PROVIDER_URL,\"http-remoting://localhost:8080\");\njndiProps.put(\"invocation.timeout\", 500);\ncontext = new InitialContext(jndiProps);\n\n\nThe \"invocation.timeout\" property has no effect, if it's set as an integer.\n"
            },
            "2": {
                "commit_sha_buggy": "7f62895ecf728e64a73d63d8038968e34f1246d9",
                "commit_sha_fixed": "5a931cbdbbe7eae09b7cb06a0b27c2eb133908c9",
                "report_id": "WFNC-56",
                "report_url": "https://issues.redhat.com/browse/WFNC-56",
                "issue_title": "WildFly Naming ClientWFNC-56Naming client - env property takes no effect when value is an Integer rather than String",
                "issue_description": "\n\nProperties jndiProps = new Properties();\njndiProps.put(Context.INITIAL_CONTEXT_FACTORY, \"org.jboss.naming.remote.client.InitialContextFactory\");\njndiProps.put(Context.PROVIDER_URL,\"http-remoting://localhost:8080\");\njndiProps.put(\"invocation.timeout\", 500);\ncontext = new InitialContext(jndiProps);\n\n\nThe \"invocation.timeout\" property has no effect, if it's set as an integer.\n"
            }
        }
    },
    "Dosgi_common": {
        "owner_repo": "apache/cxf-dosgi",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "43ec6113775c4293c3c72780899a21a38ee05e14",
                "commit_sha_fixed": "a3a97938043a250fcf1e3c76b861600e4a9ee83f",
                "report_id": "DOSGI-262",
                "report_url": "https://issues.apache.org/jira/browse/DOSGI-262",
                "issue_title": "[DOSGI-262] Configure intent objects from service object (IntentsProvider, @Features) - ASF JIRA",
                "issue_description": "\nCurrently all CXF configs have to be done using service based intents. While this matches RSA spec nicely it is a bit indirect and extensive to set up.\nSo for the special case where the intent should only work on a single service and only on the export we can make this simpler.\npublic interface IntentsProvider {\n    List<?> getIntents();\n}\nWith an interface like this we can add logging:\n@Component( ... )\npublic class TaskResourceImpl implements TaskResource, IntentsProvider {\n....\n    public List<?> getIntents() \n{\n        return asList(new LoggingFeature());\n    }\n\n}\n"
            },
            "2": {
                "commit_sha_buggy": "97873bb00d3fd3343351368d4a95f23992b2cee4",
                "commit_sha_fixed": "88b51ef4cbd45eabbf47b6e62a3b2eabd5080bc4",
                "report_id": "DOSGI-254",
                "report_url": "https://issues.apache.org/jira/browse/DOSGI-254",
                "issue_title": "[DOSGI-254] ServiceInvocationHandler does not handle checked super-interface exceptions correctly - ASF JIRA",
                "issue_description": "\nIf a remote service interface is composed of an interface hierarchy, the ServiceInvocationHandler (in org.apache.cxf.dosgi.dsw.handlers package on 1.7.0)  only handles correctly the checked exceptions of the interface the service directly implements/exports (the lowest level interface of the hierarchy). The checked exceptions of the superinterface methods are thrown as generic ServiceExceptions (which are RuntimeExceptions). \nFor example below, the IOException thrown by the throwBaseException method gets converted to ServiceException while the URISyntaxException thrown by the throwSubException method remains correctly as URISyntaxException. The service is exported as a TestSubInterface service.\n\n    public interface TestBaseInterface {\n        void throwBaseException() throws IOException;\n    }\n    \n    public interface TestSubInterface extends TestBaseInterface {\n        void throwSubException() throws URISyntaxException;\n    }\n\n    public class TestClass implements TestSubInterface {\n        @Override\n        public void throwBaseException() throws IOException {\n            throw new IOException(\"expected baseinterface exception\");\n        }\n\n        @Override\n        public void throwSubException() throws URISyntaxException {\n            throw new URISyntaxException(\"some input\", \"expected subinterface exception\");\n        }\n    }\n\n\nI have been using DOSGi 1.7.0 but I also checked version 2.0.0 and ServiceInvocationHandler (now in org.apache.cxf.dosgi.common.proxy package) seems the same as in previous releases.\nThe problem seems to be in ServiceInvocationHandler in the method\n\n    private void introspectType(Class<?> iType) {\n        for (Method m : iType.getDeclaredMethods()) {\n            for (Class<?> excType : m.getExceptionTypes()) {\n                if (Exception.class.isAssignableFrom(excType)) {\n                    List<Class<?>> types = exceptionsMap.get(m);\n                    if (types == null) {\n                        types = new ArrayList<Class<?>>();\n                        exceptionsMap.put(m, types);\n                    }\n                    types.add(excType);\n                }\n            }\n        }\n    }\n\n\nfor which the javadocs of  iType.getDeclaredMethods() say \"Returns an array of Method objects reflecting all the methods declared by the class or interface represented by this Class object. This includes public, protected, default (package) access, and private methods, but excludes inherited methods.\" \nThe introspectType method should be changed so that it also processes at least the public methods of the superinterfaces/classes. This can be achieved e.g. with iType.getMethods().\n"
            }
        }
    },
    "Fluo_api": {
        "owner_repo": "apache/fluo",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3340f5d3a909ae76f0c8309d3913b1639574811c",
                "commit_sha_fixed": "7d86080479b593684452d96eab574d59d2950c2a",
                "report_id": "218",
                "report_url": "https://github.com/apache/fluo/issues/218",
                "issue_title": "Stop accumulo classpath value from being shortened",
                "issue_description": "While working on #214, I discovered that the Accumulo classpath was being shortened when fluo.properties was used to create FluoConfiguration.  This is due to the properties file being loaded into a PropertiesConfiguration object that did not have `setDelimiterParsingDisable()` set to true.\n\nThis bug needs to be fixed for the alpha release as it causes iterators to not be loaded into Fluo when running on YARN.\n"
            },
            "3": {
                "commit_sha_buggy": "86248f67e3a631a567c18078c448c0f050e2294d",
                "commit_sha_fixed": "0a5876c8fa7e3aabde7790385fb87d6f6ca53523",
                "report_id": "323",
                "report_url": "https://github.com/apache/fluo/issues/323",
                "issue_title": "FluoOutputFormat is dropping zookeepers from config",
                "issue_description": "Trying to run the stress test on a 20 node aws cluster.  I have 3 zookeepers.  My config looks like the following\n\n```\nio.fluo.client.zookeeper.connect=ip-10-1-2-10,ip-10-1-2-11,ip-10-1-2-12/fluo\n```\n\nMappers fail w/ the following exception\n\n```\nCaused by: java.lang.IllegalStateException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /config/accumulo.instance.name\n    at io.fluo.core.impl.Environment.init(Environment.java:118)\n    at io.fluo.core.impl.Environment.<init>(Environment.java:95)\n    at io.fluo.core.client.FluoClientImpl.<init>(FluoClientImpl.java:53)\n    ... 15 more\n```\n\nIn the mapper log, I found the following.   So I think something is dropping everything after the 1st comma.\n\n```\n2014-11-12 20:39:25,294 INFO [main] org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=ip-10-1-2-10 sessionTimeout=30000 watcher=org.apache.curator.ConnectionState@60a46327\n```\n"
            }
        }
    },
    "Hivemall_core": {
        "owner_repo": "apache/incubator-hivemall",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bcae1534a2894d98746210ed20985c115a99678e",
                "commit_sha_fixed": "50867c178784bee74bbb0abcc8209266e7665764",
                "report_id": "HIVEMALL-72",
                "report_url": "https://issues.apache.org/jira/browse/HIVEMALL-72",
                "issue_title": "[HIVEMALL-72] Fix rescale UDF behavior to return range [0.0,1.0] - ASF JIRA",
                "issue_description": "\nrescale(value, min, max) should return min value when value is less than min.\nrescale(value, min, max) should return max value when value is greater than min.\no Current behavior\n\nselect rescale(4.2,1.0,3.0),rescale(-0.3, 1.0, 3.0);\n\n\n> 1.5999999\t-0.65\no Expected behavior\n\nselect rescale(4.2,1.0,3.0),rescale(-0.3, 1.0, 3.0);\n\n\n> 1.0 3.0\n"
            },
            "2": {
                "commit_sha_buggy": "912010305286f673cc7e8bcbdf1555be4a38921a",
                "commit_sha_fixed": "8ac3165db33a63cf3da9c2598b9051c26736cdd1",
                "report_id": "HIVEMALL-219",
                "report_url": "https://issues.apache.org/jira/browse/HIVEMALL-219",
                "issue_title": "[HIVEMALL-219] NullPointerException in pLSA model - ASF JIRA",
                "issue_description": "\n\u00a0\nI was not able to have pLSA model working on relatively small production workload (5000 docs) with number of reducers > 1.\nIt worked with 1000 documents in a single reducer.\n\u00a0\nI tried Tez or map-reduce engines:\nhive> create table docres as\n\u00a0\u00a0\u00a0 > with word_counts as (\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 select docid, feature(word, count(word)) as f\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 from docs t1 lateral view explode(tokenize(doc, true)) t2 as word\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 where not is_stopword(word)\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 group by docid, word\n\u00a0\u00a0\u00a0 > ),\n\u00a0\u00a0\u00a0 > input as (\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 select docid, collect_list(f) as features\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 from word_counts\n\u00a0\u00a0\u00a0 >\u00a0\u00a0 group by docid)\n\u00a0\u00a0\u00a0 > select\u00a0 train_plsa(features, '-topics 20 -iter 10 -s 500 -delta 1 -alpha 500 -eps 1') as (label, word, prob)\n\u00a0\u00a0\u00a0 > from\u00a0 input;\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Defaulting to jobconf value of: 4\nIn order to change the average load for a reducer (in bytes):\n\u00a0 set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n\u00a0 set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n\u00a0 set mapreduce.job.reduces=<number>\nKill Command = /usr/hdp/2.6.1.10-4/hadoop/bin/hadoop job\u00a0 -kill job_1536748924580_2024\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 4\n2018-09-17 19:05:38,300 Stage-1 map = 0%,\u00a0 reduce = 0%\n2018-09-17 19:05:52,225 Stage-1 map = 35%,\u00a0 reduce = 0%, Cumulative CPU 10.56 sec\n2018-09-17 19:05:55,428 Stage-1 map = 100%,\u00a0 reduce = 0%, Cumulative CPU 14.69 sec\n2018-09-17 19:06:01,903 Stage-1 map = 100%,\u00a0 reduce = 25%, Cumulative CPU 14.69 sec\n2018-09-17 19:06:02,963 Stage-1 map = 100%,\u00a0 reduce = 0%, Cumulative CPU 14.69 sec\n2018-09-17 19:06:09,433 Stage-1 map = 100%,\u00a0 reduce = 17%, Cumulative CPU 25.22 sec\n2018-09-17 19:06:12,803 Stage-1 map = 100%,\u00a0 reduce = 18%, Cumulative CPU 28.45 sec\n2018-09-17 19:06:24,672 Stage-1 map = 100%,\u00a0 reduce = 19%, Cumulative CPU 41.58 sec\n2018-09-17 19:06:36,482 Stage-1 map = 100%,\u00a0 reduce = 20%, Cumulative CPU 53.84 sec\n2018-09-17 19:07:16,082 Stage-1 map = 100%,\u00a0 reduce = 100%, Cumulative CPU 14.69 sec\nMapReduce Total cumulative CPU time: 14 seconds 690 msec\nEnded Job = job_1536748924580_2024 with errors\nError during job, obtaining debugging information...\nExamining task ID: task_1536748924580_2024_m_000000 (and more) from job job_1536748924580_2024\nExamining task ID: task_1536748924580_2024_r_000003 (and more) from job job_1536748924580_2024\nExamining task ID: task_1536748924580_2024_r_000001 (and more) from job job_1536748924580_2024\nTask with the most failures(10):\n\n\nDiagnostic Messages for this Task:\nError: java.lang.RuntimeException: Hive Runtime Error while closing operators: null\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:286)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:453)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:170)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.security.AccessController.doPrivileged(Native Method)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at javax.security.auth.Subject.doAs(Subject.java:422)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:164)\nCaused by: java.lang.NullPointerException\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at hivemall.topicmodel.ProbabilisticTopicModelBaseUDTF.finalizeTraining(ProbabilisticTopicModelBaseUDTF.java:277)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at hivemall.topicmodel.ProbabilisticTopicModelBaseUDTF.close(ProbabilisticTopicModelBaseUDTF.java:270)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.UDTFOperator.closeOp(UDTFOperator.java:145)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:620)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:634)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:634)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:634)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:634)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:278)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ... 7 more\n\u00a0\n\u00a0\n\u00a0\nJAR :hivemall-all-0.5.0-incubating.jar\n"
            },
            "3": {
                "commit_sha_buggy": "04fa7545b4e4b540a6a8c610c36450a8e2320ba7",
                "commit_sha_fixed": "e86815a5e88a161803a62c70ebbd00d5d688be2c",
                "report_id": "HIVEMALL-296",
                "report_url": "https://issues.apache.org/jira/browse/HIVEMALL-296",
                "issue_title": "[HIVEMALL-296] NPE happens in General classifier/regressor when the number of input records is zero - ASF JIRA",
                "issue_description": "\nThe following error happens when the number of input records is zero.\n\n\r\nCaused by: java.lang.NullPointerException\r\n\tat hivemall.GeneralLearnerBaseUDTF.forwardModel(GeneralLearnerBaseUDTF.java:763)\r\n\tat hivemall.GeneralLearnerBaseUDTF.close(GeneralLearnerBaseUDTF.java:560)\r\n\tat org.apache.hadoop.hive.ql.exec.UDTFOperator.closeOp(UDTFOperator.java:152)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:697)\r\n\tat org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:711)\r\n\tat org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:279)\r\n\n\n"
            }
        }
    },
    "Knox_assertion_common": {
        "owner_repo": "apache/knox",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3a394adb19573ecff255b1b8858f4586e2d88457",
                "commit_sha_fixed": "b4fea509fde4d292893bd98043f1efc5231d0103",
                "report_id": "KNOX-790",
                "report_url": "https://issues.apache.org/jira/browse/KNOX-790",
                "issue_title": "[KNOX-790] URL parameters with empty/null value are ignored - ASF JIRA",
                "issue_description": "\nFrom the logs - \n2016-11-19 01:18:42,973 DEBUG hadoop.gateway (UrlRewriteProcessor.java:rewrite(164)) - Rewrote URL: https://localhost:8443/gateway/sandbox/druid-coordinator/druid/coordinator/v1/servers?simple, direction: IN via implicit rule: DRUID-COORDINATOR/druid-coordinator/inbound/api to URL: http://nbangarw-druid-1:8081/druid/coordinator/v1/servers?simple\n2016-11-19 01:18:42,979 DEBUG hadoop.gateway (DefaultDispatch.java:executeOutboundRequest(120)) - Dispatch request: GET http://nbangarw-druid-1:8081/druid/coordinator/v1/servers?user.name=guest\nNote the final request Dispatched to does not have the parameter simple. \n"
            }
        }
    },
    "Oozie_client": {
        "owner_repo": "apache/oozie",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b42ea8eea7e64a5d9c0ae7a028a59bd58f949475",
                "commit_sha_fixed": "f5d4dfe21280ddbbb6cd79579bf7ec2e43c08223",
                "report_id": "OOZIE-785",
                "report_url": "https://issues.apache.org/jira/browse/OOZIE-785",
                "issue_title": "[OOZIE-785] No JsonToBean mapping for coord pausetime - ASF JIRA",
                "issue_description": "\nThere is no json to bean mapping in JsonToBean.java for coord pause time\n"
            },
            "2": {
                "commit_sha_buggy": "4927f857d9be8ca5709ca0c7bd260bd34ec6e6d7",
                "commit_sha_fixed": "41a5a31aba4f303efb3fe9c5e2d0ad0dd6bd2c52",
                "report_id": "OOZIE-1482",
                "report_url": "https://issues.apache.org/jira/browse/OOZIE-1482",
                "issue_title": "[OOZIE-1482] 4.0 client does not work with 3.x server for coord jobs - ASF JIRA",
                "issue_description": "\njava.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.String\n\tat com.sun.proxy.$Proxy0.getFrequency(Unknown Source)\n\tat org.apache.oozie.cli.OozieCLI.printCoordJobs(OozieCLI.java:1266)\n\tat org.apache.oozie.cli.OozieCLI.jobsCommand(OozieCLI.java:1220)\n\tat org.apache.oozie.cli.OozieCLI.processCommand(OozieCLI.java:517)\nOOZIE-1408 changed type of frequency to String from int.\n"
            }
        }
    },
    "Qpidjms_client": {
        "owner_repo": "apache/qpid-jms-amqp-0-x",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "472aea78d0ca77144000aacdd932ebb4a8fed192",
                "commit_sha_fixed": "8774a1c38d596e17683aac1a285ec437d82c7767",
                "report_id": "QPID-7897",
                "report_url": "https://issues.apache.org/jira/browse/QPID-7897",
                "issue_title": "[QPID-7897] [Java 0-8...0-9-1 Client] Message#getJMSCorrelationIDAsBytes() erroneously first converts to string before retreiving bytes  - ASF JIRA",
                "issue_description": "\nIf the correlationId of a message does not contain valid UTF_8 (e.g., set via javax.jms.Message#setJMSCorrelationIDAsBytes) then javax.jms.Message#getJMSCorrelationIDAsBytes does not return the correct value.\nSome relevant code snippets:AMQMessageDelegate_0_8#getJMSCorrelationIDAsBytes is implemented as follows:\nAMQMessageDelegate_0_8.java\npublic byte[] getJMSCorrelationIDAsBytes() throws JMSException\n{\n    return getContentHeaderProperties().getCorrelationIdAsString().getBytes();\n}\n\nBasicContentHeaderProperties\npublic String getCorrelationIdAsString()\n{\n    return (_correlationId == null) ? null : _correlationId.toString();\n}\n\nAMQShortString\npublic String toString()\n{\n    if (_asString == null)\n    {\n        _asString = new String(_data, _offset, _length, StandardCharsets.UTF_8);\n    }\n    return _asString;\n}\n\nIf _data does not contain valid UTF_8 the result of this call chain is incorrect.\nI do not see a reason why AMQMessageDelegate_0_8#getJMSCorrelationIDAsBytes should not return getContentHeaderProperties().getCorrelationId().getBytes() instead.\n"
            },
            "2": {
                "commit_sha_buggy": "78cf85c60fbedddfc08f978262aaa23061cae2b4",
                "commit_sha_fixed": "97347f0fb0e0782398bd16a7ba2d318bbb759bd1",
                "report_id": "QPID-8135",
                "report_url": "https://issues.apache.org/jira/browse/QPID-8135",
                "issue_title": "[QPID-8135] [JMS AMQP 0-x] Connection URL options for end-to-end encryption keystore/trustore passwords can be logged when log level for 'org.apache.qpid' loggers is lower than 'warn' - ASF JIRA",
                "issue_description": "\nThe connection URL password options can be logged when log level for 'org.apache.qpid' loggers is lower than 'warn'.\nThe following cases are identified when password is logged\n\nwhen encryption keystore/trustore parameters are declared as part of broker URL , 'org.apache.qpid' loggers log level is set to ''info' or lower threshold and connectivity is not established, the encryption_key_store_password or encryption_trust_store_password can be logged with info log level as below\n\n2018-03-16 12:56:02,196 INFO  [main] o.a.q.c.AMQConnection Unable to connect to broker at tcp://localhost:5672?encryption_trust_store='/path/to/trustore.jks'&encryption_trust_store_password='password'\r\norg.apache.qpid.transport.TransportException: Error connecting to broker\r\n\tat org.apache.qpid.transport.network.io.IoNetworkTransport.connectTcp(IoNetworkTransport.java:151)\r\n...\r\n2018-03-16 12:56:02,196 INFO  [main] o.a.q.j.f.FailoverRoundRobinServers ==== Checking failoverAllowed() ====\r\n2018-03-16 12:56:02,197 INFO  [main] o.a.q.j.f.FailoverRoundRobinServers Cycle Servers:\r\nCycle Retries:20\r\nCurrent Cycle:20\r\nServer Retries:0\r\nCurrent Retry:0\r\nCurrent Broker:0\r\n>tcp://localhost:5672?encryption_trust_store='/path/to/trsutsore.jks'&encryption_trust_store_password='password'\r\n\n\nwhen encryption keystore/trustore parameters  or/and SSL trust store  parameters or/and SSL client-auth parameters are declared as part of connection URL and 'org.apache.qpid' loggers log level is set to 'debug' or lower threshold, the password options can be logged with DEBUG log level as below:\n\n2018-03-16 13:03:20,879 DEBUG [main] o.a.q.c.AMQConnection Connection(1):amqp://admin:********@consumer/?encryption_trust_store='/path/to/keystore.jks'&trust_store='/path/to/trsustore.ts'&key_store_password='secret'&encryption_trust_store_password='password'&key_store='/path/to/keystore.ks'&trust_store_password='secret'&brokerlist='tcp://localhost:5672'&failover='roundrobin?cyclecount='20''\r\n\n\n\nThe work around for the issue would be to set debug log level to warn at least for the following loggers:\n\norg.apache.qpid.client.AMQConnection\norg.apache.qpid.jms.failover.FailoverRoundRobinServers\n\n"
            },
            "3": {
                "commit_sha_buggy": "5b87b511c8b6d02fe50544ed33c2a152c34ebc22",
                "commit_sha_fixed": "e3a88f02b5c099fe4b21bec1790cae7731795810",
                "report_id": "QPID-8283",
                "report_url": "https://issues.apache.org/jira/browse/QPID-8283",
                "issue_title": "[QPID-8283] [JMS AMQP 0-x] Connection option 'encryption_trust_store_password' is mistakenly used to set encryption keystore password rather than encryption trust store password as intendant  - ASF JIRA",
                "issue_description": "\nConnection option encryption_trust_store_password is mistakenly used to set encryption keystore password rather than encryption trust store password as intendant.\nHere is problematic code in BrokerDetails:\n\n\r\n        if (getProperty(BrokerDetails.OPTIONS_ENCRYPTION_TRUST_STORE_PASSWORD) != null)\r\n        {\r\n            conSettings.setEncryptionKeyStorePassword(\r\n                    getProperty(BrokerDetails.OPTIONS_ENCRYPTION_TRUST_STORE_PASSWORD));\r\n        }\r\n\r\n\n\nMethod conSettings.setEncryptionTrustStorePassword should be invoked instead. \nThe workaround for this issue is to set trust store password using JVM property javax.net.ssl.trustStorePassword.\n"
            }
        }
    },
    "Rdf4j_query": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5c8373aa4ac7ec7ce4c4e96fe080c433d01ab693",
                "commit_sha_fixed": "0bf78791e4bb59ee52b3c11706262bdab576e973",
                "report_id": "676",
                "report_url": "https://github.com/eclipse/rdf4j/issues/676",
                "issue_title": "Regression in hashCode vs equals for AbstractBindingSet",
                "issue_description": "In 2.0.2 hashCode() and equals() were consistent for AbstractBindingSet (and thus all of its descendants) but in 2.0.3 hashCode() suddenly began to be sensitive to the order bindings are added, while equals() stayed agnostic to the order. As this is a Set I believe both hashCode() and equals() shouldn't care about the order and it's a good idea to keep them consistent either way.\r\n\r\nThis change was introduced by https://github.com/eclipse/rdf4j/pull/650. "
            },
            "2": {
                "commit_sha_buggy": "1606411178f724db76b84da8d1e37583f67ef6dd",
                "commit_sha_fixed": "e3ebbdd888b4711804415b1665ddf9c0685c3c22",
                "report_id": "677",
                "report_url": "https://github.com/eclipse/rdf4j/pull/677",
                "issue_title": "Fix #676: revert changes to hashcode of AbstractBindingSet",
                "issue_description": "This PR addresses GitHub issue: #676 .\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\n* reverted changed hashcode impl back to be API-conformant \r\n* add regression tests for all BindingSet implementations \r\n\r\n"
            },
            "3": {
                "commit_sha_buggy": "7a6abb9966da1288c3c926d77aceb53ec5de509a",
                "commit_sha_fixed": "246a35b84fc04405b029afb3ead2843be5aaa468",
                "report_id": "216",
                "report_url": "https://github.com/eclipse/rdf4j/issues/216",
                "issue_title": "Re-Include ManifestTest and testcases-dawg",
                "issue_description": "This set of testcases was in the 4.0/master branch of sesame in sparql-testsuite but have now gone from rdf4j.\n"
            },
            "4": {
                "commit_sha_buggy": "2e730c6258922b9369d448490b2cea4482b25c44",
                "commit_sha_fixed": "189aa8c5fb00331da91b430a137b0ff7f17715eb",
                "report_id": "677",
                "report_url": "https://github.com/eclipse/rdf4j/pull/677",
                "issue_title": "Fix #676: revert changes to hashcode of AbstractBindingSet",
                "issue_description": "This PR addresses GitHub issue: #676 .\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\n* reverted changed hashcode impl back to be API-conformant \r\n* add regression tests for all BindingSet implementations \r\n\r\n"
            }
        }
    },
    "Rdf4j_rio_api": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ef1ab8521ef8b3c35b787740b8b3eaabf3e547e2",
                "commit_sha_fixed": "59eb4120c373224391c6e6511a1201e6050a14f9",
                "report_id": "2039",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2039",
                "issue_title": "GH-2004: handling of RDF:langString without language tag",
                "issue_description": "Signed-off-by: Mirr99 <mihir17166@iiitd.ac.in>\r\n\r\nGitHub issue resolved: #2004\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\n* Handles rdf:langStrings which do not have a language tag defined through changes in `createLiteral` function in RDFParserHelper.java\r\n* Added test case in `org.eclipse.rdf4j.rio.AbstractParserHandlingTest`\r\n* Added function `protected InputStream getNoLanguageWithRDFLangStream` and overwrote it in the required java files.\r\n* Added files in testcases subdir in the resource folder of the concerned test folder.\r\n* Modified existing test case in `RDFParserHelperTest` and added a new test case. The two test cases check the functioning of `createLiteral` function when `VERIFY_DATATYPE_VALUES` is set to `true` and when it is set to `false`."
            },
            "2": {
                "commit_sha_buggy": "176616a83721655a13ee314b328d221c0bc71e9e",
                "commit_sha_fixed": "caf4e4682e5707a9870333d8ad3e2d548f89018c",
                "report_id": "2042",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2042",
                "issue_title": "Merge master into develop",
                "issue_description": "Automatically generated PR to keep develop in sync with master. See .github/workflows/merge_master_to_develop.yml"
            }
        }
    },
    "Rdf4j_rio_jsonld": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "caf4e4682e5707a9870333d8ad3e2d548f89018c",
                "commit_sha_fixed": "3ada7e68cfafc5a28461dd72b88353469ca1bc8e",
                "report_id": "1920",
                "report_url": "https://github.com/eclipse/rdf4j/pull/1920",
                "issue_title": "GH-1484 rdfstar and sparqlstar support",
                "issue_description": "GitHub issue resolved: #1484  <!-- add a Github issue number here, e.g #123. This line \r\n                              automatically closes the issue when the PR is merged --> \r\n\r\nOver-arching feature branch for RDF* and SPARQL* support.\r\n\r\nTo do:\r\n\r\n- [x] RDF* parsers/writers for Turtle* and TriG*\r\n- [x] model support\r\n- [x] conversion utilities between Triple and RDF reification\r\n- [x] update SPARQL parser (may split this out)\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "26b5bcbb60dd7918cb923914a2839039ebe52d45",
                "commit_sha_fixed": "beb82f906a305a8244d528e0fdaaf7bc09c0627c",
                "report_id": "2674",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2674",
                "issue_title": "Merge master develop",
                "issue_description": "resolving merge conflict.\r\n\r\n----\r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [ ] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [ ] I've added tests for the changes I made\r\n - [ ] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [ ] I've [squashed](https://rdf4j.org/documentation/developer/squashing) my commits down to one or a few meaningful commits\r\n - [ ] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [ ] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\n"
            }
        }
    },
    "Rdf4j_rio_rdfjson": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "caf4e4682e5707a9870333d8ad3e2d548f89018c",
                "commit_sha_fixed": "3ada7e68cfafc5a28461dd72b88353469ca1bc8e",
                "report_id": "1920",
                "report_url": "https://github.com/eclipse/rdf4j/pull/1920",
                "issue_title": "GH-1484 rdfstar and sparqlstar support",
                "issue_description": "GitHub issue resolved: #1484  <!-- add a Github issue number here, e.g #123. This line \r\n                              automatically closes the issue when the PR is merged --> \r\n\r\nOver-arching feature branch for RDF* and SPARQL* support.\r\n\r\nTo do:\r\n\r\n- [x] RDF* parsers/writers for Turtle* and TriG*\r\n- [x] model support\r\n- [x] conversion utilities between Triple and RDF reification\r\n- [x] update SPARQL parser (may split this out)\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "d406b1f43a87584cd207b8f0dbf9bcf0382065e6",
                "commit_sha_fixed": "0ead5cdb3c53eebfece9431b79226e02362115a6",
                "report_id": "2194",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2194",
                "issue_title": "Prep release 3.2: merge develop to master",
                "issue_description": ""
            }
        }
    },
    "Rdf4j_rio_rdfxml": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3f9056a9ab1026a4e911ceb7f978d111f539280b",
                "commit_sha_fixed": "686d3350aa8749e01590b2f77473d62785676eb1",
                "report_id": "222",
                "report_url": "https://github.com/eclipse/rdf4j/pull/222",
                "issue_title": "Fixed whitespace handling in rdf/xml.",
                "issue_description": "This PR addresses GitHub issue: #213 \n\nBriefly describe the changes proposed in this PR:\n- ...\n- ...\n- ...\n\nMake sure you've followed the [Contributor Guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md). In particular (please tick to indicate you've taken care of it):\n- [x] RDF4J code formatting has been applied\n- [x] tests are included\n- [x] all tests succeed\n\nSigned-off-by: Mark Hale mark.hale@physics.org\n"
            }
        }
    },
    "Rdf4j_rio_turtle": {
        "owner_repo": "eclipse/rdf4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f427fdbc2ebb1125d96f0913e6d3586603313d72",
                "commit_sha_fixed": "cc9077e5b32619e7882d7c4f6f736e95b44c0c6a",
                "report_id": "264",
                "report_url": "https://github.com/eclipse/rdf4j/issues/264",
                "issue_title": "TurtleParser does not report line numbers / location in file",
                "issue_description": "The class `org.eclipse.rdf4j.rio.turtle.TurtleParser` does not report location info while parsing. Only during start of parsing (line number 1) and after processing a comment (e.g. line that starts with '#').\n\nInstead of during processing comments, the `reportLocation()` method should be called after incrementing the line number  in the method `skipWSC()`.\n\nI also suggest changing the visibility of the method `getLineNumber()` to protected (instead of private). This would allow subclasses to access line number information directly, instead of relying on reportLocation to do the job.\n"
            },
            "2": {
                "commit_sha_buggy": "c1ada486c7e2efec118f07aea6eec122902b92ba",
                "commit_sha_fixed": "d5fa7185243c8c3661a04a44cb90e8f2c5ecca95",
                "report_id": "265",
                "report_url": "https://github.com/eclipse/rdf4j/pull/265",
                "issue_title": "Issues/#264 turtle line numbers",
                "issue_description": "This PR addresses GitHub issue: #264\n\nBriefly describe the changes proposed in this PR:\n- TurtleParser does not report when lines tick over to the location listener\n- TurtleParser does not increment line numbers for lines with comments\n- TurtleParser does not allow subclasses, of which we have two internally and external users have more, to get the lineNumber information without using reportLocation that is fairly roundabout\n\nMake sure you've followed the [Contributor Guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md). In particular (please tick to indicate you've taken care of it):\n- [x] RDF4J code formatting has been applied\n- [x] tests are included\n- [x] all tests succeed\n"
            },
            "3": {
                "commit_sha_buggy": "e2190d8a7660cbf57ff81f9e6ed03556b5693925",
                "commit_sha_fixed": "46b83ed38d0a66fa298c3ea245b255f25b0eebaf",
                "report_id": "1886",
                "report_url": "https://github.com/eclipse/rdf4j/pull/1886",
                "issue_title": "GH-1883 unhandled namespaces of statement subjects for TurtleWriter",
                "issue_description": "GitHub issue resolved: #1883\r\n\r\nThis change amends the pretty-printer of the TurtleWriter to take the namespaces of subjects of statements into account."
            },
            "4": {
                "commit_sha_buggy": "032da3107ffb10ba8cdc1674170e1c09872c307b",
                "commit_sha_fixed": "c59447ae783494e89c0a3bfc9b53bdcb1028e6e3",
                "report_id": "2316",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2316",
                "issue_title": "GH-2315 bugfix: some complex unicode characters fail to unread properly",
                "issue_description": "e.g. this character:\r\nhttps://www.compart.com/en/unicode/U+1109D\r\n\r\nthe following string fail to unread:\r\n```\r\n\"<r:\\uD804\\uDC9D>\"\r\n```\r\nsince same position is loaded more than once into reader's buf.\r\n\r\n\r\nGitHub issue resolved: #2315\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\nunread index is decremented properly to ensure proper unread\r\n\r\n---- \r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [x] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [x] I've added tests for the changes I made\r\n - [x] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [x] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [x] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\nNote: we merge all feature pull requests using [squash and merge](https://help.github.com/en/github/administering-a-repository/about-merge-methods-on-github#squashing-your-merge-commits). See [RDF4J git merge strategy](https://rdf4j.org/documentation/developer/merge-strategy/) for more details.\r\n\r\n"
            },
            "6": {
                "commit_sha_buggy": "663e59d7fc5c6277fb98a5dd6bde05e1c8902b12",
                "commit_sha_fixed": "381a45952f42eaba3fcc7f58d8f4eeae2b97bfa8",
                "report_id": "2339",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2339",
                "issue_title": "GH-2338 Increased TurtleParser pushback reader buffer to 10",
                "issue_description": "Signed-off-by: Elad Shaked <elad.shaked@sparkbeyond.com>\r\n\r\n\r\nGitHub issue resolved: #2338\r\n\r\nBriefly describe the changes proposed in this PR:\r\nTurtleParser pops chars until the StringBuilder has 8 or more chars. It may be the case that Unicode surrogates cause 9 chars to be read (say 7 normal chars followed by a surrogate pair). When trying to pushback those chars into buffer of size 8 causes an overflow.\r\n\r\nIncrease PushbackReader buffer size to 10 (could have done with 9)\r\n---- \r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [x] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [x] I've added tests for the changes I made\r\n - [x] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [x] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [x] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\nNote: we merge all feature pull requests using [squash and merge](https://help.github.com/en/github/administering-a-repository/about-merge-methods-on-github#squashing-your-merge-commits). See [RDF4J git merge strategy](https://rdf4j.org/documentation/developer/merge-strategy/) for more details.\r\n\r\n"
            },
            "8": {
                "commit_sha_buggy": "7d68d6ad0f10d5ead60606c515b76f41f8b30ff7",
                "commit_sha_fixed": "bb42955c0564492de043a75ad50cfe4c022faa2b",
                "report_id": "2531",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2531",
                "issue_title": "GH-2511 allow regular Turtle parser to process RDF*",
                "issue_description": "\r\n\r\nGitHub issue resolved: #2511 <!-- add a Github issue number here, e.g #123. -->\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\n- regular turtle parser accepts Turtle* (to handle cases where endpoints send it on the normal Turtle MIME-type)\r\n- can be configured to _not_ accept RDF* data when needed (e.g. for validation)\r\n\r\n\r\n---- \r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [x] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [x] I've added tests for the changes I made\r\n - [x] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [x] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [x] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\nNote: we merge all feature pull requests using [squash and merge](https://help.github.com/en/github/administering-a-repository/about-merge-methods-on-github#squashing-your-merge-commits). See [RDF4J git merge strategy](https://rdf4j.org/documentation/developer/merge-strategy/) for more details.\r\n\r\n"
            },
            "9": {
                "commit_sha_buggy": "08944557b0971c6735b6fe41278304adfb1139e7",
                "commit_sha_fixed": "c0f31a46b152803182b3aa4688abe65a3236aeca",
                "report_id": "2901",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2901",
                "issue_title": "GH-2886 added abbreviate number setting for pretty print turtlewriter",
                "issue_description": "GitHub issue resolved: #2886 <!-- add a Github issue number here, e.g #123. -->\r\n\r\nBriefly describe the changes proposed in this PR:\r\n - Added TurtleWriter Rio setting for abbreviating numeric values\r\n - Added tests\r\n - Minor cleanup\r\n\r\n----\r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [x] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [x] I've added tests for the changes I made\r\n - [x] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [x] I've [squashed](https://rdf4j.org/documentation/developer/squashing) my commits down to one or a few meaningful commits\r\n - [x] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [x] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\n"
            },
            "10": {
                "commit_sha_buggy": "2549f873716cf07eb4e8ce597046a8cf3314b55c",
                "commit_sha_fixed": "8c9220cbba15a2fc992901e06b64ab2e8664df6f",
                "report_id": "2934",
                "report_url": "https://github.com/eclipse/rdf4j/pull/2934",
                "issue_title": "GH-2932 blank node inlining with circular references",
                "issue_description": "GitHub issue resolved: #2932 <!-- add a Github issue number here, e.g #123. -->\r\n\r\nBriefly describe the changes proposed in this PR:\r\n\r\n<!-- short description of your change goes here -->\r\n\r\n----\r\nPR Author Checklist (see the [contributor guidelines](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md) for more details):\r\n\r\n - [ ] my pull request is [self-contained](https://rdf4j.org/documentation/developer/merge-strategy/#self-contained-changes-pull-requests-and-commits)\r\n - [ ] I've added tests for the changes I made\r\n - [ ] I've applied [code formatting](https://github.com/eclipse/rdf4j/blob/master/.github/CONTRIBUTING.md#code-formatting) (you can use `mvn process-resources` to format from the command line)\r\n - [ ] I've [squashed](https://rdf4j.org/documentation/developer/squashing) my commits down to one or a few meaningful commits\r\n - [ ] every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\r\n - [ ] every commit has been [signed off](https://stackoverflow.com/questions/1962094/what-is-the-sign-off-feature-in-git-for)\r\n\r\n"
            }
        }
    },
    "Sentry_ccommon": {
        "owner_repo": "apache/sentry",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "598b203c8cf91897a970ad086461f4c75897c74c",
                "commit_sha_fixed": "a001d43992eab3d543927580da1f7533a3279897",
                "report_id": "SENTRY-2039",
                "report_url": "https://issues.apache.org/jira/browse/SENTRY-2039",
                "issue_title": "[SENTRY-2039] KeyValue is case sensitive and it causes incompatibility issues with external components - ASF JIRA",
                "issue_description": "\nA refactor done on SENTRY-999 changed the way KeyValue.equals() checks for equality. It used to be case insensitive and now it is case sensitive. This may cause issues (like hbase indexer) when policies are written with case insensitive.\n"
            },
            "2": {
                "commit_sha_buggy": "5fc1e97790936ff0002fbebc156fccd06b4a9014",
                "commit_sha_fixed": "9c541adf15194c44800555f0fb161463df68feac",
                "report_id": "SENTRY-2032",
                "report_url": "https://issues.apache.org/jira/browse/SENTRY-2032",
                "issue_title": "[SENTRY-2032] Leading Slashes need to removed when creating HMS path entries - ASF JIRA",
                "issue_description": "\nWhen retrieving full path image update, we split a path by \"/\" and create HMS Path entries. However, the leading \"/\" presence will cause issues because on splitting the value at index 0 will be empty. This will affect the creation of HMS path entries. \n"
            }
        }
    },
    "Sling_apiregions": {
        "owner_repo": "apache/sling-org-apache-sling-feature-extension-apiregions",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1f4edc77457e99af348d8e025920675f8e752752",
                "commit_sha_fixed": "d05abdcc2c881f9d2dd8a4ad402d28ac508f3b17",
                "report_id": "SLING-9954",
                "report_url": "https://issues.apache.org/jira/browse/SLING-9954",
                "issue_title": "[SLING-9954] Validation errors not reported by analyser - ASF JIRA",
                "issue_description": "\nValidation errors in configuration properties are not correctly reported as errors but warnings\n"
            },
            "2": {
                "commit_sha_buggy": "7ab7d0b13db436991d993b7f777606ff1de1eaa8",
                "commit_sha_fixed": "9c8b36d23a8974105610564db3bceb54b1d7b914",
                "report_id": "SLING-10565",
                "report_url": "https://issues.apache.org/jira/browse/SLING-10565",
                "issue_title": "[SLING-10565] Additional properties are not validated according to the validation mode - ASF JIRA",
                "issue_description": "\nWhen a configuration is having additional (internal) properties, this currently always results in a validation error regardless of the validation mode\n"
            },
            "3": {
                "commit_sha_buggy": "17c6b50cbe28b1bdff6a1334c84838a31b96635d",
                "commit_sha_fixed": "66a745b5e4385fb74d6999a9eabae4d1d32195e5",
                "report_id": "SLING-10575",
                "report_url": "https://issues.apache.org/jira/browse/SLING-10575",
                "issue_title": "[SLING-10575] Bundles without feature-origin result in empty bundle to feature mapping - ASF JIRA",
                "issue_description": "\nWhen installing a feature archive of a feature similar to the following\n\n\r\n{\r\n  \"id\":\"com.exmaple:my-feature-pkg:slingosgifeature:tiera:12345-SNAPSHOT\",\r\n  \"bundles\":[\r\n    {\r\n      \"id\":\"com.example:my-bundle:1.2.3-SNAPSHOT\",\r\n      \"start-order\":\"20\"\r\n    }\r\n  ],\r\n  \"api-regions:JSON|false\":[\r\n    {\r\n      \"name\":\"global\",\r\n      \"exports\":[\r\n        \"com.example.my\"\r\n      ]\r\n    }\r\n  ]\r\n} \n\nA bundle to feature mapping like \n\n\r\ncom.example:my-bundle:1.2.3-SNAPSHOT=\r\n\n\nwill be created in the feature's org.apache.sling.feature.apiregions.factory configuration. This is because the bundle does not specify any feature-origin(s).\nFor those cases the feature it self should be the origin of the bundle. The current version of the api regions runtime will otherwise not find the feature a bundle belongs to and so may not be able to resolve the api regions the bundle belongs to. \nAn example where that can happen is the usage of the slingfeature-maven-plugin without using the aggregation feature. When just building far from a hand-crafted feature model the feature-origin may not be set on the api-region(s).\n"
            }
        }
    },
    "Sling_cpconverter": {
        "owner_repo": "apache/sling-org-apache-sling-feature-cpconverter",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bed04b3c4995c109903c6b97134c6184ed6f1789",
                "commit_sha_fixed": "b85d162afa7e62adc52d2e56e387f437b14b769d",
                "report_id": "SLING-8381",
                "report_url": "https://issues.apache.org/jira/browse/SLING-8381",
                "issue_title": "[SLING-8381] Converter produces broken hull subpackages - ASF JIRA",
                "issue_description": "\nThe contentpackage to feature converter flattens out content packages but the empty subpackages being produced to satisfy the inner dependencies are currently invalid and miss out the jcr_root structure and also still have the old filters which might create trouble on wiping out content when being installed - to mitigate either the filters need to be  adjusted or set to merge mode.\nSuggestion:\nbuild a default filter (root path) on mode merge with exclude on everything below (to avoid creation of huge snapshot packages when being manually installed) that would be reused for all  hull packages) and add the missing jcr_content folder.\n"
            },
            "2": {
                "commit_sha_buggy": "c06dd911b0449bc71e90f42b96b06e76c19ef44f",
                "commit_sha_fixed": "16eed311862fb5df9eed1daaf367e0f8c5c6120c",
                "report_id": "SLING-8384",
                "report_url": "https://issues.apache.org/jira/browse/SLING-8384",
                "issue_title": "[SLING-8384] Convertion of configs might miss out properties - ASF JIRA",
                "issue_description": "\nThe content-package to featuremodel converter seems to miss out some properties (conditions yet not fully clear). It looks like escaped characters can cause properties to be missed from the resulting feature model.\n"
            },
            "3": {
                "commit_sha_buggy": "4c64dee451bee0b03aa00283a52ac07e1f2236d5",
                "commit_sha_fixed": "812794edee8f406b036449b4d901f08f175903e8",
                "report_id": "SLING-8527",
                "report_url": "https://issues.apache.org/jira/browse/SLING-8527",
                "issue_title": "[SLING-8527] Glob restrictions for content-package formatted wrong - ASF JIRA",
                "issue_description": "\nA defined rep:glob on an acl is currently converted in something like this:\n\"allow jcr:all on /home restriction(/xyz/)\",\nwhile the result should be\n\"allow jcr:all on /home restriction(rep:glob,/xyz/)\",\nThis renders the generated repoinit section unparsable. The current logic should be revised to make sure the generated repoinit statements really represent and generate what was defined in the package.\n"
            }
        }
    },
    "Tiles_api": {
        "owner_repo": "apache/tiles",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7fbeaabb91693456a41ec2a47f97c7282e3e0627",
                "commit_sha_fixed": "3a03bfd44c322113360298431fbd9a25900a6350",
                "report_id": "TILES-437",
                "report_url": "https://issues.apache.org/jira/browse/TILES-437",
                "issue_title": "[TILES-437] Definition.toString may throw a NPE - ASF JIRA",
                "issue_description": "\nThe Definition.toString method may throw a NullPointerException in case the templateAttribute property is null.\n"
            },
            "2": {
                "commit_sha_buggy": "b95208f046edd266d0883213d0389476b7e54b66",
                "commit_sha_fixed": "ec4bf8960a122eb92c1664f0d630ab89079b4aed",
                "report_id": "TILES-483",
                "report_url": "https://issues.apache.org/jira/browse/TILES-483",
                "issue_title": "[TILES-483] BasicAttributeContext.addMissing does not work well with cascaded attributes - ASF JIRA",
                "issue_description": "\nIn presence of cascaded attributes, the method BasicAttributeContext does not put the missing attributes in the correct order.\n"
            }
        }
    },
    "Tiles_core": {
        "owner_repo": "apache/tiles",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bd0d2d9a21bfae333a8fceff4c18cad4f5ac38fd",
                "commit_sha_fixed": "764404322620cda1b0a996965e8232467da6389a",
                "report_id": "TILES-322",
                "report_url": "https://issues.apache.org/jira/browse/TILES-322",
                "issue_title": "[TILES-322] Type renderers list is not split correctly - ASF JIRA",
                "issue_description": "\nThe type renderers list is not split correctly: there is the need of a space between each pair of renderers.\n"
            },
            "2": {
                "commit_sha_buggy": "1d34986318a0c7284398de5f1f53d7abdc22c333",
                "commit_sha_fixed": "149cb7b2a7a0fb3f28851249c2831ff548072ed1",
                "report_id": "TILES-512",
                "report_url": "https://issues.apache.org/jira/browse/TILES-512",
                "issue_title": "[TILES-512] Definition \"templateType\" attribute not propagated to extending definition - ASF JIRA",
                "issue_description": "\nIf I have a template definition with a custom \"templateType\" attribute, child definitions that extend that definition do not pick up the custom templateType attribute value.  They get the default \"template\" value.  For example:\n<definition name=\"parent\" template=\"mytemplate.vm\" templateType=\"custom\"/>\n<definition name=\"child\" extends=\"parent\"/>\n"
            },
            "3": {
                "commit_sha_buggy": "109bc00ab6bf345de6108782500b72f707f03f31",
                "commit_sha_fixed": "951d6a227dd4caaf402ab4ec11fbfda7db1dbcb4",
                "report_id": "TILES-574",
                "report_url": "https://issues.apache.org/jira/browse/TILES-574",
                "issue_title": "[TILES-574] Tiles expressions do not work after wildcard - ASF JIRA",
                "issue_description": "\nUsing tiles 3.0.1 w. Spring 3.2.4 I am trying to use an multiple expressions that include a wildcard:\n\n<definition name=\"*.container\" extends=\"base.container.layout\">\n\t<put-list-attribute name=\"commonContainerScripts\" cascade=\"true\">\n\t\t<add-attribute expression=\"resources/${buildVersion}/scripts{1}/startup${minType}.js\" />\n\t</put-list-attribute>\n</definition>\n\n\nthe first variable buildVersion resolves correctly. {1} also resolves correctly, however if minType appears after {1}, minType resolves to buildVersion.  If I move minType in my expression to before {1}, then it resolves properly.\n"
            }
        }
    },
    "Twill_dcore": {
        "owner_repo": "apache/twill",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0208a84330154f8bd7c1630b1a5dd18207b5351f",
                "commit_sha_fixed": "fc265f1a2dcd7fe2af3f92ad4294446e6f744436",
                "report_id": "TWILL-75",
                "report_url": "https://issues.apache.org/jira/browse/TWILL-75",
                "issue_title": "[TWILL-75] Race condition in InMemoryDiscoveryService - ASF JIRA",
                "issue_description": "\nWhen new service is registering with the InMemoryDiscoveryService when some client is trying to discovery by iterating the ServiceDiscovered, concurrent modification exception raised sometime.\n"
            }
        }
    },
    "Maven2_artifact": {
        "owner_repo": "apache/maven-2",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "22000809c3190f69fa56593d1111be30d478cb30",
                "commit_sha_fixed": "d8875a4f7d3c4a56fb81a4668775a3becb3d5c75",
                "report_id": "MNG-818",
                "report_url": "https://issues.apache.org/jira/browse/MNG-818",
                "issue_title": "[MNG-818] Ability to disable transitive dependency in a bundle artifact - ASF JIRA",
                "issue_description": "\nThere are 2 use cases:\n\nnative-plugin can combine it built .o files with additional libraries on dependency list to produce a big bundle.  However other native pom\n      using bundle artifact will fail at link time ( linker not happy about duplicate referenes)\n\n\nI will have custom mojo to combine a bunch of jars on my dependcies list.  However any pom file uses that bundle jar will have\n      to carry extra jars with it.\n\nCan we have a api method to trigger to install/deploy not to add the dependency artifacts in to pom??\n"
            },
            "2": {
                "commit_sha_buggy": "ed7cc01b88173ef0be12fbab4cfc56fc19c5c223",
                "commit_sha_fixed": "1bdeecccadb9951fd48550a7aa3b9ee23ea111bc",
                "report_id": "MNG-1205",
                "report_url": "https://issues.apache.org/jira/browse/MNG-1205",
                "issue_title": "[MNG-1205] dependency with scope:system & flag optional = true doesn't appear in the class path - ASF JIRA",
                "issue_description": "\nDependency with scope:system & flag  optional = true doesn't appear in the class path\nTry to call m2 install  or compiler:compile in the attached project. Compilation will fail ...\nbest regards\nJuBu\n"
            }
        }
    },
    "Maven2_project": {
        "owner_repo": "apache/maven-2",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e7fb994cd79a9602392d3e77b62262fc77594da3",
                "commit_sha_fixed": "3b956f78c84293cc88ad760f7a39c456c8ada4a1",
                "report_id": "MNG-2234",
                "report_url": "https://issues.apache.org/jira/browse/MNG-2234",
                "issue_title": "[MNG-2234] activeProfile in ~/.m2/settings.xml is ignored when profiles section is missing or empty - ASF JIRA",
                "issue_description": "\nWhen i have this settings.xml file in my user home dir, the activeProfile setting is simply ignored by Maven:\n<settings>\n <activeProfiles>\n     <activeProfile>env-test</activeProfile>\n </activeProfiles>\n</settings>\nAdding an empty profiles section does not help:\n<settings>\n <profiles>\n </profiles>\n <activeProfiles>\n     <activeProfile>env-test</activeProfile>\n </activeProfiles>\n</settings>\nWell, adding a dummy profile makes it work:\n<settings>\n <profiles>\n    <profile>\n          <id>dummy</id>\n    </profile>\n </profiles>\n <activeProfiles>\n     <activeProfile>env-test</activeProfile>\n </activeProfiles>\n</settings>\nFunny, isn't it?\nRegards,\nManfred\n"
            },
            "2": {
                "commit_sha_buggy": "b52f1b5f0c4e1860539f7fd10783bb9fb9f5d249",
                "commit_sha_fixed": "6098b08a5482409cb1dd78f94b3741b64e704cfe",
                "report_id": "MNG-3621",
                "report_url": "https://issues.apache.org/jira/browse/MNG-3621",
                "issue_title": "[MNG-3621] site url inheritance broken for UNC paths - ASF JIRA",
                "issue_description": "\nI have a parent POM that is inherited by multiple projects that specifies site wide default settings. \n(e.g)\nParent\\pom.xml <--- this is the pom containing the site configuration\nParent\\CheckStyleConfig\\pom.xml\nPart of this is the site deploy \n<distributionManagement>\n<site>\n<id>nds-uk.site</id>\n<url>file://///scg-nas.uk.nds.com/maven_sites/${project.groupId}/${project.artifactId}/${project.version}</url>\n</site>\n</distributionManagement>\nrunning site:deploy on the sub procject results in it using a corrupted version of the url.\nbuild output attached.\nNotice the corruption of the original parent  file:///// (2 slashes are removed so it tries to deploy to local HDD)\nparent (OK 5 slashes) file://///scg-nas.uk.nds.com/maven_sites/com.nds.cab.scg/common-parent/1.0.0.0-SNAPSHOT - Session: Opened \nchild (bad 3 slashes) file:///scg-nas.uk.nds.com/maven_sites/com.nds.cab.scg/common-checkstyle/1.0.0.0-SNAPSHOT/common-checkstyle - Session: Opened \n"
            }
        }
    },
    "Wicket_request": {
        "owner_repo": "apache/wicket",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e0d2b7c38188f34d669a47c6f22d8965fa0c295a",
                "commit_sha_fixed": "518c933bb31c35b736253936ba080ac21e6cb19f",
                "report_id": "WICKET-5114",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5114",
                "issue_title": "[WICKET-5114] Url#toString(StringMode.FULL) throws exception if a segment contains two dots - ASF JIRA",
                "issue_description": "\nWhen invoking toString(StringMode.FULL) for a URL like\n/mountPoint/whatever.../\nan IllegalStateException is thrown with message: Cannot render this url in FULL mode because it has a `..` segment: /mountPoint/whatever.../\nThe method does not actually check for `..` segments but rather checks whether path.contains(\"..\")\n"
            },
            "2": {
                "commit_sha_buggy": "908dc6f8e429270e2ae95d7049a28db3e9bbef91",
                "commit_sha_fixed": "961f2477660925a111c581660909c5632d15ef4b",
                "report_id": "WICKET-5157",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5157",
                "issue_title": "[WICKET-5157] URL query parameter values containing equals sign get cut off - ASF JIRA",
                "issue_description": "\nWhen calling a page with a query parameter like 'param1=val1=val2' the value of 'param1' obtained from PageParameters will be 'val1'. Everything after the equals sign inside the parameter value gets cut off.\n"
            },
            "3": {
                "commit_sha_buggy": "ff4ebd898e1f6a88979fb5a5bb078498e391adaa",
                "commit_sha_fixed": "2fcb34178a13b54e9718f40b0b4fe19475fa5dad",
                "report_id": "WICKET-4664",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4664",
                "issue_title": "[WICKET-4664] Url#getQueryString(charset) method returns quesrystring with \"?\" prefixed to it - ASF JIRA",
                "issue_description": "\ni have just pointed out 6.0.0-beta3/6.x but it must be same in 1.5.x too ,afaik \"?\" is not considered part of querystring ,\"?\" is considered separator see http://tools.ietf.org/html/rfc3986#section-3\nthis method is used in Url#toString() too which can be easily fixed but it may be used at other places too so i don't know if removing \"?\" will break things now.\nso how things break currently\nRequestUtils.decodeParameters(url.getQueryString(),parameters);\ndecodeparameters will considered first key to be \"?key\" \nso may be requestutils#decodeparameters method should strip away \"?\" if it's present in the query string before populating pageparameters\nthanks!\n"
            },
            "4": {
                "commit_sha_buggy": "f5d586b9b039a4b16e6e856f1a5d9947ce737074",
                "commit_sha_fixed": "a9e56e1e8d75ac87a5db4a55dadb52de7d90f770",
                "report_id": "WICKET-5259",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5259",
                "issue_title": "[WICKET-5259] Url can't parse urls with username and password - ASF JIRA",
                "issue_description": "\nUrl tries to parse the password as the portnumber, because it's after the :, resulting in the following exception:\njava.lang.NumberFormatException: For input string: \"23dc429c-4ffa-4e99-8e24-984571f4c3b6@digdag-rest-dev2.topicusonderwijs.nl\"\n\tjava.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tjava.lang.Integer.parseInt(Integer.java:492)\n\tjava.lang.Integer.parseInt(Integer.java:527)\n\torg.apache.wicket.request.Url.parse(Url.java:276)\n\torg.apache.wicket.request.Url.parse(Url.java:192)\n\torg.apache.wicket.protocol.http.servlet.ServletWebResponse.encodeRedirectURL(ServletWebResponse.java:212)\n\torg.apache.wicket.protocol.http.servlet.ServletWebResponse.sendRedirect(ServletWebResponse.java:236)\n\torg.apache.wicket.protocol.http.BufferedWebResponse$SendRedirectAction.invoke(BufferedWebResponse.java:400)\n\torg.apache.wicket.protocol.http.BufferedWebResponse.writeTo(BufferedWebResponse.java:588)\n\torg.apache.wicket.protocol.http.HeaderBufferingWebResponse.stopBuffering(HeaderBufferingWebResponse.java:60)\n\torg.apache.wicket.protocol.http.HeaderBufferingWebResponse.flush(HeaderBufferingWebResponse.java:97)\n\torg.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:269)\n\torg.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:201)\n\torg.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:282)\n"
            },
            "5": {
                "commit_sha_buggy": "ad1b70e2fae5a8eb808dbb0fd27caf48ea0710be",
                "commit_sha_fixed": "f45ce896d02aeda3c09d56bc4ceac425929973a1",
                "report_id": "WICKET-5698",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5698",
                "issue_title": "[WICKET-5698] WebApplication#unmount() unmounts the whole compound mapper if some of its inner ones matches - ASF JIRA",
                "issue_description": "\nFrom dev@ mailing lists: http://markmail.org/message/wmdgbrhvrvaeygvr\nWebApplication.unmount() calls getRootRequestMapperAsCompound(), and \ncalls unmount() on that.\ngetRootRequestMapperAsCompound() checks if the root request mapper is a \ncompound, if not, wraps it in a compound, sets the compound as root and \nreturns the compound.\nCompoundRequestMapper.unmount() identifies which of the mappers added \ndirectly to the compound handle the url, and removes them.\nThe problem:\nIf the original root mapper was a single wrapper, or layer of wrappers, \nwith the actual mounted mapper wrapped some levels down, then the whole \nwrapper is removed, not just the specific MountedMapper that is wrapped. \nThis has the effect of removing every single mapper, leaving root mapper \nas an empty compound.\nI would like to attempt to provide a patch to fix this, but would like \nguidance on the approach. I have come up with three approaches:\n1. Introduce interface IWrappedRequestMapper. This will be an interface \nwhich has one method: IRequestMapper getWrappedRequestMapper(). We can \nthen have all wrapper mappers implement this and work down the tree to \nfind the correct MountedMapper (wicket 6) to remove.\n2. Have WebApplication hold a reference to a specific \nCompoundRequestMapper, and have all mount()/unmount() operations add and \nremove from this mapper. This compound would need to be added to the \ndefault list during init. This makes it complicated to work out how to \ndo things like have CryptoMapper not apply to mounted pages.\n3. Add method unmount() to IRequestMapper, so that wrappers can \ndelegate. This obviously can only be done in wicket 7, but we're making \nmounting a problem of every single request mapper, when not even \nApplication cares about mounting.\n"
            },
            "6": {
                "commit_sha_buggy": "1cb35a0670c29536ff35a7f91aa9b2e88e85fb79",
                "commit_sha_fixed": "cf6172bd5acceac19f4322dcf7ce2ec7aef76a38",
                "report_id": "WICKET-5770",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5770",
                "issue_title": "[WICKET-5770] PageParametersEncoder should not decode parameters with no name - ASF JIRA",
                "issue_description": "\nFrom dev@ mailing list: http://markmail.org/message/khuc2v37aakzyfth\nPageParametersEncoder should ignore query parameters like \"&=&\" and \"&=value\" because they make no sene and lead to exceptions later at PageParameters#add() call.\n"
            }
        }
    },
    "Cayenne_xmpp": {
        "owner_repo": "apache/cayenne",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4724ab3f97869620397e8801f97f9b88be8d972d",
                "commit_sha_fixed": "e338bbaf356060b1437e2bd3dbf0c7ca10c7efce",
                "report_id": "CAY-2505",
                "report_url": "https://issues.apache.org/jira/browse/CAY-2505",
                "issue_title": "[CAY-2505] EventBridge providers should be bound without scope - ASF JIRA",
                "issue_description": "\nCurrently all event bridge providers (JMS, XMPP, JGroups) are bound in default scope (i.e. as singletons). And that brakes things in case of shared DataRowStore is disabled.\nSo they should be bound without scope and provide new instances for every request to provider.\n"
            }
        }
    },
    "Wicket_util": {
        "owner_repo": "apache/wicket",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e41a6523c0dc266b3f6d05e4e586dee9a91c8d17",
                "commit_sha_fixed": "a382917f7f5b502d72277de9a29b3fcca67209ca",
                "report_id": "WICKET-5442",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5442",
                "issue_title": "[WICKET-5442] TimeOfDay.valueOf(Calendar, Time) and TimeOfDay.valueOf(Time) incorrectly use 12-hour clock - ASF JIRA",
                "issue_description": "\nTimeOfDay.valueOf(Calendar, Time) is implemented as:\n    return militaryTime(time.getHour(calendar), time.getMinute(calendar), time.getSecond(calendar));\nThis is flawed because Time.getHour() is implemented as:\n    return get(calendar, Calendar.HOUR);\nand Calendar.HOUR is for the 12-hour clock. The result is that TimeOfDay.valueOf(Calendar, Time) incorrectly only returns 12-hour results, not 24-hour results. This affects TimeOfDay.valueOf(Time) as well since it is implemented in terms of the previously-named method.\nOne fix would be to change Time.getHour() to use Calendar.HOUR_OF_DAY. Since Time doesn't have an am/pm indicator this seems reasonable. An alternate, more localized fix would be to change TimeOfDay.valueOf(Calendar, Time) to call time.get(Calendar.HOUR_OF_DAY) to get the hour value.\n"
            },
            "2": {
                "commit_sha_buggy": "f0a6399c0bda530513734a6c76c7941d028b4c6f",
                "commit_sha_fixed": "2fc6a3957da8b59443afb6e97e849510983a411b",
                "report_id": "WICKET-5720",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5720",
                "issue_title": "[WICKET-5720] Method Strings.join doesn't work correctly if separator is empty. - ASF JIRA",
                "issue_description": "\nIf we use an empty separator (\"\") to join strings, the first character of any fragment is truncated.\nEs \"foo\", \"bar\", \"baz\" became \"ooaraz\".\n"
            },
            "3": {
                "commit_sha_buggy": "988f0fa57195ed60fcf1ac00d1023ca024647ca5",
                "commit_sha_fixed": "bcea89fc8a196d2e1ebdcecf9c81298a06b4f5cb",
                "report_id": "WICKET-5751",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5751",
                "issue_title": "[WICKET-5751] NullPointerException in IntHashMap - ASF JIRA",
                "issue_description": "\nI was looking through a tester's log file to track down a separate issue. I came across a NullPointerException with IntHashMap, apparently when the server was shutting down.\nSee also WICKET-5584, which also deals with a NullPointerException with IntHashMap, and also seems to relate to a null modCount (judging by the line number).\n\nINFO  (ExampleServer) [2014-11-06 00:49:24,979] - com.example.server.ExampleServer.stopServer(ExampleServer.java:268): Stopping server.\nINFO  (ServerConnector) [2014-11-06 00:49:24,982] - org.eclipse.jetty.server.AbstractConnector.doStop(AbstractConnector.java:306): Stopped ServerConnector@3b7d3a38{HTTP/1.1}{0.0.0.0:8099}\nINFO  (Application) [2014-11-06 00:49:24,983] - org.apache.wicket.Application.destroyInitializers(Application.java:588): [org.apache.wicket.protocol.http.WicketFilter-55b0dcab] destroy: Wicket core library initializer\nINFO  (Application) [2014-11-06 00:49:24,983] - org.apache.wicket.Application.destroyInitializers(Application.java:588): [org.apache.wicket.protocol.http.WicketFilter-55b0dcab] destroy: Wicket extensions initializer\nERROR (DiskDataStore) [2014-11-06 00:49:24,988] - org.apache.wicket.pageStore.DiskDataStore.saveIndex(DiskDataStore.java:282): Couldn't write DiskDataStore index to file C:\\Windows\\SERVIC~2\\NETWOR~1\\AppData\\Local\\Temp\\org.apache.wicket.protocol.http.WicketFilter-55b0dcab-filestore\\DiskDataStoreIndex.\njava.lang.NullPointerException\n\tat org.apache.wicket.util.collections.IntHashMap$HashIterator.<init>(IntHashMap.java:777)\n\tat org.apache.wicket.util.collections.IntHashMap$EntryIterator.<init>(IntHashMap.java:871)\n\tat org.apache.wicket.util.collections.IntHashMap$EntryIterator.<init>(IntHashMap.java:871)\n\tat org.apache.wicket.util.collections.IntHashMap.newEntryIterator(IntHashMap.java:896)\n\tat org.apache.wicket.util.collections.IntHashMap$EntrySet.iterator(IntHashMap.java:1055)\n\tat org.apache.wicket.util.collections.IntHashMap.writeObject(IntHashMap.java:1128)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat java.util.HashMap.internalWriteEntries(HashMap.java:1777)\n\tat java.util.HashMap.writeObject(HashMap.java:1354)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.wicket.pageStore.DiskDataStore.saveIndex(DiskDataStore.java:274)\n\tat org.apache.wicket.pageStore.DiskDataStore.destroy(DiskDataStore.java:106)\n\tat org.apache.wicket.pageStore.AsynchronousDataStore.destroy(AsynchronousDataStore.java:118)\n\tat org.apache.wicket.pageStore.AbstractPageStore.destroy(AbstractPageStore.java:53)\n\tat org.apache.wicket.pageStore.AbstractCachingPageStore.destroy(AbstractCachingPageStore.java:102)\n\tat org.apache.wicket.page.PageStoreManager.destroy(PageStoreManager.java:437)\n\tat org.apache.wicket.Application.internalDestroy(Application.java:659)\n\tat org.apache.wicket.protocol.http.WebApplication.internalDestroy(WebApplication.java:607)\n\tat org.apache.wicket.protocol.http.WicketFilter.destroy(WicketFilter.java:605)\n\tat org.eclipse.jetty.servlet.FilterHolder.destroyInstance(FilterHolder.java:173)\n\tat org.eclipse.jetty.servlet.FilterHolder.doStop(FilterHolder.java:151)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:143)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:162)\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:73)\n\tat org.eclipse.jetty.servlet.ServletHandler.doStop(ServletHandler.java:230)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:143)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:162)\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:73)\n\tat org.eclipse.jetty.security.SecurityHandler.doStop(SecurityHandler.java:411)\n\tat org.eclipse.jetty.security.ConstraintSecurityHandler.doStop(ConstraintSecurityHandler.java:457)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:143)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:162)\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:73)\n\tat org.eclipse.jetty.server.session.SessionHandler.doStop(SessionHandler.java:127)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:143)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:162)\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:73)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:833)\n\tat org.eclipse.jetty.servlet.ServletContextHandler.doStop(ServletContextHandler.java:215)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:143)\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:162)\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:73)\n\tat org.eclipse.jetty.server.Server.doStop(Server.java:456)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\n\tat com.example.server.ExampleServer.stopServer(ExampleServer.java:269)\n\tat com.example.server.ExampleServer.stop(ExampleServer.java:279)\nINFO  (ContextHandler) [2014-11-06 00:49:24,990] - org.eclipse.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:863): Stopped o.e.j.s.ServletContextHandler@63f259c3{/,null,UNAVAILABLE}\n\n\n"
            },
            "4": {
                "commit_sha_buggy": "1861b9f7b6f0b47a14a2337a3ab47be7d4baac39",
                "commit_sha_fixed": "e93fdd5ab088d8638c5f1f58e2d337823cbcc020",
                "report_id": "WICKET-5838",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5838",
                "issue_title": "[WICKET-5838] Last-modified header of external markup is ignored - ASF JIRA",
                "issue_description": "\nWhen using external base markup(in my case a drupal page with a wicket:child element in it) this markup is supposed to be cached after first fetch. For subsequent requests the last-modified header is checked to see if the markup has changed and when it has the markup is fetched again.\nThis does not work, Connections.getLastModified(URL url) always returns 0 when the URL is a http url(in fact, when url.openConnection returns a sun.net.www.protocol.http.HttpURLConnection.\nSolution could be to not setDoInput to false on this URLConnection(tested that)\n"
            }
        }
    },
    "Wicket_spring": {
        "owner_repo": "apache/wicket",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "450d89da0b8a322ea99c943e726d654728264b66",
                "commit_sha_fixed": "8e794fc468c1142b218d33ea3cbb67584d6c1441",
                "report_id": "WICKET-5686",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5686",
                "issue_title": "[WICKET-5686] @Inject should require the bean dependency instead of setting null - ASF JIRA",
                "issue_description": "\nWhen using @SpringBean, if the bean cannot be injected then Wicket will throw Exception.\nHowever current behavior if when using @Inject inside component, the field will be left as null. This is inconsistent behavior with what CDI spec and how the \"real\" Spring does it.\nWicket should change its behavior so that @Inject is always required. If the dependency is optional the user can use @SpringBean(required=false) as always.\n"
            }
        }
    },
    "Cayenne_jgroups": {
        "owner_repo": "apache/cayenne",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4724ab3f97869620397e8801f97f9b88be8d972d",
                "commit_sha_fixed": "e338bbaf356060b1437e2bd3dbf0c7ca10c7efce",
                "report_id": "CAY-2505",
                "report_url": "https://issues.apache.org/jira/browse/CAY-2505",
                "issue_title": "[CAY-2505] EventBridge providers should be bound without scope - ASF JIRA",
                "issue_description": "\nCurrently all event bridge providers (JMS, XMPP, JGroups) are bound in default scope (i.e. as singletons). And that brakes things in case of shared DataRowStore is disabled.\nSo they should be bound without scope and provide new instances for every request to provider.\n"
            }
        }
    },
    "Cayenne_jms": {
        "owner_repo": "apache/cayenne",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4724ab3f97869620397e8801f97f9b88be8d972d",
                "commit_sha_fixed": "e338bbaf356060b1437e2bd3dbf0c7ca10c7efce",
                "report_id": "CAY-2505",
                "report_url": "https://issues.apache.org/jira/browse/CAY-2505",
                "issue_title": "[CAY-2505] EventBridge providers should be bound without scope - ASF JIRA",
                "issue_description": "\nCurrently all event bridge providers (JMS, XMPP, JGroups) are bound in default scope (i.e. as singletons). And that brakes things in case of shared DataRowStore is disabled.\nSo they should be bound without scope and provide new instances for every request to provider.\n"
            }
        }
    },
    "Struts1_core": {
        "owner_repo": "apache/struts1",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c6d96ed883afa264ef72c3f4fc72c24a29b8b892",
                "commit_sha_fixed": "108d1109a394741782ac4f9a1f753c576f74cab9",
                "report_id": "STR-2802",
                "report_url": "https://issues.apache.org/jira/browse/STR-2802",
                "issue_title": "[STR-2802] Validator validwhen cannot test between two different indices in array - ASF JIRA",
                "issue_description": "\nThis code in the validator.xml fails with this error : \"unexpected token adr..\"\n<field property=\"adr[0]\" depends =\"validwhen\"> \n  <var> \n      <var-name>test</var-name> \n      <var-value>((this!=null) or (adr[1] != null ))</var-value> \n  </var> \n</field> \nadr is an array of two adress lines. Only one of them needs tobe filled.\nAccording to the document of the validator, it should work.\n"
            },
            "2": {
                "commit_sha_buggy": "a197a2151b1aa2d3e0fca59989a706b670ed3739",
                "commit_sha_fixed": "4b67567a26acf31d7e52ac31c52c4055ecdb6f89",
                "report_id": "STR-3088",
                "report_url": "https://issues.apache.org/jira/browse/STR-3088",
                "issue_title": "[STR-3088] N-length empty strings not treated as *null* by validwhen - ASF JIRA",
                "issue_description": "\nHello,\nAs for validator required/requiredif , the continuous space string (ex. \"   \") is jugded blank field.\nBut 'null' of validwhen shows only null or length 0 String .\nFor ex,'this == null' is not hit the continuous space string (ex. \"   \").\nI think it should be same behavior because 'Validator Guide' described as follows:\n>  requiredif  - field dependant validator\n>Deprecated, use validwhen.\nNow, requiredif cannot be replaced validwhen.\n"
            }
        }
    },
    "Wicket_cdi": {
        "owner_repo": "apache/wicket",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f583754f9deb35d98ec1229e565ea39cee0e296b",
                "commit_sha_fixed": "8e518d884ee35a118d6f7772ce3900abd07206f9",
                "report_id": "WICKET-5226",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5226",
                "issue_title": "[WICKET-5226] CDI integration fails in Glassfish 4.0 with WELD-000070 - ASF JIRA",
                "issue_description": "\nWhen CDI is configured in the Application and a page has a non-static inner class the page throws exception, regardless of whether there are any injected fields.\nCaused by: org.jboss.weld.exceptions.DefinitionException: WELD-000070 Simple bean [EnhancedAnnotatedTypeImpl] private  class com.inversebit.HomePage$AForm cannot be a non-static inner class\n\tat org.jboss.weld.injection.producer.BasicInjectionTarget.checkType(BasicInjectionTarget.java:81)\n\tat org.jboss.weld.injection.producer.BasicInjectionTarget.<init>(BasicInjectionTarget.java:69)\n\tat org.jboss.weld.injection.producer.BeanInjectionTarget.<init>(BeanInjectionTarget.java:52)\n\tat org.jboss.weld.manager.InjectionTargetFactoryImpl.createInjectionTarget(InjectionTargetFactoryImpl.java:95)\n\tat org.jboss.weld.manager.InjectionTargetFactoryImpl.createInjectionTarget(InjectionTargetFactoryImpl.java:78)\n\t... 65 more\n"
            }
        }
    },
    "Wicket_core": {
        "owner_repo": "apache/wicket",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cfd70cc0f5507f7beb2d6ef5726509c8bfe16c7f",
                "commit_sha_fixed": "42af7491fd34cfe05cf1df2143a96f7169654811",
                "report_id": "WICKET-4718",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4718",
                "issue_title": "[WICKET-4718] ResourceStreamResource#getResourceStream() is called multiple times - ASF JIRA",
                "issue_description": "\nWhen a ResourceStreamResource is implemented to return a IResourceStream dynamically, by returning a new instance of an extended AbstractResourceStream, that ResourceStream is instantiated multiple times when a ResourceLink is clicked.\nIn my case, that ResourceStream returns an AttachmentInputStream from the Ektorp library (for CouchDB interaction). This behavior results in multiple queries (currently up to four) when I click once on a ResourceLink to that resource.\nCode Examples\nExtended ResourceStreamResource: http://pastebin.com/9BB7LEiV\nExtended IResouceStream: http://pastebin.com/Z7GvzGja\n"
            },
            "2": {
                "commit_sha_buggy": "ed2b021fdba5161c587719c9118327ecf49c6a4c",
                "commit_sha_fixed": "fd910746d7c1ed83f49eb58c63c6249439b9a0cd",
                "report_id": "WICKET-4757",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4757",
                "issue_title": "[WICKET-4757] FormComponents remain invalid forever if there is no feedback panel - ASF JIRA",
                "issue_description": "\nif there is no feedback panel the error messages are not removed in ondetach and form component re-validation is skipped so the form component, once marked as invalid, will remain invalid forever or at least until its error messages are rendered.\nthe error messages should be dropped and the form component should be re-validated on every form submit.\n"
            },
            "3": {
                "commit_sha_buggy": "ce9b3ce8ed28a5cd277733759fdb30e824f62f22",
                "commit_sha_fixed": "2f1ece4b9db4e013b6b492c88b26295b60472859",
                "report_id": "WICKET-4760",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4760",
                "issue_title": "[WICKET-4760] JavaScriptStripper fails with single line comments - ASF JIRA",
                "issue_description": "\nThe valid input\nx++ //\nx++\ngets transformed to\nx++ x++\nwhich is syntactically invalid. This breaks the unminified version of bootstrap 2.1.1.\nThe problem doesn't occur with multiline comments because the linebreaks are preserved there.\n"
            },
            "4": {
                "commit_sha_buggy": "f3c4baec7f60115b0e43e00f36b5740198dc7e3c",
                "commit_sha_fixed": "eccb3b11875f93d9ad99ae680b4283008c75ee37",
                "report_id": "WICKET-4777",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4777",
                "issue_title": "[WICKET-4777] JavaScriptReference escapes given URL - ASF JIRA",
                "issue_description": "\nwhile trying to integrate gmaps3 in our webapp i had issues with the wicketstuff-gmap3 stuff ( - we need a client-id for our request) ...\nso i have:\n\npublic static final String GMAP_API_URL = \"%s://maps.google.com/maps/api/js?v=3&sensor=%s&client-id=%s\";\n\nresponse.render(JavaScriptHeaderItem.forUrl(String.format(GMAP_API_URL, schema, sensor, clientid)));\n\n\nthe rendered result of this is:\n\n<script type=\"text/javascript\" src=\"http://maps.google.com/maps/api/js?v=3&amp;sensor=false&amp;client-id=....\"></script>\n\n\nso the requestparameters are encoded\nwhich is happening in the JavaScriptUtils Helper:\n\npublic static void writeJavaScriptUrl(final Response response, final CharSequence url, final String id, boolean defer, String charset)\n{\n        response.write(\"<script type=\\\"text/javascript\\\" \");\n        if (id != null)\n        {\n            response.write(\"id=\\\"\" + Strings.escapeMarkup(id) + \"\\\" \");\n        }\n        if (defer)\n        {\n            response.write(\"defer=\\\"defer\\\" \");\n        }\n        if (charset != null)\n        {\n            response.write(\"charset=\\\"\" + Strings.escapeMarkup(charset) + \"\\\" \");\n        }\n        response.write(\"src=\\\"\");\n        response.write(Strings.escapeMarkup(url));\n        response.write(\"\\\"></script>\");\n        response.write(\"\\n\");\n}\n\n\nbut ... is this right to escape the url?\nwhen i open the above mentioned script, google tells me i have no parameter \"sensor\" ... which i can understand as ther is only a parameter amp ... \n"
            },
            "5": {
                "commit_sha_buggy": "600f5dfb15830288e04e5723fd5237e73de4536e",
                "commit_sha_fixed": "ad849602d5dac53706da6f67175e3a22b7f3b418",
                "report_id": "WICKET-4824",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4824",
                "issue_title": "[WICKET-4824] Redirect to HTTPS is using wrong port 80 if HttpsConfig with default ports 80/443 is used - ASF JIRA",
                "issue_description": "\nHttpsMapper#mapHandler() doesn't set the Url's port, if the desired protocol uses the standard port.\nThis leads to UrlRenderer choosing to the request's port as fallback (which is 80 before switching to https).\n"
            },
            "6": {
                "commit_sha_buggy": "02d3e2135891cb2b9a4681278848c860ba280eab",
                "commit_sha_fixed": "d78132be9f3634960f3e87704d40a13887626c00",
                "report_id": "WICKET-4923",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4923",
                "issue_title": "[WICKET-4923] CryptoMapper ignores original queryString parameters - ASF JIRA",
                "issue_description": "\nWhen an AjaxRequest with parameters (e.g.: Autocomplete.getChoices()) arrives and CryptoMapper decrypts it, original queryString parameters dissapears.\nDebugging CryptoMapper, I've checked that this method:\nprivate Url decryptUrl(final Request request, final Url encryptedUrl) {\n        ...\n}\nreceives querystrings parameters (on field url.parameter from \"request\" parameter) and the new Url returned by the method never adds them to its own list. \n"
            },
            "7": {
                "commit_sha_buggy": "742cade5f27a9e8adf2f944a8fb2c1179b8ca6dc",
                "commit_sha_fixed": "917dd2b5e3314fe7c98a61cb3d16f0fef2c148c6",
                "report_id": "WICKET-5019",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5019",
                "issue_title": "[WICKET-5019] Handling of NO_MINIFIED_NAME in PackageResourceReference#internalGetMinifiedName()    - ASF JIRA",
                "issue_description": "\nThe Value NO_MINIFIED_NAME is not handled correctly as entry in the MINIFIED_NAMES_CACHE in PackageResourceReference#internalGetMinifiedName()   \n\tprivate String internalGetMinifiedName()\n\t{\n\t\tString minifiedName = MINIFIED_NAMES_CACHE.get(this);\n\t\tif (minifiedName != null && minifiedName != NO_MINIFIED_NAME)\n\t\t{                                                        ^^^^^^^\n\t\t\treturn minifiedName;\n                }\n                ...\nYou should remove the condition \"minifiedName != NO_MINIFIED_NAME\" here to leverage the \nMINIFIED_NAMES_CACHE for NO_MINIFIED_NAME cache entries. Otherwise you always run into the resource resolving code if there is no minified resource.\n"
            },
            "8": {
                "commit_sha_buggy": "b1e68de911c0ccb71df58a6744bf3ad18c2f265d",
                "commit_sha_fixed": "381b90fd0a55e40983d0e826139363a7d965ee0e",
                "report_id": "WICKET-5072",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5072",
                "issue_title": "[WICKET-5072] Cookies#isEqual(Cookie, Cookie) may fail with NullPointerException - ASF JIRA",
                "issue_description": "\nIf c1.getPath == null but c2.getPath != null then a NPE will occur.\nSame is valid for the 'domain' property.\n"
            },
            "9": {
                "commit_sha_buggy": "b3982a4beff352cd5e61521490a397a926c13eed",
                "commit_sha_fixed": "5e1bf8d8169a8d01f041a1d2bf41a8b8fe170dbd",
                "report_id": "WICKET-4594",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-4594",
                "issue_title": "[WICKET-4594] Do not use the parsed PageParameters when re-creating an expired page - ASF JIRA",
                "issue_description": "\nWICKET-4014 and WICKET-4290 provided functionality to re-create an expired page if there is a mount path in the current request's url.\nThere is a minor problem with that because the page parameters are passed to the freshly created page. I.e. parameters for a callback behavior are now set as page construction parameters.\nSince the execution of the behavior is ignored for the recreated page these parameters should be ignored too.\n"
            },
            "10": {
                "commit_sha_buggy": "62fe0a96ea58bc2ed986a78f430e3701604635fa",
                "commit_sha_fixed": "beee594d98f82d1bf8b59c3c69dbe33eb1743091",
                "report_id": "WICKET-5083",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5083",
                "issue_title": "[WICKET-5083] Page#isPageStateless() may return wrong value - ASF JIRA",
                "issue_description": "\nThis ticket is a follow up to WICKET-5078 (WICKET-4763 also seems related).\nPage#isPageStateless() can be invoked at a time where onInitialize() hasn't been called yet. This causes pages to report that they are not stateful, even though they are, if the stateful components are added in onInitialize() and not in the constructor.\n"
            },
            "11": {
                "commit_sha_buggy": "14d018dabd6a9e3fcb9492d927ae721f46c99382",
                "commit_sha_fixed": "ed780cc72eb70a71291a724dbced24e1af56653a",
                "report_id": "WICKET-5112",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5112",
                "issue_title": "[WICKET-5112] Parantheses problem with UrlValidator - ASF JIRA",
                "issue_description": "\nOne of our users got an error message when trying to add a new URL:\n'http://en.wikipedia.org/wiki/Genus_(mathematics)' is not a valid URL\nI just created very quickly a junit test and it fails:\nString[] schemes = \n{\"http\"}\n;\nUrlValidator urlValidator = new UrlValidator(schemes);\nassertTrue(urlValidator.isValid(\"http://en.wikipedia.org/wiki/Genus_(mathematics)\"));\n"
            },
            "12": {
                "commit_sha_buggy": "c0015419ce465a8b56a9a220cccbb465ae7e7b23",
                "commit_sha_fixed": "3cc3fe95cbb3ebd72ff37817dd1860d828181b5e",
                "report_id": "WICKET-5728",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5728",
                "issue_title": "[WICKET-5728] Component queuing breaks with html tags that don't require close tag. - ASF JIRA",
                "issue_description": "\nComponent queuing try to skip to close tag also for those tags that don't have one. This leads to a EmptyStackException (see ArrayListStack#peek).\n"
            },
            "13": {
                "commit_sha_buggy": "d929c3e65da8b35b805c6950b9e89675d0cc5dbd",
                "commit_sha_fixed": "71674df5c8905c425152038281379027de89cf9b",
                "report_id": "WICKET-5734",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5734",
                "issue_title": "[WICKET-5734] Problem with WICKET-4441 and RestartResponseAtInterceptPageException - ASF JIRA",
                "issue_description": "\nWICKET-4441 introduced an issue when our app has an authorization strategy and user is logged out. If user tries to access a protected url/page, RestartResponseAtInterceptPageException is handled by DefaultExceptionMapper and leads to exception page instead of redirecting user.\n"
            },
            "14": {
                "commit_sha_buggy": "ca153fd4a42715fcf02cff533837a4dcd9e6ce01",
                "commit_sha_fixed": "907f891af1a158ef015e7fcd70e0c997b227d22a",
                "report_id": "WICKET-5874",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5874",
                "issue_title": "[WICKET-5874] WicketTester TagTester does not work as expected when using non self closing tags - ASF JIRA",
                "issue_description": "\nWicketTester TagTester does not work as expected when using non self closing tags.\nWicketTester code\n\nTagTester tagTester = wicketTesterInstance.getTagByWicketId(\"someInputId\");\n\n\nThis does not work, tagTester is null:\n\n<input wicket:id=\"someInputId\">\n\n\nThis works as expected:\n\n<input wicket:id=\"someInputId\"/>\n\n\nFound using Wicket version 6.17.\n"
            },
            "15": {
                "commit_sha_buggy": "24e9db6c8af85043ce36e4d25a0e8a2d8dc2f49e",
                "commit_sha_fixed": "2d9ebf9af8f9efb9cc195959b7e925d70a97a533",
                "report_id": "WICKET-5891",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5891",
                "issue_title": "[WICKET-5891] Parsing of ChinUnionPay credit card should use the first 6 characters - ASF JIRA",
                "issue_description": "\nUser report:\nA China UnionPay number has to start with 622 (622126-622925) and has to have a length between 16 and 19. The source code of CreditCardValidator is:\n  220   \tprivate boolean isChinaUnionPay(String creditCardNumber)\n  221   \t{\n  222   \t\tcardId = CreditCardValidator.INVALID;\n  223   \t\tboolean returnValue = false;\n  224   \n  225   \t\tif ((creditCardNumber.length() >= 16 && creditCardNumber.length() <= 19) &&\n  226   \t\t\t(creditCardNumber.startsWith(\"622\")))\n  227   \t\t{\n  228   \t\t\tint firstDigits = Integer.parseInt(creditCardNumber.substring(0, 5));\n  229   \t\t\tif (firstDigits >= 622126 && firstDigits <= 622925)\n  230   \t\t\t\n{\n  231   \t\t\t\tcardId = CreditCardValidator.CHINA_UNIONPAY;\n  232   \t\t\t\treturnValue = true;\n  233   \t\t\t}\n  234   \t\t}\n  235   \n  236   \t\treturn returnValue;\n  237   \t}\nThe problem is on the line 228 because the substring returns the first 5 digits and it is compared to 6 digits, so \"firstDigits\" is always < than 622126. The fix is to do #substring(0, 6).\n"
            },
            "16": {
                "commit_sha_buggy": "cab6795aa64fe2280a938f69bb304255f2fc9bbe",
                "commit_sha_fixed": "b00920f377babfb46345e51deff0748621205109",
                "report_id": "WICKET-5898",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5898",
                "issue_title": "[WICKET-5898] StackOverflowError after form submit with a validation error - ASF JIRA",
                "issue_description": "\nI was not able to find a cause or make a small quickstart, but it has something to do with a form validation, my workaround was to setDefaultFormProcessing(false) or not use required TextFields.\nIt can be reproduced on https://github.com/krasa/DevSupportApp/tree/stackOverflow \n1) run StartVojtitkoDummy\n2) go to http://localhost:8765/wicket/bookmarkable/krasa.release.frontend.TokenizationPage\n3) click on \"Generate Release json\" button \n\ninstead of SOE, it should give a validation error, probably even on fields which I would not want to validate, but that's just because I've made the page badly...\n\n\njava.lang.StackOverflowError: null\n...\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:74)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy$1.component(AbstractMarkupSourcingStrategy.java:66)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162)\n\tat org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123)\n\tat org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862)\n\tat org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65)\n\tat org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99)\n\tat org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453)\n\tat org.apache.wicket.Component.getMarkup(Component.java:755)\n\tat org.apache.wicket.Component.internalRender(Component.java:2344)\n\tat org.apache.wicket.Component.render(Component.java:2307)\n\tat org.apache.wicket.ajax.XmlAjaxResponse.writeComponent(XmlAjaxResponse.java:128)\n\tat org.apache.wicket.ajax.AbstractAjaxResponse.writeComponents(AbstractAjaxResponse.java:218)\n\tat org.apache.wicket.ajax.AbstractAjaxResponse.writeTo(AbstractAjaxResponse.java:150)\n\tat org.apache.wicket.ajax.AjaxRequestHandler.respond(AjaxRequestHandler.java:359)\n\tat org.apache.wicket.request.cycle.RequestCycle$HandlerExecutor.respond(RequestCycle.java:865)\n\tat org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64)\n\tat org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:97)\n\tat org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:265)\n\tat org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:222)\n\tat org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293)\n\tat org.apache.wicket.protocol.ws.AbstractUpgradeFilter.processRequestCycle(AbstractUpgradeFilter.java:59)\n\tat org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203)\n\tat org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:497)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248)\n\tat org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:620)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.ru\n\n\n"
            },
            "17": {
                "commit_sha_buggy": "077e1c3d54d044ccfe7b56cc4decf4baf2cc6717",
                "commit_sha_fixed": "010f0efdef14977bfef83f5975b96f24ac808ebe",
                "report_id": "WICKET-5911",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5911",
                "issue_title": "[WICKET-5911] Re-rendering page after exception in render phase does not call onBeforeRender() - ASF JIRA",
                "issue_description": "\n(I sent this to the mailing list originaly, Sven Meier replied this is probably a bug and requested creating a JIRA issue for it.)\nI got page with structure like: \n\nPage\n  +- ListView \u2013 items \n  \\ - Footer panel \n\nNow the scenario (heavily simplified): \nOne of the items in ListView gets exception from backend during onInitialize(). Required behavior in this case is to keep user on the page and replace ListView with a panel stating \"Sorry, backend outage\". \nSo I catch the backend exception using aspect, replace view in the structure with the message panel and throw NonResettingRestartException to restart rendering the page. \nPage is rendered and seems OK, BUT I realize onBeforeRender() of Footer panel is never called. \nI debugged it and found the cause: \nListView adds items in onPopulate() method which is called from onBeforeRender(). When page starts rendering, its onBeforeRender() is called. Page does: \nsetFlag(FLAG_PREPARED_FOR_RENDER, true); \nand calls onBeforeRenderChildren(). This calls onBeforeRender() of ListView, causes exception, so that onBeforeRender() of the footer is not called this time. \nWhen second rendering is attempted, call flow gets to internalBeforeRender() of the page component. There is check: \nif ((determineVisibility()) && !getFlag(FLAG_RENDERING) && !getFlag(FLAG_PREPARED_FOR_RENDER)) { \n  ... \n  onBeforeRender(); \n  ... \n} \nBut since FLAG_PREPARED_FOR_RENDER is set from previous attempt, onBeforeRender() of the page is not called (again) which means onBeforeRender() of the children is not called. \nI found that if I call \nmarkRendering(false); \non the page before throwing the NonResettingRestartException, all goes well. But I am quite uneasy about this solution, so I have two questions: \n1) Cannot this cause some unforeseen troubles? (Supposing my components are correctly written so that their onBeforeRender() / onConfigure() / onAfterRender() procedures can be safely called multiple times.) \n2) Should not Wicket itself reset the FLAG_PREPARED_FOR_RENDER when response restarting exception is caught and processed? \nI created a Wicket quickstart project demonstrating the bug here: http://lemming.hofyland.cz/restartbug.zip\n"
            },
            "18": {
                "commit_sha_buggy": "f569ea57562feb1af98db493a24910918027c082",
                "commit_sha_fixed": "548bcbe66fb0ffd7661c3ff78ba4b747aaa51c1b",
                "report_id": "WICKET-5915",
                "report_url": "https://issues.apache.org/jira/browse/WICKET-5915",
                "issue_title": "[WICKET-5915] The application can not find  /META-INF/wicket/**.properties on Windows systems - ASF JIRA",
                "issue_description": "\nApplication.java  \nLine 556:   fileName.contains(\"/META-INF/wicket/\") return false on Windows systems.\nUse something like  String.format(\"%sMETA-INF%swicket%s\", File.pathSeparatorChar);\n"
            }
        }
    },
    "Shindig_common": {
        "owner_repo": "apache/shindig",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f70f5b9060f4dc749a28ba5d306ba5a294512e4d",
                "commit_sha_fixed": "394fb610888a4b584c266e5ac7a0dd5e21306c7f",
                "report_id": "SHINDIG-965",
                "report_url": "https://issues.apache.org/jira/browse/SHINDIG-965",
                "issue_title": "[SHINDIG-965] JsonSerializer does not handle POJOs in JSONArrays correctly - ASF JIRA",
                "issue_description": "\nJSONSerializer just toString()'s JSONArrays, which doesn't handle embedded POJOs correctly.\n"
            }
        }
    },
    "Mshared_archiver": {
        "owner_repo": "apache/maven-shared",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8924a1ea44b761c0a3cda258f169857b6e9033c9",
                "commit_sha_fixed": "5322e87781085c1edb5b3f8c8d0ac43de0142e19",
                "report_id": "MSHARED-134",
                "report_url": "https://issues.apache.org/jira/browse/MSHARED-134",
                "issue_title": "[MSHARED-134] Using ${artifcactId}-Extention-Name in MANIFEST file can create invalid MANIFEST files - ASF JIRA",
                "issue_description": "\nIf you have a maven dependency on an something with an artifactId that contains a '.'  in it, it creates an illegal manifest file when trying to create an executable jar file (java -jar foo.jar).\n\nException in thread \"main\" java.io.IOException: invalid header field name: geronimo-jms_1.1_spec-Extension-Name\n        at java.util.jar.Attributes.read(Attributes.java:409)\n        at java.util.jar.Manifest.read(Manifest.java:167)\n        at java.util.jar.Manifest.<init>(Manifest.java:52)\n        at java.util.jar.JarFile.getManifestFromReference(JarFile.java:158)\n        at java.util.jar.JarFile.getManifest(JarFile.java:145)\n\n\nHere's my configuration:\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-jar-plugin</artifactId>\n        <configuration>\n          <archive>\n            <manifest>\n              <mainClass>my.class.Test</mainClass>\n              <addClasspath>true</addClasspath>\n              <addExtensions>true</addExtensions>\n              <classpathPrefix>./lib/</classpathPrefix>\n            </manifest>\n          </archive>\n        </configuration>\n      </plugin>\n\n\nI added the following dependency:\n\n    <dependency>\n      <groupId>org.apache.geronimo.specs</groupId>\n      <artifactId>geronimo-jms_1.1_spec</artifactId>\n    </dependency>\n\n\nWhen the maven-archiver tries to create a manifest file with the JARs dependencies it adds the following to the META-INF/MANIFEST.MF file:\n\ngeronimo-jms_1.1_spec-Extension-Name: geronimo-jms_1.1_spec\ngeronimo-jms_1.1_spec-Implementation-Version: 1.0\n\n\nAfter digging around a bit it turns out that '.' is an illegal character in the \"Extension-Name\" and \"Implementaion-Version\" header fields, which leads to the following exception when I try to run \"java -jar Test.jar\"\njava.io.IOException: invalid header field name: geronimo-jms_1.1_spec-Extension-Name\n"
            }
        }
    },
    "Xbean_reflect": {
        "owner_repo": "apache/geronimo-xbean",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "66467b73f57fe0f1334ef2bfb90731563ae82e97",
                "commit_sha_fixed": "1be52c5f189783fd70d18d42b478c9f5420b6f2b",
                "report_id": "XBEAN-154",
                "report_url": "https://issues.apache.org/jira/browse/XBEAN-154",
                "issue_title": "[XBEAN-154] String white space is removed during injection - ASF JIRA",
                "issue_description": "\nDuring injection leading or trailing whitespace is removed from a String. The string should be injected without any changes.\nA similar problem exists when injecting into a char/Character type and the value has to be converted from a String. It's impossible to inject a value that is considered a white space in this way.\n"
            }
        }
    },
    "Mrunit": {
        "owner_repo": "apache/mrunit",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2929a3a9659e6c511b61273026691ea7fb5e3054",
                "commit_sha_fixed": "2c24ab2af152bc7b41c4d52cba4883aacba40764",
                "report_id": "MRUNIT-186",
                "report_url": "https://issues.apache.org/jira/browse/MRUNIT-186",
                "issue_title": "[MRUNIT-186] method context.getNumReduceTasks() does not work - ASF JIRA",
                "issue_description": "\nThe method context.getNumReduceTasks() is not mocked.\n"
            },
            "2": {
                "commit_sha_buggy": "2c24ab2af152bc7b41c4d52cba4883aacba40764",
                "commit_sha_fixed": "57196c39a73cf2251e0f2ba7da225731362407ba",
                "report_id": "MRUNIT-193",
                "report_url": "https://issues.apache.org/jira/browse/MRUNIT-193",
                "issue_title": "[MRUNIT-193] Serialization.copy throws NPE instead of ISE (missing serilization impl) for Hadoop 2.x - ASF JIRA",
                "issue_description": "\nThis may be the result of a refactoring. \nThe current code attempts to catch a NPE with the intent to detect a missing serialization implementation.\nHowever this behavior differs between Hadoop 1.x and 2.x\nHadoop 1.x will NPE in the first try/catch block, while 2.x will in the second.\n\n    try {\n      serializer = (Serializer<Object>) serializationFactory\n          .getSerializer(clazz);\n      deserializer = (Deserializer<Object>) serializationFactory\n          .getDeserializer(clazz);\n    } catch (NullPointerException e) {\n      throw new IllegalStateException(\n          \"No applicable class implementing Serialization in conf at io.serializations for \"\n              + orig.getClass(), e);\n    }\n    try {\n      final DataOutputBuffer outputBuffer = new DataOutputBuffer();\n      serializer.open(outputBuffer);\n      serializer.serialize(orig);\n      final DataInputBuffer inputBuffer = new DataInputBuffer();\n      inputBuffer.reset(outputBuffer.getData(), outputBuffer.getLength());\n      deserializer.open(inputBuffer);\n      return (T) deserializer.deserialize(copy);\n    } catch (final IOException e) {\n      throw new RuntimeException(e);\n    }\n\n\nHadoop 1.x \n\n  public <T> Serializer<T> getSerializer(Class<T> c) {\n    return getSerialization(c).getSerializer(c);\n  }\n\n\nHadoop 2.x\n\n  public <T> Serializer<T> getSerializer(Class<T> c) {\n    Serialization<T> serializer = getSerialization(c);\n    if (serializer != null) {\n      return serializer.getSerializer(c);\n    }\n    return null;\n  }\n\n\n"
            }
        }
    },
    "Rave_core": {
        "owner_repo": "apache/rave",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "48dc9356a8ca78e6c37adb2a6fa6a031c8598644",
                "commit_sha_fixed": "559bdaaa85cf18e8b57d4a850a87bcfd88740f19",
                "report_id": "RAVE-331",
                "report_url": "https://issues.apache.org/jira/browse/RAVE-331",
                "issue_title": "[RAVE-331] Error when trying to upload a duplicate gadget url to widget store - ASF JIRA",
                "issue_description": "\nHow to Reproduce\n--------------------------\n1) Login to Rave as any user\n2) Upload a gadget to the widget store - verify it was added successfully\n3) Go back and try to add the same gadget url again\n4) You will see the standard \"rave has suffered a brief meltdown\" page\nThe issue is that the DefaultWidgetService.registerNewWidget function returns a null Widget object if it finds the URL already in the system.  The RavePermissionEvaluator.hasPermission functions are not properly dealing with potential null objects and thus a NPE is thrown.\nHow to Fix\n----------------\n1) Improve the RavePermissionEvaluator.hasPermission methods to check for and safely handle possible null objects.\n"
            },
            "2": {
                "commit_sha_buggy": "0a4916025a995119e22313e2398935afaa549345",
                "commit_sha_fixed": "92ebd49c897911eb46843471ac94976415f58881",
                "report_id": "RAVE-723",
                "report_url": "https://issues.apache.org/jira/browse/RAVE-723",
                "issue_title": "[RAVE-723] Widget comment button seems to be working for only canonical user - ASF JIRA",
                "issue_description": "\nWhen you add a new widget or view a widget, the comment button seems to be working only for canonical user. Mayb it has something to do with autorization when comment is posted. Getting a forbidden response.\n"
            }
        }
    },
    "Rave_commons": {
        "owner_repo": "apache/rave",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cdcf2b000525dc07e1999cf2b37a6869366eca09",
                "commit_sha_fixed": "90cb88376366702ff098dfe9cd3b884b952d7ada",
                "report_id": "RAVE-502",
                "report_url": "https://issues.apache.org/jira/browse/RAVE-502",
                "issue_title": "[RAVE-502] Unable to load an initial_data.sql file in Oracle - ASF JIRA",
                "issue_description": "\nWhen loading an initial_data.sql file in Oracle the o.a.r.jdbc.util.DataSourcePopulator fails with an \"Invalid operation for forward only resultset : first\".  This is because the Statement is producing a non-scrollable ResultSet.\nFix:  Create the Statement with a ResultSet.TYPE_SCROLL_INSENSITIVE flag.\n"
            }
        }
    },
    "Rave_web": {
        "owner_repo": "apache/rave",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5923660ff5cca14233c38421fe9343f92a74a8e2",
                "commit_sha_fixed": "ad35fcefa7d2657b34d039df499288973c3c3674",
                "report_id": "RAVE-746",
                "report_url": "https://issues.apache.org/jira/browse/RAVE-746",
                "issue_title": "[RAVE-746] Cannot change preferences through admin interface - ASF JIRA",
                "issue_description": "\nLog in as canonical\nGo to admin interface\nGo to preferences\nClick on one of the preferences to edit\nResult is an error page\nStacktrace:\n[WARNING] [talledLocalContainer] Aug 03, 2012 11:36:26 AM org.apache.catalina.core.ApplicationDispatcher invoke\n[WARNING] [talledLocalContainer] SEVERE: Servlet.service() for servlet jsp threw exception\n[WARNING] [talledLocalContainer] org.springframework.beans.NullValueInNestedPathException: Invalid property 'initialWidgetStatus' of bean class [org.apache.rave.portal.web.model.PortalPreferenceForm]: Could not instantiate property type [org.apache.rave.portal.model.PortalPreference] to auto-grow nested property path: java.lang.InstantiationException: org.apache.rave.portal.model.PortalPreference\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.newValue(BeanWrapperImpl.java:655)\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.createDefaultPropertyValue(BeanWrapperImpl.java:625)\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.setDefaultValue(BeanWrapperImpl.java:614)\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.getNestedBeanWrapper(BeanWrapperImpl.java:579)\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.getBeanWrapperForPropertyPath(BeanWrapperImpl.java:553)\n[WARNING] [talledLocalContainer]        at org.springframework.beans.BeanWrapperImpl.getPropertyValue(BeanWrapperImpl.java:719)\n[WARNING] [talledLocalContainer]        at org.springframework.validation.AbstractPropertyBindingResult.getActualFieldValue(AbstractPropertyBindingResult.java:99)\n[WARNING] [talledLocalContainer]        at org.springframework.validation.AbstractBindingResult.getFieldValue(AbstractBindingResult.java:219)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.support.BindStatus.<init>(BindStatus.java:120)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.tags.BindTag.doStartTagInternal(BindTag.java:119)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.tags.RequestContextAwareTag.doStartTag(RequestContextAwareTag.java:79)\n[WARNING] [talledLocalContainer]        at org.apache.jsp.WEB_002dINF.jsp.views.admin.preferencedetail_jsp._jspService(preferencedetail_jsp.java:478)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:388)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:313)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:260)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:646)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.doInclude(ApplicationDispatcher.java:551)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.include(ApplicationDispatcher.java:488)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:968)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.runtime.PageContextImpl.doInclude(PageContextImpl.java:653)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.runtime.PageContextImpl.include(PageContextImpl.java:647)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.jsp.context.JspTilesRequestContext.include(JspTilesRequestContext.java:103)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.jsp.context.JspTilesRequestContext.dispatch(JspTilesRequestContext.java:96)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.TemplateAttributeRenderer.write(TemplateAttributeRenderer.java:44)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.AbstractBaseAttributeRenderer.render(AbstractBaseAttributeRenderer.java:106)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.ChainedDelegateAttributeRenderer.write(ChainedDelegateAttributeRenderer.java:76)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.AbstractBaseAttributeRenderer.render(AbstractBaseAttributeRenderer.java:106)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:670)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:336)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.template.InsertAttributeModel.renderAttribute(InsertAttributeModel.java:210)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.template.InsertAttributeModel.end(InsertAttributeModel.java:126)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.jsp.taglib.InsertAttributeTag.doTag(InsertAttributeTag.java:311)\n[WARNING] [talledLocalContainer]        at org.apache.jsp.WEB_002dINF.jsp.templates.base_005flayout_jsp._jspx_meth_tiles_005finsertAttribute_005f1(base_005flayout_jsp.java:225)\n[WARNING] [talledLocalContainer]        at org.apache.jsp.WEB_002dINF.jsp.templates.base_005flayout_jsp._jspService(base_005flayout_jsp.java:94)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:388)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:313)\n[WARNING] [talledLocalContainer]        at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:260)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:646)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:436)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:374)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:302)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.servlet.context.ServletTilesRequestContext.forward(ServletTilesRequestContext.java:241)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.servlet.context.ServletTilesRequestContext.dispatch(ServletTilesRequestContext.java:222)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.TemplateAttributeRenderer.write(TemplateAttributeRenderer.java:44)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.renderer.impl.AbstractBaseAttributeRenderer.render(AbstractBaseAttributeRenderer.java:106)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:670)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:690)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:644)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:627)\n[WARNING] [talledLocalContainer]        at org.apache.tiles.impl.BasicTilesContainer.render(BasicTilesContainer.java:321)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.view.tiles2.TilesView.renderMergedOutputModel(TilesView.java:124)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:262)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1180)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:950)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:852)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882)\n[WARNING] [talledLocalContainer]        at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:617)\n[WARNING] [talledLocalContainer]        at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:322)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:116)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:83)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:113)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:103)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:113)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.rememberme.RememberMeAuthenticationFilter.doFilter(RememberMeAuthenticationFilter.java:146)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:54)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:45)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilter(BasicAuthenticationFilter.java:150)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:182)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:182)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:105)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:87)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:184)\n[WARNING] [talledLocalContainer]        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:155)\n[WARNING] [talledLocalContainer]        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)\n[WARNING] [talledLocalContainer]        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:615)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)\n[WARNING] [talledLocalContainer]        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)\n[WARNING] [talledLocalContainer]        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859)\n[WARNING] [talledLocalContainer]        at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:602)\n[WARNING] [talledLocalContainer]        at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)\n[WARNING] [talledLocalContainer]        at java.lang.Thread.run(Thread.java:722)\n[WARNING] [talledLocalContainer] \n"
            }
        }
    },
    "Jmh_core": {
        "owner_repo": "openjdk/jmh",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ec0740c2bfa23041f247654bc6fbf6fab7a4a417",
                "commit_sha_fixed": "3b7bab948801128ef7d07aaacf0804f8a8c5d0d5",
                "report_id": "CODETOOLS-7902840",
                "report_url": "https://bugs.openjdk.java.net/browse/CODETOOLS-7902840",
                "issue_title": "Code ToolsCODETOOLS-7902840JMH: Fix *Statistics iterators to throw NoSuchElementException properly",
                "issue_description": "\n                    SonarCloud instance reports:\r\n\u00a0Add a \"NoSuchElementException\" for iteration beyond the end of the collection.\r\n\n...in places like:\r\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0@Override\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0public Map.Entry<Double, Long> next() {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return new AbstractMap.SimpleImmutableEntry<>(values[currentIndex++], 1L);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\r\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0@Override\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0public Map.Entry<Double, Long> next() {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0entryReturned = true;\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return new AbstractMap.SimpleImmutableEntry<>(value, 1L);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n            "
            }
        }
    },
    "Sdk_core": {
        "owner_repo": "IBM/java-sdk-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "6cd63c4f17e5145fcdedc91f26f2f2ca6f4dad95",
                "commit_sha_fixed": "386a772d0bb63b657e6ee6db21641b0f3d564ef0",
                "report_id": "15",
                "report_url": "https://github.com/IBM/java-sdk-core/pull/15",
                "issue_title": "Add method to just get system info",
                "issue_description": "This PR makes a small change to allow external packages to _just_ grab system information, which currently consists of the Java vendor, Java version OS architecture, OS name, and OS version.\r\n\r\nThis change is related to a Slack discussion that was had where we decided that by default, the core version would be included in the `User-Agent` header, but that if a `User-Agent` was provided by an external SDK, they could avoid appending the core version."
            },
            "2": {
                "commit_sha_buggy": "5e8e603470a9f16a8a09f8bd3a01cdea7754fcc6",
                "commit_sha_fixed": "a6d65419c4edccb039ea094e485fd4c8ba13f02c",
                "report_id": "75",
                "report_url": "https://github.com/IBM/java-sdk-core/pull/75",
                "issue_title": "fix: use correct json serialization for lists",
                "issue_description": "Fixes the case when a list formatted object is passed to the request builder. Now, this is converted to a string then passed to the content builder."
            },
            "3": {
                "commit_sha_buggy": "aa73a1197f0a945b6542c20b297712be7feae554",
                "commit_sha_fixed": "349ca1ad5bb8b59dfb3fbccf309be90e93740663",
                "report_id": "83",
                "report_url": "https://github.com/IBM/java-sdk-core/pull/83",
                "issue_title": "fix: surface ServiceResponseError outside of RuntimeError",
                "issue_description": "This PR will allow ServiceResponseErrors to be returned directly, as opposed to in the `causedBy:` of a RuntimeException."
            }
        }
    },
    "Cargo_container": {
        "owner_repo": "codehaus-cargo/cargo",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f162e15de7bdac4c9b8d54ac5868df49d146e921",
                "commit_sha_fixed": "6854b89b6ceab0b9c2307e4ca0b882493b39fb8b",
                "report_id": "CARGO-778",
                "report_url": "https://codehaus-cargo.atlassian.net/browse/CARGO-778",
                "issue_title": "remove the geronimo1x exceptions (it doesn't pass anything, can't get worse anyway!)",
                "issue_description": "remove the geronimo1x exceptions (it doesn't pass anything, can't get worse anyway!)"
            },
            "2": {
                "commit_sha_buggy": "4dcaebd43d87ce887a907d7910481fafd1ec42f1",
                "commit_sha_fixed": "a8b19f14578e29129538f0d2a24b0d06c4025463",
                "report_id": "CARGO-581",
                "report_url": "https://codehaus-cargo.atlassian.net/browse/CARGO-581",
                "issue_title": "JBoss 6 has been released, 2010-12-29 12:12:33",
                "issue_description": "JBoss 6 has been released, 2010-12-29 12:12:33"
            },
            "3": {
                "commit_sha_buggy": "d76a1d003bbe41b59d565f87eb71c704f4332e60",
                "commit_sha_fixed": "f2743efe68588ce97007d859a0d3bab89b90d976",
                "report_id": "CARGO-526",
                "report_url": "https://codehaus-cargo.atlassian.net/browse/CARGO-526",
                "issue_title": "Sort the profiles in various archetypes in the same order to make it look nicer",
                "issue_description": "Sort the profiles in various archetypes in the same order to make it look nicer"
            },
            "4": {
                "commit_sha_buggy": "cf7184c441ee78e0e6a22f974b573ffa58057b8f",
                "commit_sha_fixed": "d832b004e144c71da69f0495a13b36b33912d964",
                "report_id": "CARGO-1131",
                "report_url": "https://codehaus-cargo.atlassian.net/browse/CARGO-1131",
                "issue_title": "Added a new ANT sample for configuration files",
                "issue_description": "Added a new ANT sample for configuration files"
            }
        }
    },
    "Oak_commons": {
        "owner_repo": "apache/jackrabbit-oak",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2b62838ae3876fed42c82cb5655a89fe60afca4d",
                "commit_sha_fixed": "05caed7a20b128119f02eaa810b3dbda6328b8ec",
                "report_id": "OAK-888",
                "report_url": "https://issues.apache.org/jira/browse/OAK-888",
                "issue_title": "[OAK-888] PathUtils#getDepth returns 1 for empty path - ASF JIRA",
                "issue_description": "\nPathUtils#getDepths that the root path / has depth 0.\nhowever, passing in a empty string is accepted and returns 1.\naccording to the API contract getDepth is counting the number of elements\nin the path which for \"\" should IMO be zero.\n"
            }
        }
    },
    "Streamex": {
        "owner_repo": "amaembo/streamex",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "6540b17c9583ee9d01250c9779402f26b5f04d41",
                "commit_sha_fixed": "8ded57a542b33e87d16b0c2bf5e9994ba20c9e20",
                "report_id": "54",
                "report_url": "https://github.com/amaembo/streamex/issues/54",
                "issue_title": "Implement headTail(): map (head, tailStream) to another stream",
                "issue_description": "Extracted from #50 as it's substantially different feature.\n\nThe following method is proposed:\n\n```\nclass StreamEx<T> {\n    // Return StreamEx which is the result of applying the mapper function to the first\n    // stream element and the stream of the rest elements; the mapper function is applied \n    // at most once during the terminal operation execution\n    <U> StreamEx<U> headTail(BiFunction<T, StreamEx<T>, Stream<U>> mapper) { ... };\n\n    // Supplier is called if this stream is empty\n    <U> StreamEx<U> headTail(BiFunction<T, StreamEx<T>, Stream<U>> mapper, Supplier<Stream<U>> supplier) { ... };\n}\n```\n\nSuch method is really flexible (it allows to implement most of other intermediate operations). The drawback is that it cannot be parallelized well (only poor-man buffered parallelization could be performed) and recursive usage eats the stack (which could be partially solved if TSO can be implemented for some spliterators).\n\nUsage examples.\n\n**Prime numbers:**\n\n```\nstatic StreamEx<Integer> sieve(StreamEx<Integer> input) {\n    return input.withFirst((head, tail) -> sieve(tail.filter(n -> n % head != 0))\n                      .prepend(head));\n}\n\nsieve(StreamEx.iterate(2, x -> x+1)).takeWhile(x -> x < 10000).forEach(System.out::println);\n```\n\n**Lazy scanLeft:**\n\n```\nstatic <T> StreamEx<T> scanLeft(StreamEx<T> input, BinaryOperator<T> operator) {\n    return input.headTail((head, tail) -> \n        scanLeft(tail.mapFirst(cur -> operator.apply(head, cur)), operator)\n            .prepend(head));\n}\n```\n\n**Revert stream:**\n\n```\nstatic <T> StreamEx<T> reverse(StreamEx<T> input) {\n    return input.headTail((head, tail) -> reverse(tail).append(head));\n}\n```\n\n**takeWhile op implementation:**\n\n```\nstatic <T> StreamEx<T> takeWhile(StreamEx<T> input, Predicate<T> predicate) {\n    return input.headTail((head, tail) -> predicate.test(head) ? \n                 takeWhile(tail, predicate).prepend(head) : null );\n}\n```\n\n**takeWhileClosed (including the first violating element):**\n\n```\nstatic <T> StreamEx<T> takeWhileClosed(StreamEx<T> input, Predicate<T> predicate) {\n    return input.headTail((head, tail) -> predicate.test(head) ? \n            ? takeWhileClosed(tail, predicate).prepend(head)\n            : Stream.of(head));\n}\n```\n\n**cycle - infinitely cycles the input, lazy**\n\n```\nstatic <T> StreamEx<T> cycle(StreamEx<T> input) {\n    return input.headTail((head, tail) -> cycle(tail.append(head)).prepend(head));\n}\n```\n\n**mirror - this stream, then reversed stream, also lazy**\n\n```\nstatic <T> StreamEx<T> mirror(StreamEx<T> input) {\n    return input.headTail((head, tail) -> mirror(tail).append(head).prepend(head));\n}\n```\n\n**every - take every nth element**\n\n```\nstatic <T> StreamEx<T> every(StreamEx<T> input, int n) {\n    return input.headTail((head, tail) -> every(tail.skip(n-1), n).prepend(head) );\n}\n```\n\n**the first stream element if nothing matches the predicate; the first matching otherwise**\n\n```\nstatic <T> T firstMatchingOrFirst(StreamEx<T> stream, Predicate<T> predicate) {\n    return stream.headTail(\n          (head, tail) -> tail.prepend(head).filter(predicate).append(head))\n                    .findFirst().get();\n}\n```\n\n**stream of singleton lists to stream of fixed-size batches**\n\n```\nstatic <T> StreamEx<List<T>> batches(StreamEx<List<T>> input, int size) {\n    return input.headTail((head, tail) -> head.size() >= size ? \n        batches(tail, size).prepend(head) : \n        batches(tail.mapFirst(next -> StreamEx.of(head, next).toFlatList(l -> l)), size));\n}\n```\n\n**stream of singleton lists to stream of sliding windows**\n\n```\nstatic <T> StreamEx<List<T>> sliding(StreamEx<List<T>> input, int size) {\n    return input.headTail((head, tail) -> head.size() == size ? \n        sliding(tail.mapFirst(next -> StreamEx.of(head.subList(1, size), next)\n              .toFlatList(l -> l)), size).prepend(head) : \n        sliding(tail.mapFirst(next -> StreamEx.of(head, next).toFlatList(l -> l)), size));\n}\n```\n\nPrimitive specializations also could be implemented using `BiFunction<Integer, IntStreamEx, IntStream> mapper`, etc. (postponed)\n- [x] Implementation\n- [x] JavaDoc\n- [x] TSO implementation (Tail-stream optimization)\n- [x] TSO documentation\n- [x] Tests\n- [x] Examples\n- [x] Changes\n- [x] Cheatsheet\n"
            },
            "2": {
                "commit_sha_buggy": "760976f6291e9c69cee61f4363efcff8acecf188",
                "commit_sha_fixed": "9672cb18b708ee009c88c82c80af96d5f3937e95",
                "report_id": "55",
                "report_url": "https://github.com/amaembo/streamex/issues/55",
                "issue_title": "Replace PrependSpliterator with TailConcatSpliterator",
                "issue_description": "Currently only `StreamEx.prepend(T...)` is TSO-optimized which is inconvenient sometimes. It would be better to reimplement the standard `.concat` operation fully with our own `TailConcatSpliterator` which will concatenate two streams and work as TSO for the second one.\n\nOther improvements which could be implemented here:\n- Do not create unnecessary close handlers.\n- Do not concatenate with SIZED/empty source: just wrap the original stream.\n- Use TSO internally, so the long series of `prepend` calls would not lead to StackOverflow error (though it would not work with `append`, but we can also consider \"rotating\" or even truly balancing the concatenation tree).\n\nPrimitive specializations could be postponed as we have no primitive `headTail` yet.\n\nRelated to #54.\n- [x] Implementation\n- [x] Additional tests\n- [x] Documentation updates\n- [x] Changes\n"
            },
            "3": {
                "commit_sha_buggy": "ace9f29fe9eaea9003a2a25cd7595617bc392986",
                "commit_sha_fixed": "40f00795cc74ab10c9ffa1f96956df09109c2fed",
                "report_id": "57",
                "report_url": "https://github.com/amaembo/streamex/issues/57",
                "issue_title": "Defer JDK stream creation until necessary and merge Custom* streams with normal ones",
                "issue_description": "A big refactoring effort could be made to defer creation of JDK stream until it's really necessary. This would allow to stick with spliterators for most of sources and quasi-intermediate operations and sometimes don't create Stream at all. For example `StreamEx.of(array).pairMap(blahblah).forEach(blahblah)`.\n\nThis also assumes merging `CustomStreamEx` and friends into their parents eliminating several classes (and actually reducing the library size a little bit).\n"
            },
            "4": {
                "commit_sha_buggy": "e4fef072a1924c1ecf4f4a9c336feab853759951",
                "commit_sha_fixed": "26c29a0adf50a4db61d20ec2a35c5d6a27acc738",
                "report_id": "59",
                "report_url": "https://github.com/amaembo/streamex/issues/59",
                "issue_title": "Restore PrependSpliterator",
                "issue_description": "While `TailConcatSpliterator` is implemented (see #55) and useful, the `PrependSpliterator` which allows adding exactly one element at the beginning of the stream is very important use case for `headTail` scenarios (see #54). As recursively defined operations may use `prepend` for every single element, it's significant allocation pressure to create `TailConcatSpliterator` and `ArraySpliterator` every time. Replacing them both with simple `PrependSpliterator` reduces allocation and improves overall performance of recursive `headTail` operations.\n- [x] Implement `StreamEx.prepend(T)` and `StreamEx.append(T)` (for symmetry)\n- [x] Implement `PrependSpliterator`\n- [x] JavaDoc for new methods\n- [x] Tests\n- [x] Changes\n"
            },
            "5": {
                "commit_sha_buggy": "cdcd4ec897340cd26c8c6eda08375967bb68680d",
                "commit_sha_fixed": "c63b210d454360d63f298fae01ed095d90a1ab5e",
                "report_id": "71",
                "report_url": "https://github.com/amaembo/streamex/issues/71",
                "issue_title": "Empty collector fails when used with JDK Stream",
                "issue_description": "Here's test code which fails:\n\n```\nList<Integer> list = Arrays.asList(1, 2, 3).stream().collect(MoreCollectors.head(0));\n```\n\nThe problem is that the collector incorrectly reports `IDENTITY_FINISH` characteristic.\n"
            },
            "6": {
                "commit_sha_buggy": "c7c7ae7dcfcc34e55857c9168ff2037b6c324325",
                "commit_sha_fixed": "a3f1ddfcc9947d7ccfab282e59b53d0f1516a802",
                "report_id": "201",
                "report_url": "https://github.com/amaembo/streamex/pull/201",
                "issue_title": "Improve StreamEx coverage",
                "issue_description": "PIT 1.4.3 (default mutators): 100% line and mutation coverage of StreamEx by StreamExTest"
            },
            "7": {
                "commit_sha_buggy": "6b6bbf5202e13e021872113d80881ae10c7414db",
                "commit_sha_fixed": "c86dd7ad4c07011a80a21fb0f850c84b9a480a17",
                "report_id": "51",
                "report_url": "https://github.com/amaembo/streamex/issues/51",
                "issue_title": "StreamEx.parallel(fjp).runLengths() fails to run the task in the specified pool",
                "issue_description": "`runLengths()` method creates normal `EntryStream` instead of using the appropriate strategy.\n"
            }
        }
    },
    "RTree": {
        "owner_repo": "davidmoten/rtree",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bcd1193fbf765eda32b94e2d54b09e978ad39cc6",
                "commit_sha_fixed": "adc99ad31b7a1b4debe74e84121c054c733cc829",
                "report_id": "28",
                "report_url": "https://github.com/davidmoten/rtree/issues/28",
                "issue_title": "Longitude -180 normalized to 180",
                "issue_description": "I encountered a problem using the R-Tree and the root cause appeared to be that `Geometries.normalizeLongitude` was adjusting -180 to 180. \n\nThat seems to contradict the [documentation](https://github.com/davidmoten/rtree#geospatial-geometries-lats-and-longs), which indicates that longitudes are normalized to [-180, 180).\n\nThanks!\n"
            },
            "2": {
                "commit_sha_buggy": "f158eab63606b7339bf6f94e3f6ded9b031f7257",
                "commit_sha_fixed": "bb3b0b3b773630a286a9e16797aad2861ebf0765",
                "report_id": "34",
                "report_url": "https://github.com/davidmoten/rtree/issues/34",
                "issue_title": "Util.mbr() issues with negative numbers such as negative longitudes",
                "issue_description": "Float.MIN_VALUE is \"the smallest positive nonzero value of type float\". This causes issues with negative values. In particular, I noticed in my tests that a negative longitude value was resulting in a maxX2 (and resulting Rectangle x2) value of 1.4E-45.\n\nPlease consider changing from:\n\nfloat maxX2 = Float.MIN_VALUE;\nfloat maxY2 = Float.MIN_VALUE;\n\nto:\n\nfloat maxX2 = -Float.MAX_VALUE;\nfloat maxY2 = -Float.MAX_VALUE;\n"
            },
            "3": {
                "commit_sha_buggy": "271e224c8aefce9fa9bb7dc2859bec2529eb07b9",
                "commit_sha_fixed": "7e53efecdebff95c8e3bd6911cee6843e381d0fd",
                "report_id": "38",
                "report_url": "https://github.com/davidmoten/rtree/issues/38",
                "issue_title": "Tree hangs when finding the nearest ",
                "issue_description": "I have the following example:\n\n```\nimport com.github.davidmoten.rtree.RTree;\nimport com.github.davidmoten.rtree.geometry.Geometries;\nimport com.github.davidmoten.rtree.geometry.Line;\n\npublic class TreeExample {\n\n    public static void main(String[] args) {\n\n        RTree<String, Line> tree = RTree.star().create();\n\n        for(int i = 0; i < 5;++i) {\n            tree = tree.add(String.format(\"Hello %d\", i), Geometries.line(-i, -i, 5 + i, i));\n        }\n\n        System.out.println(tree.nearest(Geometries.point(2, 0.4), Double.MAX_VALUE, 1)\n                .toBlocking().single().value());\n\n    }\n}\n```\n\nUnfortunately the program hangs and I never get any output. Any ideas what is causing this?\n\nI am using the following version:\n\n```\n<dependency>\n  <groupId>com.github.davidmoten</groupId>\n  <artifactId>rtree</artifactId>\n  <version>0.7.2</version>\n</dependency>\n<dependency>\n  <groupId>com.vividsolutions</groupId>\n  <artifactId>jts-core</artifactId>\n  <version>1.14.0</version>\n</dependency>\n```\n"
            },
            "4": {
                "commit_sha_buggy": "3f5a55d7fa0308cb7ceac846a2ae24be8799e0a8",
                "commit_sha_fixed": "c74e1b397b7caa3771c679eaf48b4d95c18cded4",
                "report_id": "40",
                "report_url": "https://github.com/davidmoten/rtree/issues/40",
                "issue_title": "groupBy hangs (0.7.5)",
                "issue_description": "Hello, after last update groupBy is not working anymore,\nhere is the test for it\n\n``` java\n    @Test(timeout = 1000)\n    public void testGroupBy() {\n        RTree<Integer, Geometry> tree = RTree.star().create();\n\n        tree = tree.add(1, Geometries.point(13.0, 52.0));\n        tree = tree.add(2, Geometries.point(13.0, 52.0));\n        tree = tree.add(3, Geometries.point(13.0, 52.0));\n        tree = tree.add(4, Geometries.point(13.0, 52.0));\n        tree = tree.add(5, Geometries.point(13.0, 52.0));\n        tree = tree.add(6, Geometries.point(13.0, 52.0));\n\n        Rectangle rectangle = Geometries.rectangle(12.9, 51.9, 13.1, 52.1);\n        assertEquals(Integer.valueOf(6), tree.search(rectangle).count().toBlocking().single());\n        assertEquals(Integer.valueOf(2), tree.search(rectangle)\n                .groupBy(new Func1<Entry<Integer, Geometry>, Boolean>() {\n                    @Override\n                    public Boolean call(Entry<Integer, Geometry> entry) {\n                        return entry.value() % 2 == 0;\n                    }\n                })\n                .flatMap(new Func1<GroupedObservable<Boolean, Entry<Integer, Geometry>>, Observable<Integer>>() {\n                    @Override\n                    public Observable<Integer> call(GroupedObservable<Boolean, Entry<Integer, Geometry>> group) {\n                        return group.count();\n                    }\n                })\n                .count()\n                .toBlocking()\n                .single());\n    }\n```\n"
            },
            "5": {
                "commit_sha_buggy": "14fd4d1e62c4354ab9d11fbf76a02950887c12ea",
                "commit_sha_fixed": "75da48987d7235afe1cfc970df4717c6f1c2f957",
                "report_id": "60",
                "report_url": "https://github.com/davidmoten/rtree/issues/60",
                "issue_title": "Point.contains() method is always true",
                "issue_description": "Hello davidmoten\n\nI think this **contains()** is always true.\nSo, I think there is need change to this.x and this.y.\n\n```\n    @Override\n    public boolean contains(double x, double y) {\n        return x == x && y == y;\n    }\n```\n\nin here\nhttps://github.com/davidmoten/rtree/blob/master/src/main/java/com/github/davidmoten/rtree/geometry/Point.java#L121\n\nThanks.\n"
            },
            "6": {
                "commit_sha_buggy": "236680b5ce46a14265b5c027356c66d2ee9d9f8b",
                "commit_sha_fixed": "8786a08157f31ccd61ed75437912a9a4c3b21b48",
                "report_id": "91",
                "report_url": "https://github.com/davidmoten/rtree/issues/91",
                "issue_title": "Incorrect result for horizontal line search",
                "issue_description": "Hi,\r\nThanks for this awesome library, with lots of cool features.\r\n\r\nI found the search result for horizontal line is empty, might because it got a special bound box which height value is 0. Thus the **RectangleUtil.outcode()** always return OUT_TOP | OUT_BOTTOM.\r\n\r\nHere's my test code:\r\n<pre name=\"code\" class=\"java\"> \r\nRTree<Integer, Line> rtree = RTree.star().create();\r\nLine simLine = Geometries.line(40.0d, -20.0d, 45.0d, -40.0d);\r\nrtree = rtree.add(1, simLine);\r\nLine segLine = Geometries.line(35.0d, -25.0d, 45.0d, -25.0d);\r\nList<Entry<Integer, Line>> result = rtree.search(segLine)\r\n            .toList()\r\n            .toBlocking()\r\n            .single();\r\n</pre>\r\n"
            },
            "7": {
                "commit_sha_buggy": "6798826689a85050c248dac32879518c910cf1a9",
                "commit_sha_fixed": "3cb0490709bb98d49990d49113009a4951aff5d8",
                "report_id": "92",
                "report_url": "https://github.com/davidmoten/rtree/pull/92",
                "issue_title": "fix intersection with zero area rectangles",
                "issue_description": "See discussion in #91.\r\n\r\nI've started with rectangleIntersectsLine. Might have to check rectangle intersects rectangle case too."
            },
            "8": {
                "commit_sha_buggy": "3adeb4ce0109eba6c109a0b99435bfc9ad9bb861",
                "commit_sha_fixed": "8617933a0707533f75521e0043edf0971160f9c3",
                "report_id": "1",
                "report_url": "https://github.com/davidmoten/rtree/pull/1",
                "issue_title": "ensure fast path can only be requested once",
                "issue_description": "need to set requested to Long.MAX_VALUE to prevent repeated calls of fast path\n"
            },
            "9": {
                "commit_sha_buggy": "81a212e43e9649cf6181a6ef40572ee180509826",
                "commit_sha_fixed": "98bac668a8b3856d18ca6037886c4e7361d25d33",
                "report_id": "21",
                "report_url": "https://github.com/davidmoten/rtree/issues/21",
                "issue_title": "RTree.nearest does not return in ascending order of distance",
                "issue_description": "As raised by @virtuald, the use of a Guava `MinMaxPriorityQueue` and its iterator under the covers means that there is no guarantee of ascending order of distance. \n\nThe fix will likely be to not use the iterator to emit the elements but rather poll in a loop.\n"
            },
            "10": {
                "commit_sha_buggy": "b17a51128636b6cbc24935c3eb2f33612dca1f7e",
                "commit_sha_fixed": "7019ef296bf1fa731ccea37eed2224d79618e62d",
                "report_id": "33",
                "report_url": "https://github.com/davidmoten/rtree/pull/33",
                "issue_title": "Use JTS for Line Geometry methods",
                "issue_description": "Use JTS for Line geometry methods\n"
            },
            "11": {
                "commit_sha_buggy": "c0844a65fb081ffa1657ba98c96052ec74002bca",
                "commit_sha_fixed": "16400fc53d776a352ca65390c5e93e4e479f3d32",
                "report_id": "50",
                "report_url": "https://github.com/davidmoten/rtree/issues/50",
                "issue_title": "Deserialization bug",
                "issue_description": "Using 0.8-RC7, I've seen the following problem when trying to deserialize a tree:\n\n```\nCaused by: java.lang.RuntimeException: unexpected\n    at com.github.davidmoten.rtree.fbs.SerializerFlatBuffers.readFully(SerializerFlatBuffers.java:165)\n    at com.github.davidmoten.rtree.fbs.SerializerFlatBuffers.read(SerializerFlatBuffers.java:123)\n```\n\nThe error occurs here:\n\n```\n    @VisibleForTesting\n    static byte[] readFully(InputStream is, int numBytes) throws IOException {\n        byte[] b = new byte[numBytes];\n        int n = is.read(b);\n        if (n != numBytes)\n            throw new RuntimeException(\"unexpected\");\n        return b;\n    }\n```\n\nI believe the contract of InputStream.read(byte[]) does not always do full reads, there should be some form of loop here to retry. I've seen such errors before.\n\nDo let me know if I'm missing something.\n"
            },
            "12": {
                "commit_sha_buggy": "b16d1378ac07fc33fb25533988103d8ada6faafb",
                "commit_sha_fixed": "2beeb6fbe649b3d099004d5b024a085b0b9a90d4",
                "report_id": "81",
                "report_url": "https://github.com/davidmoten/rtree/issues/81",
                "issue_title": "Possible Issue on delete",
                "issue_description": "Hello,\r\nI believe there is a bug on delete. The following code worked up to the 0.8-RC10 version:\r\nval newT=tree.delete(obj, Geometries.pointGeographic((long).toDouble, (lat).toDouble))\r\nUpdating to 0.8.5 makes this code stop working, with the new tree returning the same size as the former.\r\nTrying things out, I found the problem to be related with the generation of points, which somehow don't get recognized now. I tried searching for my point through the search method and testing different combinations and these are my findings (myValue and myGeometry are the ones I create, while value and geometry are the ones returned from the searched object):\r\ntree.delete(myValue, geometry) -> Works\r\ntree.delete(value, myGeometry) -> Doesn't Work\r\ntree.delete(myValue, myGeometry) -> Doesn't Work\r\ntree.delete(value, geometry) -> Works"
            }
        }
    },
    "Javapoet": {
        "owner_repo": "square/javapoet",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5fd4670eb4ea534ae25261eaba7bc3f0075a1ec1",
                "commit_sha_fixed": "5a34049e7ce96c334077db15459b05257af2a9e3",
                "report_id": "5",
                "report_url": "https://github.com/square/javapoet/pull/5",
                "issue_title": "adds support for wildcard static imports, fixed up invalid code",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "737879fb79e3cbc17fe6808e4b6b62e94df6168d",
                "commit_sha_fixed": "17605c52dfe212a4b9d205f32097e752027fbd0d",
                "report_id": "8",
                "report_url": "https://github.com/square/javapoet/issues/8",
                "issue_title": "address simple name collisions in compressType",
                "issue_description": "When there exists the same named simple type in the package of the class being written and also imports, parameterized types should retain the package.\n\nFailing test case below:\n\n```\n@Test public void compressSimpleNameCollisionInSamePackage() throws IOException {\n    javaWriter.emitPackage(\"denominator\");\n    javaWriter.emitImports(\"javax.inject.Provider\", \"dagger.internal.Binding\");\n    String actual = javaWriter.compressType(\"dagger.internal.Binding<denominator.Provider>\");\n    assertThat(actual).isEqualTo(\"Binding<denominator.Provider>\");\n  }\n```\n"
            },
            "3": {
                "commit_sha_buggy": "737879fb79e3cbc17fe6808e4b6b62e94df6168d",
                "commit_sha_fixed": "834f118d58933a531787fcc59681a8e631b4f03e",
                "report_id": "9",
                "report_url": "https://github.com/square/javapoet/pull/9",
                "issue_title": "retain package when simple name ambiguous in compressType",
                "issue_description": "fix issue #8: retain package when simple name ambiguous in compressType\n"
            },
            "4": {
                "commit_sha_buggy": "087d2d7983f27e5a405cbd7aa31d6f098b91c13f",
                "commit_sha_fixed": "7d57a5909c7c54502db6ffa27ea0ccc08d0cd696",
                "report_id": "6",
                "report_url": "https://github.com/square/javapoet/issues/6",
                "issue_title": "End of Line Comment Limited Use",
                "issue_description": "The end-of-line comment has little value with it's current behavior.\n\n``` java\nw.emitStatement(\"foo()\");\nw.emitEndOfLineComment(\"Call foo!\");\n```\n\nproduces something like:\n\n``` java\n    ...\n    foo();\n// Call foo!\n    ...\n```\n\nIts Javadoc is also wrong.\n"
            },
            "5": {
                "commit_sha_buggy": "9f648476fdd63a1d34997e45ab49d696ad305706",
                "commit_sha_fixed": "7cf6e171e1309364cd12f73ecce33ce3a6911cdb",
                "report_id": "40",
                "report_url": "https://github.com/square/javapoet/pull/40",
                "issue_title": "Properly handle subpackages of java.lang in compressType.",
                "issue_description": "Previously, all types prefixed by java.lang would have the java.lang prefix\nremoved even if they weren't in that package leading to invalid types in\nthe written source.\n\nThis fixes issue #39\n"
            },
            "6": {
                "commit_sha_buggy": "c5de70d09debc3aa90819b073a596f652fd5117e",
                "commit_sha_fixed": "181c7ca6d6fe328628b855bdf9582b238bf7d896",
                "report_id": "49",
                "report_url": "https://github.com/square/javapoet/pull/49",
                "issue_title": "Support interface method declarations.",
                "issue_description": "1. Used `INTERFACE_DECLARATION` to keep track of scope.\n2. Emitters are not ignored.\n"
            },
            "7": {
                "commit_sha_buggy": "2dccc7175cd0cf6bfca7f047cb10717f54d16376",
                "commit_sha_fixed": "cb24911fdcfe3a96a54c30f5f63871a7f03c16f9",
                "report_id": "55",
                "report_url": "https://github.com/square/javapoet/pull/55",
                "issue_title": "Skip work when modifier set is empty.",
                "issue_description": "This both avoids an exception from EnumSet.copyOf when empty and avoids wasting an iterator on looping over an empty set.\n\nCloses #52.\n"
            },
            "8": {
                "commit_sha_buggy": "edb9565883a140c635aac17dbcb5555c20d143b7",
                "commit_sha_fixed": "6fff17a988deb4e0d8c35cf6b7607d7db83035ff",
                "report_id": "60",
                "report_url": "https://github.com/square/javapoet/pull/60",
                "issue_title": "Use canonical class name when importing as class.",
                "issue_description": "`emitImports(Parent.Nested.class)` would write `import some.pkg.Parent$Nested;`. Even though it's valid import, having `.` instead of `$` is more natural and keeps compressing `some.pkg.Parent.Nested` occurrences correctly.\n"
            },
            "9": {
                "commit_sha_buggy": "8131bca7ca212199102a3cc2567dad731f8e54f3",
                "commit_sha_fixed": "1249d23d0ea84130d28640b08866d25f9169ae17",
                "report_id": "16",
                "report_url": "https://github.com/square/javapoet/pull/16",
                "issue_title": "Modify emitAnnotation to elide the \"value\" key\u2026",
                "issue_description": "\u2026in annotation declarations for annotations with a single value attribute.\nE.g.:\n@Generated(\"blah.Generator\")\ninstead of\n@Generated(value = \"blah.Generator\")\n"
            },
            "10": {
                "commit_sha_buggy": "c567dc6891837ab745c557e6f3d9cf1c42c00e5a",
                "commit_sha_fixed": "c37943b7be8ab364f4eeed9453a06679082a433c",
                "report_id": "20",
                "report_url": "https://github.com/square/javapoet/pull/20",
                "issue_title": "Fix JavaWriter.stringLiteral",
                "issue_description": "JavaWriter.stringLiteral did not handle escapes correctly. Fixing the bug and extending to support escaping of control chars.\n"
            },
            "11": {
                "commit_sha_buggy": "bb64e88ef6b1d1c95c7891586e4f95c834274759",
                "commit_sha_fixed": "9d72297471d954536e2898fb37ef23300f0628ac",
                "report_id": "21",
                "report_url": "https://github.com/square/javapoet/pull/21",
                "issue_title": "Try to keep annotations on a single line",
                "issue_description": "@swankjesse \n"
            },
            "12": {
                "commit_sha_buggy": "1cd91ed6bd46557e7ca23145e99353b7ca7cde38",
                "commit_sha_fixed": "01b43708337a55f54a2b1b8717d5da20670f327c",
                "report_id": "30",
                "report_url": "https://github.com/square/javapoet/pull/30",
                "issue_title": "Do not emit trailing white-space for empty javadoc lines.",
                "issue_description": "This occurs when multiple newlines are present. While the HTML-rendered Javadoc will collapse these, we preserve them for the sake of continuity with input.\n\n@swankjesse @danrice-square\n"
            },
            "13": {
                "commit_sha_buggy": "ad9cbcdeba94925bf7fbf7f0995bca795c5e6ccf",
                "commit_sha_fixed": "98f792d249948ae559f7ef99a84fedeb6c799f11",
                "report_id": "38",
                "report_url": "https://github.com/square/javapoet/pull/38",
                "issue_title": "Fix an issue introduced when adding constructor scope.",
                "issue_description": ""
            },
            "14": {
                "commit_sha_buggy": "e66d8ba46f82eaa4bd1842dfa8fcfb5fe1d2ead1",
                "commit_sha_fixed": "270570874f5b8697768d5fc4e1fd20964387cd45",
                "report_id": "41",
                "report_url": "https://github.com/square/javapoet/pull/41",
                "issue_title": "Properly indent newlines in fields.",
                "issue_description": ""
            },
            "15": {
                "commit_sha_buggy": "cb24911fdcfe3a96a54c30f5f63871a7f03c16f9",
                "commit_sha_fixed": "93ddadf971a8504ff1781f045d9e0e7520f7c246",
                "report_id": "56",
                "report_url": "https://github.com/square/javapoet/pull/56",
                "issue_title": "Don't emit a trailing space after '=' at end-of-line",
                "issue_description": "@JakeWharton \n"
            },
            "16": {
                "commit_sha_buggy": "66c9095d027da6aad0ad7cc24e01422beedf901b",
                "commit_sha_fixed": "d39761f9ec25ca5bf3b7bf15d34fa2b831fed9c1",
                "report_id": "64",
                "report_url": "https://github.com/square/javapoet/pull/64",
                "issue_title": "Automatically compress varargs and array types.",
                "issue_description": "Closes #63.\n"
            },
            "17": {
                "commit_sha_buggy": "5f4068a054d3e03d59a94862f34b384d79dc3b6d",
                "commit_sha_fixed": "c567dc6891837ab745c557e6f3d9cf1c42c00e5a",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix JavaWriter.stringLiteral",
                "issue_description": "Fix JavaWriter.stringLiteral"
            }
        }
    },
    "Spoon": {
        "owner_repo": "INRIA/spoon",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e38a9c9936106caa8c3fae7b498c07a04a79c203",
                "commit_sha_fixed": "771f63588bb5e2e3069446dad6420207b7e71aaa",
                "report_id": "8",
                "report_url": "https://github.com/INRIA/spoon/pull/8",
                "issue_title": "CompositeFilter had some problems. Those problems where replicated in 4 ...",
                "issue_description": "...new test cases for FilterTest class. A patch has been offered to correct the INTERSECTION and UNION cases (not the SUBSTRACTION case, which might still be faulty).\n"
            },
            "2": {
                "commit_sha_buggy": "ed6d1b711c36c8f33a3883fa7342e81eebd97761",
                "commit_sha_fixed": "261fb25a9ef8eb8c9175915b01e16b9c94646f52",
                "report_id": "22",
                "report_url": "https://github.com/INRIA/spoon/pull/22",
                "issue_title": "fixes bug when pretty-printing an invocation",
                "issue_description": "- reorganized folders\n- the class file is now in a *jar, so now it can stay in \"stc/test/resources\"\n"
            },
            "3": {
                "commit_sha_buggy": "8480f4da5dd5ea6cbb64224c3dea30857a04f05f",
                "commit_sha_fixed": "1e3c6589ac82410b09299f5ca9614342a00e5e41",
                "report_id": "35",
                "report_url": "https://github.com/INRIA/spoon/pull/35",
                "issue_title": "Annotation values bug",
                "issue_description": "This pull contributes some test cases for issue #30.\n"
            },
            "4": {
                "commit_sha_buggy": "134fe1c2fdb2917fe37d9a6370dc083113d4a3bd",
                "commit_sha_fixed": "cf41e72c0c2e12b71099725fc9eb4d19689ae076",
                "report_id": "40",
                "report_url": "https://github.com/INRIA/spoon/pull/40",
                "issue_title": "Test and fix for a bug with getAllExecutables() that does not recurse into the type hierarchy for CtInterface.",
                "issue_description": "Subject says it all.\n\nThis pull request comes with a fix ... and a test (private joke for @monperrus)\n\nLionel.\n"
            },
            "5": {
                "commit_sha_buggy": "35bb2f2af8d9194b3672bfc1518552bbeb5dff4f",
                "commit_sha_fixed": "52fe7dcaffbbd18f3d4046de11e7961b95708e8a",
                "report_id": "44",
                "report_url": "https://github.com/INRIA/spoon/pull/44",
                "issue_title": "fixes a CtPackage problem",
                "issue_description": "This pull request fixes a problem related to the packages. \nA package which contains a package-info.java file doesn't have a SourceReference instance. This pr adds the information of the SourceReference to the package if a package-info.java file exists.\nFurthermore if an CtElement doesn't have a SourceReference info, the implementation tries to load the information of the parent element. This doesn't work for packages. The parent element of a package is another package and it's package-java.file isn't related to the current package. Therefore I override the method within the CtPackageImpl, which just returns the own SourcePosition. \n\nEdit:\nThe second commit adds JavaDoc to the CtPackage instances. \n"
            },
            "6": {
                "commit_sha_buggy": "6d56ade6ad5466dff8450c7c1f07ec3dff828fe2",
                "commit_sha_fixed": "bf6240dfd8d7f86b6a4e689cacc74c620214f694",
                "report_id": "49",
                "report_url": "https://github.com/INRIA/spoon/pull/49",
                "issue_title": "supports creation of  spoon objects on the fly for classes in class path",
                "issue_description": "with the new feature to inspect inside classes in the source class path\nthere was a new bug introduced: the URLClassLoader inspecting each\nreferenced class had two problems. firstly, a memory performance\nissue: many URLClassLoaders were being created with each invocation,\nbut all of them using the same class path. secondly, they class loader\nwas closed after loading each class, but this could cause the program\nto throw a NoClassDefFoundError (because the class is found, but it\ncan't be loaded because the loader is closed).\n\nnow, it is the Environment who gives support to load external classes\n(but yet found on the source class path), providing its own ClassLoader\n"
            },
            "7": {
                "commit_sha_buggy": "1489d90a29ea2e80d5a41deec22b36667beb7725",
                "commit_sha_fixed": "ac0f9cda00527676e98dd2aaeeb17d3132da1a4c",
                "report_id": "67",
                "report_url": "https://github.com/INRIA/spoon/pull/67",
                "issue_title": "fixes bug invoking super with an enclosing instance",
                "issue_description": "before this commit the DefaultJavaPrettyPrinter was printing with one compilation error inside the constructor of a class extending a nested class.\n"
            },
            "8": {
                "commit_sha_buggy": "ac0f9cda00527676e98dd2aaeeb17d3132da1a4c",
                "commit_sha_fixed": "880b3737b35f7666e2746e8b8b1688f9459aafda",
                "report_id": "70",
                "report_url": "https://github.com/INRIA/spoon/pull/70",
                "issue_title": "fixes bug in FileSystemFolder.getSubFolder",
                "issue_description": "fixes https://github.com/INRIA/spoon/issues/69\n"
            },
            "9": {
                "commit_sha_buggy": "880b3737b35f7666e2746e8b8b1688f9459aafda",
                "commit_sha_fixed": "728b371783f1248a0b81927f79523250dce1e95b",
                "report_id": "71",
                "report_url": "https://github.com/INRIA/spoon/pull/71",
                "issue_title": "fixes bug in CtStatementImpl.insertBefore",
                "issue_description": ""
            },
            "10": {
                "commit_sha_buggy": "728b371783f1248a0b81927f79523250dce1e95b",
                "commit_sha_fixed": "e1d2a19b55a962c04c9cf04752a5eb262707efa6",
                "report_id": "77",
                "report_url": "https://github.com/INRIA/spoon/pull/77",
                "issue_title": "fixes a bug in noclasspath mode (NPE in some special cases)",
                "issue_description": ""
            },
            "11": {
                "commit_sha_buggy": "e1d2a19b55a962c04c9cf04752a5eb262707efa6",
                "commit_sha_fixed": "55626f0c8f7a3f88413a8e3561d7c205aa9fa0c2",
                "report_id": "82",
                "report_url": "https://github.com/INRIA/spoon/issues/82",
                "issue_title": "Expressions in arrays inside annotations cause IllegalArgumentException",
                "issue_description": "Suppose I have a class like\n\n``` java\npublic class TestClass {\n\n    private static final String PREFIX = \"my-prefix\";\n\n    @Produces({PREFIX + \"-test-object-1\",PREFIX + \"-test-object-2\"})\n    public Object getObject(){\n        return null;\n    }\n}\n```\n\nand I start processing it with processor like\n\n``` java\npublic class TestProcessor extends AbstractProcessor<CtAnnotation<?>> {\n\n    public void process(CtAnnotation<?> element) {\n        Object elementValue = element.getElementValue(\"value\");     \n        System.out.println(elementValue.toString());\n    }\n}\n```\n\nthen I receive an error:\n\n```\njava.lang.IllegalArgumentException: array element type mismatch\n    at java.lang.reflect.Array.set(Native Method)\n    at spoon.support.reflect.declaration.CtAnnotationImpl.convertValue(CtAnnotationImpl.java:212)\n    at spoon.support.reflect.declaration.CtAnnotationImpl.getElementValue(CtAnnotationImpl.java:284)\n    at org.raml.test.TestProcessor.process(TestProcessor.java:10)\n    at org.raml.test.TestProcessor.process(TestProcessor.java:1)\n    at spoon.support.visitor.ProcessingVisitor.scan(ProcessingVisitor.java:94)\n    at spoon.support.visitor.ProcessingVisitor.scan(ProcessingVisitor.java:66)\n    at spoon.reflect.visitor.CtScanner.visitCtMethod(CtScanner.java:469)\n```\n"
            },
            "12": {
                "commit_sha_buggy": "eec95fd0b6d4a38c02a93239f0e99a876bf1189d",
                "commit_sha_fixed": "3f6ff67b6dca12c635033bf7a8657f66d1f32547",
                "report_id": "1602",
                "report_url": "https://github.com/INRIA/spoon/pull/1602",
                "issue_title": "fix: pretty printer adds no space before comma in new array expression",
                "issue_description": "```java\r\nString[] field = new String[]{ \"a\" , \"b\" , \"c\" }; //old printing\r\nString[] field = new String[]{ \"a\", \"b\", \"c\" }; //new printing\r\n```\r\n... needed to pass Spoon checkstyle in generated `ModelRoleHandlers` of #1582\r\n"
            },
            "13": {
                "commit_sha_buggy": "dc9492eac1edb540ceedd40ab54141c2504bfe42",
                "commit_sha_fixed": "3cd7a265d4559aba4516ca168e8bee5fb4b3549f",
                "report_id": "1611",
                "report_url": "https://github.com/INRIA/spoon/pull/1611",
                "issue_title": "review: fix: imports in package-info",
                "issue_description": ""
            },
            "14": {
                "commit_sha_buggy": "3cd7a265d4559aba4516ca168e8bee5fb4b3549f",
                "commit_sha_fixed": "e620e692915979b40b49acc225ffa51d9db799ac",
                "report_id": "1609",
                "report_url": "https://github.com/INRIA/spoon/pull/1609",
                "issue_title": "review: Fix: bug related with TypeReference generics in noclasspath",
                "issue_description": ""
            },
            "15": {
                "commit_sha_buggy": "217fe26618442cf3cba2adb829be585b0a027fdf",
                "commit_sha_fixed": "f38e9fae99ec413ba4d86fb95d3d1f53669fc028",
                "report_id": "1664",
                "report_url": "https://github.com/INRIA/spoon/pull/1664",
                "issue_title": "review: fix: AbstractTypingContext inconsitent parents",
                "issue_description": ""
            },
            "16": {
                "commit_sha_buggy": "7fc402fe078886e36cc1f019bd332c23baf7477e",
                "commit_sha_fixed": "e2e359e2e59c23a94cd042a6851e8058cd62dc5c",
                "report_id": "1667",
                "report_url": "https://github.com/INRIA/spoon/pull/1667",
                "issue_title": "review: alternative to #1589",
                "issue_description": "completely different way of fixing #1589\r\n\r\nWDYT?\r\n"
            },
            "17": {
                "commit_sha_buggy": "eb734222dbe5af285c6597547d255ea2ef03e80b",
                "commit_sha_fixed": "64787724c075b82f57d7e4514324f9e3e38e909d",
                "report_id": "1684",
                "report_url": "https://github.com/INRIA/spoon/pull/1684",
                "issue_title": "review: fix: CtVariableAccess#getVariable()",
                "issue_description": ""
            }
        }
    },
    "Canvas_api": {
        "owner_repo": "kstateome/canvas-api",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "27e7c85790d17a77577462f6f12c8da3ddcba71f",
                "commit_sha_fixed": "f2cc44d704eb2ab7b6aed40f490f806e5259f74f",
                "report_id": "90",
                "report_url": "https://github.com/kstateome/canvas-api/pull/90",
                "issue_title": "61E for release.",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "b74e6f41d382719aa716cc7a5876bbc364f8976d",
                "commit_sha_fixed": "f4c66aba0ac27daa465335f9903941b77cad23c1",
                "report_id": "43",
                "report_url": "https://github.com/kstateome/canvas-api/pull/43",
                "issue_title": "Fixing date format when serializing Date objects",
                "issue_description": "We already have a custom adapter for deserialization but didn't put one in for serialization. Canvas expects all dates in ISO 8601 format."
            },
            "3": {
                "commit_sha_buggy": "349859619436bf83de7040eb33aa36ae422c5d2a",
                "commit_sha_fixed": "894d8a7a9cc769b3e53007b88eff0fd74e667c44",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixed RefreshableTokenUTest.\n\nWas previously relying on actual date change when running tests.",
                "issue_description": "Fixed RefreshableTokenUTest.\n\nWas previously relying on actual date change when running tests."
            },
            "4": {
                "commit_sha_buggy": "c5ab407346bb3db13d3468378058d312c5db6a70",
                "commit_sha_fixed": "dcf10e7c984498fdb82bd370d25b33485de75379",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixing object types in Assignment class\n\nThis version successfully parsed 14,000 assignments in our test instance",
                "issue_description": "Fixing object types in Assignment class\n\nThis version successfully parsed 14,000 assignments in our test instance"
            }
        }
    },
    "Coveralls_maven_plugin": {
        "owner_repo": "trautonen/coveralls-maven-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cbbd1e3e0ce1ad2702e78b99b7bf44517346f5f8",
                "commit_sha_fixed": "b42861ae147755ba6a4f35de2739840a332be1fb",
                "report_id": "13",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/issues/13",
                "issue_title": "Dry run property for test builds",
                "issue_description": "It would be good to test what kind of Coveralls JSON the plugin creates without actually sending it to Coveralls. When dry run is enabled, the JSON would not be sent to Coveralls.\n"
            },
            "2": {
                "commit_sha_buggy": "78fac3d88634ba96d66a4f98b9c73ae48b802948",
                "commit_sha_fixed": "4168307f266187e061620aa517d3351e72278c96",
                "report_id": "24",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/issues/24",
                "issue_title": "Filter out remote name from branch",
                "issue_description": "At least Jenkins seems to add remote name to branch, and that will break the links in Coveralls. Scanning possible remotes and removing any remote from the branch name fixes the issue. Reported in #21.\n"
            },
            "3": {
                "commit_sha_buggy": "79a7bd961bba44afa2a47120c4d0e417a7da1123",
                "commit_sha_fixed": "ed66669cf039f7c2c560c87629482ddbe935dfa2",
                "report_id": "95",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/issues/95",
                "issue_title": "Build error: charset",
                "issue_description": "Hi,\n\nI don't know why because I don't change something but since yesterday, the report upload doesn't work in my Travis builds with this error:\n\n``` console\nFailed to execute goal org.eluder.coveralls:coveralls-maven-plugin:3.2.1:report (default-cli) on project spoon-core: Build error: charset\n```\n\nAnd yesterday, I had some 500 HTTP code errors.\n\nAny idea if the problem comes from me or you?\n"
            },
            "4": {
                "commit_sha_buggy": "82768a8135fad38a356cd77d9b4ac0204865f08f",
                "commit_sha_fixed": "0240da3cc053bfc6f48e5da81442069f0307937f",
                "report_id": "96",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/pull/96",
                "issue_title": "#95 Fix for NPE if Content-Type is null",
                "issue_description": "#95 Fix for NPE if Content-Type is null\n\nNow, instead of NPE we will see following (example):\n\n```\norg.eluder.coveralls.maven.plugin.ProcessingException: Report submission to Coveralls API failed with HTTP status 400: Bad Request (Response doesn't contain Content-Type header)\n```\n\nWith real error code and error message\n"
            },
            "5": {
                "commit_sha_buggy": "0c780b01d1b083793563320b2e85f900629e7fe8",
                "commit_sha_fixed": "a07d85b4b3330a92326454f5fd3c570beda01e0a",
                "report_id": "100",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/pull/100",
                "issue_title": "Fixed Wercker environment variables",
                "issue_description": "Unfortunately the implementation in #99 failed because the documentation of wercker seems to list some wrong environment variables.\nI was able to retrieve the real variables from the wercker/maven debug output, so this time it should really work.\n"
            },
            "6": {
                "commit_sha_buggy": "e7640980c43c620bdc40c935768b8793357954f8",
                "commit_sha_fixed": "0c780b01d1b083793563320b2e85f900629e7fe8",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixed Wercker environment variables",
                "issue_description": "Fixed Wercker environment variables"
            },
            "7": {
                "commit_sha_buggy": "bb450dd410dbec199c1f05630cc1b0e1c8000e15",
                "commit_sha_fixed": "bf09c8d6dd5aac8d6eae17495173892d11da8342",
                "report_id": "31",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/issues/31",
                "issue_title": "Build fails when Coveralls API response is not in expected format",
                "issue_description": "Sometimes a build on Travis CI fails, I guess because the response of Coveralls API, is not in the expected format.\n\nA more elaborate error message, instead of the thrown ProcessingException, might be useful, fe. 'Coveralls API was unresponsive',\nor showing/logging the coveralls response, for future debugging?\n\nSome more info on the failure :\nBuilding, testing, code coverage goes well, but transfering the result to coveralls fails : \nBTW : this test was run on my own box, not on Travis CI (hence the repository token), to get some more debug info, file paths have been obfuscated.\n\n[...]\n[INFO] Cobertura Report generation was successful.\n[...]\n[INFO] --- coveralls-maven-plugin:2.1.0:cobertura (default-cli) @ getback_gps ---\n[INFO] Starting Coveralls job\n[INFO] Using repository token <secret>\n[INFO] Git commit 44a49e9 in master\n[INFO] Writing Coveralls data to [HOME]/target/coveralls.json from coverage report [HOME]/target/site/cobertura/coverage.xml\n[INFO] Successfully wrote Coveralls data in 482ms\n[INFO] Gathered code coverage metrics for 23 source files with 5157 lines of code:\n[INFO] - 1123 relevant lines\n[INFO] - 276 covered lines\n[INFO] - 847 missed lines\n[INFO] Submitting Coveralls data to API\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n\nCaused by: org.eluder.coveralls.maven.plugin.ProcessingException: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')\n at [Source: java.io.InputStreamReader@489d479b; line: 1, column: 2]\n        at org.eluder.coveralls.maven.plugin.httpclient.CoverallsClient.parseResponse(CoverallsClient.java:99)\n        at org.eluder.coveralls.maven.plugin.httpclient.CoverallsClient.submit(CoverallsClient.java:89)\n        at org.eluder.coveralls.maven.plugin.AbstractCoverallsMojo.submitData(AbstractCoverallsMojo.java:300)\n        at org.eluder.coveralls.maven.plugin.AbstractCoverallsMojo.execute(AbstractCoverallsMojo.java:184)\n        ... 21 more\nCaused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')\n at [Source: java.io.InputStreamReader@489d479b; line: 1, column: 2]\n"
            },
            "8": {
                "commit_sha_buggy": "76ae2d0852d4ad0a13cf3ffda661b1e048f0d96a",
                "commit_sha_fixed": "28e376d0bef6928f7219023e8c5c4cb9eb3109c9",
                "report_id": "53",
                "report_url": "https://github.com/trautonen/coveralls-maven-plugin/issues/53",
                "issue_title": "Improved error message for missing source encoding",
                "issue_description": "Missing source encoding property results a not very descriptive null pointer exception. This can be improved by a descriptive error message telling how to set the source encoding.\n"
            }
        }
    },
    "Slack_java_webhook": {
        "owner_repo": "ashwanthkumar/slack-java-webhook",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cd6501d3659b1fec80dc663fa09fd275eeae7204",
                "commit_sha_fixed": "5b6b71a3c38ba11f627a805cd14b744a1645ca39",
                "report_id": "4",
                "report_url": "https://github.com/ashwanthkumar/slack-java-webhook/pull/4",
                "issue_title": "Added functionality for adding colon to icon/image name",
                "issue_description": "I made a small addon to the existing code. So it adds a colon before and after the image/icon name, if the user forgets to add it. So that you will get the correct icon either you remember to add the colons or not."
            }
        }
    },
    "Zip4j": {
        "owner_repo": "srikanth-lingala/zip4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d9817ffb812f49c680367aacf3443ab7eee98167",
                "commit_sha_fixed": "37a49d09056962a598cd854d2218e8b155893657",
                "report_id": "14",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/14",
                "issue_title": "zip4j 2.0.3: when execute ZipFile.getInputStream(FileHeader), java.lang.ArrayIndexOutOfBoundsException happened.",
                "issue_description": "**Code:**\r\n\r\n\tpublic static void main(String[] args)\r\n\t{\r\n\t\ttry\r\n\t\t{\r\n\t\t\tString zipFilePath = \"D:\\\\temp\\\\GoogleInstaller_3.0.zip\";\r\n\t\t\tString filePathInZip = \"classes.dex\";\r\n\t\t\tZipFile zipFile = new ZipFile(zipFilePath);\t\t\t\t\r\n\t\t\tFileHeader fileHeader = zipFile.getFileHeader(filePathInZip);\r\n\t\t\t\r\n\t\t\tif(null != fileHeader && !fileHeader.isDirectory())\r\n\t\t\t{\r\n\t\t\t\tzipFile.getInputStream(fileHeader);\r\n\t\t\t}\r\n\t\t}\r\n\t\tcatch(Exception e)\r\n\t\t{\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t}\r\n\r\n**Exception:**\r\njava.lang.ArrayIndexOutOfBoundsException: 3\r\n\tat net.lingala.zip4j.util.RawIO.readShortLittleEndian(RawIO.java:107)\r\n\tat net.lingala.zip4j.headers.HeaderReader.parseExtraDataRecords(HeaderReader.java:303)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readExtraDataRecords(HeaderReader.java:279)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readExtraDataRecords(HeaderReader.java:256)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readCentralDirectory(HeaderReader.java:208)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:75)\r\n\tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:831)\r\n\tat net.lingala.zip4j.ZipFile.getFileHeader(ZipFile.java:565)\r\n\tat com.dancen.util.filecompressor.MyZipUtil.main(MyZipUtil.java:37)\r\n\r\nUsually, I can execute ZipFile.getInputStream(FileHeader) successfull, but for the file \"GoogleInstaller_3.0.zip\", ArrayIndexOutOfBoundsException throwed. I have attached the file.\r\n\r\n[GoogleInstaller_3.0.zip](https://github.com/srikanth-lingala/zip4j/files/3371860/GoogleInstaller_3.0.zip)\r\n"
            },
            "2": {
                "commit_sha_buggy": "5e418a623cd316174e91835a5ea7e0c4b2a763ca",
                "commit_sha_fixed": "3c7b8000fefa1516c949bd1049d700e58e2dc46b",
                "report_id": "16",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/16",
                "issue_title": "Set custom file name when adding via ZipFile.addFile",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "e849b62bb94b506de8e76cdc7f0164d7fc145608",
                "commit_sha_fixed": "c158768c2880615bae983789690b5713e8de6794",
                "report_id": "55",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/55",
                "issue_title": "ZipSlip not fixed",
                "issue_description": "According to tests and manual debugging, the library is still vulnerable against [ZipSlip](https://snyk.io/research/zip-slip-vulnerability).\r\n\r\nThe fix seems to be a change in `AbstractExtractFileTask#extractFile(...)`, namely:\r\n```\r\nif (!new File(completePath).getPath().startsWith(new File(outPath).getPath())) {\r\n```\r\nshould be replaced with\r\n```\r\nif (!new File(completePath).getCanonicalPath().startsWith(new File(outPath).getPath())) {\r\n```\r\n\r\nTest case (JUnit5 + AspectJ) for verification:\r\n```\r\n@Test\r\npublic void testUnzipFileZipSlip(@TempDir File tempDir) throws Exception {\r\n\tfinal File badFile = new File(tempDir, \"bad.txt\");\r\n\tassertThat(badFile.createNewFile()).isTrue();\r\n\tFileUtils.write(badFile, \"bad\", StandardCharsets.UTF_8);\r\n\r\n\tfinal ZipParameters zipParameters = new ZipParameters();\r\n\tzipParameters.setFileNameInZip(\"../../bad.txt\");\r\n\r\n\tfinal ZipFile zip = new ZipFile(new File(tempDir, \"test.zip\"));\r\n\tzip.addFile(badFile, zipParameters);\r\n\r\n\ttry {\r\n\t\tzip.extractAll(new File(tempDir, \"unzipped\").getAbsolutePath());\r\n\t\tfail(\"zip4j is vulnerable for slip zip\");\r\n\t}\r\n\tcatch (ZipException e) {\r\n\t\tassertThat(e).hasMessageStartingWith(\"illegal file name that breaks out of the target directory: \");\r\n\t}\r\n} \r\n```"
            },
            "4": {
                "commit_sha_buggy": "83d0f2babfba934d3c795b0db6e8ff971ac67fd2",
                "commit_sha_fixed": "cbd88b4d576e02986f78a01b7d58d053556fc3d5",
                "report_id": "70",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/70",
                "issue_title": "Add a file as a stream, with the file name repeated, not overwritten",
                "issue_description": "        ZipParameters zipParameters = new ZipParameters();\r\n        zipParameters.setFileNameInZip(\"data/result.csv\");\r\n        ZipFile zipFile = new ZipFile(\"D:\\\\\u6d4f\u89c8\u5668\u4e0b\u8f7d\u8def\u5f84\\\\jmeterTemplate.zip\");\r\n        List<FileHeader> fileHeaders = zipFile.getFileHeaders();\r\n        for (FileHeader fileHeader : fileHeaders) {\r\n            new ZipFile(\"D:\\\\\u6d4f\u89c8\u5668\u4e0b\u8f7d\u8def\u5f84\\\\aaa.zip\").addStream(zipFile.getInputStream(fileHeader), zipParameters);\r\n            System.out.println(fileHeader.getFileName());\r\n        }\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/49773498/65675395-b6463180-e080-11e9-999e-8483708700be.png)\r\n"
            },
            "5": {
                "commit_sha_buggy": "d3125e4cf98f330179ab03393e6302f42401c89e",
                "commit_sha_fixed": "40014d3ccfba5f9a40a5bb6b85ea88d04c0b4d06",
                "report_id": "86",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/86",
                "issue_title": "Can't unzip file on MacOS Catalina",
                "issue_description": "I'm generating a zip file using zip4j, and it opens perfectly on older MacOS but since upgrading to Catalina I get the following error:\r\n\"Unable to expand <filename> into 'Downloads'. (Error 79 - Inappropriate file type or format.)\"\r\nAfter playing with the code a bit I narrowed it down to happening only when using streams (`addStream`) and the compression method is \"deflate\".\r\nLooking at the logs in the Console I saw this error:\r\n\"[ERROR] Couldn't read the header of the entry: Error Domain=NSPOSIXErrorDomain Code=79 UserInfo={NSURL=<private>, NSDebugDescription=<private>}\"\r\nUnzipping with the command line works fine.\r\nTested on the newest version (2.2.2).\r\nAttaching an example zip file.\r\n\r\n[example.zip](https://github.com/srikanth-lingala/zip4j/files/3721663/example.zip)\r\n\r\n"
            },
            "6": {
                "commit_sha_buggy": "1001f91a0ecb4dd751c7d853f2f28b99b258da90",
                "commit_sha_fixed": "156e51a6fe618b32e0db4bb09bdb11fa65157e87",
                "report_id": "118",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/118",
                "issue_title": "Error when extracting files from an empty archive",
                "issue_description": "version: \"net.lingala.zip4j:zip4j:2.2.7\"\r\n\r\nI'm trying to extract the files from a zip archive\r\n\r\n```\r\nval zipFile = new ZipFile(new File(\"some/path\"))\r\nzipFile.extractAll(\"/tmp\")\r\n```\r\n\r\nIf the archive is an empty archive (the file has length of 22 bytes) this code crashes with the following error:\r\n\r\n> Exception in thread \"main\" net.lingala.zip4j.exception.ZipException: java.io.IOException: Negative seek offset\r\n> \tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:856)\r\n> \tat net.lingala.zip4j.ZipFile.extractAll(ZipFile.java:425)\r\n> \tat \r\n> \tat .....\r\n> Caused by: java.io.IOException: Negative seek offset\r\n> \tat java.io.RandomAccessFile.seek(RandomAccessFile.java:555)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.setFilePointerToReadZip64EndCentralDirLoc(HeaderReader.java:529)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.readZip64EndOfCentralDirectoryLocator(HeaderReader.java:345)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:74)\r\n> \tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:851)\r\n> \t... 12 more\r\n\r\nSorry, not familiar with ZIP so can't help with the fix."
            },
            "7": {
                "commit_sha_buggy": "1ca1244c2028c47aabcbd836436a7bbb53ef6015",
                "commit_sha_fixed": "1c227b534d9766acf3c2e8cd7c0bed78b90b16cf",
                "report_id": "118",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/118",
                "issue_title": "Error when extracting files from an empty archive",
                "issue_description": "version: \"net.lingala.zip4j:zip4j:2.2.7\"\r\n\r\nI'm trying to extract the files from a zip archive\r\n\r\n```\r\nval zipFile = new ZipFile(new File(\"some/path\"))\r\nzipFile.extractAll(\"/tmp\")\r\n```\r\n\r\nIf the archive is an empty archive (the file has length of 22 bytes) this code crashes with the following error:\r\n\r\n> Exception in thread \"main\" net.lingala.zip4j.exception.ZipException: java.io.IOException: Negative seek offset\r\n> \tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:856)\r\n> \tat net.lingala.zip4j.ZipFile.extractAll(ZipFile.java:425)\r\n> \tat \r\n> \tat .....\r\n> Caused by: java.io.IOException: Negative seek offset\r\n> \tat java.io.RandomAccessFile.seek(RandomAccessFile.java:555)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.setFilePointerToReadZip64EndCentralDirLoc(HeaderReader.java:529)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.readZip64EndOfCentralDirectoryLocator(HeaderReader.java:345)\r\n> \tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:74)\r\n> \tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:851)\r\n> \t... 12 more\r\n\r\nSorry, not familiar with ZIP so can't help with the fix."
            },
            "8": {
                "commit_sha_buggy": "548e18c8429ef6c4e0952c4a6f65acc445df6552",
                "commit_sha_fixed": "ff3d3b3400de4ccc113d916f326fe4ac59036041",
                "report_id": "133",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/133",
                "issue_title": "File containing Path traversal payload is unchecked",
                "issue_description": "Team- we found an issue where a file containing a path traversal payload is not validated before unzipping the file. Take a zip file that contains the path traversal payload in the name (../) and try to unzip the file. After a call to the extractAll API (zipFile.extractAll(destimation_path), the file isnt unarchived at the destination location but at the root location.\r\n\r\nis there a fix available for this vulnerability?"
            },
            "9": {
                "commit_sha_buggy": "c2ea650148ea7a1a5a8cee7f6476332c572c741e",
                "commit_sha_fixed": "767436f43fd6842f56d9e8f2960175dad36a5112",
                "report_id": "149",
                "report_url": "https://github.com/srikanth-lingala/zip4j/pull/149",
                "issue_title": "Add offset support to readLongLittleEndian when reading from small array",
                "issue_description": "Not sure if bug or feature, but I noticed that the `RawIO#readLongLittleEndian` method does support reading long values from arrays smaller than 8 bytes by adding `0`s and it also supports reading long values from an (at least 8 byte length) array with a given offset. However using both features together (reading with an offset from an array smaller than `offset + 8`) resulted in an exception.\r\n\r\nI added two small tests for the offset feature (`testReadLongLitteEndianWithByteArrayAndOffset` succeded while `testReadLongLittleEndianWithSmallByteArrayAndOffset` failed) and tried to \"fix\" the read method to make its behavior more consistent."
            },
            "10": {
                "commit_sha_buggy": "0123ae52b1da3bc3bb612c39f132a82ba54a4ea2",
                "commit_sha_fixed": "dcc9b8382b56facf4cefcfa30186a59f745fe78e",
                "report_id": "190",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/190",
                "issue_title": "Exception adding Streams at result file size > 4.2 GB",
                "issue_description": "Hi, I'm getting a exception if I add multiple streams to a zip file. The pseudo code and exception is below. Let the code run until the resulting zip file reaches 4.2 GB. I think that code should work, what do you think?\r\n\r\nThx in advance!\r\n\r\nCode:\r\nPath zipFile = /* zip File */;\r\nbyte[] bytes = Files.readAllBytes(/* path to 10 Mb file*/);\r\nfor (int i = 0; i < 500; i++) {\r\n  ZipParameters parameters = new ZipParameters();\r\n  parameters.setFileNameInZip(i + \"\");\r\n  new ZipFile(zipFile.toFile()).addStream(new ByteArrayInputStream(bytes), parameters);\r\n }\r\n\r\nException:\r\nnet.lingala.zip4j.exception.ZipException: invalid signature for zip64 end of central directory record\r\n\tat net.lingala.zip4j.headers.HeaderReader.readZip64EndCentralDirRec(HeaderReader.java:389)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:91)\r\n\tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:973)\r\n\tat net.lingala.zip4j.ZipFile.addStream(ZipFile.java:403)\r\n\r\nI'm using version 2.6 but earlier versions were also affected in a different way. Version 2.3 doesnt throw an exception but produces a corrupted zip file."
            },
            "11": {
                "commit_sha_buggy": "0eb7e86f47b4ab43c9c55b4429cab71bd045433e",
                "commit_sha_fixed": "5a3233b1355cbb89a9dae367584fbf8135c7f2ac",
                "report_id": "195",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/195",
                "issue_title": "Support zipping symlinks that point to non-existent files",
                "issue_description": "Created out of PR #193 \r\n\r\n> I ran into an issue where zip4j threw an Exception trying to zip a directory that had a symlink to a file that didn't exist. Since I don't control the directory contents (it's a vendored dependency) I was hoping you'd accept this patch that adds the broken symlink as is to the zip if you specify ZipParameters.SymbolicLinkAction.INCLUDE_LINK_ONLY."
            },
            "12": {
                "commit_sha_buggy": "1bbb90c955a85129cf1778284732ce64244421c0",
                "commit_sha_fixed": "ffe28c2db5b3d3717d5a5a48f6cf33dbf5d600eb",
                "report_id": "228",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/228",
                "issue_title": "net.lingala.zip4j.exception.ZipException: invalid code lengths set",
                "issue_description": "Hi,\r\n\r\nI cannot unzip files with following information (prodived by 7zip):\r\n\r\n**Method: pkAES-256 Deflate**\r\n**Chraracteristics: 0xD StrongCrypto : Encrypt StrongCrypto**\r\n\r\nI will get the following stacktrace:\r\n\r\n`net.lingala.zip4j.exception.ZipException: java.io.IOException: java.util.zip.DataFormatException: invalid code lengths set\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:51)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:38)\r\n\tat net.lingala.zip4j.ZipFile.extractFile(ZipFile.java:494)\r\n\tat net.lingala.zip4j.ZipFile.extractFile(ZipFile.java:460)\r\n\tat Main.main(Main.java:29)\r\nCaused by: java.io.IOException: java.util.zip.DataFormatException: invalid code lengths set\r\n\tat net.lingala.zip4j.io.inputstream.InflaterInputStream.read(InflaterInputStream.java:55)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:141)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:121)\r\n\tat net.lingala.zip4j.tasks.AbstractExtractFileTask.unzipFile(AbstractExtractFileTask.java:82)\r\n\tat net.lingala.zip4j.tasks.AbstractExtractFileTask.extractFile(AbstractExtractFileTask.java:64)\r\n\tat net.lingala.zip4j.tasks.ExtractFileTask.executeTask(ExtractFileTask.java:39)\r\n\tat net.lingala.zip4j.tasks.ExtractFileTask.executeTask(ExtractFileTask.java:21)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:44)\r\n\t... 4 more\r\nCaused by: java.util.zip.DataFormatException: invalid code lengths set\r\n\tat java.util.zip.Inflater.inflateBytes(Native Method)\r\n\tat java.util.zip.Inflater.inflate(Inflater.java:259)\r\n\tat net.lingala.zip4j.io.inputstream.InflaterInputStream.read(InflaterInputStream.java:45)`\r\n\r\nThank you!\r\n"
            },
            "13": {
                "commit_sha_buggy": "b1d523cdf9cbe808b7a271095c3add7c877bb8e5",
                "commit_sha_fixed": "13c170672da595561163804dc62451dc21bfc870",
                "report_id": "279",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/279",
                "issue_title": "Errors while reading archives from java.util.zip via ZipInputStream",
                "issue_description": "There is an error while reading zip archive from standard java.util.zip archiver. Zip4j ZipInputStream successfully read only first header in archive, next it can not find any.\r\n\r\nHere is a full code example (with zip generating, and reading via zip4j stream) and reasoning below:\r\n```java\r\n   \r\n    @Test\r\n    public void test() throws IOException {\r\n        // Arrange\r\n        String archivePath = \"C:/Users/Public/test.zipByJavaUtilZip\";\r\n        File zipArchive = new File(archivePath);\r\n\r\n        File folderToZip = new File(\"C:/Users/Public/FolderToZip\");\r\n        int expectedNumberOfEntries;\r\n        try (java.util.zip.ZipOutputStream zos = new ZipOutputStream(new FileOutputStream(zipArchive))) {\r\n            expectedNumberOfEntries = zipByJavaUtilZip(zos, folderToZip, folderToZip.listFiles());\r\n            zos.flush();\r\n        }\r\n\r\n        // Act\r\n        List<String> elements = new ArrayList<>();\r\n        try(InputStream is = new FileInputStream(zipArchive);\r\n                net.lingala.zip4j.io.inputstream.ZipInputStream zis = new ZipInputStream(is)) {\r\n\r\n            LocalFileHeader fh;\r\n            while((fh = zis.getNextEntry()) != null)\r\n                elements.add(fh.getFileName());\r\n        }\r\n\r\n        // Act-assert\r\n        // Lets prove that there are five elements in archive\r\n        net.lingala.zip4j.ZipFile zf = new net.lingala.zip4j.ZipFile(zipArchive);\r\n        Assertions.assertEquals(expectedNumberOfEntries, zf.getFileHeaders().size());\r\n        Assertions.assertEquals(5, zf.getFileHeaders().size());\r\n\r\n        // Assert\r\n        // Check for mistakes in zip4j streams\r\n        Assertions.assertEquals(expectedNumberOfEntries, elements.size()); // (elements.size() == 1) = true\r\n    }\r\n\r\n    private static int zipByJavaUtilZip(ZipOutputStream zos, File rootFolder, File[] files) throws IOException {\r\n        int entriesNumber = 0;\r\n        for (File f : files) {\r\n            if (f.isDirectory())\r\n                entriesNumber += zipByJavaUtilZip(zos, rootFolder, f.listFiles());\r\n            else {\r\n                entriesNumber++;\r\n                String path = rootFolder.toPath().relativize(f.toPath()).toString().replaceAll(\"\\\\\\\\\", \"/\");\r\n                ZipEntry entry = new ZipEntry(path);\r\n                zos.putNextEntry(entry);\r\n                try (InputStream fis = new FileInputStream(f)) {\r\n                    IOUtils.copy(fis, zos);\r\n                }\r\n                zos.closeEntry();\r\n            }\r\n        }\r\n        return entriesNumber;\r\n    }\r\n```\r\n\r\nHowever, comparing archives from ```zip4j``` and ```java.util.zip``` in hex viewer, I found, that there are not many differences between them. One of them is the general purpose flag, but the 3rd bit of it have been set in both archives. That means, that in LFH compression size is 0, and the actual size is written in the data descriptor (they are identical). So it is normal to dont know the actual size while reading LFH. But the problem is, then I call  ```zis.getNextEntry()``` second time the result will be null, because in ```zis.getNextEntry()``` there is call of ```readUntilEndOfEntry()```, in it I can see this code:\r\n```java\r\n    if (localFileHeader.isDirectory() || localFileHeader.getCompressedSize() == 0) {\r\n      return;\r\n    }\r\n.....\r\n```\r\nIn this condition there is a leaving from function, because localFileHeader.getCompressedSize() is equal to zero. But after creating archive with the same content via zip4j ZipFile or ZipOutputStream, the test above will pass. So I found this as a strange behaviour.\r\n\r\nMoreover, if I fix it in my code with the problems will appear in reading directories-lfh:\r\n```\r\nif (!lfh.isDirectory())\r\n   zis.readAllBytes();\r\n```\r\n\r\nI don\u2019t know exactly why this is happening and how to fix it (maybe it doesn't need to be fixed at all).\r\nThe test archive in attach. Thank you!\r\n[test.zip](https://github.com/srikanth-lingala/zip4j/files/5857122/test.zip)\r\n"
            },
            "14": {
                "commit_sha_buggy": "1e98d3ed1352148f635c1217ff3cbbc47d4789fe",
                "commit_sha_fixed": "7447ea64d038443d517522213977acb263521dfe",
                "report_id": "263",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/263",
                "issue_title": "ZipFile can be constructed with a null File causing NPE some time later",
                "issue_description": "Current version (2.6.4) allows to construct a `ZipFile` with a `null` `File` reference: (i.e. `new ZipFile((File) null)`) without proper validation. This does not happen if you use the constructor with the `String` argument as internally it does a `new File(string)` and if the string is `null` the `File` constructor throws a NPE.\r\n\r\nThe consequence of this is that when you want to do an operation with the `ZipFile` instance (e.g. `zipFile.getFileHeaders()` it throws a NPE on this [line](https://github.com/srikanth-lingala/zip4j/blob/b1d523cdf9cbe808b7a271095c3add7c877bb8e5/src/main/java/net/lingala/zip4j/ZipFile.java#L960).\r\n\r\nTo avoid these scenarios, it should be properly validated on construction of `ZipFile` if accepting a null reference as File is not valid later.\r\n\r\nOn previous versions (1.3.2) there was a check that somehow on later releases it was removed (particularly on [this commit](https://github.com/srikanth-lingala/zip4j/commit/d72a4710b2b70c0674b4bd6a180381d70e20c5cc)).\r\nThis is 1.3.2:\r\n![image](https://user-images.githubusercontent.com/1738654/100474497-87ca4900-30bf-11eb-9005-0c7b64274f7c.png)\r\n"
            },
            "15": {
                "commit_sha_buggy": "197fca0c5a03f6654ca9fb6d7a5c2ef1a4da30e3",
                "commit_sha_fixed": "a59f424d53b113e4f8d5adbb826141406c6608db",
                "report_id": "256",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/256",
                "issue_title": "EncryptionMethod.ZIP_STANDARD_VARIANT_STRONG",
                "issue_description": "https://github.com/srikanth-lingala/zip4j/blob/b1d523cdf9cbe808b7a271095c3add7c877bb8e5/src/main/java/net/lingala/zip4j/model/enums/EncryptionMethod.java#L20\r\n\r\nWhen using ZIP_STANDARD_VARIANT_STRONG, a ZipException(\"Invalid encryption method\") is thrown because in ZipOutputStream only AES and ZIP_STANDARD encryption methods are treated."
            },
            "16": {
                "commit_sha_buggy": "cd37bb56ef3127e18b270d82f8f23fd5a56386fb",
                "commit_sha_fixed": "f31f930ee66e6c9ac639affe0530a68381140fec",
                "report_id": "315",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/315",
                "issue_title": "when call the ZipFile.removefile method  have some problems about building zipmodel for remove",
                "issue_description": "a.zip inside have two file \r\na.js\r\na.json \r\n\r\nwhen try remove file (a.js)\r\n\r\nZipFile zip = new ZipFile(\"a,zip\");\r\nzip.removeFile(\"a.js\");\r\n\r\nwill remove a.js and a.json together \r\n\r\n\r\n"
            },
            "17": {
                "commit_sha_buggy": "f88f0fb3e6a02705ec9ff445fe169964c90de1d3",
                "commit_sha_fixed": "a0b9deeb9c14aceec738561f4e2b3daa20a81e43",
                "report_id": "287",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/287",
                "issue_title": "method close() does not call the correspondant close method on childs",
                "issue_description": "As per the Stream specification, the close() method should recursively call the child's correspondent method so that the user does not have to iterate all over the nested childs. As far as I can see, the ZipOutputStream.close() method does not call the ZipOutputStream.closeEntry(), thus leaving the stream in an inconsistent value. \r\nTo prove this behavior it's sufficient to close the stream without explicitly calling the closeEntry() method: in this case the JVM will throw an exception (java.io.IOException: java.util.zip.DataFormatException: invalid stored block lengths).\r\n"
            },
            "18": {
                "commit_sha_buggy": "f290b66f5a815182b4a6e5a6bef4a1cf55131a01",
                "commit_sha_fixed": "861f03e96c7feafef1b1772bd3fc93522d69790e",
                "report_id": "327",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/327",
                "issue_title": "[Feature Request] close() on ZipFile to close previously returned `InputStream`\u00b4s",
                "issue_description": "Hi,\r\n\r\nas far as i can tell there\u00b4s currently no way to close all InputStreams returned by `getInputStream()` on `ZipFile` at once, each stream needs to be closed individually. A `close()` on the ZipFile class itself would help to ensure that all input streams are closed and the zip file is 'closed'.\r\nThe `java.util.ZipFile` class has a close: https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/util/zip/ZipFile.html#close()\r\n\r\nThanks!  "
            },
            "19": {
                "commit_sha_buggy": "1039324a533dd12e59b08cf991b823e38470bc74",
                "commit_sha_fixed": "14aebe0d05e7c7c3537fb2e4fcb80a31b07e8168",
                "report_id": "348",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/348",
                "issue_title": "Folder extraction does not work",
                "issue_description": "Hi,\r\nI'd like to extract a folder from my zip file, but it doesn't work.\r\nI got the following exception:\r\n```\r\n[2021-08-13 07:00:51.489         Console d.d.c.c.ConsoleSender                     INFO]:   net.lingala.zip4j.exception.ZipException: File header and local file header mismatch\r\n[2021-08-13 07:00:51.489         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.AbstractExtractFileTask.verifyNextEntry(AbstractExtractFileTask.java:151)\r\n[2021-08-13 07:00:51.489         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.AbstractExtractFileTask.extractFile(AbstractExtractFileTask.java:59)\r\n[2021-08-13 07:00:51.490         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.ExtractFileTask.executeTask(ExtractFileTask.java:43)\r\n[2021-08-13 07:00:51.490         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.ExtractFileTask.executeTask(ExtractFileTask.java:22)\r\n[2021-08-13 07:00:51.490         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:51)\r\n[2021-08-13 07:00:51.490         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.AsyncZipTask.access$400(AsyncZipTask.java:9)\r\n[2021-08-13 07:00:51.491         Console d.d.c.c.ConsoleSender                     INFO]:       at net.lingala.zip4j.tasks.AsyncZipTask$1.run(AsyncZipTask.java:36)\r\n[2021-08-13 07:00:51.491         Console d.d.c.c.ConsoleSender                     INFO]:       at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n[2021-08-13 07:00:51.491         Console d.d.c.c.ConsoleSender                     INFO]:       at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n[2021-08-13 07:00:51.491         Console d.d.c.c.ConsoleSender                     INFO]:       at java.base/java.lang.Thread.run(Thread.java:829)\r\n```\r\n\r\nI use the following code to extract the folder: \r\n```\r\nZipFile zipFile = new ZipFile(archive.toFile());\r\nzipFile.setRunInThread(true);\r\nzipFile.extractFile(\"data/\", \"/srv/test/\");\r\n```\r\n\r\nThank you for your help.\r\nDominic"
            },
            "20": {
                "commit_sha_buggy": "3224fb8ef5b3f9dd8fc9b18683f20384f550d274",
                "commit_sha_fixed": "7a139612cea3b7abe5c666087e24d587de9ebeda",
                "report_id": "347",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/347",
                "issue_title": "extracting subdirectory requires directory entries in the zip",
                "issue_description": "According to the docs, it should be possible to extract subdirectories, e.g.\r\n\r\n```\r\nnew ZipFile(\"filename.zip\").extractFile(\"folderNameInZip/\", \"/destination_directory\");\r\n```\r\n\r\nHowever, this requires a directory entry to be present in the archive:\r\n\r\n* https://github.com/srikanth-lingala/zip4j/blob/v2.9.0/src/main/java/net/lingala/zip4j/ZipFile.java#L638-L640\r\n* https://github.com/srikanth-lingala/zip4j/blob/v2.9.0/src/main/java/net/lingala/zip4j/headers/HeaderUtil.java#L69-L79\r\n\r\nAs far as I understand, having directory entries in zips is optional, so the unzipping should not check for them. Presumably it should only compare against the user-supplied entry name (and ensure the user-supplied name ends with a slash).\r\n\r\nHere's an example archive with no directory entires:\r\n\r\n[archive-no-dirs.zip](https://github.com/srikanth-lingala/zip4j/files/6973121/archive-no-dirs.zip)\r\n\r\nThe archive was created with Powershell 7 `Compress-Archive` cmdlet ( https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.archive/compress-archive?view=powershell-7.1 )"
            },
            "21": {
                "commit_sha_buggy": "66dc565a252a2eb277f1e739bddbeb797b3c3acb",
                "commit_sha_fixed": "35122fd19b3f1fae531d9e20d54e8dc894414dab",
                "report_id": "373",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/373",
                "issue_title": "java.lang.NullPointerException in `net.lingala.zip4j.io.inputstream.AesCipherInputStream.getSalt::AesCipherInputStream.java:161` zip4j 2.9.0",
                "issue_description": "This vulnerability is of java.lang.NullPointerException, and can be triggered in latest version zip4j (2.9.0).\r\nIt is caused by not checking the pointer before dereference it and also failing to catch the runtime java exception (it should be wrapped as one kind of JSONException) and can be used for attackers to launch DoS (Denial of Service) attack for any java program that uses this library (since the user of zip4j doesn't know they need to catch this kind of exception) (CWE-476: NULL Pointer Dereference, CWE-248: Uncaught exception).\r\nLikely, the root cause of this crash is in `net.lingala.zip4j.io.inputstream.AesCipherInputStream.getSalt::AesCipherInputStream.java:161`.\r\nhttps://github.com/srikanth-lingala/zip4j/blob/ce1cff61c019d61f5db603cba908118a3a0e3b93/src/main/java/net/lingala/zip4j/io/inputstream/AesCipherInputStream.java#L161  The variable \"aesExtraDataRecord\" has a NULL value and it results in NullPointerException.\r\n\r\nSee more detail from the following crash stack.\r\n\r\n# Crash stack:\r\nThe crash thread's stack is as follows:\r\n\r\n```\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.getSalt::AesCipherInputStream.java:161\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.initializeDecrypter::AesCipherInputStream.java:37\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.initializeDecrypter::AesCipherInputStream.java:18\r\nnet.lingala.zip4j.io.inputstream.CipherInputStream.<init>::CipherInputStream.java:25\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.<init>::AesCipherInputStream.java:32\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.initializeCipherInputStream::ZipInputStream.java:234\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.initializeEntryInputStream::ZipInputStream.java:223\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:113\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:83\r\ncom.test.Entry.main::Entry.java:37\r\n```\r\n\r\n\r\n# Steps to reproduce: \r\n\r\n1. Build the following java code with the corresponding zip4j library (version 2.9.0).\r\n\r\n```\r\n## Download zip4j_env_reproduce.tar.gz from https://drive.google.com/file/d/1MekCBIghKxIW4j-TLjZkm8ovvLb_grm5/view?usp=sharing\r\ntar -xf zip4j_env_reproduce.tar.gz\r\ncd zip4j_env_reproduce\r\nbash build.sh\r\n```\r\n\r\n2. Run the built program to see the crash by feeding one of the poc file contained in the pocs.tar.gz, e.g. :\r\n(poc file can be downloaded from https://drive.google.com/file/d/1OM47k2Q9nGgj32UU-npTN2FrUePo7ehF/view?usp=sharing)\r\n```\r\njava -jar target/Entry-1.0-SNAPSHOT-jar-with-dependencies.jar pocs/crash-d6e84c761cc0e655ae615ce3473793935ee337bf\r\n```\r\n\r\nAny further discussion for this vulnerability including fix is welcomed! "
            },
            "22": {
                "commit_sha_buggy": "be95bc3c9663ed3a58b6a3c067a5604e36ddd0a2",
                "commit_sha_fixed": "e6c2d1394252440477bd0b7efde77af4d1e6f96d",
                "report_id": "375",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/375",
                "issue_title": "java.lang.NullPointerException in `net.lingala.zip4j.io.inputstream.ZipInputStream.isEntryDirectory::ZipInputStream.java:314` zip4j 2.9.0",
                "issue_description": "This vulnerability is of java.lang.NullPointerException, and can be triggered in latest version zip4j (2.9.0).\r\nIt is caused by not checking the pointer before dereference it and also failing to catch the runtime java exception (it should be wrapped as one kind of JSONException) and can be used for attackers to launch DoS (Denial of Service) attack for any java program that uses this library (since the user of zip4j doesn't know they need to catch this kind of exception) (CWE-476: NULL Pointer Dereference, CWE-248: Uncaught exception).\r\nLikely, the root cause of this crash is in `net.lingala.zip4j.io.inputstream.ZipInputStream.isEntryDirectory::ZipInputStream.java:314`.\r\nhttps://github.com/srikanth-lingala/zip4j/blob/ce1cff61c019d61f5db603cba908118a3a0e3b93/src/main/java/net/lingala/zip4j/io/inputstream/ZipInputStream.java#L314  The variable \"entryName\" has a NULL value and it results in NullPointerException.\r\n\r\nSee more detail from the following crash stack.\r\n\r\n# Crash stack:\r\nThe crash thread's stack is as follows:\r\n\r\n```\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.isEntryDirectory::ZipInputStream.java:314\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.verifyLocalFileHeader::ZipInputStream.java:267\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:97\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:83\r\ncom.test.Entry.main::Entry.java:37\r\n```\r\n\r\n\r\n# Steps to reproduce: \r\n\r\n1. Build the following java code with the corresponding zip4j library (version 2.9.0).\r\n\r\n```\r\n## Download zip4j_env_reproduce.tar.gz from https://drive.google.com/file/d/1MekCBIghKxIW4j-TLjZkm8ovvLb_grm5/view?usp=sharing\r\ntar -xf zip4j_env_reproduce.tar.gz\r\ncd zip4j_env_reproduce\r\nbash build.sh\r\n```\r\n\r\n2. Run the built program to see the crash by feeding one of the poc file contained in the pocs.tar.gz, e.g. :\r\n(poc file can be downloaded from https://drive.google.com/file/d/1is17ysO4o5FsjHnXMIWHIQ9zGiHM5S-n/view?usp=sharing)\r\n```\r\njava -jar target/Entry-1.0-SNAPSHOT-jar-with-dependencies.jar pocs/crash-e2a9439c6d0b7e34d11105eb910bb6a539613652\r\n```\r\n\r\nAny further discussion for this vulnerability including fix is welcomed! "
            },
            "23": {
                "commit_sha_buggy": "849aea970913224bbd9df4822e3f624b83360b4e",
                "commit_sha_fixed": "22471c12029d4f8e3e3accf910f41378d7828989",
                "report_id": "410",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/410",
                "issue_title": "How to correctly add empty folder entries with ZipOutputStream",
                "issue_description": "I'm getting \"Error 79 - Inappropriate file type or format.\" on macOS Montery if I try to extract a file that's created using ZipOutPutStream and that contains empty folders. \r\n\r\nOn Windows 11, using the built in Zip utility, no error is shown. When using 7zip on Windows, the files and folders are successfully extracted, but 7zip warns me about \"Header errors\". On Mac, I was able to successfully extract the empty folders using a tool called \"The Unarchiver\".\r\n\r\nI'm not sure if I'm adding the empty folder zip entries correct. Basically, I'm just looping over all the empty folders that should be added to the zip first, and then, in a secondary loop, I'm adding all the actual files.\r\n\r\nA folder is added like this, where the filename is the folder path with a trailing \"/\":\r\n```\r\nzipParameters.setFileNameInZip(\"/20220310T0800 - 75 - test/1 - Presenter - test/\"));\r\n```\r\n\r\nRelevant part of the code:\r\n```\r\n  .....\r\n\r\n  ByteArrayOutputStream bos = new ByteArrayOutputStream();\r\n  try(ZipOutputStream zos = initializeZipOutputStream(bos, input.isEncryptZip(), password )) {\r\n\r\n      // Add all empty folders first\r\n      for (String emptyFolder : emptyFolders){\r\n          zipParameters.setFileNameInZip(emptyFolder);\r\n          zos.putNextEntry(zipParameters);\r\n          zos.closeEntry();\r\n      }\r\n\r\n      ..... loop adding actual files here (code removed. Is just like the example in the readme).\r\n\r\n      // closing the stream and uploading to AWS S3\r\n      zos.close();\r\n      s3Client.putObject(putObjectRequest, RequestBody.fromBytes(bos.toByteArray()));\r\n  }\r\n\r\n  .....\r\n\r\n```\r\n\r\nAttached an example Zip generated by Zip4j with one empty folder and one folder with a file. \r\n\r\n[futureconf2021-20220309T1159AM.zip](https://github.com/srikanth-lingala/zip4j/files/8214041/futureconf2021-20220309T1159AM.zip)\r\n"
            },
            "24": {
                "commit_sha_buggy": "3cf0cf72870c3ee6e1109e69b1f73cf91fb634f1",
                "commit_sha_fixed": "229d90216692354ae2662f299084305792a81bdf",
                "report_id": "366",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/366",
                "issue_title": "java.lang.ArrayIndexOutOfBoundsException in `net.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675` zip4j 2.9.0",
                "issue_description": "This vulnerability is of java.lang.ArrayIndexOutOfBoundsException, and can be triggered in latest version zip4j (2.9.0).\r\nIt is caused by missing check the array index < array size and also failing to catch the runtime java exception (it should be wrapped as one kind of JSONException) and can be used for attackers to launch DoS (Denial of Service) attack for any java program that uses this library (since the user of zip4j doesn't know they need to catch this kind of exception) (CWE-129: Improper Validation of Array Index, CWE-248: Uncaught exception).\r\nLikely, the root cause of this crash is in `net.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675`.\r\nhttps://github.com/srikanth-lingala/zip4j/blob/ce1cff61c019d61f5db603cba908118a3a0e3b93/src/main/java/net/lingala/zip4j/headers/HeaderReader.java#L675 Lenght of variable \"aesData\" is less than 4 thus it results in ArrayIndexOutOfBoundsException.\r\n\r\nSee more detail from the following crash stack.\r\n\r\n# Crash stack:\r\nThe crash thread's stack is as follows:\r\n\r\n```\r\njava.base/java.lang.System.arraycopy::Native Method\r\nnet.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675\r\nnet.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:642\r\nnet.lingala.zip4j.headers.HeaderReader.readLocalFileHeader::HeaderReader.java:576\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:91\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:83\r\ncom.test.Entry.main::Entry.java:37\r\n```\r\n\r\n\r\n# Steps to reproduce: \r\n\r\n1. Build the following java code with the corresponding zip4j library (version 2.9.0).\r\n\r\n```\r\n## Download zip4j_env_reproduce.tar.gz from https://drive.google.com/file/d/1MekCBIghKxIW4j-TLjZkm8ovvLb_grm5/view?usp=sharing\r\ntar -xf zip4j_env_reproduce.tar.gz\r\ncd zip4j_env_reproduce\r\nbash build.sh\r\n```\r\n\r\n2. Run the built program to see the crash by feeding one of the poc file contained in the pocs.tar.gz, e.g. :\r\n(poc file can be downloaded from https://drive.google.com/file/d/10H3WTdosQtnyq8St933R92WhIfAL7920/view?usp=sharing)\r\n```\r\njava -jar target/Entry-1.0-SNAPSHOT-jar-with-dependencies.jar pocs/crash-b10d5442f242277593267acb91a2f01fd0632413\r\n```\r\n\r\nAny further discussion for this vulnerability including fix is welcomed! "
            },
            "25": {
                "commit_sha_buggy": "229d90216692354ae2662f299084305792a81bdf",
                "commit_sha_fixed": "ccb9937d20a9e3e62aca2e3e3376682e458adb20",
                "report_id": "366",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/366",
                "issue_title": "java.lang.ArrayIndexOutOfBoundsException in `net.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675` zip4j 2.9.0",
                "issue_description": "This vulnerability is of java.lang.ArrayIndexOutOfBoundsException, and can be triggered in latest version zip4j (2.9.0).\r\nIt is caused by missing check the array index < array size and also failing to catch the runtime java exception (it should be wrapped as one kind of JSONException) and can be used for attackers to launch DoS (Denial of Service) attack for any java program that uses this library (since the user of zip4j doesn't know they need to catch this kind of exception) (CWE-129: Improper Validation of Array Index, CWE-248: Uncaught exception).\r\nLikely, the root cause of this crash is in `net.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675`.\r\nhttps://github.com/srikanth-lingala/zip4j/blob/ce1cff61c019d61f5db603cba908118a3a0e3b93/src/main/java/net/lingala/zip4j/headers/HeaderReader.java#L675 Lenght of variable \"aesData\" is less than 4 thus it results in ArrayIndexOutOfBoundsException.\r\n\r\nSee more detail from the following crash stack.\r\n\r\n# Crash stack:\r\nThe crash thread's stack is as follows:\r\n\r\n```\r\njava.base/java.lang.System.arraycopy::Native Method\r\nnet.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:675\r\nnet.lingala.zip4j.headers.HeaderReader.readAesExtraDataRecord::HeaderReader.java:642\r\nnet.lingala.zip4j.headers.HeaderReader.readLocalFileHeader::HeaderReader.java:576\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:91\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:83\r\ncom.test.Entry.main::Entry.java:37\r\n```\r\n\r\n\r\n# Steps to reproduce: \r\n\r\n1. Build the following java code with the corresponding zip4j library (version 2.9.0).\r\n\r\n```\r\n## Download zip4j_env_reproduce.tar.gz from https://drive.google.com/file/d/1MekCBIghKxIW4j-TLjZkm8ovvLb_grm5/view?usp=sharing\r\ntar -xf zip4j_env_reproduce.tar.gz\r\ncd zip4j_env_reproduce\r\nbash build.sh\r\n```\r\n\r\n2. Run the built program to see the crash by feeding one of the poc file contained in the pocs.tar.gz, e.g. :\r\n(poc file can be downloaded from https://drive.google.com/file/d/10H3WTdosQtnyq8St933R92WhIfAL7920/view?usp=sharing)\r\n```\r\njava -jar target/Entry-1.0-SNAPSHOT-jar-with-dependencies.jar pocs/crash-b10d5442f242277593267acb91a2f01fd0632413\r\n```\r\n\r\nAny further discussion for this vulnerability including fix is welcomed! "
            },
            "26": {
                "commit_sha_buggy": "5b3c43bb4d3ea2a2a2b38cf6d688fc50e7d3302a",
                "commit_sha_fixed": "55dc47b38ab530663e142bd3647a8f43a556b23b",
                "report_id": "371",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/371",
                "issue_title": "java.lang.IndexOutOfBoundsException in `net.lingala.zip4j.io.inputstream.ZipEntryInputStream.readUntilBufferIsFull::ZipEntryInputStream.java:78` zip4j 2.9.0",
                "issue_description": "This vulnerability is of java.lang.IndexOutOfBoundsException, and can be triggered in latest version zip4j (2.9.0).\r\nIt is caused by getting an index of an array which is out of the range. and can be used for attackers to launch DoS (Denial of Service) attack for any java program that uses this library (since the user of zip4j doesn't know they need to catch this kind of exception) ( CWE-248: Uncaught exception).\r\nLikely, the root cause of this crash is in `net.lingala.zip4j.io.inputstream.ZipEntryInputStream.readUntilBufferIsFull::ZipEntryInputStream.java:78`.\r\nhttps://github.com/srikanth-lingala/zip4j/blob/ce1cff61c019d61f5db603cba908118a3a0e3b93/src/main/java/net/lingala/zip4j/io/inputstream/ZipEntryInputStream.java#L78  Either variable \"remainingLength\" is index out of bounds for array \"b\" or both variables \"remainingLength\" and \"readLength\" are index out of bounds. \r\n\r\nSee more detail from the following crash stack.\r\n\r\n# Crash stack:\r\nThe crash thread's stack is as follows:\r\n\r\n```\r\njava.base/java.io.PushbackInputStream.read::PushbackInputStream.java:167\r\nnet.lingala.zip4j.io.inputstream.ZipEntryInputStream.readUntilBufferIsFull::ZipEntryInputStream.java:78\r\nnet.lingala.zip4j.io.inputstream.ZipEntryInputStream.readRawFully::ZipEntryInputStream.java:62\r\nnet.lingala.zip4j.io.inputstream.CipherInputStream.readRaw::CipherInputStream.java:71\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.getPasswordVerifier::AesCipherInputStream.java:168\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.initializeDecrypter::AesCipherInputStream.java:37\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.initializeDecrypter::AesCipherInputStream.java:18\r\nnet.lingala.zip4j.io.inputstream.CipherInputStream.<init>::CipherInputStream.java:25\r\nnet.lingala.zip4j.io.inputstream.AesCipherInputStream.<init>::AesCipherInputStream.java:32\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.initializeCipherInputStream::ZipInputStream.java:234\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.initializeEntryInputStream::ZipInputStream.java:223\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:113\r\nnet.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry::ZipInputStream.java:83\r\ncom.test.Entry.main::Entry.java:37\r\n```\r\n\r\n\r\n# Steps to reproduce: \r\n\r\n1. Build the following java code with the corresponding zip4j library (version 2.9.0).\r\n\r\n```\r\n## Download zip4j_env_reproduce.tar.gz from https://drive.google.com/file/d/1MekCBIghKxIW4j-TLjZkm8ovvLb_grm5/view?usp=sharing\r\ntar -xf zip4j_env_reproduce.tar.gz\r\ncd zip4j_env_reproduce\r\nbash build.sh\r\n```\r\n\r\n2. Run the built program to see the crash by feeding one of the poc file contained in the pocs.tar.gz, e.g. :\r\n(poc file can be downloaded from https://drive.google.com/file/d/1hviHw44Ym55ybVloEYYPwTtwlaIj0LvW/view?usp=sharing)\r\n```\r\njava -jar target/Entry-1.0-SNAPSHOT-jar-with-dependencies.jar pocs/crash-71415be583f0456949797dc42f9bcd265a067336\r\n```\r\n\r\nAny further discussion for this vulnerability including fix is welcomed! "
            },
            "27": {
                "commit_sha_buggy": "6e65b561fdacfd018d499154638335f980478713",
                "commit_sha_fixed": "498a1256a85155927f26dfd70a55b6bd1fb98e98",
                "report_id": "12",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/12",
                "issue_title": "Zip file created with v1.3.3 and STORE compression cannot be decrypted with Zip4j 2.x.",
                "issue_description": "Issue spawned from #11 "
            },
            "28": {
                "commit_sha_buggy": "36bac3df2e69af9cb1217658bb46defdaa4c1115",
                "commit_sha_fixed": "c4bf27e28adea27b49b5eb11df7a59c9c9639619",
                "report_id": "20",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/20",
                "issue_title": "Password protection not working?",
                "issue_description": "Hello,\r\n\r\nI'm trying to create a password protected ZIP file, but I keep getting that the password is not correct when I try to unzip the contents:\r\n\r\n```java\r\nvar params1 = new ZipParameters();\r\nparams1.setEncryptionMethod(EncryptionMethod.ZIP_STANDARD);\r\nparams1.setCompressionLevel(CompressionLevel.NORMAL);\r\nparams1.setCompressionMethod(CompressionMethod.DEFLATE);\r\nparams1.setEncryptFiles(true);\r\nparams1.setFileNameInZip(\"file1.csv\");\r\nparams1.setEncryptFiles(true);\r\n\r\nvar params2 = new ZipParameters();\r\nparams2.setEncryptionMethod(EncryptionMethod.ZIP_STANDARD);\r\nparams2.setCompressionLevel(CompressionLevel.NORMAL);\r\nparams2.setCompressionMethod(CompressionMethod.DEFLATE);\r\nparams2.setEncryptFiles(true);\r\nparams2.setFileNameInZip(\"file2.csv\");\r\nparams2.setEncryptFiles(true);\r\n\r\nvar zip = new ZipFile(\"MY_ZIP.zip\", \"hello\".toCharArray());\r\nzip.addStream(s1, params1);\r\nzip.addStream(s2, params2);\r\n\r\nzip.getFile();\r\n// Check the file...\r\n```\r\n\r\nThis issue seems related: https://github.com/srikanth-lingala/zip4j/issues/6, but I'm using version 2.1.0, so it should be fixed now?\r\n\r\nI'll report if I find anything else.\r\n\r\nThank you.\r\n"
            },
            "29": {
                "commit_sha_buggy": "c4bf27e28adea27b49b5eb11df7a59c9c9639619",
                "commit_sha_fixed": "777f36634d7a7aca528d6693cc2e65dbf232a1c9",
                "report_id": "22",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/22",
                "issue_title": "AES encrypted files sometimes produce wrong checksums",
                "issue_description": "Hi,\r\n\r\nwhen I create a password protected zip file I get the following error message during uncompress:\r\n```\r\nnet.lingala.zip4j.exception.ZipException: java.io.IOException: Reached end of data for this entry, but aes verification failed\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:48)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:35)\r\n\tat net.lingala.zip4j.ZipFile.extractAll(ZipFile.java:431)\r\n```\r\n\r\nwhen compressing files with a specific compressed size. See \r\n[zip4j-failing-compress.zip](https://github.com/srikanth-lingala/zip4j/files/3386075/zip4j-failing-compress.zip) for an example (Maven project with failing unit test).\r\n\r\nI guess the issue occurs when `net.lingala.zip4j.io.outputstream.CompressedOutputStream.decrementBytesWrittenForThisEntry(int)` is called. Maybe the length is calculated correct but the checksum is using a wrong range.\r\n\r\nThe issue is reproducible when the stacktrace runs through `net.lingala.zip4j.io.outputstream.DeflaterOutputStream.deflate()` and the `len` is in between 1..3\r\n\r\nThe resulting zip file can be decompressed, but throws an error when using zip4j, 7z and winrar."
            },
            "30": {
                "commit_sha_buggy": "493dbfce63122e85fa2d28704a1169c23373a7de",
                "commit_sha_fixed": "a7afefc93e6dec0e7c37f21098c228e1eeb1ea6f",
                "report_id": "33",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/33",
                "issue_title": "ArrayIndexOutofBoundsException when read directory from zipInputStream",
                "issue_description": "Hi, Author. I found out this bug that when I tried to read encrypted zip files from ZipInputStream, if it meet some directories, it would throw this exception:\r\njava.lang.ArrayIndexOutOfBoundsException: 11\r\n\tat net.lingala.zip4j.util.RawIO.readShortLittleEndian(RawIO.java:109)\r\n\tat net.lingala.zip4j.headers.HeaderReader.parseExtraDataRecords(HeaderReader.java:309)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readExtraDataRecords(HeaderReader.java:297)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readExtraDataRecords(HeaderReader.java:264)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readLocalFileHeader(HeaderReader.java:553)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry(ZipInputStream.java:66)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.getNextEntry(ZipInputStream.java:62)\r\n\r\nThis error only happens on reading directories from ZipInputStream. \r\nPlease help me fix this bug. I am in urgent need. \r\n\r\nThank you in advance!\r\n"
            },
            "31": {
                "commit_sha_buggy": "65db4eec6ccd450ff0c630bf0ff372254655c6b3",
                "commit_sha_fixed": "3f15884e338fd2490bb9ee710cf0828aca55d285",
                "report_id": "62",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/62",
                "issue_title": "False-positive result while checking for slip zip if target path is not normalized",
                "issue_description": "If i use non normalized target paths while unzipping, the check for slip zip ends with a false-positive result.\r\nThe issue is, that the path of the extracted file is compared with a non normalized target path in `AbstractExtractFileTask#extractFile(...)`:\r\n\r\n` if (!new File(completePath).getCanonicalPath().startsWith(new File(outPath).getPath())) {`\r\n\r\nThis line should be changed to\r\n\r\n`!new File(completePath).getCanonicalPath().startsWith(new File(outPath).getCanonicalPath())`\r\n\r\nTest case (JUnit5 + AssertJ) for verification:\r\n\r\n```\r\n@Test\r\npublic void testUnzipFileZipSlipWithNotNormalizedTarget(@TempDir File tempDir) throws Exception {\r\n\tfinal File goodFile = new File(tempDir, \"good.txt\");\r\n\tassertThat(goodFile.createNewFile()).isTrue();\r\n\tFileUtils.write(goodFile, \"good\", StandardCharsets.UTF_8);\r\n\r\n\tfinal ZipParameters zipParameters = new ZipParameters();\r\n\tzipParameters.setFileNameInZip(\"good.txt\");\r\n\r\n\tfinal ZipFile zip = new ZipFile(new File(tempDir, \"test.zip\"));\r\n\tzip.addFile(goodFile, zipParameters);\r\n\r\n\tzip.extractAll(new File(tempDir, \"../\" + tempDir.getName() + \"/unzipped\").getAbsolutePath());\r\n}\r\n```\r\n"
            },
            "32": {
                "commit_sha_buggy": "a7d4b245498af60b6bb1e4ced01bcd0c34c4adf2",
                "commit_sha_fixed": "5676742a4ca2e3d8480d966f165100d02798363f",
                "report_id": "65",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/65",
                "issue_title": "unzip sucessfully in 1.x but failed in latest version",
                "issue_description": "Hello,\r\n\r\nI created the zip using c# `ICSharpCode.SharpZipLib.Zip` with password. And it could be unzipped when I extracted it using zip4j `version 1.3.2`. I upgrade it 2.x in order to support stream. And some exception when I extract the same zip file:\r\n\r\nCode:\r\n```java\r\n    try {\r\n      ZipFile zipFile = new ZipFile(source);\r\n      if (zipFile.isEncrypted()) {\r\n        zipFile.setPassword(password);\r\n      }\r\n      zipFile.extractAll(destination);\r\n    } catch (ZipException e) {\r\n      e.printStackTrace();\r\n    }\r\n```\r\n\r\nException:\r\n```java\r\nnet.lingala.zip4j.exception.ZipException: java.io.IOException: Negative seek offset\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:49)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:36)\r\n\tat net.lingala.zip4j.ZipFile.extractAll(ZipFile.java:431)\r\n\tat app.util.ZipMaker.unzip(ZipMaker.java:108)\r\n```\r\n\r\nThe sample zip [hello.zip](https://github.com/srikanth-lingala/zip4j/files/3616840/hello.zip) with password `Shu1an@2019GTS`\r\n"
            },
            "33": {
                "commit_sha_buggy": "58f8582d151e310b4f7503192be64c6f5615f252",
                "commit_sha_fixed": "30974c6b5b8d983126d34d72f315996baa382c91",
                "report_id": "162",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/162",
                "issue_title": "Errors extracting old Zip4J Archives (1.x) with new Zip4J",
                "issue_description": "I have a couple of Zips that were built with Zip4J 1.3.1 for backup-purposes of our users. Because of the size limitation 65.535 files with the old zip, we changed to Zip4J 2.1.2 and now tried 2.5.0. None of the work correctly.\r\n\r\nThe first error was the same as described here: https://github.com/srikanth-lingala/zip4j/issues/39. Extraction stopped with the crc-exception.\r\n\r\nZip4J 2.1.4 and 2.5.0 don't give this error, but  with 2.5.0 some(!) extracted files with german Umlauts (\u00e4,\u00f6,\u00fc) and other non-Ascii characters now contain garbage chars. With 1.3.1 they extract normally.\r\n\r\nEven more confusing is the fact, that not all characters are garbled. Sometime even the same subdirectory gets extracted twice, one time with the correct Umlaut and some files and a second time with the garbled char and the rest of the files.\r\n\r\nDo you have any idea why this is happening? The archives were created with Zip4J 1.3.1 in one piece and have not been edited after creation. I can try to replicate the error with some non-confidential archives but this may take some time."
            },
            "34": {
                "commit_sha_buggy": "7fb9db6c804970e274ba9eeef20e55bf995ae399",
                "commit_sha_fixed": "bd9d7325c4402241025aef89a25896ee877a455f",
                "report_id": "166",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/166",
                "issue_title": "Valid zip file fails to extract with Zip headers not found exception",
                "issue_description": "I'm trying to open a malicious APK (which is just a ZIP) : https://www.virustotal.com/gui/file/3d442706c36549bb412684471746d4b6537751d8cdb6a40f4f18872a09fa7acd/detection\r\n\r\nAttached: [48ff2a2b08d18d12d9110a3ad3c86ea0ba33487d.zip](https://github.com/srikanth-lingala/zip4j/files/4396035/48ff2a2b08d18d12d9110a3ad3c86ea0ba33487d.zip)\r\n\r\nThe file unzips fine. Only a warning about truncated comment.\r\n\r\n```\r\n$ unzip -t 3d4_failed.apk\r\nArchive:  3d4_failed.apk\r\n\r\ncaution:  zipfile comment truncated\r\n    testing: META-INF/MANIFEST.MF     OK\r\n    testing: META-INF/CERT.SF         OK\r\n    testing: META-INF/CERT.RSA        OK\r\n    testing: .resouces_(manifest      OK\r\n    testing: AndroidManifest.xml      OK\r\n    testing: classes.dex              OK\r\n    testing: res/drawable-hdpi-v11/ikbstwxtz.png   OK\r\n    testing: res/drawable-hdpi-v4/ic_launcher.png   OK\r\n    testing: res/drawable-hdpi-v4/ikbstwxtz.png   OK\r\n    testing: res/drawable-mdpi-v11/ikbstwxtz.png   OK\r\n    testing: res/drawable-mdpi-v4/ic_launcher.png   OK\r\n    testing: res/drawable-mdpi-v4/ikbstwxtz.png   OK\r\n    testing: res/drawable-xhdpi-v11/ikbstwxtz.png   OK\r\n    testing: res/drawable-xhdpi-v4/ic_launcher.png   OK\r\n    testing: res/drawable-xhdpi-v4/ikbstwxtz.png   OK\r\n    testing: res/drawable-xxhdpi-v11/ikbstwxtz.png   OK\r\n    testing: res/drawable-xxhdpi-v4/ic_launcher.png   OK\r\n    testing: res/drawable-xxhdpi-v4/ikbstwxtz.png   OK\r\n    testing: res/drawable-xxxhdpi-v11/ikbstwxtz.png   OK\r\n    testing: res/drawable-xxxhdpi-v4/ikbstwxtz.png   OK\r\n    testing: res/drawable/cpcqdnmlemk.xml   OK\r\n    testing: res/layout-v17/dialog_web_view.xml   OK\r\n    testing: res/layout/dialog_web_view.xml   OK\r\n    testing: res/layout/fjtrduihiljh.xml   OK\r\n    testing: res/layout/relative_layout.xml   OK\r\n    testing: res/xml/wrqlcjxeg.xml    OK\r\n    testing: resources.arsc           OK\r\nNo errors detected in compressed data of 3d4_failed.apk.\r\n```\r\n\r\nZip4j 2.5.1 throws an exception:\r\n\r\n```\r\nException in thread \"main\" net.lingala.zip4j.exception.ZipException: Zip headers not found. Probably not a zip file or a corrupted zip file\r\n\tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:78)\r\n\tat net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:964)\r\n\tat net.lingala.zip4j.ZipFile.getFileHeader(ZipFile.java:582)\r\n\tat org.cf.apkfile.Main2.main(Main2.java:29)\r\nCaused by: java.io.EOFException\r\n\tat java.io.RandomAccessFile.readFully(RandomAccessFile.java:438)\r\n\tat java.io.RandomAccessFile.readFully(RandomAccessFile.java:416)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readEndOfCentralDirectoryRecord(HeaderReader.java:137)\r\n\tat net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:74)\r\n\t... 3 more\r\n```\r\n\r\nTo be fair, Java native libraries also have trouble opening the file:\r\n\r\n```\r\nException in thread \"main\" java.util.zip.ZipException: error in opening zip file\r\n\tat java.util.zip.ZipFile.open(Native Method)\r\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:225)\r\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:155)\r\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:169)\r\n\tat org.cf.apkfile.Main2.main(Main2.java:26)\r\n```\r\n\r\nOddly, running `zip -FF` (to fix the archive) works and creates another valid zip that Zip4j _also_ cannot open. I can upload that if you want, too."
            },
            "35": {
                "commit_sha_buggy": "7be1b0620bf9dbb4c023a1682698ac5436b41fad",
                "commit_sha_fixed": "d5c5b413a2996bceb65db4adfd353030baf21d94",
                "report_id": "194",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/194",
                "issue_title": "Extracting jar file: Unexpected end of input stream",
                "issue_description": "Hi,\r\n\r\nwe want to extract a \"ordinary\" jar file. With version 1.3.3 it's working like a charm. From version 2.0 on we get a\r\n> net.lingala.zip4j.exception.ZipException: Could not read corresponding local file header for file header: META-INF/MANIFEST.MF\r\n\r\nWith verion 2.6.0, it's a \r\n> java.io.EOFException: Unexpected end of input stream\r\n\r\nThis is the code\r\n\r\n> ZipFile zipFile = new ZipFile(JAR_FILE_NAME);\r\n    Path tempDirectory = Files.createTempDirectory(null);\r\n    tempDirectory.toFile().deleteOnExit();\r\n    zipFile.extractAll(tempDirectory.toString());\r\n\r\nYou can use your [own jar](https://repo1.maven.org/maven2/net/lingala/zip4j/zip4j/2.6.0/zip4j-2.6.0.jar) for reproducing the issue."
            },
            "36": {
                "commit_sha_buggy": "d5c5b413a2996bceb65db4adfd353030baf21d94",
                "commit_sha_fixed": "179e3766c03f850b93b5204cdc7aee6c04f9f95b",
                "report_id": "194",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/194",
                "issue_title": "Extracting jar file: Unexpected end of input stream",
                "issue_description": "Hi,\r\n\r\nwe want to extract a \"ordinary\" jar file. With version 1.3.3 it's working like a charm. From version 2.0 on we get a\r\n> net.lingala.zip4j.exception.ZipException: Could not read corresponding local file header for file header: META-INF/MANIFEST.MF\r\n\r\nWith verion 2.6.0, it's a \r\n> java.io.EOFException: Unexpected end of input stream\r\n\r\nThis is the code\r\n\r\n> ZipFile zipFile = new ZipFile(JAR_FILE_NAME);\r\n    Path tempDirectory = Files.createTempDirectory(null);\r\n    tempDirectory.toFile().deleteOnExit();\r\n    zipFile.extractAll(tempDirectory.toString());\r\n\r\nYou can use your [own jar](https://repo1.maven.org/maven2/net/lingala/zip4j/zip4j/2.6.0/zip4j-2.6.0.jar) for reproducing the issue."
            },
            "37": {
                "commit_sha_buggy": "8ce786808a33bae964c9e549d0b77db93b967002",
                "commit_sha_fixed": "3d9f8dec9a35efdb528d56afaecc95aa073d5f57",
                "report_id": "202",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/202",
                "issue_title": "Feature: add validity check for missing z* files",
                "issue_description": "is it possible to add (or change existing) validity check that will verify if all split files exists?\r\n\r\nit happens that sometimes one or few zip split files (z01, z02 ...etc.) are missing on the disk (due to various reasons, not related to zip4j). The `extractAll` method will start the extraction and will fail only when it encounter the missing file with\r\n```Caused by: java.io.FileNotFoundException: zip split file does not exist: /home/ec2-user/bigZip.z11```\r\n\r\nit would be nice if i could test for missing files in advance. (like `zipFile.isValidZipFile()` add `zipFile.isValidSplitZipFile()` )"
            },
            "38": {
                "commit_sha_buggy": "ffe28c2db5b3d3717d5a5a48f6cf33dbf5d600eb",
                "commit_sha_fixed": "aae1798a3dbae113d7ef61f7cae2bf3e9dd2eebd",
                "report_id": "220",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/220",
                "issue_title": "net.lingala.zip4j.exception.ZipException: invalid offsets",
                "issue_description": "net.lingala.zip4j.exception.ZipException: invalid offsets\r\n\tat net.lingala.zip4j.util.FileUtils.copyFile(FileUtils.java:287)\r\n\tat net.lingala.zip4j.tasks.AbstractModifyFileTask.copyFile(AbstractModifyFileTask.java:70)\r\n\tat net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:66)\r\n\tat net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:21)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:44)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:38)\r\n\tat net.lingala.zip4j.ZipFile.removeFiles(ZipFile.java:716)\r\n\tat net.lingala.zip4j.ZipFile.removeFile(ZipFile.java:684)\r\n\r\n\r\nAn exception occurred when deleting the zip file"
            },
            "39": {
                "commit_sha_buggy": "aae1798a3dbae113d7ef61f7cae2bf3e9dd2eebd",
                "commit_sha_fixed": "9de9fbf737b836241232c12178cfef0dfc740591",
                "report_id": "220",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/220",
                "issue_title": "net.lingala.zip4j.exception.ZipException: invalid offsets",
                "issue_description": "net.lingala.zip4j.exception.ZipException: invalid offsets\r\n\tat net.lingala.zip4j.util.FileUtils.copyFile(FileUtils.java:287)\r\n\tat net.lingala.zip4j.tasks.AbstractModifyFileTask.copyFile(AbstractModifyFileTask.java:70)\r\n\tat net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:66)\r\n\tat net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:21)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:44)\r\n\tat net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:38)\r\n\tat net.lingala.zip4j.ZipFile.removeFiles(ZipFile.java:716)\r\n\tat net.lingala.zip4j.ZipFile.removeFile(ZipFile.java:684)\r\n\r\n\r\nAn exception occurred when deleting the zip file"
            },
            "40": {
                "commit_sha_buggy": "a20fcf8a48c88279493ec578356cdf361a045bb3",
                "commit_sha_fixed": "576b664c05154ae8ffce6b7044ff9b5a2a56868b",
                "report_id": "245",
                "report_url": "https://github.com/srikanth-lingala/zip4j/pull/245",
                "issue_title": "Updated ZipInputStream to throw ZipException for Strong Encryption",
                "issue_description": "The current ZipInputStream throws a ZipException in verifyCrc() when attempting to read an entry encrypted with the patented strong encryption algorithm.  This PR brings ZipInputStream in line with the recent updates to AbstractExtractFileTask described in #228 and throws a ZipException when encountering the strong encryption algorithm in initializeCipherInputStream()."
            },
            "41": {
                "commit_sha_buggy": "13c170672da595561163804dc62451dc21bfc870",
                "commit_sha_fixed": "d568afc8111bf566e8f551d5a282aa4e8660d44b",
                "report_id": "279",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/279",
                "issue_title": "Errors while reading archives from java.util.zip via ZipInputStream",
                "issue_description": "There is an error while reading zip archive from standard java.util.zip archiver. Zip4j ZipInputStream successfully read only first header in archive, next it can not find any.\r\n\r\nHere is a full code example (with zip generating, and reading via zip4j stream) and reasoning below:\r\n```java\r\n   \r\n    @Test\r\n    public void test() throws IOException {\r\n        // Arrange\r\n        String archivePath = \"C:/Users/Public/test.zipByJavaUtilZip\";\r\n        File zipArchive = new File(archivePath);\r\n\r\n        File folderToZip = new File(\"C:/Users/Public/FolderToZip\");\r\n        int expectedNumberOfEntries;\r\n        try (java.util.zip.ZipOutputStream zos = new ZipOutputStream(new FileOutputStream(zipArchive))) {\r\n            expectedNumberOfEntries = zipByJavaUtilZip(zos, folderToZip, folderToZip.listFiles());\r\n            zos.flush();\r\n        }\r\n\r\n        // Act\r\n        List<String> elements = new ArrayList<>();\r\n        try(InputStream is = new FileInputStream(zipArchive);\r\n                net.lingala.zip4j.io.inputstream.ZipInputStream zis = new ZipInputStream(is)) {\r\n\r\n            LocalFileHeader fh;\r\n            while((fh = zis.getNextEntry()) != null)\r\n                elements.add(fh.getFileName());\r\n        }\r\n\r\n        // Act-assert\r\n        // Lets prove that there are five elements in archive\r\n        net.lingala.zip4j.ZipFile zf = new net.lingala.zip4j.ZipFile(zipArchive);\r\n        Assertions.assertEquals(expectedNumberOfEntries, zf.getFileHeaders().size());\r\n        Assertions.assertEquals(5, zf.getFileHeaders().size());\r\n\r\n        // Assert\r\n        // Check for mistakes in zip4j streams\r\n        Assertions.assertEquals(expectedNumberOfEntries, elements.size()); // (elements.size() == 1) = true\r\n    }\r\n\r\n    private static int zipByJavaUtilZip(ZipOutputStream zos, File rootFolder, File[] files) throws IOException {\r\n        int entriesNumber = 0;\r\n        for (File f : files) {\r\n            if (f.isDirectory())\r\n                entriesNumber += zipByJavaUtilZip(zos, rootFolder, f.listFiles());\r\n            else {\r\n                entriesNumber++;\r\n                String path = rootFolder.toPath().relativize(f.toPath()).toString().replaceAll(\"\\\\\\\\\", \"/\");\r\n                ZipEntry entry = new ZipEntry(path);\r\n                zos.putNextEntry(entry);\r\n                try (InputStream fis = new FileInputStream(f)) {\r\n                    IOUtils.copy(fis, zos);\r\n                }\r\n                zos.closeEntry();\r\n            }\r\n        }\r\n        return entriesNumber;\r\n    }\r\n```\r\n\r\nHowever, comparing archives from ```zip4j``` and ```java.util.zip``` in hex viewer, I found, that there are not many differences between them. One of them is the general purpose flag, but the 3rd bit of it have been set in both archives. That means, that in LFH compression size is 0, and the actual size is written in the data descriptor (they are identical). So it is normal to dont know the actual size while reading LFH. But the problem is, then I call  ```zis.getNextEntry()``` second time the result will be null, because in ```zis.getNextEntry()``` there is call of ```readUntilEndOfEntry()```, in it I can see this code:\r\n```java\r\n    if (localFileHeader.isDirectory() || localFileHeader.getCompressedSize() == 0) {\r\n      return;\r\n    }\r\n.....\r\n```\r\nIn this condition there is a leaving from function, because localFileHeader.getCompressedSize() is equal to zero. But after creating archive with the same content via zip4j ZipFile or ZipOutputStream, the test above will pass. So I found this as a strange behaviour.\r\n\r\nMoreover, if I fix it in my code with the problems will appear in reading directories-lfh:\r\n```\r\nif (!lfh.isDirectory())\r\n   zis.readAllBytes();\r\n```\r\n\r\nI don\u2019t know exactly why this is happening and how to fix it (maybe it doesn't need to be fixed at all).\r\nThe test archive in attach. Thank you!\r\n[test.zip](https://github.com/srikanth-lingala/zip4j/files/5857122/test.zip)\r\n"
            },
            "42": {
                "commit_sha_buggy": "d568afc8111bf566e8f551d5a282aa4e8660d44b",
                "commit_sha_fixed": "b69843a2a03b673792d3c3630ffbbfb5edbecd3a",
                "report_id": "282",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/282",
                "issue_title": "Cannot solve the problem of password in Chinese",
                "issue_description": "When encrypting, set the Chinese password, and it will always prompt the password error when decrypting. I tried to convert the password into other codes, but also always prompt the password error\uff0cThe version used is zip4j2.6.1\u3002The unzip password is \u4f60\u597d  \u3002Below is my code and zip file\r\n[\u6d4b\u8bd5.zip](https://github.com/srikanth-lingala/zip4j/files/5901557/default.zip)\r\n\u3002\r\n\r\n@Test\r\n    public void testZip4j() throws Exception {\r\n        String zipFile =\"F:\\\\a\\\\a\\\\\u6d4b\u8bd5.zip\";\r\n        String destDir =\"F:\\\\a\\\\a\\\\\";\r\n        String password = \"\u4f60\u597d\";\r\n        ZipFile zip = new ZipFile(zipFile, password.toCharArray());\r\n        zip.extractAll(destDir);\r\n    }\r\n"
            },
            "43": {
                "commit_sha_buggy": "00101a916a2b371219a868aa25c6c637f4fce228",
                "commit_sha_fixed": "2412fb52161e01b1fe9c23e046cfbb0831aa733d",
                "report_id": "274",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/274",
                "issue_title": "Zip File Header requiring either \"\\\" or \"/\" for an entry to be considered a directory",
                "issue_description": "I have come across some software that generates a zip file which does not include a trailing \"\\\" or \"/\" on the filename of a directory.  Instead they update the \"External File Attributes\" (which seems to have been the standard way of doing it with the pkware/pkzip stuff.  \r\n\r\nI found this answer on stackoverflow to be useful: \r\n\r\n- https://stackoverflow.com/questions/39290157/determine-if-file-is-a-directory-inside-zip-archive\r\n- https://docs.microsoft.com/en-us/windows/win32/fileio/file-attribute-constants\r\n\r\nIs there a specific reason why you are just looking for a trailing \"/\" or \"\\\" to determine if the Zip Header Entry represents a directory instead of the \"External File Attributes\"?\r\n\r\nI have had to patch the HeaderReader code to look at the value read into the ExternalFileAttributes byte array and compare it against the value 16 (0x10) (values from the above Microsoft documentation, they seem to be valid for linux, macos and windows) and it seemed to work fine.\r\n"
            },
            "44": {
                "commit_sha_buggy": "da55c5807011350f872628655dd996601f31600c",
                "commit_sha_fixed": "4e2f5b2b2b8becdbf2c2729d3d160520cb0c63ef",
                "report_id": "290",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/290",
                "issue_title": "ZipException: Expected central directory entry not found (#1)",
                "issue_description": "One of my users is getting this error when the app is calling ZipFile.getFileHeaders(). I've attached the zip file for your reference. The zip was created using zip4j v2.7.0 on the user's Android device.\r\n[error.zip](https://github.com/srikanth-lingala/zip4j/files/6054468/error.zip)\r\n\r\nI've also tested extracting it with 7z and it works fine. Also tried the 'Test archive' option in 7z and it reports that there are no errors in the archive.\r\n\r\nCan you try it out at your end? Please let me know if you need more information.\r\n\r\n```\r\nnet.lingala.zip4j.exception.ZipException: Expected central directory entry not found (#1)\r\n        at net.lingala.zip4j.headers.HeaderReader.readCentralDirectory(HeaderReader.java:153)\r\n        at net.lingala.zip4j.headers.HeaderReader.readAllHeaders(HeaderReader.java:101)\r\n        at net.lingala.zip4j.ZipFile.readZipInfo(ZipFile.java:1136)\r\n        at net.lingala.zip4j.ZipFile.getFileHeaders(ZipFile.java:700)\r\n```"
            },
            "45": {
                "commit_sha_buggy": "d61b423d68f0e1488add05d4b5474d8fde5fedfc",
                "commit_sha_fixed": "e94b7528836b3a2b1cd1c5fe558dfc4e77fab1ad",
                "report_id": "311",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/311",
                "issue_title": "Feature Request: ZipInputStream should properly implement `available()`",
                "issue_description": "The https://github.com/srikanth-lingala/zip4j/blob/master/src/main/java/net/lingala/zip4j/io/inputstream/ZipInputStream.java should properly implement the `InputStream::available()` method preferably with the same behavior as https://docs.oracle.com/javase/7/docs/api/java/util/zip/ZipInputStream.html#available()\r\n\r\nIn the meanwhile, do you have a workaround for that?"
            },
            "46": {
                "commit_sha_buggy": "97679f85cae993b9ef274b78cde73f4b660d9440",
                "commit_sha_fixed": "3d0bfc3b3ed0a1725e0c1b515be136818daae43e",
                "report_id": "287",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/287",
                "issue_title": "method close() does not call the correspondant close method on childs",
                "issue_description": "As per the Stream specification, the close() method should recursively call the child's correspondent method so that the user does not have to iterate all over the nested childs. As far as I can see, the ZipOutputStream.close() method does not call the ZipOutputStream.closeEntry(), thus leaving the stream in an inconsistent value. \r\nTo prove this behavior it's sufficient to close the stream without explicitly calling the closeEntry() method: in this case the JVM will throw an exception (java.io.IOException: java.util.zip.DataFormatException: invalid stored block lengths).\r\n"
            },
            "47": {
                "commit_sha_buggy": "9bdd936b6fd6f2054c97fade5a00100c4419851b",
                "commit_sha_fixed": "44e74c6a2a30fb709ced175d769b19e452756160",
                "report_id": "326",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/326",
                "issue_title": "Unable to extract zip file using InputStream (AES-encrypted, CompressionMethod.STORE)",
                "issue_description": "Hi,\r\n\r\nwith the following code I am able to produce an IOExceoption \"Reached end of data for this entry, but aes verification failed\" when the CompressionMethod.STORE is used. This exception does not occurs when using CompressionMethod.DEFLATE. I used Zip4j in Version 2.6.1, 2.6.4 and 2.8.0. \r\n\r\n```java\r\nimport org.apache.commons.io.FileUtils;\r\n\r\nimport net.lingala.zip4j.ZipFile;\r\nimport net.lingala.zip4j.io.inputstream.ZipInputStream;\r\n...\r\n\r\npublic class MainCompact {\r\n   private static final String PW = \"test\".toCharArray();\r\n   private static final String TESTFOLDER = \"testfolder\";\r\n   private static final String OUT_ZIP = \"out.zip\";\r\n\r\n   public static void main(String[] args) throws IOException {\r\n      packWithStream(TESTFOLDER);\r\n      unpackWithStream(OUT_ZIP);\r\n   }\r\n\r\n   private static void packWithStream(String dirpath) throws IOException {\r\n      var zipParameters = new ZipParameters();\r\n      zipParameters.setCompressionMethod(CompressionMethod.DEFLATE);\r\n      zipParameters.setIncludeRootFolder(false);\r\n      zipParameters.setEncryptFiles(true);\r\n      zipParameters.setEncryptionMethod(EncryptionMethod.AES);\r\n\r\n      File[] files = new File(dirpath).listFiles();\r\n      var zipFile = new ZipFile(OUT_ZIP, PW);\r\n\r\n      for (File file : files) {\r\n         if (file.isFile()) {\r\n            var zipParametersForFile = new ZipParameters(zipParameters);\r\n            zipParametersForFile.setFileNameInZip(file.getName());\r\n            zipFile.addStream(new ByteArrayInputStream(FileUtils.readFileToByteArray(file)), zipParametersForFile);\r\n         }\r\n      }\r\n   }\r\n\r\n   private static void unpackWithStream(String zipFileName) throws IOException {\r\n      LocalFileHeader localFileHeader;\r\n      int readLen;\r\n      var readBuffer = new byte[4096];\r\n\r\n      try (var zipInputStream = new ZipInputStream(new FileInputStream(new File(zipFileName)), PW)) {\r\n         while ((localFileHeader = zipInputStream.getNextEntry()) != null) {\r\n            var extractedFile = new File(\"out/\" + localFileHeader.getFileName());\r\n            try (OutputStream outputStream = new FileOutputStream(extractedFile)) {\r\n               while ((readLen = zipInputStream.read(readBuffer)) != -1) {\r\n                  outputStream.write(readBuffer, 0, readLen);\r\n               }\r\n            }\r\n         }\r\n      }\r\n   }\r\n}\r\n```\r\nException:\r\n```\r\nException in thread \"main\" java.io.IOException: Reached end of data for this entry, but aes verification failed\r\n\tat net.lingala.zip4j.io.inputstream.AesCipherInputStream.verifyContent(AesCipherInputStream.java:140)\r\n\tat net.lingala.zip4j.io.inputstream.AesCipherInputStream.endOfEntryReached(AesCipherInputStream.java:121)\r\n\tat net.lingala.zip4j.io.inputstream.DecompressedInputStream.endOfEntryReached(DecompressedInputStream.java:43)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.endOfCompressedDataReached(ZipInputStream.java:205)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:159)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:132)\r\n\tat com.example.MainCompact.unpackWithStream(MainCompact.java:58)\r\n\tat com.example.MainCompact.main(MainCompact.java:27)\r\n```\r\nExtracting the generated zip file \"out.zip\" with 7-Zip or using the following method works fine:\r\n```java\r\n   private static void perform(String zipFileName) throws ZipException {\r\n      var zipFile = new ZipFile(zipFileName, PW);\r\n      zipFile.extractAll(\"out/\");\r\n   }\r\n```"
            },
            "48": {
                "commit_sha_buggy": "44e74c6a2a30fb709ced175d769b19e452756160",
                "commit_sha_fixed": "30493a59252cd2a0a282685245657abc05f56d6d",
                "report_id": "326",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/326",
                "issue_title": "Unable to extract zip file using InputStream (AES-encrypted, CompressionMethod.STORE)",
                "issue_description": "Hi,\r\n\r\nwith the following code I am able to produce an IOExceoption \"Reached end of data for this entry, but aes verification failed\" when the CompressionMethod.STORE is used. This exception does not occurs when using CompressionMethod.DEFLATE. I used Zip4j in Version 2.6.1, 2.6.4 and 2.8.0. \r\n\r\n```java\r\nimport org.apache.commons.io.FileUtils;\r\n\r\nimport net.lingala.zip4j.ZipFile;\r\nimport net.lingala.zip4j.io.inputstream.ZipInputStream;\r\n...\r\n\r\npublic class MainCompact {\r\n   private static final String PW = \"test\".toCharArray();\r\n   private static final String TESTFOLDER = \"testfolder\";\r\n   private static final String OUT_ZIP = \"out.zip\";\r\n\r\n   public static void main(String[] args) throws IOException {\r\n      packWithStream(TESTFOLDER);\r\n      unpackWithStream(OUT_ZIP);\r\n   }\r\n\r\n   private static void packWithStream(String dirpath) throws IOException {\r\n      var zipParameters = new ZipParameters();\r\n      zipParameters.setCompressionMethod(CompressionMethod.DEFLATE);\r\n      zipParameters.setIncludeRootFolder(false);\r\n      zipParameters.setEncryptFiles(true);\r\n      zipParameters.setEncryptionMethod(EncryptionMethod.AES);\r\n\r\n      File[] files = new File(dirpath).listFiles();\r\n      var zipFile = new ZipFile(OUT_ZIP, PW);\r\n\r\n      for (File file : files) {\r\n         if (file.isFile()) {\r\n            var zipParametersForFile = new ZipParameters(zipParameters);\r\n            zipParametersForFile.setFileNameInZip(file.getName());\r\n            zipFile.addStream(new ByteArrayInputStream(FileUtils.readFileToByteArray(file)), zipParametersForFile);\r\n         }\r\n      }\r\n   }\r\n\r\n   private static void unpackWithStream(String zipFileName) throws IOException {\r\n      LocalFileHeader localFileHeader;\r\n      int readLen;\r\n      var readBuffer = new byte[4096];\r\n\r\n      try (var zipInputStream = new ZipInputStream(new FileInputStream(new File(zipFileName)), PW)) {\r\n         while ((localFileHeader = zipInputStream.getNextEntry()) != null) {\r\n            var extractedFile = new File(\"out/\" + localFileHeader.getFileName());\r\n            try (OutputStream outputStream = new FileOutputStream(extractedFile)) {\r\n               while ((readLen = zipInputStream.read(readBuffer)) != -1) {\r\n                  outputStream.write(readBuffer, 0, readLen);\r\n               }\r\n            }\r\n         }\r\n      }\r\n   }\r\n}\r\n```\r\nException:\r\n```\r\nException in thread \"main\" java.io.IOException: Reached end of data for this entry, but aes verification failed\r\n\tat net.lingala.zip4j.io.inputstream.AesCipherInputStream.verifyContent(AesCipherInputStream.java:140)\r\n\tat net.lingala.zip4j.io.inputstream.AesCipherInputStream.endOfEntryReached(AesCipherInputStream.java:121)\r\n\tat net.lingala.zip4j.io.inputstream.DecompressedInputStream.endOfEntryReached(DecompressedInputStream.java:43)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.endOfCompressedDataReached(ZipInputStream.java:205)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:159)\r\n\tat net.lingala.zip4j.io.inputstream.ZipInputStream.read(ZipInputStream.java:132)\r\n\tat com.example.MainCompact.unpackWithStream(MainCompact.java:58)\r\n\tat com.example.MainCompact.main(MainCompact.java:27)\r\n```\r\nExtracting the generated zip file \"out.zip\" with 7-Zip or using the following method works fine:\r\n```java\r\n   private static void perform(String zipFileName) throws ZipException {\r\n      var zipFile = new ZipFile(zipFileName, PW);\r\n      zipFile.extractAll(\"out/\");\r\n   }\r\n```"
            },
            "49": {
                "commit_sha_buggy": "dad9a0baf5a2d34da67ad701f23b5bc42323cb43",
                "commit_sha_fixed": "5b8ad4d3383b38eb2c23f31c2bd5f84dabc5da8a",
                "report_id": "354",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/354",
                "issue_title": "ZipInputStream not finding next entry if entry is a folder with a Data Descriptor Still Not Fixed",
                "issue_description": "I believe this issue is still not fixed (tested in 2.9.0).   The attached simple example of writing a zip archive with just two directories using ZipOutputStream and then reading with ZipInputStream fails to read the second entry. \r\n\r\nThe offending code seems to be in ZipInputStream.read(byte[], int, int) lines 155-157:\r\n`\r\n    if (localFileHeader.isDirectory()) {\r\n      return -1;\r\n    }\r\n`\r\nSince this stops reading before endOfCompressedDataRecord() can be called, and subsequently read the data descriptor block.   Reading the next entry then silently fails because the signature is for a data descriptor and not a local file header.\r\n\r\n[Zip4jDirectoryDataDescriptorBug.zip](https://github.com/srikanth-lingala/zip4j/files/7093077/Zip4jDirectoryDataDescriptorBug.zip)\r\n\r\n_Originally posted by @mbach979 in https://github.com/srikanth-lingala/zip4j/issues/309#issuecomment-910485641_"
            },
            "50": {
                "commit_sha_buggy": "9eab02b675d23079fc87fe9a6c0d5503465d2e3e",
                "commit_sha_fixed": "860965237a746e481071a656377633f84dfb388b",
                "report_id": "365",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/365",
                "issue_title": "ZipException when remove file on android device : ivalid offsets",
                "issue_description": "When I use the tool(2.9.0) to delete the file in the zip (android device), I can get the fileHeader by looking at the file name as garbled on the PC side, but an error is reported when I use fileHeader or filename to delete it....However, it works normally in version 1.3.2\r\nfile name: \u03c3\u00c5\u00ec\u00b5\u00e8\u00ffL\u03c3\u20a7\u00ef\u03c4\u255d\u2551\u03c3\u00c5\u00fa\u00b5\u00a5\u2510.SLDPRT.view\r\ncode:\r\nZipFile zipFile = new ZipFile(destFile);\r\nString removeName = null;\r\ntry {\r\n    List<FileHeader> fileHeaders = zipFile.getFileHeaders();\r\n    for (FileHeader fileHeader : fileHeaders) {\r\n        String name = fileHeader.getFileName();\r\n        if (name.endsWith(\".view\")) {\r\n            removeName = name;\r\n            break;\r\n        }\r\n    }\r\n    if (removeName == null)\r\n        return;\r\n    zipFile.removeFile(removeName);\r\n} catch (ZipException e) {\r\n    e.printStackTrace();\r\n}\r\n\r\nException:\r\n\r\nSystem.err: net.lingala.zip4j.exception.ZipException: invalid offsets\r\nSystem.err:     at net.lingala.zip4j.util.FileUtils.copyFile(FileUtils.java:305)\r\nSystem.err:     at net.lingala.zip4j.tasks.AbstractModifyFileTask.copyFile(AbstractModifyFileTask.java:72)\r\nSystem.err:     at net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:67)\r\nSystem.err:     at net.lingala.zip4j.tasks.RemoveFilesFromZipTask.executeTask(RemoveFilesFromZipTask.java:22)\r\nSystem.err:     at net.lingala.zip4j.tasks.AsyncZipTask.performTaskWithErrorHandling(AsyncZipTask.java:51)\r\nSystem.err:     at net.lingala.zip4j.tasks.AsyncZipTask.execute(AsyncZipTask.java:45)\r\nSystem.err:     at net.lingala.zip4j.ZipFile.removeFiles(ZipFile.java:839)\r\nSystem.err:     at net.lingala.zip4j.ZipFile.removeFile(ZipFile.java:807)\r\nSystem.err:     at me.pqpo.zip4jdemo.MainActivity.testremove(MainActivity.java:48)"
            },
            "51": {
                "commit_sha_buggy": "db41e9b47c82d728b66e9209a66cd00fa4aa52c0",
                "commit_sha_fixed": "66dc565a252a2eb277f1e739bddbeb797b3c3acb",
                "report_id": "388",
                "report_url": "https://github.com/srikanth-lingala/zip4j/issues/388",
                "issue_title": "Nullpointer exception with empty file name in ZipParameters",
                "issue_description": "Since [this change](https://github.com/srikanth-lingala/zip4j/compare/v2.9.0...v2.9.1#diff-100b4db33b29b6e975cd85b189f47189ef011d29acf01618ad322a19a27e1a45L75) from version 2.9.0 tot 2.9.1 the file name could still be null leading to a null pointer exception.\r\n\r\nThe validation is done in the `FileHeaderFactory`, but this is called from the `initializeAndWriteFileHeader`. As this is now after the directory check, this will never trigger:\r\n```\r\n  private String validateAndGetFileName(String fileNameInZip) throws ZipException {\r\n    if (!Zip4jUtil.isStringNotNullAndNotEmpty(fileNameInZip)) {\r\n      throw new ZipException(\"fileNameInZip is null or empty\");\r\n    } else {\r\n      return fileNameInZip;\r\n    }\r\n  }\r\n```\r\n\r\nProblematic code, 2e line is the problem when file name is null:\r\n```\r\nZipParameters clonedZipParameters = new ZipParameters(zipParameters);\r\nif (isZipEntryDirectory(zipParameters.getFileNameInZip())) {\r\n  clonedZipParameters.setWriteExtendedLocalFileHeader(false);\r\n  clonedZipParameters.setCompressionMethod(CompressionMethod.STORE);\r\n  clonedZipParameters.setEncryptFiles(false);\r\n}\r\ninitializeAndWriteFileHeader(clonedZipParameters);\r\n```\r\n\r\nThere are multiple solutions to solve this. Moving the validation to an earlier point or making sure there is no null pointer exception by checking if it's not null."
            },
            "52": {
                "commit_sha_buggy": "44e74c6a2a30fb709ced175d769b19e452756160",
                "commit_sha_fixed": "9bdd936b6fd6f2054c97fade5a00100c4419851b",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "#326 Fix compression method check in AddStreamTask",
                "issue_description": "#326 Fix compression method check in AddStreamTask"
            }
        }
    },
    "Sparsebitset": {
        "owner_repo": "brettwooldridge/SparseBitSet",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "37ec0681635c8e0c536f0d63fc52d8d19367110a",
                "commit_sha_fixed": "0622dfd9721e7e2ae8a1cc2e8dcdd0e31daaaad1",
                "report_id": "7",
                "report_url": "https://github.com/brettwooldridge/SparseBitSet/issues/7",
                "issue_title": "Request for previousSetBit and previousClearBit methods",
                "issue_description": "The java BitSet implementation has these as: \r\n\r\n\r\n    int\tpreviousClearBit(int fromIndex)\r\n    int\tpreviousSetBit(int fromIndex)\r\n\r\nMany thanks for this excellent implementation. This is truly useful and a great addition to the JVM ecosystem of tools. \r\n\r\nI started looking at creating a pull request but given the complexity of the implementation I backed out and figured I would ask the implementor for help first. Let me know if this would be feasible and if so, whether this is something you could envision adding. "
            },
            "2": {
                "commit_sha_buggy": "e8d1c80f14184cb069478d4f445ef97ead2f2a84",
                "commit_sha_fixed": "cc7b16f6328df8ce5c8ef74c92e8c72b193de2fa",
                "report_id": "15",
                "report_url": "https://github.com/brettwooldridge/SparseBitSet/issues/15",
                "issue_title": "Bug in previousClearBit",
                "issue_description": "Hi,\r\n\r\nwhile testing the 1.2 version I found the following issue:\r\n```\r\nSparseBitSet set = new SparseBitSet();\r\nset.set(0);\r\nset.set(64);\r\nSystem.out.println(set.previousClearBit(64));\r\nset.clear(0);\r\nset.set(1);\r\nSystem.out.println(set.previousClearBit(64));\r\n```\r\n\r\nExpected: (consistent with BitSet)\r\n```\r\n63\r\n63\r\n```\r\nGot:\r\n```\r\n-1\r\n0\r\n```\r\n\r\n@BrentDouglas "
            }
        }
    },
    "Incubator_retired_pirk": {
        "owner_repo": "apache/incubator-retired-pirk",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "697913a0665af7bedb438bbfb595e14741e8340f",
                "commit_sha_fixed": "5ebe1bf2fddbd0ff9e36016bc49afb4ba33ab09d",
                "report_id": "42",
                "report_url": "https://github.com/apache/incubator-retired-pirk/pull/42",
                "issue_title": "[PIRK-41]: Add JSON Serialization for Java Objects",
                "issue_description": ""
            }
        }
    },
    "Assertj_assertions_generator": {
        "owner_repo": "assertj/assertj-assertions-generator",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0793b76ea9a186bf4d1d3d4ffdf7a8243d3ff449",
                "commit_sha_fixed": "039ae53441513941ab57b32e201d7857272f1aae",
                "report_id": "25",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/issues/25",
                "issue_title": "Generated assertion for public boolean field is wrong",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "c8dc7c7f2fc2d5a8c006ba3fa1913c45c76eac8b",
                "commit_sha_fixed": "5ea763b52d7a5186d79141ac6b00dc81d2781113",
                "report_id": "46",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/issues/46",
                "issue_title": "Predicate assertions are badly generated if boolean property contains is  ",
                "issue_description": "```\n public PropertyDomainEventAssert<S, T> isDisabled() {\n    // check that actual PropertyDomainEvent we want to make assertions on is not null.\n    isNotNull();\n\n    // check\n    if (!actual.isDisabled()) {\n      failWithMessage(\"\\nExpecting that actual PropertyDomainEvent is dabled but is not.\");\n    }\n\n    // return the current assertion for method chaining\n    return this;\n  }\n```\n"
            },
            "3": {
                "commit_sha_buggy": "7ced7f3d837971a2464701023fb65ad265c5caeb",
                "commit_sha_fixed": "850a460ab6f5764fb4f33636b6c6a157b194af63",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix the case where actual.get${Property}() doesn't return the same value on successive calls ( example : java.util.zip.ZipInputStream.getNextEntry() )",
                "issue_description": "fix the case where actual.get${Property}() doesn't return the same value on successive calls ( example : java.util.zip.ZipInputStream.getNextEntry() )"
            },
            "4": {
                "commit_sha_buggy": "30e99e6f4db090605d042cab1e0fd96d5b1b6b39",
                "commit_sha_fixed": "b81e487df34f15d622c3bf482eddbb144fd986d5",
                "report_id": "6",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/issues/6",
                "issue_title": "Don't generate hasDeclaringClass for Enum",
                "issue_description": ""
            },
            "5": {
                "commit_sha_buggy": "039ae53441513941ab57b32e201d7857272f1aae",
                "commit_sha_fixed": "fe273b62fc7a124c245f9d444a878b6d83a1d8bc",
                "report_id": "18",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/issues/18",
                "issue_title": "Assertation generation throws when generating assertions for scala case class",
                "issue_description": "First: thanks for your great assertion generator!\n\nI was trying to use the maven plugin to generate assertions for a mixed java/scala project. I reported it here, because I think it is related to generation instead of the maven plugin. It turns out the generator throws the following exception when a assertion classes are generated for a case class or object.\n\n```\n[INFO] --- assertj-assertions-generator-maven-plugin:1.2.0:generate-assertions (default) @ AssertJAssertionsGenerationsBugWithScala ---\n[INFO] \n\n====================================\nAssertJ assertions generation report\n====================================\n\n--- Generator input parameters ---\n\n\n--- Generator results ---\n\nAssertions failed with error : Illegal group referenceFull error stack : java.lang.IllegalArgumentException: Illegal group reference\n    at java.util.regex.Matcher.appendReplacement(Matcher.java:808)\n    at java.util.regex.Matcher.replaceAll(Matcher.java:906)\n    at java.lang.String.replaceAll(String.java:2162)\n    at org.assertj.assertions.generator.BaseAssertionGenerator.generateCustomAssertionContentFor(BaseAssertionGenerator.java:224)\n    at org.assertj.assertions.generator.BaseAssertionGenerator.generateCustomAssertionFor(BaseAssertionGenerator.java:198)\n    at org.assertj.maven.generator.AssertionsGenerator.generateAssertionsFor(AssertionsGenerator.java:49)\n    at org.assertj.maven.AssertJAssertionsGeneratorMojo.executeWithAssertionGenerator(AssertJAssertionsGeneratorMojo.java:83)\n    at org.assertj.maven.AssertJAssertionsGeneratorMojo.execute(AssertJAssertionsGeneratorMojo.java:75)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)\n    at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320)\n    at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156)\n    at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537)\n    at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196)\n    at org.apache.maven.cli.MavenCli.main(MavenCli.java:141)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\n```\n\nI made a small project to show the bug at https://github.com/TimSoethout/AssertJAssertionsGenerationsBugWithScala\n\nIn the file `src/main/scala/pack/Scala.scala`  I created a case class. This will trigger above message on a build (`mvn clean package`).\nIt also fails when the case class is replaced with an object; this can be found on branch `object`.\n"
            },
            "6": {
                "commit_sha_buggy": "3ce0471340c6327d60ca3a4db162fcf0e6d0bcaa",
                "commit_sha_fixed": "ac7125ecf21867ba65e97b610beb8ac826f8ace2",
                "report_id": "13",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/pull/13",
                "issue_title": "rename errorMessage with an assertJ name",
                "issue_description": "Hi,\n\nI have a bean : \n\n``` java\npublic class SessionBean {\n\n    /**\n     * sessionKey opened on my  awesome service.\n     */\n    private String sessionKey;\n\n    /**\n     * url of my awesome service.\n     */\n    private String url;\n\n    /**\n     * Error message if any.\n     */\n    private String errorMessage;\n}\n```\n\nand the generated file contains:\n\n``` java\n    public SessionBeanAssert hasErrorMessage(String errorMessage)\n    {\n        // check that actual SessionBean we want to make assertions on is not null.\n        isNotNull();\n\n        // we overrides the default error message with a more explicit one\n        String errorMessage = \"\\nExpected errorMessage of:\\n  <%s>\\nto be:\\n  <%s>\\n but was:\\n  <%s>\";\n\n        // check\n        if (!actual.getErrorMessage().equals(errorMessage)) {\n            failWithMessage(errorMessage, actual, errorMessage, actual.getErrorMessage());\n        }\n\n        // return the current assertion for method chaining\n        return this;\n    }\n```\n\nwith a compilation error.\n\nI propose to rename the internal field with an assertj name.\n"
            },
            "7": {
                "commit_sha_buggy": "7b75fd10cc524e4f88746e905219121d3837dd3c",
                "commit_sha_fixed": "2a04691661e1f230f948fbd23c6d8ebfb469c949",
                "report_id": "20",
                "report_url": "https://github.com/assertj/assertj-assertions-generator/pull/20",
                "issue_title": "Fixed some typos in the assertion template's Javadoc",
                "issue_description": "Couple of broken html tags and a minor grammatical fix.\n"
            }
        }
    },
    "Config_magic": {
        "owner_repo": "brianm/config-magic",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2e84e68ec0eb70465a54d41c5a381f4ab452a093",
                "commit_sha_fixed": "eeb2fd4bc8b6b574b0a25dd1795e87a172939a96",
                "report_id": "12",
                "report_url": "https://github.com/brianm/config-magic/pull/12",
                "issue_title": "[config-magic] Add min as an alias for minutes.",
                "issue_description": "Useful because 5m is very close to 5ms but 5min is much clearer.\r\n\r\nTested: Unit test."
            },
            "2": {
                "commit_sha_buggy": "6699981d792b90936defeee748e9d9283b55aa78",
                "commit_sha_fixed": "c3d86553f93b07ff039f5bbab47d8c3c27e4151d",
                "report_id": "2",
                "report_url": "https://github.com/brianm/config-magic/pull/2",
                "issue_title": "Support for arrays and collections",
                "issue_description": "Plus better null handling\n"
            }
        }
    },
    "Deft": {
        "owner_repo": "rschildmeijer/deft",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7907b95aff987f0bef408e0aec1caea3267986cb",
                "commit_sha_fixed": "fb3df4a7dfb4ae4453a896a33f06c70e72c964ad",
                "report_id": "55",
                "report_url": "https://github.com/rschildmeijer/deft/issues/55",
                "issue_title": "Dont set Etag response header if payload is empty",
                "issue_description": ""
            }
        }
    },
    "Jcodemodel": {
        "owner_repo": "phax/jcodemodel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "530dceb0a91fbb76a678389996a1a1db26d5cbc4",
                "commit_sha_fixed": "1e91d0eb53123d84e40cad5cf1a85bbc9cf2f128",
                "report_id": "61",
                "report_url": "https://github.com/phax/jcodemodel/issues/61",
                "issue_title": "Flush needed when writing resources",
                "issue_description": "When writing a `JTextFile`, some data might be missing due to an intermediate `Writer` neither being flushed nor closed."
            },
            "2": {
                "commit_sha_buggy": "ddd91831f8aa4eae92c2acc6cde90c533813b08c",
                "commit_sha_fixed": "9da04c8b236a340815f7f0e0f433eb720c25ff2f",
                "report_id": "62",
                "report_url": "https://github.com/phax/jcodemodel/pull/62",
                "issue_title": "Proposed fix for issue #61",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "fb5dc5f4f5d70084cd84ae6039a053fd7e322331",
                "commit_sha_fixed": "64f07e6884559c5467bdbb6536cfb68402e6842a",
                "report_id": "9",
                "report_url": "https://github.com/phax/jcodemodel/pull/9",
                "issue_title": "Support multiple bounds on type variables",
                "issue_description": "This change supports multiple bounds on type variables, which resolves #8 \n"
            },
            "4": {
                "commit_sha_buggy": "c82778e29aa7cb2b6fafee0b63241bbeccec0935",
                "commit_sha_fixed": "bc32a3b11d2e09067e5d0d8b6d76b332e9763de9",
                "report_id": "20",
                "report_url": "https://github.com/phax/jcodemodel/issues/20",
                "issue_title": "equals/hashCode for IJExpressions",
                "issue_description": "Seems that implementing `equals()` and `hashCode()` methods for `IJExpression` subclasses is an absolute requirement for starting any analysis (#18). What way of implementing this do you prefer for the lib? Some particular auto generation utility, such as from Apache Commons, or Lombok, or Google's auto-value? Generating from Eclipse/Intellij? Or writing by hand?\n\n(Of cause I would be very grateful if you implement this, but if don't want to, I will be forced to do it myself, and will try to accout your advice.)\n"
            },
            "5": {
                "commit_sha_buggy": "164389bb9256d8757faec19638a37c3a1e9a04c0",
                "commit_sha_fixed": "e1b768556c33cca2e97e138ff2bd1391d65f8451",
                "report_id": "27",
                "report_url": "https://github.com/phax/jcodemodel/issues/27",
                "issue_title": "JPackage.parent() cannot walk to root package",
                "issue_description": "When producing a code model using JCodeModel.ref(<clazz>), the following operation doesn't work as expected:\n\n<code>\n// Create JCodeModel\n\nJCodeModel wModel = new JCodeModel();\n\n// Reflect into class\n\nAbstractJClass wClass = wModel.ref(com.redfish.prod.Boomer.class);\n\n// Walk up to the root package\n\nJPackage wCurrentPackage = null;\n\nfor (wCurrentPackage = wClass._package(); wCurrentPackage.parent() != null; wCurrentPackage = wCurrentPackage.parent());\n\nJPackage wRoot = wCurrentPackage;\n\n</code>\n\nThe problem occurs in JPackage.parent() on the package just above the root package.  The name is just \"com\", and so the existing code:\n\n<code>\n  /**\n- Gets the parent package, or null if this class is the root package.\n  */\n  \n  @Nullable\n  \n  public JPackage parent ()\n  \n  {\n  \n    if (m_sName.length () == 0)\n  \n  ```\n  return null;\n  ```\n  \n    final int idx = m_sName.lastIndexOf ('.');\n  \n    return m_aOwner._package (m_sName.substring (0, idx));\n  \n  }\n\n</code>\n\nThe result in the lowest level non-root package is a StringIndexOutOfBoundsException as \"idx\" is set to -1.\n\nThis seems to be correct usage based on what I seei in the method's documentation, but clearly it can't handle it.\n"
            },
            "6": {
                "commit_sha_buggy": "04f585d95e4828ee219202e4d21713a46557569a",
                "commit_sha_fixed": "d4b3464d5aa7351d0a4dc083aa1e4af091cee459",
                "report_id": "30",
                "report_url": "https://github.com/phax/jcodemodel/issues/30",
                "issue_title": "Clash when importing inner class with the same name as package suffix",
                "issue_description": "Importing inner classes can introduce not expected compilation problems\n\nFor example in [AndroidAnnotations](https://github.com/excilys/androidannotation), the user can have a following annotated class.\n\n``` java\npackage id.mypapp;\npublic class R {\n  public static class id {\n     public static final int myItem = 1;\n  }\n   public static class menu {\n     public static final int menu = 2;\n  }\n}\n```\n\n``` java\nimport id.myapp.R;\n// other imports\n\n@OptionsMenu(R.menu.menu)\npublic class HelloAndroidActivity extends Activity {\n    @OptionsItem(R.id.myItem)\n    void myItemClicked() {\n\n    }\n}\n```\n\nThis is generated:\n\n``` java\nimport id.myapp.R.id;\n// other imports\n\npublic final class HelloAndroidActivity_ extends HelloAndroidActivity {\n\n    @Override\n    public boolean onCreateOptionsMenu(Menu menu) {\n        // compilation error:\n        // id is a package name part here, but compiler thinks its\n        // inner class id.myapp.R.id\n        menuInflater.inflate(id.myapp.R.menu.mymenu, menu);\n        return super.onCreateOptionsMenu(menu);\n    }\n\n    @Override\n    public boolean onOptionsItemSelected(MenuItem item) {\n        if (itemId_ == id.mymenuitem) { // id.myapp.R.id\n            //\n        }\n        return super.onOptionsItemSelected(item);\n    }\n}\n```\n\nSo the main problem is that jcodemodel imports `id.myapp.R.id` **inner class**, however when it references `id.myapp.R.menu.mymenu` **field** , the compiler will think the first part of it is not a **package part**, but the **inner class** `id.myapp.R.id`.\n\nThe most easier solution would be to never import inner classes or maybe add an option to not to do so. (BTW, in Android, it is conventional to only import the `id.myapp.R` class, and not its inner classes.)\n"
            },
            "7": {
                "commit_sha_buggy": "d4b3464d5aa7351d0a4dc083aa1e4af091cee459",
                "commit_sha_fixed": "bc30972d02c4c09b82b5be41d450992ec1858171",
                "report_id": "30",
                "report_url": "https://github.com/phax/jcodemodel/issues/30",
                "issue_title": "Clash when importing inner class with the same name as package suffix",
                "issue_description": "Importing inner classes can introduce not expected compilation problems\n\nFor example in [AndroidAnnotations](https://github.com/excilys/androidannotation), the user can have a following annotated class.\n\n``` java\npackage id.mypapp;\npublic class R {\n  public static class id {\n     public static final int myItem = 1;\n  }\n   public static class menu {\n     public static final int menu = 2;\n  }\n}\n```\n\n``` java\nimport id.myapp.R;\n// other imports\n\n@OptionsMenu(R.menu.menu)\npublic class HelloAndroidActivity extends Activity {\n    @OptionsItem(R.id.myItem)\n    void myItemClicked() {\n\n    }\n}\n```\n\nThis is generated:\n\n``` java\nimport id.myapp.R.id;\n// other imports\n\npublic final class HelloAndroidActivity_ extends HelloAndroidActivity {\n\n    @Override\n    public boolean onCreateOptionsMenu(Menu menu) {\n        // compilation error:\n        // id is a package name part here, but compiler thinks its\n        // inner class id.myapp.R.id\n        menuInflater.inflate(id.myapp.R.menu.mymenu, menu);\n        return super.onCreateOptionsMenu(menu);\n    }\n\n    @Override\n    public boolean onOptionsItemSelected(MenuItem item) {\n        if (itemId_ == id.mymenuitem) { // id.myapp.R.id\n            //\n        }\n        return super.onOptionsItemSelected(item);\n    }\n}\n```\n\nSo the main problem is that jcodemodel imports `id.myapp.R.id` **inner class**, however when it references `id.myapp.R.menu.mymenu` **field** , the compiler will think the first part of it is not a **package part**, but the **inner class** `id.myapp.R.id`.\n\nThe most easier solution would be to never import inner classes or maybe add an option to not to do so. (BTW, in Android, it is conventional to only import the `id.myapp.R` class, and not its inner classes.)\n"
            }
        }
    },
    "Jdbm3": {
        "owner_repo": "jankotek/JDBM3",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "82b439ec707ae732361ba1775e30d8adb31fbfd8",
                "commit_sha_fixed": "cb04445a2506a3fd749a288374330f67f29d4578",
                "report_id": "22",
                "report_url": "https://github.com/jankotek/JDBM3/issues/22",
                "issue_title": "BTreeBench reports IOException: Cannot allocate memory",
                "issue_description": "Iterations=0 Objects=0, elapsed=1ms\nIterations=5000 Objects=4666, elapsed=3049ms\n\njava.io.IOError: java.io.IOException: Cannot allocate memory\n    at net.kotek.jdbm.DBStore.commit(DBStore.java:573)\n    at net.kotek.jdbm.DBCache.commit(DBCache.java:343)\n    at net.kotek.jdbm.BTreeBench.doTest(BTreeBench.java:59)\n    at net.kotek.jdbm.BTreeBench.test_001(BTreeBench.java:42)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n    at com.intellij.junit3.JUnit3IdeaTestRunner.doRun(JUnit3IdeaTestRunner.java:139)\n    at com.intellij.junit3.JUnit3IdeaTestRunner.startRunnerWithArgs(JUnit3IdeaTestRunner.java:52)\n    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:202)\n    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120)\nCaused by: java.io.IOException: Cannot allocate memory\n    at java.nio.MappedByteBuffer.force0(Native Method)\n    at java.nio.MappedByteBuffer.force(MappedByteBuffer.java:154)\n    at net.kotek.jdbm.StorageDiskMapped.sync(StorageDiskMapped.java:176)\n    at net.kotek.jdbm.RecordFile.sync(RecordFile.java:376)\n    at net.kotek.jdbm.TransactionManager.synchronizeLogFromMemory(TransactionManager.java:123)\n    at net.kotek.jdbm.TransactionManager.start(TransactionManager.java:221)\n    at net.kotek.jdbm.RecordFile.commit(RecordFile.java:237)\n    at net.kotek.jdbm.PageManager.commit(PageManager.java:203)\n    at net.kotek.jdbm.DBStore.commit(DBStore.java:564)\n    ... 24 more\n\nIf I reduce the test to doTest(db, tree, 601); it passes but doTest(db, tree, 611); does not.  Do you have any suggestions?\n\nThe machine has 16 GB of memory, 14 GB of swap and 180 GB of free disk. Running Centos 6.2.\n"
            },
            "2": {
                "commit_sha_buggy": "67a5d6ff2e2be12f77851894b4ad4fe25770f76d",
                "commit_sha_fixed": "10538e67a06f8c824c32999b6fb70d8f292e149d",
                "report_id": "73",
                "report_url": "https://github.com/jankotek/JDBM3/issues/73",
                "issue_title": "Error while using putAll on a previously deleted collection",
                "issue_description": "Hi,\nI have written a test case to show the issue.\n\npackage net.kotek.jdbm;\n\nimport org.junit.Test;\n\nimport java.io.IOException;\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n- Yoocos S\u00e0rl\n- User: David\n- Date: 25.04.12\n- Time: 12:52\n  */\n  public class RootIsNullTest {\n  public DB db;\n  @Test\n  public void test() throws IOException {\n      db = DBMakerTest.newDBCache();\n      Map<String,Object> toAdd = new HashMap<String, Object>() ;\n      toAdd.put(\"description\",\"test\");\n      toAdd.put(\"descriptio1\",\"test\");\n  \n  ```\n  Map<String,Object> map = db.createHashMap(\"test\");\n  map.putAll(toAdd);\n  db.commit();\n  db.deleteCollection(\"test\");\n  map = getOrCreate(\"test\");\n  map.putAll(toAdd);\n  db.commit();\n  ```\n  \n  }\n  \n  private Map<String,Object> getOrCreate(String name){\n      Map<String,Object> result = db.getHashMap(name);\n      return result == null ? db.<String,Object>createHashMap(name) : result;\n  }\n  }\n\nWhen you run this test, you get a NullPointerException on line 437 because getRoot returns null.\nDo I do something wrong or is it a bug?\n\nThank you in advance!\n"
            },
            "3": {
                "commit_sha_buggy": "275f231026dc49aa8fc9556064442a6420364fb3",
                "commit_sha_fixed": "d247a9254a002fb8f0a29a27589b4f303094c0d8",
                "report_id": "74",
                "report_url": "https://github.com/jankotek/JDBM3/issues/74",
                "issue_title": "java.util.Locale serialization fails",
                "issue_description": "This unit test fails, on db.close();\n\n``` java\nimport static org.junit.Assert.*;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.Locale;\nimport java.util.concurrent.ConcurrentMap;\n\nimport net.kotek.jdbm.DB;\nimport net.kotek.jdbm.DBMaker;\n\nimport org.apache.commons.io.FileUtils;\nimport org.apache.commons.io.FilenameUtils;\nimport org.junit.Test;\n\nimport com.validit.vitam.utils.jdbm.JDBMBuilder;\nimport com.validit.vitam.utils.jdbm.JDBMBuilderOptions;\n\npublic class JDBMTest {\n\n    @Test\n    public void test() throws IOException {\n        File directory = new File(\"test.serializer/test\");\n        FileUtils.deleteDirectory(directory);\n        directory.mkdirs();\n\n        DBMaker dbMaker = DBMaker.openFile(directory.getPath() + \"/jdbm\");\n        DB db = dbMaker.make();\n        try {\n            ConcurrentMap<String, Locale> map = db.createHashMap(\"map\");\n\n            map.put(\"en\", Locale.ENGLISH);\n            map.put(\"fr\", Locale.FRENCH);\n\n            db.commit();\n        } finally {\n            db.close();\n        }\n\n        dbMaker = DBMaker.openFile(directory.getPath() + \"/jdbm\");\n        db = dbMaker.make();\n\n        ConcurrentMap<String, Locale> map = db.getHashMap(\"map\");\n        assertEquals(map.get(\"en\"), Locale.ENGLISH);\n        assertEquals(map.get(\"fr\"), Locale.FRENCH);\n    }\n\n}\n\n```\n\n```\njava.lang.NoSuchFieldError: class java.util.Locale.hashcode\n    at net.kotek.jdbm.SerialClassInfo.getFieldValue(SerialClassInfo.java:221)\n    at net.kotek.jdbm.SerialClassInfo.writeObject(SerialClassInfo.java:299)\n    at net.kotek.jdbm.Serialization.serialize(Serialization.java:377)\n    at net.kotek.jdbm.Serialization.serialize(Serialization.java:84)\n    at net.kotek.jdbm.HTreeBucket.writeExternal(HTreeBucket.java:297)\n    at net.kotek.jdbm.HTree$1.serialize(HTree.java:68)\n    at net.kotek.jdbm.DBStore.update2(DBStore.java:331)\n    at net.kotek.jdbm.DBStore.update(DBStore.java:315)\n    at net.kotek.jdbm.DBCache.updateCacheEntries(DBCache.java:146)\n    at net.kotek.jdbm.DBCacheMRU.close(DBCacheMRU.java:183)\n    at JDBMTest.test(JDBMTest.java:38)\n......\n```\n"
            },
            "4": {
                "commit_sha_buggy": "8ff1d770b95bfe74a46649312371dd67422442e0",
                "commit_sha_fixed": "67a5d6ff2e2be12f77851894b4ad4fe25770f76d",
                "report_id": "74",
                "report_url": "https://github.com/jankotek/JDBM3/issues/74",
                "issue_title": "java.util.Locale serialization fails",
                "issue_description": "This unit test fails, on db.close();\n\n``` java\nimport static org.junit.Assert.*;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.Locale;\nimport java.util.concurrent.ConcurrentMap;\n\nimport net.kotek.jdbm.DB;\nimport net.kotek.jdbm.DBMaker;\n\nimport org.apache.commons.io.FileUtils;\nimport org.apache.commons.io.FilenameUtils;\nimport org.junit.Test;\n\nimport com.validit.vitam.utils.jdbm.JDBMBuilder;\nimport com.validit.vitam.utils.jdbm.JDBMBuilderOptions;\n\npublic class JDBMTest {\n\n    @Test\n    public void test() throws IOException {\n        File directory = new File(\"test.serializer/test\");\n        FileUtils.deleteDirectory(directory);\n        directory.mkdirs();\n\n        DBMaker dbMaker = DBMaker.openFile(directory.getPath() + \"/jdbm\");\n        DB db = dbMaker.make();\n        try {\n            ConcurrentMap<String, Locale> map = db.createHashMap(\"map\");\n\n            map.put(\"en\", Locale.ENGLISH);\n            map.put(\"fr\", Locale.FRENCH);\n\n            db.commit();\n        } finally {\n            db.close();\n        }\n\n        dbMaker = DBMaker.openFile(directory.getPath() + \"/jdbm\");\n        db = dbMaker.make();\n\n        ConcurrentMap<String, Locale> map = db.getHashMap(\"map\");\n        assertEquals(map.get(\"en\"), Locale.ENGLISH);\n        assertEquals(map.get(\"fr\"), Locale.FRENCH);\n    }\n\n}\n\n```\n\n```\njava.lang.NoSuchFieldError: class java.util.Locale.hashcode\n    at net.kotek.jdbm.SerialClassInfo.getFieldValue(SerialClassInfo.java:221)\n    at net.kotek.jdbm.SerialClassInfo.writeObject(SerialClassInfo.java:299)\n    at net.kotek.jdbm.Serialization.serialize(Serialization.java:377)\n    at net.kotek.jdbm.Serialization.serialize(Serialization.java:84)\n    at net.kotek.jdbm.HTreeBucket.writeExternal(HTreeBucket.java:297)\n    at net.kotek.jdbm.HTree$1.serialize(HTree.java:68)\n    at net.kotek.jdbm.DBStore.update2(DBStore.java:331)\n    at net.kotek.jdbm.DBStore.update(DBStore.java:315)\n    at net.kotek.jdbm.DBCache.updateCacheEntries(DBCache.java:146)\n    at net.kotek.jdbm.DBCacheMRU.close(DBCacheMRU.java:183)\n    at JDBMTest.test(JDBMTest.java:38)\n......\n```\n"
            },
            "5": {
                "commit_sha_buggy": "7621c122f4fa31232d8a1b2489e2f65eed6b93ba",
                "commit_sha_fixed": "c4bebaf3202ca5b6796cdd08d8c7153493a143e3",
                "report_id": "64",
                "report_url": "https://github.com/jankotek/JDBM3/issues/64",
                "issue_title": "Getting out of memory exception when inserting millions of records",
                "issue_description": "``` java\n        DB db = DBMaker.openFile(\"bigdb2\").make();\n        SortedMap<String, Data> map = db.getTreeMap(\"bigmap\");\n        if( map == null ) map = db.createTreeMap(\"bigmap\");\n\n        for(int i = 0; i < 1000000000; i++)\n        {\n            map.put(\"key\"+i, new Data(\"data\" + i) );\n\n            if( i % 1000 == 0 )\n            {\n                System.out.println(i);\n                db.commit(); // excepton on this line\n            }\n        }\n\n        db.close();\n```\n\nData class is a pojo with one string field, getter/setter and default constructor.\nException thrown at around 4M inserted records:\n\n```\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n    at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:39)\n    at java.nio.ByteBuffer.allocate(ByteBuffer.java:312)\n    at net.kotek.jdbm.BlockIo.setDirty(BlockIo.java:92)\n    at net.kotek.jdbm.BlockIo.writeByte(BlockIo.java:155)\n    at net.kotek.jdbm.RecordHeader.setCurrentSize(RecordHeader.java:65)\n    at net.kotek.jdbm.PhysicalRowIdManager.write(PhysicalRowIdManager.java:314)\n    at net.kotek.jdbm.PhysicalRowIdManager.update(PhysicalRowIdManager.java:87)\n    at net.kotek.jdbm.DBStore.update2(DBStore.java:343)\n    at net.kotek.jdbm.DBStore.update(DBStore.java:318)\n    at net.kotek.jdbm.DBCache.updateCacheEntries(DBCache.java:135)\n    at net.kotek.jdbm.DBCache.commit(DBCache.java:90)\n```\n\nData class:\n\n``` java\n\n    public static class Data implements Serializable\n    {\n        String str;\n\n        Data() { }\n        public Data(String s) { str = s; }\n\n        public String getStr() {\n            return str;\n        }\n\n        public void setStr(String str) {\n            this.str = str;\n        }\n    }\n```\n"
            },
            "6": {
                "commit_sha_buggy": "f7de66797bf7e38bc529a1aee005d493b7f8f8ba",
                "commit_sha_fixed": "6b2d997804a454828a8b9b237d876c86ae89de3c",
                "report_id": "89",
                "report_url": "https://github.com/jankotek/JDBM3/issues/89",
                "issue_title": "TreeMap#size() returns wrong values after rollback",
                "issue_description": "Bug or feature?\n\n```\nSortedMap<Integer, String> map = db.createTreeMap(\"collectionName\");\n\nmap.put(1, \"one\");\nmap.put(2, \"two\");\n\n//map.size() --> 2\ndb.commit(); //persist changes into disk\n\nmap.put(3, \"three\");\n//map.size() --> 3\ndb.rollback(); //revert recent changes\n//map.size() --> 3 ????\n```\n"
            }
        }
    },
    "Mybatis_pagehelper": {
        "owner_repo": "pagehelper/Mybatis-PageHelper",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3d0091331d77f458b613555ff112d5398c8854ff",
                "commit_sha_fixed": "2b50dac36f595d61dd9a52457de6a7c2270996e8",
                "report_id": "110",
                "report_url": "https://github.com/pagehelper/Mybatis-PageHelper/issues/110",
                "issue_title": "\u6392\u5e8f\u5355\u72ec\u4f7f\u7528\u65e0\u6548",
                "issue_description": "\u5355\u72ec\u4f7f\u7528startPage\u6709\u6548.\r\n\u5355\u72ec\u4f7f\u7528orderBy\u6ca1\u6709\u6548\u679c.\r\n\u4e24\u4e2a\u4e00\u8d77\u4f7f\u7528\u662f\u6709\u6548\u679c\u7684.\r\nPageHelper.startPage(1, 10);\r\nPageHelper.orderBy(\"sort asc, id asc\");"
            },
            "2": {
                "commit_sha_buggy": "c1d2134088fc63ee7c4e2d6a2069190a6555abfc",
                "commit_sha_fixed": "6c64fc7bf137eee14974f35d2027ab8c2db8fb96",
                "report_id": "534",
                "report_url": "https://github.com/pagehelper/Mybatis-PageHelper/issues/534",
                "issue_title": "RowBounds\u5206\u9875\u7ed3\u679c\u4e0d\u51c6\u786e",
                "issue_description": "\u6570\u636e\u5e93\u603b\u6761\u65708\u6761\uff0cnew RowBounds(7,2)\uff1b\u9884\u671f\u7ed3\u679c\u4e3a\u7b2c8\u6761\u6570\u636e\uff1b\u5b9e\u9645\u7ed3\u679c\u4e00\u6761\u6570\u636e\u6ca1\u6709\r\n\r\n\u5206\u6790\u6e90\u7801\u53d1\u73b0\uff0cRowBounds\u8f6cpageNum\u4e3a\uff1a\r\n\r\nthis.pageNum = rowBounds[1] != 0 ? (int) (Math.ceil(((double) rowBounds[0] + rowBounds[1]) / rowBounds[1])) : 0;\r\n\r\n\u5c06pageNum\u8f6c\u4e3a\u4e865\r\n\r\n### \u4f7f\u7528\u73af\u5883\r\n* PageHelper \u7248\u672c: 5.1.9\r\n* \u6570\u636e\u5e93\u7c7b\u578b\u548c\u7248\u672c: oracle\r\n\r\n"
            },
            "3": {
                "commit_sha_buggy": "23286824152c686b80a0dd8c364d632e58eb55bc",
                "commit_sha_fixed": "a93195e1c0833d5014aa59d0584dbf15c40eabae",
                "report_id": "498",
                "report_url": "https://github.com/pagehelper/Mybatis-PageHelper/issues/498",
                "issue_title": "reasonable\u57285.x\u4e2d\u4e0d\u8d77\u4f5c\u7528",
                "issue_description": "\u5927\u795e\u597d\uff1a\r\n\u4ee5\u4e0b\u4ee3\u7801\u57285.1.x\u4e2d reasonable \u7684\u53c2\u6570\u4e3a false \u7684\u60c5\u51b5\u4e0b\u4e0d\u8d77\u4f5c\u7528\uff0c\u4f1a\u67e5\u8be2\u51fa10\u6761\u8bb0\u5f55\uff0c\r\n\u4f46\u5728\u4f46\u57284.2.1\u4e2d\u6d4b\u8bd5\u662f\u8d77\u4f5c\u7528\u7684\uff0c\u67e5\u4e0d\u51fa\u8bb0\u5f55\uff0c\r\n```java\r\nPageHelper.startPage(-1, 10,true,false,true);\r\n```\r\n\u8bf7\u5e2e\u5fd9\u89e3\u60d1\uff0c\u8c22\u8c22"
            },
            "4": {
                "commit_sha_buggy": "a93195e1c0833d5014aa59d0584dbf15c40eabae",
                "commit_sha_fixed": "3e5bdcc68bbd6d8b6285054d1352f06c062b54ba",
                "report_id": "506",
                "report_url": "https://github.com/pagehelper/Mybatis-PageHelper/issues/506",
                "issue_title": "pageSizeZero \u8bbe\u7f6e\u65e0\u6548\uff0c\u65e0\u8bba\u5982\u4f55\u8bbe\u7f6e\u6216\u8005\u4f7f\u7528\u9ed8\u8ba4\u503c\uff0cpageSize = 0\u5c31\u4f1a\u67e5\u5168\u90e8\u6570\u636e",
                "issue_description": "\u6309\u6587\u6863\u8bf4\u660e\u6d4b\u8bd5\u8fd9\u4e2a\u53c2\u6570\uff0c\u53d1\u73b0\u4e0d\u7b26\u5408\u9884\u671f"
            }
        }
    },
    "N5": {
        "owner_repo": "saalfeldlab/n5",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0994b959eafcf36fa030f9d5cedec8205770d23d",
                "commit_sha_fixed": "e94edb60d5cd72f41a509f3f550d2cfc7b9b471d",
                "report_id": "3",
                "report_url": "https://github.com/saalfeldlab/n5/pull/3",
                "issue_title": "Fix dataset existence check",
                "issue_description": "https://github.com/saalfeldlab/n5/blob/1.1.1/src/main/java/org/janelia/saalfeldlab/n5/N5FSReader.java#L245\r\nThe above code behaves incorrectly in the case there is a group with the same name but with no attributes. It throws an `IOException` (tries to load missing file _attributes.json_). But I would expect it to return `false` as in the case when the attributes are not consistent with the mandatory dataset attributes.\r\n\r\nThis PR introduces `hasAttributes()` method which tests whether a file _attributes.json_ exists. This method also allows to safely test for its existence before reading the attributes of a group (where this file is not guaranteed to be present)."
            },
            "2": {
                "commit_sha_buggy": "8f59cf09fe32f1e831d3f8831b6b1558a3416a73",
                "commit_sha_fixed": "b9c98275b045fad5e367dc27e5ecfd47d25d7356",
                "report_id": "8",
                "report_url": "https://github.com/saalfeldlab/n5/pull/8",
                "issue_title": "Fix N5FSWriter not writing numElements in mode=1",
                "issue_description": "When the mode is 1 (determined automatically by the `N5FSWriter` depending on whether `numElements` equals `getNumElements(getSize())`), `numElements` should have been written after the dimensions and before the data, as [specified](https://github.com/saalfeldlab/n5#specifications), and as `N5FSReader` [expects](https://github.com/saalfeldlab/n5/blob/master/src/main/java/org/janelia/saalfeldlab/n5/N5FSReader.java#L236). Also adds a test case to make sure this functionality isn't broken by a future change."
            }
        }
    },
    "Stash_jenkins_postreceive_webhook": {
        "owner_repo": "mohamicorp/stash-jenkins-postreceive-webhook",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "204c77d7e08d0494c89bb5bae5e0adc2470f3b5b",
                "commit_sha_fixed": "919b108a272a2c48401dbddaaa1d513fd1e689cb",
                "report_id": "134",
                "report_url": "https://github.com/mohamicorp/stash-jenkins-postreceive-webhook/issues/134",
                "issue_title": "commit notification null",
                "issue_description": "I am getting this error if i manually trigger the plugin from stash without this options turned on:\nOmit SHA1 Hash Code\nOmit Branch Name\nSystem:\nJenkins 1609.1\nGit plugin 2.3.5\nStash Jenkins Webhook plugin 2.7.0\nStash Server version 3.6.0\n\nI am basically having 2 jobs identical, only the branches name is different:\none is \"master\" the other one \"release\"\n\nThe error from Jenkins console:\n\n commit notification null\n00:00:00.027 [EnvInject] - Loading node environment variables.\n00:00:00.037 Building remotely on *****\\* (automation 10xwindows) in workspace C:\\jenkins\\workspace\\StashJobTrigger_Branch\n00:00:00.090  > C:\\jenkins\\tools\\git\\bin\\git.exe rev-parse --is-inside-work-tree # timeout=10\n00:00:00.106 Fetching changes from the remote Git repository\n00:00:00.110  > C:\\jenkins\\tools\\git\\bin\\git.exe config remote.origin.url ssh://***********_.git # timeout=10\n00:00:00.130 Fetching upstream changes from ssh://**_*************_.git\n00:00:00.132  > C:\\jenkins\\tools\\git\\bin\\git.exe --version # timeout=10\n00:00:00.145  > C:\\jenkins\\tools\\git\\bin\\git.exe -c core.askpass=true fetch --tags --progress ssh://**_********_.git +refs/heads/_:refs/remotes/origin/*\n00:00:04.745  > C:\\jenkins\\tools\\git\\bin\\git.exe rev-parse \"null^{commit}\" # timeout=10\n00:00:04.764 FATAL: Command \"C:\\jenkins\\tools\\git\\bin\\git.exe rev-parse \"null^{commit}\"\" returned status code 128:\n00:00:04.764 stdout: null^{commit}\n00:00:04.764 \n00:00:04.764 stderr: fatal: ambiguous argument 'null^{commit}': unknown revision or path not in the working tree.\n00:00:04.764 Use '--' to separate paths from revisions, like this:\n00:00:04.764 'git <command> [<revision>...] -- [<file>...]'\n00:00:04.764 \n00:00:04.764 hudson.plugins.git.GitException: Command \"C:\\jenkins\\tools\\git\\bin\\git.exe rev-parse \"null^{commit}\"\" returned status code 128:\n00:00:04.765 stdout: null^{commit}\n00:00:04.765 \n00:00:04.765 stderr: fatal: ambiguous argument 'null^{commit}': unknown revision or path not in the working tree.\n00:00:04.765 Use '--' to separate paths from revisions, like this:\n00:00:04.765 'git <command> [<revision>...] -- [<file>...]'\n00:00:04.765 \n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandIn(CliGitAPIImpl.java:1591)\n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandIn(CliGitAPIImpl.java:1567)\n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandIn(CliGitAPIImpl.java:1563)\n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommand(CliGitAPIImpl.java:1249)\n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommand(CliGitAPIImpl.java:1261)\n00:00:04.765    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.revParse(CliGitAPIImpl.java:622)\n00:00:04.765    at hudson.plugins.git.GitAPI.revParse(GitAPI.java:316)\n00:00:04.765    at sun.reflect.GeneratedMethodAccessor80.invoke(Unknown Source)\n00:00:04.765    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n00:00:04.765    at java.lang.reflect.Method.invoke(Method.java:601)\n00:00:04.765    at hudson.remoting.RemoteInvocationHandler$RPCRequest.perform(RemoteInvocationHandler.java:299)\n00:00:04.765    at hudson.remoting.RemoteInvocationHandler$RPCRequest.call(RemoteInvocationHandler.java:280)\n00:00:04.765    at hudson.remoting.RemoteInvocationHandler$RPCRequest.call(RemoteInvocationHandler.java:239)\n00:00:04.765    at hudson.remoting.UserRequest.perform(UserRequest.java:118)\n00:00:04.765    at hudson.remoting.UserRequest.perform(UserRequest.java:48)\n00:00:04.765    at hudson.remoting.Request$2.run(Request.java:328)\n00:00:04.765    at hudson.remoting.InterceptingExecutorService$1.call(InterceptingExecutorService.java:72)\n00:00:04.765    at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n00:00:04.765    at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n00:00:04.765    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n00:00:04.765    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n00:00:04.765    at hudson.remoting.Engine$1$1.run(Engine.java:63)\n00:00:04.765    at java.lang.Thread.run(Thread.java:722)\n00:00:04.765    at ......remote call to oo10.x_node2(Native Method)\n00:00:04.766    at hudson.remoting.Channel.attachCallSiteStackTrace(Channel.java:1360)\n00:00:04.766    at hudson.remoting.UserResponse.retrieve(UserRequest.java:221)\n00:00:04.766    at hudson.remoting.Channel.call(Channel.java:753)\n00:00:04.766    at hudson.remoting.RemoteInvocationHandler.invoke(RemoteInvocationHandler.java:179)\n00:00:04.766    at com.sun.proxy.$Proxy50.revParse(Unknown Source)\n00:00:04.766    at org.jenkinsci.plugins.gitclient.RemoteGitImpl.revParse(RemoteGitImpl.java:546)\n00:00:04.766    at hudson.plugins.git.RevisionParameterAction.toRevision(RevisionParameterAction.java:85)\n00:00:04.766    at hudson.plugins.git.GitSCM.determineRevisionToBuild(GitSCM.java:903)\n00:00:04.766    at hudson.plugins.git.GitSCM.checkout(GitSCM.java:1017)\n00:00:04.766    at hudson.scm.SCM.checkout(SCM.java:484)\n00:00:04.766    at hudson.model.AbstractProject.checkout(AbstractProject.java:1270)\n00:00:04.766    at hudson.model.AbstractBuild$AbstractBuildExecution.defaultCheckout(AbstractBuild.java:609)\n00:00:04.766    at jenkins.scm.SCMCheckoutStrategy.checkout(SCMCheckoutStrategy.java:86)\n00:00:04.766    at hudson.model.AbstractBuild$AbstractBuildExecution.run(AbstractBuild.java:531)\n00:00:04.766    at hudson.model.Run.execute(Run.java:1741)\n00:00:04.766    at hudson.maven.MavenModuleSetBuild.run(MavenModuleSetBuild.java:537)\n00:00:04.766    at hudson.model.ResourceController.execute(ResourceController.java:98)\n00:00:04.766    at hudson.model.Executor.run(Executor.java:374)\n00:00:04.772 Finished: FAILURE\n"
            }
        }
    },
    "Suffixtree": {
        "owner_repo": "abahgat/suffixtree",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "cf068ad25cc1980d8e8693011fc2850c281ab56b",
                "commit_sha_fixed": "1ce6869c2d0f8474421251cd39c22057b5a3abdd",
                "report_id": "3",
                "report_url": "https://github.com/abahgat/suffixtree/pull/3",
                "issue_title": "Return empty collection, never null, from search",
                "issue_description": ""
            }
        }
    },
    "Template_benchmark": {
        "owner_repo": "mbosecke/template-benchmark",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7ac6dd0b160aa8b0a3f31abe0fb9588cc220db6b",
                "commit_sha_fixed": "58e188517288c409781b65f16f1c4fc19ad75764",
                "report_id": "5",
                "report_url": "https://github.com/mbosecke/template-benchmark/pull/5",
                "issue_title": "Trimou 1.8.0",
                "issue_description": ""
            }
        }
    },
    "Vectorz": {
        "owner_repo": "mikera/vectorz",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "dc3b088283a5cf861cb5d2884c46f7dd3b476dde",
                "commit_sha_fixed": "b5507df1ba4de4692fd80d97e816347f4a445c0b",
                "report_id": "44",
                "report_url": "https://github.com/mikera/vectorz/pull/44",
                "issue_title": "fix getP bug",
                "issue_description": "There was a bug in the `getPivotMatrix` function. I am sorry. I don't know how I missed it.\n"
            },
            "2": {
                "commit_sha_buggy": "8b5d6146b4a84a9843e7db762579926a785997cf",
                "commit_sha_fixed": "7446c9e2c1b63732d3a2a165d642a4db8740d1e7",
                "report_id": "52",
                "report_url": "https://github.com/mikera/vectorz/pull/52",
                "issue_title": "Add householder implementation to QR decomposition.",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "81bf8d52939c9b2abaebe106fb93ec29708098f5",
                "commit_sha_fixed": "1637d1eb79319026734f2d57f42bb683ee52bfc7",
                "report_id": "68",
                "report_url": "https://github.com/mikera/vectorz/pull/68",
                "issue_title": "Speed up and OOB fix",
                "issue_description": "Added a check to SparseIndexedVector#add(ASparseVector) for ZeroVector, skips iterating over values if argument is a ZeroVector.\n\nFixed an OutOfBounds error in SparseIndexedVector#includeIndices when the instance was empty.\n"
            },
            "4": {
                "commit_sha_buggy": "63ac59a21b978ed4d22307d25454bc1ccc953523",
                "commit_sha_fixed": "7ad8cdeb55b697ad6c7be5cd098f4dc4e5b5eaa4",
                "report_id": "75",
                "report_url": "https://github.com/mikera/vectorz/pull/75",
                "issue_title": "Integer overflow when finding index position",
                "issue_description": "There was an integer overflow in calculating the midpoint when searching for an index position. Pull request includes a fix and a test.\n"
            },
            "5": {
                "commit_sha_buggy": "7b6265731a4a74cb133057b94dfa173db595ca60",
                "commit_sha_fixed": "81bf8d52939c9b2abaebe106fb93ec29708098f5",
                "report_id": "67",
                "report_url": "https://github.com/mikera/vectorz/pull/67",
                "issue_title": "Sparse set fix and speed up.",
                "issue_description": "Changes to fix nop row assignment, faster nonZeroIndices, faster setting from sparse sources\n"
            },
            "6": {
                "commit_sha_buggy": "ec1d63d5f9938ca4bba47aef5c87e7e4a40d85ac",
                "commit_sha_fixed": "dbfd4c3030a8854b33cdd32bb97c2dd85136e289",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "generic fill, make set() throw error for non-0d cases",
                "issue_description": "generic fill, make set() throw error for non-0d cases"
            }
        }
    },
    "Cli_parser": {
        "owner_repo": "spullara/cli-parser",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "86ee326f3e7519947227be6a40d06fc43ce1da08",
                "commit_sha_fixed": "6bb1296cea485751ff0da629866de0bc896077cb",
                "report_id": "3",
                "report_url": "https://github.com/spullara/cli-parser/pull/3",
                "issue_title": "support of argument fields in superclasses",
                "issue_description": "The current implementation doesn't support argument fields declared in superclasses. This is useful when using hierarchies of command classes, each having different possible options.\n"
            }
        }
    },
    "Gatling_report": {
        "owner_repo": "nuxeo/gatling-report",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "59c329f425fb576b0bd9fcadd0d752e59f47923a",
                "commit_sha_fixed": "060be21ee40950df32a4e676caf312d0fc0632ff",
                "report_id": "14",
                "report_url": "https://github.com/nuxeo/gatling-report/pull/14",
                "issue_title": "Support for Gatling 3.0.0",
                "issue_description": "In Gatling 3.0.0, the REQUEST line no longer has the scenario. To\r\ndetermine the scenario, you need to get the userId, then lookup\r\nthe scenario associated with the user.\r\n\r\nFix is a little ugly, relying on `getUserType` being invoked, but\r\notherwise it would require more extensive changes.\r\n\r\nSome of the other indexes were also wrong, updated them."
            },
            "2": {
                "commit_sha_buggy": "9f4d705260a0035e5efaab3deae96f841342ca04",
                "commit_sha_fixed": "df6eaa5df394c030b7b3222aec0311a0f3c82c81",
                "report_id": "28",
                "report_url": "https://github.com/nuxeo/gatling-report/pull/28",
                "issue_title": "Support gatling 3.4 simulation log format",
                "issue_description": "User numbers are no longer part of the simulation log, so I added a `userCount` variable instead. "
            },
            "3": {
                "commit_sha_buggy": "df6eaa5df394c030b7b3222aec0311a0f3c82c81",
                "commit_sha_fixed": "0c3fc4a1de95067a43f148e6b95ee215054ad3c9",
                "report_id": "27",
                "report_url": "https://github.com/nuxeo/gatling-report/pull/27",
                "issue_title": "Support gatling v3.5 simulation.log",
                "issue_description": "The simulation log seems to have changed some where between version 3.2 and 3.5.\r\nA new parser is added to support version 3.5"
            }
        }
    },
    "Jumblr": {
        "owner_repo": "tumblr/jumblr",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "47f746c0925b1aeb94dc6f2dd74029ee7252905c",
                "commit_sha_fixed": "f067ff717dd1ae97ff4c4bebc2f4415c33fa1df3",
                "report_id": "5",
                "report_url": "https://github.com/tumblr/jumblr/issues/5",
                "issue_title": "Implement Photoset Support",
                "issue_description": "Please add support for Photosets in the PhotoPost Class, as well as needed Methods in the **Photo** Class, like \n\n```\nsetSource()\nsetData()\nsetHeight()\nsetWidth()\n```\n\nto comply the API.\nPhotoPost methods `setSource()` and similar should be migrated to Photo to avoid redundancy.\nPhotoPost needs a method `setPhotos()`\n\nThat's how I would expect it. Feel free to implement it another way.\n"
            },
            "2": {
                "commit_sha_buggy": "2fef8c416e54d353e9d0eca1de0c88fb49d8ec6a",
                "commit_sha_fixed": "69d63e5cb303460016b49d6cb57d8be9c6284d82",
                "report_id": "34",
                "report_url": "https://github.com/tumblr/jumblr/pull/34",
                "issue_title": "Photo post",
                "issue_description": ""
            }
        }
    },
    "Tabula_java": {
        "owner_repo": "tabulapdf/tabula-java",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "00bee456790c16d9d972de1e5d513b58ced37a48",
                "commit_sha_fixed": "2ab8579ef7dd5a7f9913f243b6e0e766f25f99bd",
                "report_id": "379",
                "report_url": "https://github.com/tabulapdf/tabula-java/issues/379",
                "issue_title": "Incorrect handling of -c option with %",
                "issue_description": "The following code does not expect `%` in the beginning of `-c` option and fails on \"Wrong number syntax\": \r\n\r\nhttps://github.com/tabulapdf/tabula-java/blob/ebc83ac2bb1a1cbe54ab8081d70f3c9fe81886ea/src/main/java/technology/tabula/CommandLineApp.java#L59-L61\r\n\r\nThat piece of code is not needed at all because `-c` option is already parsed in this piece of code that was already ran:\r\nhttps://github.com/tabulapdf/tabula-java/blob/ebc83ac2bb1a1cbe54ab8081d70f3c9fe81886ea/src/main/java/technology/tabula/CommandLineApp.java#L54"
            }
        }
    },
    "Ber_tlv": {
        "owner_repo": "evsinev/ber-tlv",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1c8d392cd20c29adead72078bbac8b63ffc9e88f",
                "commit_sha_fixed": "5f6bdef7604cd9e787da1d9ebd55d1d660ad98e3",
                "report_id": "13",
                "report_url": "https://github.com/evsinev/ber-tlv/issues/13",
                "issue_title": "Custom buffer size ignored when adding BerTlv to BerTlvBuilder",
                "issue_description": "The following code will lead to an error, if myBerTlv has a value that has over 5120 bytes:\r\n```java\r\nBerTlvBuilder berTlvBuilder = new BerTlvBuilder(myBerTlv.getTag(),\r\n                                                        new byte[1000000],\r\n                                                        0,\r\n                                                        1000000);\r\nbyte[] bytes = berTlvBuilder.addBerTlv(myBerTlv);\r\n```\r\nThe exception I got was:\r\n```bash\r\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException\r\n\tat java.lang.System.arraycopy(Native Method)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBytes(BerTlvBuilder.java:178)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBytes(BerTlvBuilder.java:162)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBerTlv(BerTlvBuilder.java:196)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.from(BerTlvBuilder.java:45)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBerTlv(BerTlvBuilder.java:194)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.from(BerTlvBuilder.java:45)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBerTlv(BerTlvBuilder.java:194)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.from(BerTlvBuilder.java:45)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBerTlv(BerTlvBuilder.java:194)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.from(BerTlvBuilder.java:45)\r\n\tat com.payneteasy.tlv.BerTlvBuilder.addBerTlv(BerTlvBuilder.java:194)\r\n```\r\n\r\nWhen using the `addBerTlv` method, the code eventually calls `public BerTlvBuilder(BerTag aTemplate)`, a method that overwrites the custom buffer with the default settings."
            },
            "2": {
                "commit_sha_buggy": "1c8d392cd20c29adead72078bbac8b63ffc9e88f",
                "commit_sha_fixed": "e3f58a4b9c3d36ff2c50b22bab6996b5bbf8f161",
                "report_id": "14",
                "report_url": "https://github.com/evsinev/ber-tlv/pull/14",
                "issue_title": "#13: Add possibility to add large constructed TLV elements to BerTlvBuilder",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "b55186821a43758ddff4ebd88c0ccc7b5124b7d6",
                "commit_sha_fixed": "f19dd6bc41a0b12c10cf56028ba4b9db5c9e1971",
                "report_id": "1",
                "report_url": "https://github.com/evsinev/ber-tlv/issues/1",
                "issue_title": "Add a way to get the byte representation of constructed tags",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "4cb2adcfb181b3140e621af74a24f1b80e72fcfc",
                "commit_sha_fixed": "1d887ab7bb49e617205b3ab5e509f44f96162342",
                "report_id": "10",
                "report_url": "https://github.com/evsinev/ber-tlv/issues/10",
                "issue_title": "Last tag from a hex string is sometimes missing after parsing",
                "issue_description": "Hi\r\n\r\nWhile I was using this librairy, i've encountered a bug that prevented the parsing of the following Hex String:\r\n\r\nBF01820114DF0105A0000000049F2201EFDF020101DF030101DF0481F8A191CB87473F29349B5D60A88B3EAEE0973AA6F1A082F358D849FDDFF9C091F899EDA9792CAF09EF28F5D22404B88A2293EEBBC1949C43BEA4D60CFD879A1539544E09E0F09F60F065B2BF2A13ECC705F3D468B9D33AE77AD9D3F19CA40F23DCF5EB7C04DC8F69EBA565B1EBCB4686CD274785530FF6F6E9EE43AA43FDB02CE00DAEC15C7B8FD6A9B394BABA419D3F6DC85E16569BE8E76989688EFEA2DF22FF7D35C043338DEAA982A02B866DE5328519EBBCD6F03CDD686673847F84DB651AB86C28CF1462562C577B853564A290C8556D818531268D25CC98A4CC6A0BDFFFDA2DCCA3A94C998559E307FDDF915006D9A987B07DDAEB3BDF050103\r\n\r\nThe node \"DF05\" with the length of 1 and value of \"03\" was not found by the API (It's at the end of the String). After some debugging I've come up with a fix that I zipped and attached to this bug entry. Not being familiar with Git Hub, i've not made a push request... sorry\r\n\r\nHave a good day!\r\n[BerTlvParser.zip](https://github.com/evsinev/ber-tlv/files/3596538/BerTlvParser.zip)\r\n\r\n"
            }
        }
    },
    "Jfreechart": {
        "owner_repo": "jfree/jfreechart",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1e844059728b58800230dde274852c4418c4ad25",
                "commit_sha_fixed": "d98a34cce103a3a03080084711cf227dc8657e42",
                "report_id": "76",
                "report_url": "https://github.com/jfree/jfreechart/pull/76",
                "issue_title": "Ensure row keys are valid in sliding category datasets",
                "issue_description": "In `org/jfree/data/gantt/SlidingGanttCategoryDataset`, there are a number of methods that take a row key and a column key, look up indexes for them, and dispatch to the underlying dataset. In many of these methods, the column key is checked to make sure that it is valid, but the row key is not. \r\n\r\nFor example, consider `SlidingGanttCategoryDataset#getValue`. If an invalid column key is passed, the method cleanly throws an `UnknownKeyException` at the place where the error occurred (consistent with the documentation on the method). If an invalid row key is passed, though, the error is propagated to `TaskSeriesCollection#getRowKey` (assuming that the underlying `GanttCategoryDataset` is a `TaskSeriesCollection`). This error is misleading (it's a generic `IndexOutOfBoundsException`) and doesn't really help find the bug, which was in the call to `getValue`.\r\n\r\nWhile investigating, I noticed this pattern was repeated throughout this file, and I also found it in one place in `SlidingCategoryDataset`, so this PR adds checks to all of them so that the error is reported where it occurs."
            },
            "2": {
                "commit_sha_buggy": "e9686b8b93476437cc8c5892189ca9df17e6f9d9",
                "commit_sha_fixed": "6597144e4cc722e70daa6843b396a50999f6f622",
                "report_id": "141",
                "report_url": "https://github.com/jfree/jfreechart/issues/141",
                "issue_title": "DatasetUtils.iterateZBounds() ignores parameter `includeInterval`",
                "issue_description": "The class `DatasetUtils` has a method `iterateZBounds()` with a parameter `includeInterval` which is silently ignored inside the method:\r\nhttps://github.com/jfree/jfreechart/blob/e9686b8b93476437cc8c5892189ca9df17e6f9d9/src/main/java/org/jfree/data/general/DatasetUtils.java#L1319-L1342\r\n\r\nThe method should check like other methods do,\r\n\r\n    if (includeInterval && dataset instanceof IntervalXYZDataset) {\r\n\r\nperform necessary casts and use `getStartZValue()`/`getEndZValue()` instead of `getZValue()` if appropriate."
            },
            "3": {
                "commit_sha_buggy": "6597144e4cc722e70daa6843b396a50999f6f622",
                "commit_sha_fixed": "8bc4967c3ff266dba48e34274d90824f88fca34a",
                "report_id": "78",
                "report_url": "https://github.com/jfree/jfreechart/pull/78",
                "issue_title": "Fix incorrect return value in DefaultKeyedValues2D#getRowIndex",
                "issue_description": "DefaultKeyedValues2D#getRowIndex returns the result of Collections.binarySearch directly if the underlying List is being kept in sorted order. The specification for [Collections.binarySearch](https://docs.oracle.com/javase/7/docs/api/java/util/Collections.html#binarySearch(java.util.List,%20T)) is unusual: if the element being searched for is not found, a negative index indicating where to insert the value to keep the list in sorted order is returned. The specification on getRowIndex, defined in the KeyedValues2D interface, says:\r\n ``` * @return The row index, or {@code -1} if the key is unrecognised```. \r\n\r\nThis pull request changes DefaultKeyedValues2D#getRowIndex to respect the specification written on KeyedValues2D#getRowIndex; an alternative option would be to change the spec there to allow a negative index to be returned."
            },
            "4": {
                "commit_sha_buggy": "952e96e8a3297c9bdd96d059aaf6212a3e6a0cfa",
                "commit_sha_fixed": "97d995549452b1e966c9391b07e9532f080ad41c",
                "report_id": "137",
                "report_url": "https://github.com/jfree/jfreechart/pull/137",
                "issue_title": "Fixed Bug in Week.java #134 ",
                "issue_description": ""
            }
        }
    },
    "Commons_suncalc": {
        "owner_repo": "shred/commons-suncalc",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "5b4dc008376aa9a122a8b13bafb16205b9ec2d90",
                "commit_sha_fixed": "f8fe605d81c53e9737162aead79c3c920e5bd97c",
                "report_id": "18",
                "report_url": "https://github.com/shred/commons-suncalc/issues/18",
                "issue_title": "SunTimes noon and nadir are null for .on(Date) near them",
                "issue_description": "When using SunTimes to do calculations starting at an arbitrary point in time using on(Date) -- e.g., to get events for the next 24 hours from now -- the noon value is null if the provided Date is too close to noon, and similarly for nadir. [This test](https://github.com/isomeme/Helios/blob/master/helios/src/test/java/org/onereed/helios/sun/SunCalcTest.java) from my project demonstrates the misbehavior.\r\n"
            },
            "2": {
                "commit_sha_buggy": "6f17cbfe8b9154bc1c1021addbf2841f8f13631c",
                "commit_sha_fixed": "d7ac6bf87475416ec03d69b726b23d31fd3dc37c",
                "report_id": "20",
                "report_url": "https://github.com/shred/commons-suncalc/issues/20",
                "issue_title": "SunTimes noon value very inconsistent with SunPosition azimuth",
                "issue_description": "The noon value from SunTimes can produce a value up to 5 degrees / 20 minutes away from when SunPosition shows sun azimuth ~= 180 at the same location. See [this unit test](https://github.com/isomeme/Helios/blob/master/helios/src/test/java/org/onereed/helios/sun/SunCalcTest.java#L88) for a demonstration; it contains a comment with more information.\r\n\r\n"
            }
        }
    },
    "Dropwizard_spring": {
        "owner_repo": "nhuray/dropwizard-spring",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "354a31797daa0343a9dd7b2847533423e4e0dea5",
                "commit_sha_fixed": "bafc489004e038d698a81eb80211e27b0df564b0",
                "report_id": "1",
                "report_url": "https://github.com/nhuray/dropwizard-spring/pull/1",
                "issue_title": "Register the Dropwizard Environment as Spring bean named \"dw-environment\"",
                "issue_description": "Sometimes it's useful to have access to the Dropwizard Environment descriptor from inside another class. To facilitate access to the environment the SpringBundle now registers a singleton named \"dw-environment\" which is being registered in the `SpringBundle#run()` method.\n"
            }
        }
    },
    "Semux_core": {
        "owner_repo": "semuxproject/semux-core",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1ea7122e4dc40bbcd615c1d78e85b507de9059aa",
                "commit_sha_fixed": "8d9b010e18d1be9a200b84befef25466d99514d5",
                "report_id": "3",
                "report_url": "https://github.com/semuxproject/semux-core/pull/3",
                "issue_title": "Consensus: change block proposal timestamp creation",
                "issue_description": "When the parent block time is in the future, use prev_block_time + 1 as\r\nthe current block time\r\n\r\nResolves #1 "
            },
            "2": {
                "commit_sha_buggy": "ae546488c0fb1471cd4680af1bef4aa13d33aaa6",
                "commit_sha_fixed": "5fe41ebef2aa7922d89f41846d5e31a3f7137963",
                "report_id": "74",
                "report_url": "https://github.com/semuxproject/semux-core/issues/74",
                "issue_title": "EVM - If using a contract to transfer funds, receiver does not see transaction",
                "issue_description": "If I create a contract that transfers from A->B\r\n\r\nI can see that B account now has a balance, but his account history is empty!\r\nWe need to figure out how to capture events or internal calls from a contract and make sure they're included in UI transactions panel (and possibly API as well)"
            },
            "3": {
                "commit_sha_buggy": "20c7e6a181805e7114bd3e8383784b0728df5adb",
                "commit_sha_fixed": "63e1a45f977e82dd75b7039421d15c301b10ad7f",
                "report_id": "3",
                "report_url": "https://github.com/semuxproject/semux-core/pull/3",
                "issue_title": "Consensus: change block proposal timestamp creation",
                "issue_description": "When the parent block time is in the future, use prev_block_time + 1 as\r\nthe current block time\r\n\r\nResolves #1 "
            }
        }
    },
    "Solarpositioning": {
        "owner_repo": "KlausBrunner/solarpositioning",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "44d273dc23cb643444a4b1396e1aaca70654248c",
                "commit_sha_fixed": "f0574eb42e92e9834ffbcf34713825f8ef4bec24",
                "report_id": "10",
                "report_url": "https://github.com/KlausBrunner/solarpositioning/issues/10",
                "issue_title": "SPA.addFractionOfDay() could fail on DST on/off days",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "44d273dc23cb643444a4b1396e1aaca70654248c",
                "commit_sha_fixed": "08300ab3ddc2958b287b864f1e3e19e8278480a5",
                "report_id": "15",
                "report_url": "https://github.com/KlausBrunner/solarpositioning/pull/15",
                "issue_title": "Dstdays",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "219b31adbdb4abdf88c0124c199c4e7d3d0690c6",
                "commit_sha_fixed": "8a48c72395ba3f421318b79827fba3f2d1aa8a24",
                "report_id": "4",
                "report_url": "https://github.com/KlausBrunner/solarpositioning/issues/4",
                "issue_title": "Implement sunrise/transit/sunset",
                "issue_description": "It's in the NREL SPA report.\n"
            }
        }
    },
    "Sparkey_java": {
        "owner_repo": "spotify/sparkey-java",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1d2f6ad658fd3072cdbae10016fddcb7ae316b34",
                "commit_sha_fixed": "41cf4378b9cf8c54bd11d3e1dc9e21d45f1616ec",
                "report_id": "22",
                "report_url": "https://github.com/spotify/sparkey-java/pull/22",
                "issue_title": "Fix filename endings for filenames containing '.'",
                "issue_description": "Is this what you had in mind @eshwaran ?\n"
            },
            "2": {
                "commit_sha_buggy": "3b6a7f844f000974f049e4924790310f3994980b",
                "commit_sha_fixed": "84956b3cfcff71d96c3d44bf236a2f9db130ec3b",
                "report_id": "30",
                "report_url": "https://github.com/spotify/sparkey-java/pull/30",
                "issue_title": "Don't stack overflow on very large writes",
                "issue_description": "`SnappyOutputStream.write(byte[] b, int off, int len)` currently recurses when there's not enough space in the current Snappy buffer for all data. This causes a StackOverflowError on very large writes.\r\n\r\nThis patch iterates instead of recursing. The added test tests a large write / block-size ratio, to verify that it solves the problem.\r\n\r\nSimilar for read and skip in SnappyReader."
            },
            "3": {
                "commit_sha_buggy": "177e9b175bed2114369bcd97a8b125970d4c0d41",
                "commit_sha_fixed": "ea93134b20e92e640b7edd9104e51b75a22b718b",
                "report_id": "13",
                "report_url": "https://github.com/spotify/sparkey-java/pull/13",
                "issue_title": "filedescriptorleak",
                "issue_description": ""
            }
        }
    },
    "Shazamcrest": {
        "owner_repo": "shazam/shazamcrest",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "0a75b2df440e7f419fb13f0ffecca25bd4a7e64a",
                "commit_sha_fixed": "752d94d7402d1976e2c4db86272179253e2c5933",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixed comparison of sets when fields are ignored",
                "issue_description": "Fixed comparison of sets when fields are ignored"
            },
            "2": {
                "commit_sha_buggy": "12a399110ef124ddc54b9c2e398be6fd85933c66",
                "commit_sha_fixed": "684117fa023291c0f140780c2b34a877414bcbe9",
                "report_id": "22",
                "report_url": "https://github.com/shazam/shazamcrest/pull/22",
                "issue_title": "added comparison of milliseconds when java.util.Date is compared",
                "issue_description": "Fix for issue #21 - \"Problem with Date and equals method\".\r\n\r\nThe new format contains \".SSS\" after seconds, otherwise it is unchanged."
            }
        }
    },
    "Restfixture": {
        "owner_repo": "smartrics/RestFixture",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "4b02670554a09ce4f6e81c32b6663118ad30272c",
                "commit_sha_fixed": "923dc80d9301653bb9f932d237a7b16b5133f3c6",
                "report_id": "69",
                "report_url": "https://github.com/smartrics/RestFixture/pull/69",
                "issue_title": "SlimFormatter now wraps everything in a DIV in order to deal with FitNesse now escaping everything that doesn't look like HTML by default",
                "issue_description": "Since version 20130530, FitNesse has started escaping fixture output by default. We recently upgraded to 20130530, and were confronted with the fact that the RestFixture output was nog longer nicely rendered HTML, with links etc., but a bunch of escaped HTML that resulted in a distinctly \"view source\" experience. Other people had this problem with other fixtures, which is why the FitNesse project accepted unclebob/fitnesse#274. This causes FitNesse to not escape fixture output if it **looks like** HTML. In practice, this means that the output has to start with an HTML tag in order for FitNesse to not escape it. Several of the cells in the RestFixture output contained HTML, but did not start with a tag, and were therefore escaped by FitNesse. This pull request modifies the SlimFormatter so that all cell content is wrapped in a DIV, and thus will never be escaped by FitNesse.\n"
            },
            "2": {
                "commit_sha_buggy": "3535a99f549dc089edf53da87294bc62000ca6a6",
                "commit_sha_fixed": "701a22c3d801fde39adc75ff1ba2bc62a229a6df",
                "report_id": "112",
                "report_url": "https://github.com/smartrics/RestFixture/issues/112",
                "issue_title": "Bad URL constucted when embedded question marks",
                "issue_description": "I found out that using some convoluted URLs, RestFixture shows some very strange behaviors.\n\n| Table: Rest Fixture | http://localhost:8070 | hopconf|\n| GET | /abc/xyz?url=http://host/ws?g | | | |\n\n=> Will make the request go on http://localhost:8070/abc/xyz\n\nI found where is located the issue in the code, it is in RestFixture#doMethod(String, String, Map<String, String>, String): the url is split by the \"?\" character, the first part being taken as the base URL and the second part as the query part. However if there is more than two parts, the remaining is left out and things go wrong...\n\nIt is very easy to fix. One can concatenate all the remaining split parts when building up the query part. Or even more simple, just add the '2' value as a second parameter of the String.split(String, int) call so that it guarantees not to create more than two chunks.\n\nI will gladly make a Pull Request as soon as I managed to use GitHub... Unless I am beaten by somebody else on this :-)\n\nNote: I _do_ need this fix for the project I'm working on.\n"
            },
            "3": {
                "commit_sha_buggy": "7d2d090a1a2f6ce405fbf9645849800bc7522d85",
                "commit_sha_fixed": "98a8730e5099a4961274e3093e68acc3e2f5a7de",
                "report_id": "145",
                "report_url": "https://github.com/smartrics/RestFixture/pull/145",
                "issue_title": "Enable both variable substitutions and URL encodings in GET calls",
                "issue_description": "When we attempted to use Smartrics/RestFixture with URL encoded json GET parameters, the %varName% variable substitution interpreted URL encoded json punctuation as the start of a variable. For example, the json string {\"myBool\":\"true\", \"myDouble\":0.3} becomes %7B%22myBool%22%3A%22true%22%2C%20%22myDouble%22%3A0.3%7D as a URL encoded parameter in the GET string.\n\nThe RestFixture variable parser looks for the variable name '7B', and fails as '7B' is not defined by a LET statement.  \n\nWe solved this issue by excluding any HEX number as a leading %varName% variable name character.  HEX numbers start with 0-9A-F.  Lowercase a-f work fine, as URL encodings are upper case.  All existing RestFixture test cases work as-is. That is, all JUnit example variable substitutions use non-HEX leading characters.  This PR also contains unit tests to illustrate the limited substitution. \n\nOthers who use capital letters A-F may find their tests break. We may want to activate this feature through a feature flag setting, although we did not add the feature flag in the PR.\n"
            },
            "4": {
                "commit_sha_buggy": "ae98ac3aab948a95c7151bea0e66cc261aed5294",
                "commit_sha_fixed": "b21cbacc82451809013068126469329b21d04ef7",
                "report_id": "166",
                "report_url": "https://github.com/smartrics/RestFixture/issues/166",
                "issue_title": "How to stop displaying results",
                "issue_description": "My test case is like this:\n\n|Table:smartrics.rest.fitnesse.fixture.RestFixture | http://localhost:8090 |\n| GET | /getClientNames | | !-Content-Type : application/json -! | |\n\nAnd it is returning a lot of data that is eating up all the screen space. how can I stop showing result on screen?\n\nThanks\n"
            }
        }
    },
    "Chronicle_network": {
        "owner_repo": "OpenHFT/Chronicle-Network",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "dffc931824d6575157efbc30c261f7107dd2b6fb",
                "commit_sha_fixed": "bc48f8901e494562ca3d2174fa5be97bdffb0922",
                "report_id": "124",
                "report_url": "https://github.com/OpenHFT/Chronicle-Network/issues/124",
                "issue_title": "Some checks for misconfiguration are assertions",
                "issue_description": "There are some assertions that check states that can be the result of misconfiguration. Because assertions are typically not enabled in production this could mean prod happily runs when it is misconfigured.\r\n\r\nFor example:\r\nhttps://github.com/OpenHFT/Chronicle-Network/blob/fb09eac213ac81de17c5be52a94683475dc30c42/src/main/java/net/openhft/chronicle/network/cluster/handlers/UberHandler.java#L105\r\nThis can be the result of an mismatch between host ID and endpoint URL in a config file, we probably never want to proceed if the other end thinks we're someone else. This should probably result in a logged error and immediate disconnection.\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "0419f2c23571ff71532b02d5b6bdb1be297af3af",
                "commit_sha_fixed": "742a04e69bb96c0a4975a2be05c13cead2aa5259",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Detect and fix a race condition in the set of TCP connections.",
                "issue_description": "Detect and fix a race condition in the set of TCP connections."
            },
            "3": {
                "commit_sha_buggy": "717aefaa0f0d1c173c4e07cf41b1f31c8672aae4",
                "commit_sha_fixed": "85bb96d2eb5ab44b7297249f3c086351579fc571",
                "report_id": "114",
                "report_url": "https://github.com/OpenHFT/Chronicle-Network/issues/114",
                "issue_title": "OverlappingFileLockException in FileBasedHostnamePortLookupTable",
                "issue_description": "Gets an exception in this test locally. I have added some diagnostics.\r\n\r\n```\r\n[ERROR] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 11.745 s <<< FAILURE! - in net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest\r\n[ERROR] net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.shouldWorkConcurrently  Time elapsed: 11.663 s  <<< ERROR!\r\njava.lang.RuntimeException: Couldn't acquire lock on shared mapping file FileBasedHostnamePortLookupTableTest-fzksa3m7uq.tmp\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.lambda$doShouldWorkConcurrently$1(FileBasedHostnamePortLookupTableTest.java:96)\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.doShouldWorkConcurrently(FileBasedHostnamePortLookupTableTest.java:105)\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.shouldWorkConcurrently(FileBasedHostnamePortLookupTableTest.java:79)\r\nCaused by: java.nio.channels.OverlappingFileLockException\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.lambda$doShouldWorkConcurrently$1(FileBasedHostnamePortLookupTableTest.java:96)\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.doShouldWorkConcurrently(FileBasedHostnamePortLookupTableTest.java:105)\r\n\tat net.openhft.chronicle.network.internal.lookuptable.FileBasedHostnamePortLookupTableTest.shouldWorkConcurrently(FileBasedHostnamePortLookupTableTest.java:79)\r\n\r\n```"
            },
            "4": {
                "commit_sha_buggy": "717aefaa0f0d1c173c4e07cf41b1f31c8672aae4",
                "commit_sha_fixed": "b0a5f8ace53d270c6449116136f8e7cabbebcfce",
                "report_id": "118",
                "report_url": "https://github.com/OpenHFT/Chronicle-Network/pull/118",
                "issue_title": "Make initial table size larger to avoid resizing",
                "issue_description": "This works around #114\r\n\r\nIt was confusing what was happening here, the `OverlappingFileLockException` was because the lookup table had acquired the lock, then `net.openhft.chronicle.bytes.MappedFile#resizeRafIfTooSmall` was attempting to acquire the lock because the table had filled up and needed to grow. This propagated to the outer loop and the lookup table kept trying to write the file because it thought it was just blocked by another process.\r\n\r\nThis doesn't fix the problem, but it works around it for all sensible cases (the initial table size is now 512KiB) and if it does occur throws a runtime exception with a meaningful message.\r\n\r\nI decided not to fix it because this table is just a utility for testing, If we think it would be used in production it would be better to fix it properly (e.g. stop using OS file locks for mutual exclusion of processes)\r\n\r\nI also create InetSocketAddresses unresolved to lighten the load on DNS in that tight loop.\r\n\r\nAnd put an upper bound of 16 on the concurrent threads, so it doesn't break when it runs on a machine with a large amount of cores."
            }
        }
    },
    "Gocd_slack_build_notifier": {
        "owner_repo": "ashwanthkumar/gocd-slack-build-notifier",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2da2f30f18f45c479254eaa251c3bc6b1fca9df0",
                "commit_sha_fixed": "79570a78645f5416e1dece087d7576da737177e8",
                "report_id": "34",
                "report_url": "https://github.com/ashwanthkumar/gocd-slack-build-notifier/pull/34",
                "issue_title": "Add handling of plugin configuration",
                "issue_description": "Go version 16.1.0 expects plugins to follow configuration protocol,  which is described here https://developer.go.cd/current/writing_go_plugins/plugin_settings/version_1_0/plugin_settings_configuration.html\n\nIn current version the plugins that don't follow this protocol generate errors like the one below.  Most likely in the future they will stop to function.  This pull request implements minimal requirements for config protocol.  This could could be used as jump start to fix #25 and #11\n\n```\nJava.lang.RuntimeException: Interaction with plugin with id 'yum' implementing 'package-repository' extension failed while requesting for 'go.plugin-settings.get-configuration'. Reason: [The plugin sent a response that could not be understood by Go. Plugin returned with code '400' and the following response: 'Invalid request name go.plugin-settings.get-configuration']\n    at com.thoughtworks.go.plugin.access.PluginRequestHelper.submitRequest(PluginRequestHelper.java:38)\n    at com.thoughtworks.go.plugin.access.common.settings.AbstractExtension.getPluginSettingsConfiguration(AbstractExtension.java:45)\n    at com.thoughtworks.go.plugin.access.packagematerial.PackageAsRepositoryExtension.getPluginSettingsConfiguration(PackageAsRepositoryExtension.java:51)\n    at com.thoughtworks.go.plugin.access.common.settings.PluginSettingsMetadataLoader.fetchPluginSettingsMetaData(PluginSettingsMetadataLoader.java:63)\n    at com.thoughtworks.go.plugin.access.common.settings.PluginSettingsMetadataLoader.pluginLoaded(PluginSettingsMetadataLoader.java:47)\n    at com.thoughtworks.go.plugin.infra.DefaultPluginManager$FilterChangeListener.pluginLoaded(DefaultPluginManager.java:262)\n    at com.thoughtworks.go.plugin.infra.FelixGoPluginOSGiFramework$2.execute(FelixGoPluginOSGiFramework.java:353)\n    at org.apache.commons.collections.CollectionUtils.forAllDo(CollectionUtils.java:389)\n    at com.thoughtworks.go.plugin.infra.FelixGoPluginOSGiFramework.getBundle(FelixGoPluginOSGiFramework.java:111)\n    at com.thoughtworks.go.plugin.infra.FelixGoPluginOSGiFramework.loadPlugin(FelixGoPluginOSGiFramework.java:97)\n    at com.thoughtworks.go.plugin.infra.listeners.DefaultPluginJarChangeListener.refreshBundle(DefaultPluginJarChangeListener.java:152)\n```\n"
            },
            "2": {
                "commit_sha_buggy": "f5ef35e521635809aa8d64ebc49e1b51a3b043e7",
                "commit_sha_fixed": "41aa9bef8e7dce1ee98f23ebc964889486a3c328",
                "report_id": "38",
                "report_url": "https://github.com/ashwanthkumar/gocd-slack-build-notifier/pull/38",
                "issue_title": "Add tests minimal config",
                "issue_description": "Added logging which should help solving problems in case loading configurations fail. Now the root cause should be visible in the plugin log file.\n\nAdded some tests for different minimal configurations (without default configurations in config file):\n- No pipelines (Example in readme)\n- One pipeline (Issue #23)\n- Invalid configuration file (Related to issue #23)\n\nFixed a bug which caused plugin's default pipeline state value to override config file pipeline's state value.\n"
            },
            "3": {
                "commit_sha_buggy": "e9805a16e309a21d16ec3cce66754a99b551a3ac",
                "commit_sha_fixed": "00a26b663da32f68d8f486128dc23a15240e3e7d",
                "report_id": "46",
                "report_url": "https://github.com/ashwanthkumar/gocd-slack-build-notifier/issues/46",
                "issue_title": "Add an ability to use environment variables for login/password",
                "issue_description": "Hi,\nWe need to have an ability to use environment variables for the login/password in config file - something like \"login = ${GO_USERNAME}\". We need this because we want to grant users access to config file under source control - so they could add their own pipelines notifications for their own channels. I've tried any possible way I could for using environment variables in config, but no luck - plugin always fails to start with the messages like:\n\n```\nFelixGoPluginOSGiFramework:124 - Failed to load plugin: plugins_work/gocd-slack-notifier-1.2.2.jar. Plugin is invalid. Reasons [Class [GoNotificationPlugin] is annotated with @Extension bu\nt cannot be constructed. Reason: com.typesafe.config.ConfigException$NotResolved: need to Config#resolve(), see the API docs for Config#resolve(); substitution not resolved: ConfigReference(${GO_USERNAME})., No extensions found in\n this plugin.Please check for @Extension annotations]\n```\n\nCan you please check if there are any possible options for us?\n"
            }
        }
    },
    "Disklrucache": {
        "owner_repo": "JakeWharton/DiskLruCache",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "793815a073a66a61a9c9817bee780c948c030c8e",
                "commit_sha_fixed": "ebe0f06d0e1002051b65d0c749d2256dbf30f499",
                "report_id": "2",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/issues/2",
                "issue_title": "Android aggresive cache clearing leads to crash",
                "issue_description": "I have the cache put inside a subdirectory in the application cache directory. On devices with low internal storage (Nexus One for example) this will eventually lead to low storage situations where Android will just clear the whole cache directory, including subdirectories.\n\nThis gives this:\n\n```\njava.io.FileNotFoundException: /data/data/<package>/cache/images/-1944396650.0.tmp (No such file or directory)\nat org.apache.harmony.luni.platform.OSFileSystem.open(Native Method)\nat dalvik.system.BlockGuard$WrappedFileSystem.open(BlockGuard.java:232)\nat java.io.FileOutputStream.<init>(FileOutputStream.java:94)\nat java.io.FileOutputStream.<init>(FileOutputStream.java:66)\nat <package>.DiskLruCache$Editor.newOutputStream(DiskLruCache.java:686)\n```\n\nIt's thrown because the images directory is now gone. I though listening for ACTION_DEVICE_STORAGE_LOW could solve this but that is broadcasted after Android has cleared the directory.\n\nIf would be nice if it was possible to just reset the cache when the whole directory has gone missing or something.\n"
            },
            "2": {
                "commit_sha_buggy": "e031fd1f06b1d8cd089e7d51c2f02f1d6c3736b1",
                "commit_sha_fixed": "f1cb7168dd323ba024d99427583432a0829b4784",
                "report_id": "22",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/pull/22",
                "issue_title": "Allow recreation of the cache directory when deleted.",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "747e27fe8d35145c0edced0a6f4eda240a75c774",
                "commit_sha_fixed": "204d41abb60f981a3f8521b7b5cb41deb43281bc",
                "report_id": "24",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/pull/24",
                "issue_title": "Allow keys with dashes (-) so one can use the return of an object's .hashCode() as key",
                "issue_description": "Useful for HTTP caching and other cases.\n\nFor instance:\n\n```\nURL url = new URL(\"http://host/path\");\nString myKey = String.valueOf(url.hashCode()); // may be a negative integer\n```\n"
            },
            "4": {
                "commit_sha_buggy": "b89285d0fdf04e064e18d5ebe5ea7e3df0d4a832",
                "commit_sha_fixed": "ebbb058e8226d2c5531bb2d66ff4d41d6edd366c",
                "report_id": "38",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/pull/38",
                "issue_title": "Automatically flush the cache when an edit is completed.",
                "issue_description": "This will remove the need for applications to manually flush\nthe cache.\n"
            },
            "5": {
                "commit_sha_buggy": "a45363b4087c192f43e1dd7d192d1cbd6a998240",
                "commit_sha_fixed": "c401a3f15500b74c3a639852f38e696bf7183614",
                "report_id": "44",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/pull/44",
                "issue_title": "Fix #43",
                "issue_description": ""
            },
            "6": {
                "commit_sha_buggy": "c2965c04a03d016c58323c41223d8e2808adf732",
                "commit_sha_fixed": "7a1ecbd38d2ad0873fb843e911d60235b7434acb",
                "report_id": "74",
                "report_url": "https://github.com/JakeWharton/DiskLruCache/pull/74",
                "issue_title": "Don't append to a truncated line in the journal.",
                "issue_description": "Related to https://github.com/square/okhttp/issues/1099\n"
            }
        }
    },
    "Kafka_graphite": {
        "owner_repo": "damienclaveau/kafka-graphite",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1c1903fa5a55271d262d5ba73a7cb9418ce6effa",
                "commit_sha_fixed": "568c331512ba2e52f6aafe97aaf7346f2ba28860",
                "report_id": "6",
                "report_url": "https://github.com/damienclaveau/kafka-graphite/issues/6",
                "issue_title": "Unable to send metrics to graphite",
                "issue_description": "I'm unable to see any metrics on graphite. I'm seeing these messages from kafka on startup:\n\n```\n[2015-04-09 23:16:05,717] INFO Verifying properties (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,742] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,742] WARN Property kafka.graphite.metrics.group is not valid (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,743] WARN Property kafka.graphite.metrics.host is not valid (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,743] WARN Property kafka.graphite.metrics.port is not valid (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,743] WARN Property kafka.graphite.metrics.reporter.enabled is not valid (kafka.utils.VerifiableProperties)\n[2015-04-09 23:16:05,743] WARN Property kafka.metrics.reporters is not valid (kafka.utils.VerifiableProperties)\n```\n\nAlso, this is what kafka launches with (`java.class.path`). I've split it on `:` so its easier to read. As you can see, the metrics jar as well as the kafka-graphite-1.0.0 jar are both present.\n\n```\n/opt/kafka/bin/../core/build/dependant-libs-2.10.4*/*.jar\n:/opt/kafka/bin/../examples/build/libs//kafka-examples*.jar\n:/opt/kafka/bin/../contrib/hadoop-consumer/build/libs//kafka-hadoop-consumer*.jar\n:/opt/kafka/bin/../contrib/hadoop-producer/build/libs//kafka-hadoop-producer*.jar\n:/opt/kafka/bin/../clients/build/libs/kafka-clients*.jar\n:/opt/kafka/bin/../libs/jopt-simple-3.2.jar\n:/opt/kafka/bin/../libs/kafka_2.10-0.8.2.0.jar\n:/opt/kafka/bin/../libs/kafka_2.10-0.8.2.0-javadoc.jar\n:/opt/kafka/bin/../libs/kafka_2.10-0.8.2.0-scaladoc.jar\n:/opt/kafka/bin/../libs/kafka_2.10-0.8.2.0-sources.jar\n:/opt/kafka/bin/../libs/kafka_2.10-0.8.2.0-test.jar\n:/opt/kafka/bin/../libs/kafka-clients-0.8.2.0.jar\n:/opt/kafka/bin/../libs/kafka-graphite-1.0.0.jar\n:/opt/kafka/bin/../libs/log4j-1.2.16.jar\n:/opt/kafka/bin/../libs/lz4-1.2.0.jar\n:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar\n:/opt/kafka/bin/../libs/metrics-graphite-2.2.0.jar\n:/opt/kafka/bin/../libs/scala-library-2.10.4.jar\n:/opt/kafka/bin/../libs/slf4j-api-1.7.6.jar\n:/opt/kafka/bin/../libs/slf4j-log4j12-1.6.1.jar\n:/opt/kafka/bin/../libs/snappy-java-1.1.1.6.jar\n:/opt/kafka/bin/../libs/zkclient-0.3.jar\n:/opt/kafka/bin/../libs/zookeeper-3.4.6.jar\n:/opt/kafka/bin/../core/build/libs/kafka_2.10*.jar (org.apache.zookeeper.ZooKeeper)\n```\n\nAny pointers to what I'm possibly missing?\n"
            }
        }
    },
    "Simple_excel": {
        "owner_repo": "tobyweston/simple-excel",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e20b43d1dbb6a72f6a449cf93b63915624d66ddf",
                "commit_sha_fixed": "552730c22c60a37bcfd4cebc57014701b5df220f",
                "report_id": "13",
                "report_url": "https://github.com/tobyweston/simple-excel/pull/13",
                "issue_title": "Comparing rows with different number of cells containing value",
                "issue_description": "Pull Request for resolving the issue #12 I have created."
            }
        }
    },
    "Trident_ml": {
        "owner_repo": "pmerienne/trident-ml",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ba0225426dfd6b8e9474de1771936ec8003054f9",
                "commit_sha_fixed": "6bdc631984bcefb9614ffd9b73efeb64a87f36f9",
                "report_id": "8",
                "report_url": "https://github.com/pmerienne/trident-ml/pull/8",
                "issue_title": "#7 Fixbug/query should return null prediction if no learner found",
                "issue_description": "Query should return null prediction if no learner found.\nThis will allow to perform test-then-update ! \n"
            }
        }
    },
    "Tascalate_concurrent": {
        "owner_repo": "vsilaev/tascalate-concurrent",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "06347d0ef49aafc9820a55e6706fc3c878120907",
                "commit_sha_fixed": "d8f2a55407485d20b85423cc841eef0bef8eaa1f",
                "report_id": "9",
                "report_url": "https://github.com/vsilaev/tascalate-concurrent/issues/9",
                "issue_title": "whenCompleteAsync adds the failure exception as a suppressed exception to itself",
                "issue_description": "The problem is in the following code:\r\n```\r\n// exceptions are handled in regular way\r\nfailure -> {\r\n    try {\r\n        action.accept(null, failure);\r\n        return forwardException(failure);\r\n    } catch (Throwable e) {\r\n        // CompletableFuture does not override exception here\r\n        // unlike as in handle[Async](BiFunction)\r\n        // Preserve this behavior, but let us add at least \r\n        // suppressed exception\r\n        failure.addSuppressed(e);\r\n        return forwardException(failure);\r\n    }\r\n}\r\n```\r\nThe `forwardException` throws a `CompletionException` which is immediatelly caught by the catch clause. Then, it is added to the `failure` as a suppressed exception. However, it can happen that `failure` == `e` (is the same object) since `failure` is retrown when its type already is the `CompletionException`.\r\n\r\nI added a test for this in #8.\r\n\r\nWhat about calling the `forwardException` after the `try-catch` block as in the following code? This also make the code a little bit cleaner since there is only one call to `forward...` now :)\r\n ```\r\n// exceptions are handled in regular way\r\nfailure -> {\r\n    try {\r\n        action.accept(null, failure);\r\n    } catch (Throwable e) {\r\n        // CompletableFuture does not override exception here\r\n        // unlike as in handle[Async](BiFunction)\r\n        // Preserve this behavior, but let us add at least \r\n        // suppressed exception\r\n        failure.addSuppressed(e);\r\n    }\r\n    return forwardException(failure);\r\n}\r\n```"
            },
            "2": {
                "commit_sha_buggy": "b90028e018fdee3c598ed18bcf4c8af765451a34",
                "commit_sha_fixed": "104d53b09611b0f99b3120ae307c604f8b480c6d",
                "report_id": "8",
                "report_url": "https://github.com/vsilaev/tascalate-concurrent/pull/8",
                "issue_title": "Suppressed self addition test for whenCompleteAsync",
                "issue_description": "Adds test for self addition as a suppressed exception in `AbstractCompletableTask.whenCompleteAsync`.\r\n\r\nThe problem is in the following code:\r\n```\r\n// exceptions are handled in regular way\r\nfailure -> {\r\n    try {\r\n        action.accept(null, failure);\r\n        return forwardException(failure);\r\n    } catch (Throwable e) {\r\n        // CompletableFuture does not override exception here\r\n        // unlike as in handle[Async](BiFunction)\r\n        // Preserve this behavior, but let us add at least \r\n        // suppressed exception\r\n        failure.addSuppressed(e);\r\n        return forwardException(failure);\r\n    }\r\n}\r\n```\r\nThe `forwardException` throws a `CompletionException` which is immediatelly caught by the catch clause. Then, it is added to the `failure` as a suppressed exception. However, it can happen that `failure` == `e` (is the same object) since `failure` is retrown when its type already is the `CompletionException`."
            }
        }
    },
    "Jcabi_github": {
        "owner_repo": "jcabi/jcabi-github",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "394e2177c29addfa393915708042c04dd0fcff78",
                "commit_sha_fixed": "b7eaa49123e45eb20dae54961f25c08495fbd825",
                "report_id": "9",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/9",
                "issue_title": "Milestones API",
                "issue_description": "Let's implement Milestones API: http://developer.github.com/v3/issues/milestones/\n"
            },
            "2": {
                "commit_sha_buggy": "fb1839557a854a90f3d71492d568de74533a743a",
                "commit_sha_fixed": "4e5bb214cc9323cd36e818fadad980eb6ba95326",
                "report_id": "131",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/131",
                "issue_title": "\"XPath '/github/gists/gist[id='1']/files/file[filename='file.txt']/raw_content/text()' not found\" in MkGist.read()",
                "issue_description": "In the MkGists.create() a new gist is created without a raw_content:\n\n``` java\nfinal Directives dirs = new Directives().xpath(this.xpath())\n    .add(\"gist\")\n    .add(\"id\").set(number).up()\n    .add(\"files\");\nfor (final String file : files) {\n    dirs.add(\"file\").add(\"filename\").set(file).up().up();\n}\n```\n\nIf I create MkGist and call its read() method, I'll get an exception:\n\n```\ncom.jcabi.xml.ListWrapper$NodeNotFoundException: XPath '/github/gists/gist[id='1']/files/file[filename='file.txt']/raw_content/text()' not found in '<?xml version=\\\\\\\"1.1\\\\\\\" encoding=\\\\\\\"UTF-8\\\\\\\"?>\\\\n<githu..336..les>\\\\n      </gist>\\\\n   </gists>\\\\n</github>': Index (0) is out of bounds (size=0)\n```\n\nI think an empty raw_content element should be created in the MkGists.create().\n\nUPD: MkGists.write() expects a raw_content too.\n"
            },
            "3": {
                "commit_sha_buggy": "a811516df77cabc834098f88d0a297585f88b6ef",
                "commit_sha_fixed": "198dbd2bacecedde0d75016ace9b32becab7ea5b",
                "report_id": "128",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/128",
                "issue_title": "\"Only text() nodes or attributes are retrievable with xpath()\" in the MkGists.create()",
                "issue_description": "Look like there is a bug in the MkGists class. A new gist's number is calculated in line 90:\n\n``` java\nnumber = Integer.toString(\n    1 + this.storage.xml().xpath(\n        String.format(\"%s/gist/id\", this.xpath())\n    ).size()\n);\n```\n\nIt works if there are no gists yet. If I call the MkGists.create() twice to create two gists, I'll get an exception:\n\n```\njava.lang.IllegalArgumentException: Only text() nodes or attributes are retrievable with xpath() '/github/gists/gist/id': 1.\n```\n\nLooks like it should be\n\n``` java\nString.format(\"%s/gist/id/text()\", this.xpath())\n```\n"
            },
            "4": {
                "commit_sha_buggy": "a3ed0de11759270663c63b424eb28a83df09144e",
                "commit_sha_fixed": "9fa538a6ad550adce5e5e27e85111738f38941b0",
                "report_id": "135",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/135",
                "issue_title": "Issue #128 MkGists.create() bug was fixed",
                "issue_description": "MkGists.create() bug was fixed. Regression test was added\n"
            },
            "5": {
                "commit_sha_buggy": "75c9a727b415328961ab72b8c559d11851aea553",
                "commit_sha_fixed": "0cd642fa7b81874513663fe716e1c808a4fdd508",
                "report_id": "170",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/170",
                "issue_title": "Wrong request in RtGist.toString() and RtGist.json()",
                "issue_description": "I found a bug. I've made it working on issue #21. In `RtGist.java` in lines 90 and 167 `this.entry` should be replaced by `this.request`.\n"
            },
            "6": {
                "commit_sha_buggy": "d5ce66f830ee8813c245fa0d3b1cea8792771623",
                "commit_sha_fixed": "8c161c9f5077deb597690a64a23dfc65cdbc34fb",
                "report_id": "187",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/187",
                "issue_title": "Issue #170 Fixed bug where gists are looked up from the wrong URI.",
                "issue_description": ""
            },
            "7": {
                "commit_sha_buggy": "c11fcda3de4eed9edad75df3428ae5d6c5662936",
                "commit_sha_fixed": "10447d121e98bc08c1ddeb3e080a5a7110badc94",
                "report_id": "183",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/183",
                "issue_title": "MkPulls.create() should also create an issue",
                "issue_description": "`MkPulls.create()` method should also create an issue, in order to properly imitate Github, which creates an issue for every pull request.\n"
            },
            "8": {
                "commit_sha_buggy": "030be4529e2211bff9ce800f7396b1b18d51c494",
                "commit_sha_fixed": "e0df33b2462af6a0bfe2b3c828b57307a0973f5d",
                "report_id": "101",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/101",
                "issue_title": "RtOrganization.java:42-44: Default implementation for user's Organization....",
                "issue_description": "Puzzle `2-9e4b61da` in `src/main/java/com/jcabi/github/RtOrganization.java:42-44` has to be resolved: Default implementation for user's Organization. Provide default implementation for user's organization. Don't forget about @EqualsAndHashCode.\n"
            },
            "9": {
                "commit_sha_buggy": "f2e2de42edbf30bf31d44b43cc815881b24d02ff",
                "commit_sha_fixed": "6d2b19d61e13f424b3fafc07fd6dc42d8f6f43d0",
                "report_id": "202",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/202",
                "issue_title": "Issue #183 MkPulls.create() creates issue first",
                "issue_description": "and than pull with te same id\n"
            },
            "10": {
                "commit_sha_buggy": "f2038fa065fa5e63aab3e7b660b1b8c513ac5a39",
                "commit_sha_fixed": "101e088ae741c1f6580bfc4a36b8223f47594572",
                "report_id": "215",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/215",
                "issue_title": "Issue #214 Corrected URI used for initializing Hook request",
                "issue_description": ""
            },
            "11": {
                "commit_sha_buggy": "9a35eb5bdee802dd5569015e16f336517b2064b4",
                "commit_sha_fixed": "72ba99f81e38b5ae40eb538bc586a9a61b969823",
                "report_id": "2",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/2",
                "issue_title": "orgs API",
                "issue_description": "Let's implement orgs API: http://developer.github.com/v3/orgs/\n"
            },
            "12": {
                "commit_sha_buggy": "94e4960742306d9bfc919943aaea54d3e397e3f9",
                "commit_sha_fixed": "cf88349d719f87b8e48ea2a1ab5c44924c985e6a",
                "report_id": "102",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/102",
                "issue_title": "Issue #94 RtAssignees iterate and check methoids were implemented",
                "issue_description": ""
            },
            "13": {
                "commit_sha_buggy": "91b9551c95e3bbb5080f39e1f22b7ad466c4c0c0",
                "commit_sha_fixed": "4a9caf2804159b68789b4b21a0b39a259d8a73e9",
                "report_id": "13",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/13",
                "issue_title": "Users API",
                "issue_description": "Let's implement Users API: http://developer.github.com/v3/users/\n"
            },
            "14": {
                "commit_sha_buggy": "5ac6f381ce612beecc4ab8384ae9cc08bb4d59f8",
                "commit_sha_fixed": "a811516df77cabc834098f88d0a297585f88b6ef",
                "report_id": "132",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/132",
                "issue_title": "Issue #131 was fixed",
                "issue_description": "Issue #131 was fixed.\n"
            },
            "15": {
                "commit_sha_buggy": "4a244d0113f0d414fbf32d9f5b850617dcb02bda",
                "commit_sha_fixed": "49d1eef64f0f30feee4fbe8c7ebd21b30bdf2367",
                "report_id": "112",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/112",
                "issue_title": "Puzzle 1-b6ff6189 in src/main/java/com/jcabi/github/GhRepos.java:90-91 resolved",
                "issue_description": ""
            },
            "16": {
                "commit_sha_buggy": "befb961ee821271fd697a1bb070d34bfe56aae01",
                "commit_sha_fixed": "8bc4aa2045a1a38b645dfebda2040f5906e9ab1d",
                "report_id": "111",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/111",
                "issue_title": "MkRepo.java:61-63: Implement milestones() method. Please, implement...",
                "issue_description": "Puzzle `9-a4bc0ae9` in `src/main/java/com/jcabi/github/mock/MkRepo.java:53-55` has to be resolved: Implement milestones() method. Please, implement milestones() method to return MkMilestones. Don't forget about unit tests\n"
            },
            "17": {
                "commit_sha_buggy": "8ef984198a52ba20d3306dc7676c8b3863e0de6e",
                "commit_sha_fixed": "c11fcda3de4eed9edad75df3428ae5d6c5662936",
                "report_id": "182",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/182",
                "issue_title": "Issue #137 Label.Unmodified.compareTo() fixed",
                "issue_description": ""
            },
            "18": {
                "commit_sha_buggy": "d4a454692a8e62463d012e929db47a67fa04da9b",
                "commit_sha_fixed": "fa20bd4304820444c4d06dbea34c71bc49c50a30",
                "report_id": "181",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/181",
                "issue_title": "RtReleasesTest.java:75-78: RtReleases should iterate multiple releases....",
                "issue_description": "Puzzle `123-d3789d9a` in `src/test/java/com/jcabi/github/RtReleasesTest.java:75-78` has to be resolved: RtReleases should iterate multiple releases. Let's implement a test here and a method of RtReleases. The method should iterate multiple releases. See how it's done in other classes with GhPagination. When done, remove this puzzle and Ignore annotation from the method.\n"
            },
            "19": {
                "commit_sha_buggy": "2c59f26c46d7feea31ed43a23ba024e40af6d42d",
                "commit_sha_fixed": "e91a3b4f806982ec48c7578a99fc1bd99cec033d",
                "report_id": "143",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/143",
                "issue_title": "Limit.Throttled.json() doesn't use SmartJson helper class.",
                "issue_description": "Limit.Throttled.json() calls origin.json().getInt(...);\n\nIt would be better to create an instance of the SmartJson helper class and call number(...) to get the \"remaining\", \"limit\" and \"reset\" json properties \n\nBecause this would provide IllegalStateException reporting consistent with the rest of the application.\n"
            },
            "20": {
                "commit_sha_buggy": "04e5c4e94fadd1e7b309b28cdcec0107754a846f",
                "commit_sha_fixed": "00f9898d6f6e4d0e2b190e4a5ec235eb38d72fa6",
                "report_id": "181",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/181",
                "issue_title": "RtReleasesTest.java:75-78: RtReleases should iterate multiple releases....",
                "issue_description": "Puzzle `123-d3789d9a` in `src/test/java/com/jcabi/github/RtReleasesTest.java:75-78` has to be resolved: RtReleases should iterate multiple releases. Let's implement a test here and a method of RtReleases. The method should iterate multiple releases. See how it's done in other classes with GhPagination. When done, remove this puzzle and Ignore annotation from the method.\n"
            },
            "21": {
                "commit_sha_buggy": "bbbe892e586f477e299af4ebb7b94b2e0bf0da3e",
                "commit_sha_fixed": "d2349a2727043560c2de3b11c855325d009f725e",
                "report_id": "209",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/209",
                "issue_title": "Issue #181",
                "issue_description": "Pull request for issue #181.\n"
            },
            "22": {
                "commit_sha_buggy": "75e159fb003092619cd2c6ff4eb5d56d32420fba",
                "commit_sha_fixed": "f8f107528f63e9fbfbaf45e6b6e3c16e4903818d",
                "report_id": "201",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/201",
                "issue_title": "143",
                "issue_description": "Please review. Thx\n"
            },
            "23": {
                "commit_sha_buggy": "ed6194323841933f1cc92de941c434f6ceb17b05",
                "commit_sha_fixed": "e23047e0c3e57e1f121c82732524846b1301f1ea",
                "report_id": "197",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/197",
                "issue_title": "MkIssue should remember its author",
                "issue_description": "`MkIssue` should remember who create it. This code now fails, but it should not:\n\n``` java\nGithub first = new MkGithub(\"first\");\nGithub second = first.relogin(\"second\");\nRepo repo = first.repos().create(...);\nIssue issue = second.repos().get(repo.coordinates()).issues().create(\"\", \"\");\nassert new Issue.Smart(issue).author().login().equals(\"second\");\n```\n"
            },
            "24": {
                "commit_sha_buggy": "1ad60d06e6cf6402838e3c5b005cc9179c73135b",
                "commit_sha_fixed": "405a3c632494e8e6800c1e2d28e87b6a51b1c504",
                "report_id": "241",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/241",
                "issue_title": "Issue #197 MkIssue should remember its author",
                "issue_description": "Done\n"
            },
            "25": {
                "commit_sha_buggy": "b2f4c30fceeb54a4a192b44899d07d44efdc7f2c",
                "commit_sha_fixed": "2e058bf53b8ec4a3132861e9ef672104ac30c1c2",
                "report_id": "299",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/299",
                "issue_title": "RtPublicKeys.java:46-47: Implement the iterate() method of...",
                "issue_description": "Puzzle `24-7296143a` in `src/main/java/com/jcabi/github/RtPublicKeys.java:46-47` has to be resolved: Implement the iterate() method of RtPublicKeys. Don't forget to implement the test {@link RtPublicKeysTest#retrievesKeys()} class when done.\n"
            },
            "26": {
                "commit_sha_buggy": "27a70229c35ec7a68d363eeb153445e691c75a75",
                "commit_sha_fixed": "786bb605231fac67de8065dd5fb940b218eeb341",
                "report_id": "303",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/303",
                "issue_title": "PublicKey.java:41-45: Implement a Smart decorator for...",
                "issue_description": "Puzzle `24-d315d228` in `src/main/java/com/jcabi/github/PublicKey.java:41-45` has to be resolved: Implement a Smart decorator for PublicKey for the purposes of JSON parsing. This class should be able to return the various attributes of the JSON response for fetching public keys, such as the ID, key, URL, and title. Include an example of how to do this in the Javadoc comment above (see other classes/interfaces for how they describe it).\n"
            },
            "27": {
                "commit_sha_buggy": "343d5873383a965128321fb5089e0de8932a8981",
                "commit_sha_fixed": "5cac3fbafc5705c7a184b76e9e1e83154afb570b",
                "report_id": "302",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/302",
                "issue_title": "Issue #299 - The iterate method  in RtPublicKeys was implemented",
                "issue_description": ""
            },
            "28": {
                "commit_sha_buggy": "ae0b600c45d293c8a46ce82731c1625e62a3da97",
                "commit_sha_fixed": "901f828adc821dbed85069efd34997f7834fcce1",
                "report_id": "309",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/309",
                "issue_title": "MkGistsTest.java:69-70: Method remove() in MkGists class...",
                "issue_description": "Puzzle `20-8aa5366a` in `src/test/java/com/jcabi/github/mock/MkGistsTest.java:69-70` has to be resolved: Method remove() in MkGists class has to be implemented. The test for this method is currently ignored.\n"
            },
            "29": {
                "commit_sha_buggy": "b18dfa2b4ef06847b02020b85e71884d941c929e",
                "commit_sha_fixed": "c98f15971cd3cfee07d699b775dc24b0ba918aba",
                "report_id": "331",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/331",
                "issue_title": "RtGist.java:56-57: RtGist.unstar() method as long as...",
                "issue_description": "Puzzle `114-b8ad47dc` in `src/main/java/com/jcabi/github/RtGist.java:56-57` has to be resolved: RtGist.unstar() method as long as unit test have to be implemented.\n"
            },
            "30": {
                "commit_sha_buggy": "55a82df7602d60882829f43d0fe23bb16e9f6ffd",
                "commit_sha_fixed": "97360a3c186594124760c18e2e67aafb0e8db31f",
                "report_id": "320",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/320",
                "issue_title": "Github should support a method to return gitignores",
                "issue_description": "Currently, we want to get gitignores instance, we have to do\n\n```\n    new RtGitignores(new RtGithub(key))\n```\n\nIt's inconsistent with others such as `markdown`, `limits`, `search`, `emojis`.\n\nSo `Github` should support method to return gitignores `gitbut.gitignores()`, similar to `markdown`, `limits`, `search`, `emojis`.\n"
            },
            "31": {
                "commit_sha_buggy": "ed6194323841933f1cc92de941c434f6ceb17b05",
                "commit_sha_fixed": "69d751fe33d6ea02b6f43aa452e4e58ec223dcfe",
                "report_id": "190",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/190",
                "issue_title": "MkPull.json() should expose \"comments\"",
                "issue_description": "`MkPull.json()` should calculate the amount of comments in the related issue and expose its number in `comments` JSON property, as specified in http://developer.github.com/v3/pulls/#get-a-single-pull-request\n\nFor example:\n\n``` java\nPull pull = repo.pulls().create(\"\", \"\", \"\");\nIssue issue = repo.issues().get(pull.number());\nassert pull.json().getInt(\"comments\") == 0;\nissue.comments().post(\"how are you?\");\nassert pull.json().getInt(\"comments\") == 1;\n```\n"
            },
            "32": {
                "commit_sha_buggy": "b17cd9b0a912b4c534de364f05004ceadf51571e",
                "commit_sha_fixed": "d140faa748e47b0237186515daca439ef4dfdb01",
                "report_id": "226",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/226",
                "issue_title": "Issue #190 MkPull.json() should expose \"comments\" is done",
                "issue_description": "I've also fixed `MkPull.xpath()`\n"
            },
            "33": {
                "commit_sha_buggy": "08af455727c48dc6dfee8bb31e1c26219cd0537a",
                "commit_sha_fixed": "13abf505ca036af7c4872167593d791e394644e1",
                "report_id": "221",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/221",
                "issue_title": "MkSearch.java:48-50: Search mock should be implemented....",
                "issue_description": "Puzzle `124-c408887d` in `src/main/java/com/jcabi/github/mock/MkSearch.java:48-50` has to be resolved: Search mock should be implemented. Implement methods repos(), issues(), and users() which should return lists of repositories, issues, and users, respectively. See http://developer.github.com/v3/search/\n"
            },
            "34": {
                "commit_sha_buggy": "c4e6b525716e4dda18bb05ea0dff9bc4a18bd7e6",
                "commit_sha_fixed": "a69e03bd0392a7c5e756300561bdbfac93a5e096",
                "report_id": "220",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/220",
                "issue_title": "RtSearch.java:44-46: Add implementations of repos(), issues(),...",
                "issue_description": "Puzzle `124-aeffd4a7` in `src/main/java/com/jcabi/github/RtSearch.java:44-46` has to be resolved: Add implementations of repos(), issues(), and users() methods. When done, don't forget to remove @Ignore annotations from the {@link RtSearchTest} class.\n"
            },
            "35": {
                "commit_sha_buggy": "be49ed21215d53f2ecb9aac5297e02088f839952",
                "commit_sha_fixed": "2588010553c8bc65a00d04f453a456b493c22c27",
                "report_id": "257",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/257",
                "issue_title": "Issue #221",
                "issue_description": "Pull request for an issue #221. There were wrong line separators, so it seems like I changed files completely. Also, I've done a todo from `MkSearchTest.java:40-41`:\n\n``` java\n/*\n * @todo #124 Implement the test cases for {@link MkSearch}.\n *  See http://developer.github.com/v3/search/\n */\n```\n"
            },
            "36": {
                "commit_sha_buggy": "2588010553c8bc65a00d04f453a456b493c22c27",
                "commit_sha_fixed": "c2bbf0f56b0da309dd25a4976b18e9bf4b397624",
                "report_id": "156",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/156",
                "issue_title": "RtHooksTest.java:84-87: RtHooks should iterate multiple hooks....",
                "issue_description": "Puzzle `122-094000b7` in `src/test/java/com/jcabi/github/RtHooksTest.java:75-78` has to be resolved: RtHooks should iterate multiple hooks. Let's implement a test here and a method of RtHooks. The method should iterate multiple hooks. See how it's done in other classes with GhPagination. When done, remove this puzzle and Ignore annotation from the method.\n"
            },
            "37": {
                "commit_sha_buggy": "be9f8730dee2b4247fe75cda25444ecb1c564f18",
                "commit_sha_fixed": "b1312beb12ee36db8278e20b333947b130d5eb15",
                "report_id": "186",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/186",
                "issue_title": "111",
                "issue_description": ""
            },
            "38": {
                "commit_sha_buggy": "f0dc80c84c840b6e355585f6e36af18e9d966360",
                "commit_sha_fixed": "663cc5c287c1a4b68fc9a8c525091124de1c9192",
                "report_id": "192",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/192",
                "issue_title": "MkForks.java:44-46: Need to implement the methods...",
                "issue_description": "Puzzle `121-311f63a9` in `src/main/java/com/jcabi/github/mock/MkForks.java:44-46` has to be resolved: Need to implement the methods of MkForks: 1) iterate, returning a list of forks, and 2) create, which will create a new fork. Don't forget to update the unit test class {@link MkForksTest}.\n"
            },
            "39": {
                "commit_sha_buggy": "1aa4af45aa2c56421c3d911a0a06da513a7316a0",
                "commit_sha_fixed": "b3b30af34b12b4450f828d84fc0b6c22dc620b9d",
                "report_id": "339",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/339",
                "issue_title": "Issue #309 Implemented MkGists.remove()",
                "issue_description": ""
            },
            "40": {
                "commit_sha_buggy": "b3b30af34b12b4450f828d84fc0b6c22dc620b9d",
                "commit_sha_fixed": "c50ef14d0f463c7daa80eaec706ca8276da5f264",
                "report_id": "341",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/341",
                "issue_title": "Issue #331 - Implemented unstar method",
                "issue_description": ""
            },
            "41": {
                "commit_sha_buggy": "1f3165a04e027304f97db58a149d96f1cc705a63",
                "commit_sha_fixed": "41d003d9edfc0903a0f39abdf4a8c06aeedcc830",
                "report_id": "263",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/263",
                "issue_title": "\"Only text() nodes or attributes are retrievable with xpath()\"",
                "issue_description": "Recently I created an issue #128. There is the same problem in methods `MkIssues.create()` and `MkReleases.create()`.\n"
            },
            "42": {
                "commit_sha_buggy": "eacb6eaeada324f6915c751778f67ac1ffd1df19",
                "commit_sha_fixed": "e1eb01310bcc1da327636a1798a769b6aa8c5ff0",
                "report_id": "358",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/358",
                "issue_title": "Issue #321 can't create multiple issues in MkIssues",
                "issue_description": ""
            },
            "43": {
                "commit_sha_buggy": "ca567b54cbe82642f408b07ec188670cb7977e29",
                "commit_sha_fixed": "884f123ad6f54d51bc08dd722426856ec00fe762",
                "report_id": "373",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/373",
                "issue_title": "Issue #308 - Implemented the iterate() method MkPublicKeys",
                "issue_description": ""
            },
            "44": {
                "commit_sha_buggy": "884f123ad6f54d51bc08dd722426856ec00fe762",
                "commit_sha_fixed": "4fd536571405cda1cca4060586e8b3c608edfd0f",
                "report_id": "372",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/372",
                "issue_title": "#263 solved error",
                "issue_description": "the create() method in MkIssues and MkReleases would give the error\n\"Only text() nodes or attributes are retrievable with xpath()\" when\ncreating more than one Issue or Release. Solved it and put some tests.\n"
            },
            "45": {
                "commit_sha_buggy": "ca93706d8293eb0dfe2da985a68116458fb0c317",
                "commit_sha_fixed": "716954b18e6066a9fc7f16e6ef0fcb56c770a2e8",
                "report_id": "300",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/300",
                "issue_title": "MkPublicKeysTest.java:77-78: Implement the remove() method of...",
                "issue_description": "Puzzle `24-c752722e` in `src/test/java/com/jcabi/github/mock/MkPublicKeysTest.java:77-78` has to be resolved: Implement the remove() method of MkPublicKey. Implement this unit test method and remove the Ignore annotation when done.\n"
            },
            "46": {
                "commit_sha_buggy": "b15d7fddb5a947e2a1943fb7910a226f1cad81e9",
                "commit_sha_fixed": "ec5749d598303e05343576f3e66caa8b330ace4f",
                "report_id": "380",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/380",
                "issue_title": "Issue #300 - Implemented the remove() method of MkPublicKeys",
                "issue_description": ""
            },
            "47": {
                "commit_sha_buggy": "61a6ca5aaf69d05a7e21ef3a41ef835e13b7bf5b",
                "commit_sha_fixed": "f23b9f3cf58ce41b4c0cb8059671954420d12ca2",
                "report_id": "35",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/35",
                "issue_title": "GhJson.java:50-52: Unit test for GhJson is...",
                "issue_description": "Puzzle `1-49e05ff2` in `src/main/java/com/jcabi/github/GhJson.java:50-52` has to be resolved: Unit test for GhJson is required. Let's create a simple one, to check that the class implements its fetching and pathing features correctly.\n"
            },
            "48": {
                "commit_sha_buggy": "b18dfa2b4ef06847b02020b85e71884d941c929e",
                "commit_sha_fixed": "633d4fb521379f745e61fed4c9162171d4608b8c",
                "report_id": "36",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/36",
                "issue_title": "GhLabel.java:47-50: Unit test for GhLabel is...",
                "issue_description": "Puzzle `1-503e3ad1` in `src/main/java/com/jcabi/github/GhLabel.java:47-50` has to be resolved: Unit test for GhLabel is required. Let's create a simple one, to check that the class implements key functions correctly. The most important methods to test are json() and patch(). Although, would be great to cover the entire class.\n"
            },
            "49": {
                "commit_sha_buggy": "ba98aebb6d4318a7968a31debf0bbfa3c7d9d2c2",
                "commit_sha_fixed": "cab0fa5c7c088ce8953143ca95317d401da30530",
                "report_id": "308",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/308",
                "issue_title": "MkPublicKeysTest.java:50-51: Implement the iterate() method of...",
                "issue_description": "Puzzle `24-fc80b8db` in `src/test/java/com/jcabi/github/mock/MkPublicKeysTest.java:50-51` has to be resolved: Implement the iterate() method of MkPublicKeys. Implement this unit test method and remove the Ignore annotation when done.\n"
            },
            "50": {
                "commit_sha_buggy": "e9c62ed18f54b8e56cdbb1008d91c279defe7e3c",
                "commit_sha_fixed": "d030a0e489b5db596b5b1088f1e341dd03fb1d47",
                "report_id": "266",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/266",
                "issue_title": "MkHooks.java:49-54: Hooks mock should be implemented....",
                "issue_description": "Puzzle `166-2a6d031d` in `src/main/java/com/jcabi/github/mock/MkHooks.java:49-54` has to be resolved: Hooks mock should be implemented. Need to implement the methods of MkHooks: 1) iterate, returning a list of hooks, 2) create, which will create a new hook and 3) get, which will fetch hook by id Don't forget to update the unit test class {@link MkHooks}. See http://developer.github.com/v3/repos/hooks/\n"
            },
            "51": {
                "commit_sha_buggy": "ec5749d598303e05343576f3e66caa8b330ace4f",
                "commit_sha_fixed": "02eb860db41d531f4eb7f6d408d63a5aa8672c20",
                "report_id": "313",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/313",
                "issue_title": "fixed issue #156",
                "issue_description": ""
            },
            "52": {
                "commit_sha_buggy": "1e233718699d4f61e3d57d30ad35fc1cc8494038",
                "commit_sha_fixed": "3f1a5256488053e3c47ac92013c5036e543263db",
                "report_id": "397",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/397",
                "issue_title": "MkMilestonesTest.java:68-69: Method create() in MkMilestones has...",
                "issue_description": "Puzzle `111-d890929c` in `src/test/java/com/jcabi/github/mock/MkMilestonesTest.java:68-69` has to be resolved: Method create() in MkMilestones has to be implemented. Until then, this test is ignored.\n"
            },
            "53": {
                "commit_sha_buggy": "02eb860db41d531f4eb7f6d408d63a5aa8672c20",
                "commit_sha_fixed": "bf9994b773242561f147df46fcf5b15342257ab2",
                "report_id": "346",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/346",
                "issue_title": "MkDeployKeys - create method is not working correctly.",
                "issue_description": "I'm working on ticket #343. I saw that create method in MkDeployKeys is not working. \nExample 1:\n\n```\n    final DeployKey key = keys.create(\"Title1\", \"Key1\");\n        System.out.println(key.number());  // println 1\n        final DeployKey key2 = keys.create(\"Title2\", \"Key2\");\n        System.out.println(key2.number()); // println 1 -- wrong here\n```\n\nExpected: `key2.number() != key.number()`\n\nExample 2:\n\n```\n    final DeployKey key = keys.create(\"Title1\", \"Key1\");\n        System.out.println(key.json().toString());\n```\n\nWe got an exception\n\n```\ncom.jcabi.xml.ListWrapper$NodeNotFoundException: XPath '/repos/jeff/test/deployKeys/deployKey[id=1]' not found in '<?xml version=\\\\\\\"1.0\\\\\\\" encoding=\\\\\\\"UTF-8\\\\\\\" standalon..75..ame>\\\\r\\\\n</repo>\\\\r\\\\n</repos>\\\\r\\\\n</github>\\\\r\\\\n': Index (0) is out of bounds (size=0)\n```\n"
            },
            "54": {
                "commit_sha_buggy": "02eb860db41d531f4eb7f6d408d63a5aa8672c20",
                "commit_sha_fixed": "3e08cd277debe33c722a11a8b5989c4df46a6bc0",
                "report_id": "409",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/409",
                "issue_title": "MkRepos.java:53-53: Implement method MkRepos.remove() to remove...",
                "issue_description": "Puzzle `262-422887da` in `src/main/java/com/jcabi/github/mock/MkRepos.java:53-53` has to be resolved: Implement method MkRepos.remove() to remove particular repository.\n"
            },
            "55": {
                "commit_sha_buggy": "02eb860db41d531f4eb7f6d408d63a5aa8672c20",
                "commit_sha_fixed": "f23d3aac01f5fb71020b8db6a0bbf8ac604fa855",
                "report_id": "404",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/404",
                "issue_title": "MkMilestonesTest.java:53-54: Method repo() in MkMilestones has...",
                "issue_description": "Puzzle `111-ed02ff36` in `src/test/java/com/jcabi/github/mock/MkMilestonesTest.java:53-54` has to be resolved: Method repo() in MkMilestones has to be implemented. Until then, this test is ignored.\n"
            },
            "56": {
                "commit_sha_buggy": "e4031afd9df9d84c75b4efdbf284611ea893aca0",
                "commit_sha_fixed": "8dea2da75c160e0e47e3454b0035fb59fc64f09b",
                "report_id": "667",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/667",
                "issue_title": "#461: Retrieve comments for a specific pull request",
                "issue_description": "Submitting a new Pull Request for this issue.\n"
            },
            "57": {
                "commit_sha_buggy": "af53879b4d1c99d2e8f800c809d0bbeb701c2d5b",
                "commit_sha_fixed": "397a0839e7c3fbdea3bbeef29e2ca9a43d8ca800",
                "report_id": "461",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/461",
                "issue_title": "RtPullCommentsTest.java:152-155: RtPullComments should be able to...",
                "issue_description": "Puzzle `416-3cc65c37` in `src/test/java/com/jcabi/github/RtPullCommentsTest.java:152-155` has to be resolved: RtPullComments should be able to fetch all pull comments of a repo. Implement {@link RtPullComments#reply(String, int))} and don't forget to include a test here. When done, remove this puzzle and the Ignore annotation of this test method.\n"
            },
            "58": {
                "commit_sha_buggy": "8dea2da75c160e0e47e3454b0035fb59fc64f09b",
                "commit_sha_fixed": "6a3d09e8d7c9b603b32bc66a9bbaa144e8764aec",
                "report_id": "671",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/671",
                "issue_title": "#650",
                "issue_description": "I re-created branch for issue 650, please, review it\n"
            },
            "59": {
                "commit_sha_buggy": "4f5f03f66265f6ccfda8f9549edadad22f7e2895",
                "commit_sha_fixed": "d000fafaaab94091439f3da238542e7582b678cd",
                "report_id": "70",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/70",
                "issue_title": " Issue #55  was implemented",
                "issue_description": ""
            },
            "60": {
                "commit_sha_buggy": "6558ee5f9cc9f4768ab5f203559a5c20c8e21796",
                "commit_sha_fixed": "aae4d4d3e7088615d49a60951ad129fe18546cde",
                "report_id": "71",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/71",
                "issue_title": "Issue #33 Created unit test class for RtGithub.",
                "issue_description": "Note: RtGithub was named DefaultGithub prior to resolution of issue #64.\n"
            },
            "61": {
                "commit_sha_buggy": "809fb4a3541ac5efb6c797d2e6640a4cad2fa42e",
                "commit_sha_fixed": "50c4228968410d99589db2d44e90e15ba122865d",
                "report_id": "418",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/418",
                "issue_title": "MkContentsTest.java:64-67: MkContents should support the removal...",
                "issue_description": "Puzzle `311-f396de13` in `src/test/java/com/jcabi/github/mock/MkContentsTest.java:64-67` has to be resolved: MkContents should support the removal of mock contents. This method should return a new instance of MkCommit. Do not forget to implement a unit test for it here and remove the Ignore annotation.\n"
            },
            "62": {
                "commit_sha_buggy": "f1a04dcc81108c6c129d0230423a8a7509672ebc",
                "commit_sha_fixed": "a736c880f46d9cad6dd92f0d4ad186b50c97d020",
                "report_id": "692",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/692",
                "issue_title": "Issue #418 - MkContents should support the removal of mock contents",
                "issue_description": ""
            },
            "63": {
                "commit_sha_buggy": "8da13afecb6c3f9c81f9409c5c41addedb8c2ae9",
                "commit_sha_fixed": "28485a55783cdc8f17678aa377f4f0e5c2a660b1",
                "report_id": "698",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/698",
                "issue_title": "Issue 443: Initial commit",
                "issue_description": "Created mock method and corresponding unit test.\n"
            },
            "64": {
                "commit_sha_buggy": "8c5da8fa6c30b0d3769272012bc0ad5e85fcf168",
                "commit_sha_fixed": "3aa9550570a0fe1ee452e26f7e32549f8cf938cc",
                "report_id": "629",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/629",
                "issue_title": "MkOrganizations get method generating two organizaions . One with id and one with login",
                "issue_description": "The get() method in MkOrganization is generating xml with two organizations one with id and one with login. Is this is right ? than which organization should be considered private and which is public?\n"
            },
            "65": {
                "commit_sha_buggy": "fc1ad9d18b9abe49be1b83d8befb183a22ea641c",
                "commit_sha_fixed": "f4fbefcbaf2d4b29b78f636ee03ef503b735db81",
                "report_id": "742",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/742",
                "issue_title": "Issue 591: Updated initial commit",
                "issue_description": "Created new pull request for the issue 591 from updated branch as we had issues with it at the https://github.com/jcabi/jcabi-github/pull/727 . \n"
            },
            "66": {
                "commit_sha_buggy": "1cadddbd0c0af94924d1e09fed230eabc9f2ac6a",
                "commit_sha_fixed": "43517813494ccd7b7d8762cd229724ff07738433",
                "report_id": "590",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/590",
                "issue_title": "MkContentsTest.java:53-61: MkContents should be able to...",
                "issue_description": "Puzzle `524-89453c40` in `src/test/java/com/jcabi/github/mock/MkContentsTest.java:53-61` has to be resolved: MkContents should be able to handle branches. In a request for file update or create you may specify a branch. Also, a branch might be specified in a reading request. So, if you changed some file in branch-1, you shouldn't get these changes in the master branch, only in branch-1. Implementation of create, update and get methods of MkContents should be changed. See http://developer.github.com/v3/repos/contents/#update-a-file for details\n"
            },
            "67": {
                "commit_sha_buggy": "2c1876d9686e9df846dd592cdee023d4f623ac41",
                "commit_sha_fixed": "d4cd663e348ee6bb410f90d156ad8a32408f449a",
                "report_id": "753",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/753",
                "issue_title": "Issue-540 MkRepoCommits.patch() method implemented.",
                "issue_description": ""
            },
            "68": {
                "commit_sha_buggy": "d4cd663e348ee6bb410f90d156ad8a32408f449a",
                "commit_sha_fixed": "83c4d98abed0273b24337df6fdcb33f18a125fe4",
                "report_id": "752",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/752",
                "issue_title": "#590 Branching functionality for MkContents.create() and get()",
                "issue_description": ""
            },
            "69": {
                "commit_sha_buggy": "8c5da8fa6c30b0d3769272012bc0ad5e85fcf168",
                "commit_sha_fixed": "196b07e5d8bf9ea57dd4e4ab2ea846982ea46cb2",
                "report_id": "78",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/78",
                "issue_title": "RtGithub.java:67-70: Unit test for RtGithub is...",
                "issue_description": "Puzzle `1-461455d0` in `src/main/java/com/jcabi/github/RtGithub.java:67-70` has to be resolved: Unit test for RtGithub is required. Let's mock request using Mockito or com.rexsl.test.request.FakeRequest, and make sure that the class can do its key operations. Let's also check emojis() and meta().\n"
            },
            "70": {
                "commit_sha_buggy": "21600e471e31e1f1e9cf7f027155ed36c664e403",
                "commit_sha_fixed": "a5a9c785cfc2154977cb30e407d79de10357e39c",
                "report_id": "755",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/755",
                "issue_title": "Issue 748: initial commit",
                "issue_description": "Create pull request for add() method and its unit test.\n"
            },
            "71": {
                "commit_sha_buggy": "3c5d8ec4daf38f08d74174286c82b7000e941f50",
                "commit_sha_fixed": "67d6f35c1e9d24cdfb7489e224fc194f38cb1113",
                "report_id": "750",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/750",
                "issue_title": "issue #745 fixed",
                "issue_description": "#745\n"
            },
            "72": {
                "commit_sha_buggy": "7626c53ae0d8bbd3b7e43ca6e4d467baf02ebf31",
                "commit_sha_fixed": "bd6c99e1fad9f0d72afa7d897dd96c0339fab3c8",
                "report_id": "780",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/780",
                "issue_title": "#772 Iterate() implementation",
                "issue_description": ""
            },
            "73": {
                "commit_sha_buggy": "c69b0f2cc15dd6dc9fa70be77c88e5be3935595e",
                "commit_sha_fixed": "9a8a581edc72e03cf3e9915adb9de23182950eb6",
                "report_id": "815",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/815",
                "issue_title": "Issue-809. RtContents.get() request body replaced with query params.",
                "issue_description": ""
            },
            "74": {
                "commit_sha_buggy": "b7f3f63796f56ab04b590d0fc74fe64d1fb6a524",
                "commit_sha_fixed": "e72b9847a0b6ff71033ae8af7e9814e6269e7210",
                "report_id": "895",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/895",
                "issue_title": "MkRepos.java:149-149: MkRepos#iterate should be implemented....",
                "issue_description": "Puzzle `841-3cbb4f08` in `src/main/java/com/jcabi/github/mock/MkRepos.java:149-149` has to be resolved: MkRepos#iterate should be implemented.\n"
            },
            "75": {
                "commit_sha_buggy": "b4d0d5da2dd3e623145813f66fc8bab492a48562",
                "commit_sha_fixed": "7648c7a4830a45a80f88ffd7d9afc102da12bdb9",
                "report_id": "94",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/94",
                "issue_title": "RtAssignees.java:41-48: Assignees API should be implemented....",
                "issue_description": "Puzzle `16-9355473c` in `src/main/java/com/jcabi/github/RtAssignees.java:41-48` has to be resolved: Assignees API should be implemented. Let's implement two methods: 1) iterate() returning a list of Users and 2) check(String) returning TRUE if provided login can be used as an assignee in repository. Also should be implemented method assignees() in RtRepo and MkRepo. Don't forget about @EqualsAndHashCode and other annotations See http://developer.github.com/v3/issues/assignees/\n"
            },
            "76": {
                "commit_sha_buggy": "6c261ad05546a8cc7e47ddd95c11e1f51ad36b32",
                "commit_sha_fixed": "6772bd14259a2d9ca877a2513145b2fdf9cf0c2e",
                "report_id": "965",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/965",
                "issue_title": "MkStars.java:46-47: Implement MkStars.star() and MkStars.unstar() operations....",
                "issue_description": "Puzzle `950-4b919e8a` in `src/main/java/com/jcabi/github/mock/MkStars.java:46-47` has to be resolved: Implement MkStars.star() and MkStars.unstar() operations. Don't forget about unit tests.\n\nIf you have any technical questions, don't ask me, submit new tickets instead\n"
            },
            "77": {
                "commit_sha_buggy": "dad90e738ccc32361481edb44aade573b52d5eed",
                "commit_sha_fixed": "cb7a58d2cca083bd164dd0b1116bb88f70ddfc13",
                "report_id": "952",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/952",
                "issue_title": "MkNotifications.java:45-46: Implement iterate() and get() operations...",
                "issue_description": "Puzzle `920-82c5cb6b` in `src/main/java/com/jcabi/github/mock/MkNotifications.java:45-46` has to be resolved: Implement iterate() and get() operations in MkNotifications. Don't forget about unit tests.\n\nIf you have any technical questions, don't ask me, submit new tickets instead\n"
            },
            "78": {
                "commit_sha_buggy": "9d418c84ac4f59a678bcb2aacda1e6ed358d22f1",
                "commit_sha_fixed": "5212bec0ddd18f786c636990123f0e0bb8f30b84",
                "report_id": "1323",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/1323",
                "issue_title": "Mock pull request created by MkGithub is not a pull according to Issue.Smart.isPull()",
                "issue_description": "The unit test below fails:\r\n\r\n```java\r\n    @Test\r\n    public void mkPullIsAPullAccordingToIssueSmart() throws Exception {\r\n        final Repo repo = new MkGithub().randomRepo();\r\n        final Pull pull = repo.pulls().create(\r\n            \"hello\",\r\n            \"head-branch\",\r\n            \"base-branch\"\r\n        );\r\n        final Issue.Smart issue = new Issue.Smart(\r\n            repo.issues().get(pull.number())\r\n        );\r\n        MatcherAssert.assertThat(\r\n            issue.isPull(),\r\n            Matchers.is(true)\r\n        );\r\n    }\r\n```\r\n\r\nSeeing that the issue referred to is actually a pull request, `issue.isPull()` should really return `true`."
            },
            "79": {
                "commit_sha_buggy": "9298f3636c540a9785001263527979814e260710",
                "commit_sha_fixed": "0ce5fdedb640db3a77527e6f2a803f9cf78d2671",
                "report_id": "1366",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/1366",
                "issue_title": "Bug: asymetrical processing of asset contents between MkReleaseAssets.upload() and MkReleaseAsset.raw()",
                "issue_description": "**Context**\r\n`MkReleaseAssets.upload()` stores the bytes as-is (in string form), while `MkReleaseAsset.raw()` will process the string with [DatatypeConverter.parseBase64Binary()](https://docs.oracle.com/javase/8/docs/api/javax/xml/bind/DatatypeConverter.html#parseBase64Binary-java.lang.String-). This despite the fact that `MkReleaseAssets` never encoded the bytes to base64 in the first place.\r\n\r\n**Problem**\r\nThe contents returned by `MkReleaseAsset` will not match the expected bytes for any non-trivial input of bytes. This is because `DatatypeConverter.parseBase64Binary` will silently drop invalid characters as per the Base64 spec without throwing an error, and thus when you decode those bytes you'll end up with a different sequence of bytes.\r\n\r\n**Test**\r\n```java\r\n    @Test\r\n    public void test() throws Exception {\r\n        final String test = \"This is a test asset.\";\r\n        final ReleaseAsset asset = new MkGithub().randomRepo().releases()\r\n          .create(\"v1.0\")\r\n          .assets()\r\n          .upload(test.getBytes(), \"type\", \"name\");\r\n        MatcherAssert.assertThat(\r\n            DatatypeConverter.printBase64Binary(IOUtils.toByteArray(asset.raw())),\r\n            Matchers.is(test)\r\n        );\r\n    }\r\n```\r\nTest error:\r\n```\r\njava.lang.AssertionError: \r\nExpected: is \"This is a test asset.\"\r\n     but: was \"Thisisatestasset\"\r\n```\r\n\r\n**References**\r\n* [RFC-4648](http://www.rfc-editor.org/rfc/rfc4648.txt) Table 1: The Base 64 Alphabet\r\n* [StackOverflow](https://stackoverflow.com/a/30708382/1623885)"
            },
            "80": {
                "commit_sha_buggy": "1e903e59a027304a2c8270182a7f5c0687fc3d25",
                "commit_sha_fixed": "d38e0055d557e23b6045ddff406a10dc844add15",
                "report_id": "1375",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/1375",
                "issue_title": "MkUser.java:56-57: Implement markAsRead(final Date...",
                "issue_description": "The puzzle `1305-b50fad21` from #1305 has to be resolved:\n\nhttps://github.com/jcabi/jcabi-github/blob/42c24f097a546761d2df560928c9457d275c8df1/src/main/java/com/jcabi/github/mock/MkUser.java#L56-L57\n\nThe puzzle was created by George Aristy on 04-Apr-18. \n\nEstimate: 30 minutes, role: DEV.\n\nIf you have any technical questions, don't ask me, submit new tickets instead. The task will be \"done\" when the problem is fixed and the text of the puzzle is _removed_ from the source code. Here is more about [PDD](http://www.yegor256.com/2009/03/04/pdd.html) and [about me](http://www.yegor256.com/2017/04/05/pdd-in-action.html)."
            },
            "81": {
                "commit_sha_buggy": "1e903e59a027304a2c8270182a7f5c0687fc3d25",
                "commit_sha_fixed": "50e38acf8bc2202c464ec05e0e914b20afcd1d1a",
                "report_id": "1389",
                "report_url": "https://github.com/jcabi/jcabi-github/pull/1389",
                "issue_title": "(#1375) Implemented MkUser.markAsRead(Date)",
                "issue_description": "This PR:\r\n\r\n* solves #1375 \r\n* Implements `MkUser.markAsRead(Date)`\r\n* Declares `User.markAsRead(Date)` to throw an `IOException`\r\n\r\n`MkUser.markAsRead` expects a sequence of nodes under `...user/notifications` like this:\r\n\r\n```xml\r\n<notification>\r\n    <id>1</id>\r\n    <date>123455667788</date>\r\n    <read>false</read>\r\n<notification>\r\n```\r\n\r\nwhere:\r\n* `id`: the notification's id\r\n* `date`: creationdate (format = unix epoch time)\r\n* `read`: boolean\r\n"
            },
            "82": {
                "commit_sha_buggy": "dfe7f7cf3d5bfc6318ff2b284e9f04c66afe32cd",
                "commit_sha_fixed": "6ae914164a1fedc6093ac2458bea070f81c73e54",
                "report_id": "1418",
                "report_url": "https://github.com/jcabi/jcabi-github/issues/1418",
                "issue_title": "MkNotification.java:43: Implement tests for...",
                "issue_description": "The puzzle `1407-bd218f2f` from #1407 has to be resolved:\n\nhttps://github.com/jcabi/jcabi-github/blob/dfe7f7cf3d5bfc6318ff2b284e9f04c66afe32cd/src/main/java/com/jcabi/github/mock/MkNotification.java#L43-L43\n\nThe puzzle was created by George Aristy on 23-May-18. \n\nEstimate: 30 minutes,     \n\nIf you have any technical questions, don't ask me, submit new tickets instead. The task will be \"done\" when the problem is fixed and the text of the puzzle is _removed_ from the source code. Here is more about [PDD](http://www.yegor256.com/2009/03/04/pdd.html) and [about me](http://www.yegor256.com/2017/04/05/pdd-in-action.html)."
            }
        }
    },
    "Spatial4j": {
        "owner_repo": "locationtech/spatial4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "6a4382895a5cf181fb49738791859a3ae166d0bc",
                "commit_sha_fixed": "63b318368ce7eca0e090af64cd49d134c8619c29",
                "report_id": "175",
                "report_url": "https://github.com/locationtech/spatial4j/issues/175",
                "issue_title": "ShapesAsWKTModule does not deserialize WKT, returns null",
                "issue_description": "The ShapesAsWKTModule serializes Geometry objects just fine, but it cannot deserialize them.  The object returned is null.\r\n\r\nHere is a test to demonstrate the issue:\r\n\r\n\r\n```package com.example;\r\n\r\nimport static org.junit.Assert.assertEquals;\r\nimport static org.junit.Assert.assertNotNull;\r\n\r\nimport com.fasterxml.jackson.annotation.JsonInclude;\r\nimport com.fasterxml.jackson.databind.DeserializationFeature;\r\nimport com.fasterxml.jackson.databind.MapperFeature;\r\nimport com.fasterxml.jackson.databind.ObjectMapper;\r\nimport com.fasterxml.jackson.databind.SerializationFeature;\r\nimport com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;\r\nimport org.junit.Test;\r\nimport org.locationtech.jts.geom.Geometry;\r\nimport org.locationtech.jts.geom.GeometryFactory;\r\nimport org.locationtech.jts.geom.PrecisionModel;\r\nimport org.locationtech.jts.io.ParseException;\r\nimport org.locationtech.jts.io.WKTReader;\r\nimport org.locationtech.spatial4j.io.jackson.ShapesAsWKTModule;\r\n\r\npublic class ObjectMapperConfigurationTest {\r\n\r\n  public static class GeomWrapper {\r\n\r\n    private Geometry geometry;\r\n\r\n    public Geometry getGeometry() {\r\n      return geometry;\r\n    }\r\n\r\n    public void setGeometry(Geometry geometry) {\r\n      this.geometry = geometry;\r\n    }\r\n  }\r\n\r\n  private static Geometry createGeometry(String wkt) throws ParseException {\r\n    GeometryFactory geometryFactory = new GeometryFactory(new PrecisionModel(), 4326);\r\n    WKTReader wktReader = new WKTReader(geometryFactory);\r\n    return wktReader.read(wkt);\r\n  }\r\n\r\n  @Test\r\n  public void test() throws Exception {\r\n    final String wkt = \"POINT (30 10)\";\r\n    final Geometry geometry = createGeometry(wkt);\r\n\r\n    ObjectMapper objectMapper = new ObjectMapper();\r\n    objectMapper.disable(MapperFeature.DEFAULT_VIEW_INCLUSION);\r\n    objectMapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);\r\n    objectMapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\r\n    objectMapper.registerModule(new ShapesAsWKTModule());\r\n    objectMapper.registerModule(new JavaTimeModule());\r\n    objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);\r\n\r\n    final GeomWrapper toSerialize = new GeomWrapper();\r\n    toSerialize.setGeometry(geometry);\r\n    String json = objectMapper.writeValueAsString(toSerialize);\r\n    System.out.println(json);\r\n    assertEquals(\"{\\\"geometry\\\":\\\"POINT (30 10)\\\"}\", json);\r\n\r\n    final GeomWrapper deserialized = objectMapper.readValue(json, GeomWrapper.class);\r\n    assertNotNull(deserialized.getGeometry());\r\n  }\r\n}```"
            },
            "2": {
                "commit_sha_buggy": "84d8294e15eda14ea9826c5ee56a574c15b0b19a",
                "commit_sha_fixed": "7cea4115fd105c7d31aacbfad31d4f88106960b3",
                "report_id": "150",
                "report_url": "https://github.com/locationtech/spatial4j/issues/150",
                "issue_title": "Confusion and possible issue around JtsSpatialContext conversion for dateline-crossing geometries",
                "issue_description": "Hi there -\r\n\r\nI'm hoping to get some guidance on a strange behavior I ran into today. I've been working to update the dependencies for a geospatial library we have at factual (https://github.com/Factual/geo) to the latest JTS and spatial4j versions. Along the way I ran into an issue where JTS geometries which cross the dateline and are converted to Spatial4J shapes get converted successfully the first time, but not on successive attempts.\r\n\r\nIt's maybe a little easier to show than to explain so I made an example project which demonstrates the issue I'm seeing here: https://github.com/worace/Spatial4JExample.\r\n\r\nI'm not sure if this is a bug in either Spatial4J or JTS, or if it's known behavior and I'm simply using one of the classes wrong.\r\n\r\nInterestingly I did notice that the test case in Spatial4J includes a `clone` of the geometry before converting, so perhaps this is a known issue? (https://github.com/locationtech/spatial4j/blob/master/src/test/java/org/locationtech/spatial4j/context/jts/JtsSpatialContextTest.java#L29)\r\n\r\nIf that's the recommended approach we could do the same, although I hate to incur the performance penalty of cloning things all the time if we don't have to.\r\n\r\nFiinally, along the lines of this issue: https://github.com/locationtech/spatial4j/issues/137, when I upgraded our dependencies I noticed those methods are marked as deprecated now. I'm wondering if there's any info somewhere on what the replacement is and how it should be used?\r\n\r\nThanks for your work on this library! Let me know if I can give any more context to explain this issue.\r\n"
            },
            "3": {
                "commit_sha_buggy": "5d8bac2836a90f8daf246d621f26b92c89d36546",
                "commit_sha_fixed": "6a4382895a5cf181fb49738791859a3ae166d0bc",
                "report_id": "183",
                "report_url": "https://github.com/locationtech/spatial4j/pull/183",
                "issue_title": "GH-162 handle empty point / shape collection in toString",
                "issue_description": "Added corner case handling for serializing points and shape collections to string. \r\n\r\nFixes issue GH-162"
            },
            "4": {
                "commit_sha_buggy": "2435128d4ea0e576c6bc3b62ad637095b22a8449",
                "commit_sha_fixed": "ee3972390dd1990fb661f2f2946fc2a08c5cb630",
                "report_id": "194",
                "report_url": "https://github.com/locationtech/spatial4j/pull/194",
                "issue_title": "Add support for dateline wrapping for circle to geometry conversion",
                "issue_description": "Added support for dateline wrapping when converting a circle to a geometry. I implemented it like this;\r\n- support geometries that start at negative pages in `JtsGeometry::cutUnwrappedGeomInto360()`\r\n- put the geometry of the circle in a `JtsGeometry` if the circle crosses the dateline"
            }
        }
    },
    "Markedj": {
        "owner_repo": "gitbucket/markedj",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3295e4ac0e2afd690d37d734b73e240a03330500",
                "commit_sha_fixed": "a80260f607e886b659791a989e2c10c75c3292a2",
                "report_id": "5",
                "report_url": "https://github.com/gitbucket/markedj/issues/5",
                "issue_title": "Add Option to convert line separator to <br>",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "794b4676415e5c2c4c81e3d53fde35b9386a322e",
                "commit_sha_fixed": "b9155beb99fe549b730af27e309723dc34a24e59",
                "report_id": "8",
                "report_url": "https://github.com/gitbucket/markedj/issues/8",
                "issue_title": "Different renderings comapared to original marked.js or github style",
                "issue_description": "Hi~ thank you for your markedj lib. : )\n\nI'm trying to use it, but I have found some different rendering results.\n\nTested strings are\n\n```\nMessage A\n- list A\n- List B\n```\n\nmarkedJ results is..\n\n![image](https://cloud.githubusercontent.com/assets/520523/13379866/c363ec88-de75-11e5-8575-5305db9d603d.png)\n\ngithub or marked.js rendering is\n\nMessage A\n- list A\n- List B\n\nIs it bug? or do I use it wrong? \n"
            },
            "3": {
                "commit_sha_buggy": "ea74b4ba175cf6f0fa7a060f1445550d791ee181",
                "commit_sha_fixed": "44b009df3ff688d989eb6bfeb95352830a3c441f",
                "report_id": "14",
                "report_url": "https://github.com/gitbucket/markedj/issues/14",
                "issue_title": "Borders don't appear for blank table cells",
                "issue_description": "When a table cell is blank, `<td></td>` is not output for the cell, causing its borders not to show up.\n\n```\n|ID|name|note|\n|-|-|-|\n|1|foo|This is foo|\n|2|bar||\n|3|fizz|This is fizz|\n|4|buzz||\n```\n\n<img width=\"199\" alt=\"2016-05-11 18 46 57\" src=\"https://cloud.githubusercontent.com/assets/121462/15177009/d873f6d8-17a8-11e6-9df7-e96990da2c2a.png\">\n\nOutputted HTML:\n\n```\n<table>\n  <thead>\n    <tr><th>ID</th><th>name</th><th>note</th></tr>\n  </thead>\n  <tbody>\n    <tr><td>1</td><td>foo</td><td>This is foo</td></tr>\n    <tr><td>2</td><td>bar</td></tr><tr>\n    <td>3</td><td>fizz</td><td>This is fizz</td></tr>\n    <tr><td>4</td><td>buzz</td></tr>\n  </tbody>\n</table>\n```\n"
            },
            "4": {
                "commit_sha_buggy": "8aeeb720665de8b2a2e43748b486a89d61977774",
                "commit_sha_fixed": "31ee911dc3ea6b934777f1c3c8ee01891e863dd4",
                "report_id": "1",
                "report_url": "https://github.com/gitbucket/markedj/issues/1",
                "issue_title": "Safety HTML tag rendering",
                "issue_description": "Currently, markedj allows whitelist based HTML tag rendering. However it should be more safety by assist missing end tag.\n"
            },
            "5": {
                "commit_sha_buggy": "6c0969afb4de4409327de367ae8bc7f4e7b632a5",
                "commit_sha_fixed": "6e6fe8d19ca826834c72e517f32c7e9e21587d5c",
                "report_id": "18",
                "report_url": "https://github.com/gitbucket/markedj/pull/18",
                "issue_title": "Render HTML tags through whitelist",
                "issue_description": "Fix #1"
            },
            "6": {
                "commit_sha_buggy": "0a8c1f57302b4e0b16f19ebcc5ac493794b24b1c",
                "commit_sha_fixed": "c11813db2c87629e0b05eef34ee7f245766877a5",
                "report_id": "20",
                "report_url": "https://github.com/gitbucket/markedj/issues/20",
                "issue_title": "Ignore extra information in Pandoc, R Markdown or PHP Markdown Extra for fenced code block",
                "issue_description": "https://github.com/gitbucket/gitbucket/issues/1644"
            },
            "7": {
                "commit_sha_buggy": "d6a51457cb5d616075da8ca02d27ec6ddc0b30e1",
                "commit_sha_fixed": "fc1018d5b7736eff9b345c53b391daec2ad2ec6b",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Small fix for Renderer",
                "issue_description": "Small fix for Renderer"
            },
            "8": {
                "commit_sha_buggy": "904f6242378df165f70c73bc838977b386580954",
                "commit_sha_fixed": "d25e152460272696636d5372d8dc1db6b148329b",
                "report_id": "2",
                "report_url": "https://github.com/gitbucket/markedj/issues/2",
                "issue_title": "ver 1.0.3 StackOverflowError",
                "issue_description": "##### Environment\n- Windows 10 Pro\n- JDK 1.8.0_51\n##### Reproduction code\n- https://github.com/OdaShinsuke/markedjtest\n##### StackTrace\n\n```\njava.lang.StackOverflowError\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n    at java.util.regex.Pattern$LazyLoop.match(Unknown Source)\n    at java.util.regex.Pattern$GroupTail.match(Unknown Source)\n    at java.util.regex.Pattern$BranchConn.match(Unknown Source)\n    at java.util.regex.Pattern$CharProperty.match(Unknown Source)\n    at java.util.regex.Pattern$Branch.match(Unknown Source)\n    at java.util.regex.Pattern$GroupHead.match(Unknown Source)\n...\n```\n"
            },
            "9": {
                "commit_sha_buggy": "0a9ce5f03b31ba3142b133ec6b374704e99055bf",
                "commit_sha_fixed": "839d2bfdbda7aa369a0f7033fa9b03b85612c637",
                "report_id": "3",
                "report_url": "https://github.com/gitbucket/markedj/issues/3",
                "issue_title": "Can't render nptable",
                "issue_description": "https://github.com/gitbucket/gitbucket/issues/949\n"
            },
            "10": {
                "commit_sha_buggy": "9902aa78a26149b9d841557bea6e2325593ec1c3",
                "commit_sha_fixed": "f7f0b14e7a526ee83ccd29a04d8e80a172d4457e",
                "report_id": "6",
                "report_url": "https://github.com/gitbucket/markedj/issues/6",
                "issue_title": "Table row which has a different number of column in causes IndexOutOfBoundsException",
                "issue_description": "https://github.com/gitbucket/gitbucket/issues/1002\n"
            },
            "11": {
                "commit_sha_buggy": "043083914592670b9937555949f413bd421ee623",
                "commit_sha_fixed": "b3332a2440be71d9ffa3f8caddd98ae601982a77",
                "report_id": "7",
                "report_url": "https://github.com/gitbucket/markedj/pull/7",
                "issue_title": "Fix bug caused by empty item of list",
                "issue_description": "If `Lexer.lex` applied to following markdown code:\n\n``` md\n* foo\n*\n* bar\n```\n\nthen `Lexer.lex` throws `StringIndexOutOfBoundsException`.\n(It includes a space after the asterisk.)\n\nSo, I fixed `Lexer.lex` to analyze as item of list.\n"
            },
            "12": {
                "commit_sha_buggy": "edbb8ea68d39afc30f8966347d29894e13d1b9c9",
                "commit_sha_fixed": "ef71a10ce9ec1e19f3ea9352423f848bc466bd35",
                "report_id": "9",
                "report_url": "https://github.com/gitbucket/markedj/pull/9",
                "issue_title": "Fix to look up case-insensitive reference link",
                "issue_description": "Current markedj converts the key of link definition to lower case, but it dosen't convert the key of reference link. It causes the key not to look up. See following Markdown:\n\n``` markdown\n[Foo]\n\n[Foo]: http://example.com\n```\n\nIt yields to `<p>[Foo]</p>`, but the result we expected is `<p><a href=\"http://example.com\">Foo</a></p>` because the key `Foo` can't be looked up.\n\nI fixed the key of reference link is converted to lower case when looking it up from definitions.\n"
            },
            "13": {
                "commit_sha_buggy": "ef71a10ce9ec1e19f3ea9352423f848bc466bd35",
                "commit_sha_fixed": "a11c691c57e3abb0c6d63de2491773b361ac58c5",
                "report_id": "10",
                "report_url": "https://github.com/gitbucket/markedj/pull/10",
                "issue_title": "Fix grammer for nested contents of list",
                "issue_description": "This request is fix for 2nd problem of https://github.com/gitbucket/gitbucket/issues/1171.\n"
            },
            "14": {
                "commit_sha_buggy": "e739d7c335e32e5d3b15baf11307e93fcd3231b8",
                "commit_sha_fixed": "96f74fa03e7e18c52908517114734885a6ff6208",
                "report_id": "15",
                "report_url": "https://github.com/gitbucket/markedj/issues/15",
                "issue_title": "\">\" in blockquote not show",
                "issue_description": "I'm using gitbucket 4.0, and have a problem in rendering README.md:\n\n`> **File > Settings > Install JetBrains plugin**` was rendered to \n\n> **FileSettingsInstall JetBrains plugin** \n\nwhich should be \n\n> **File > Settings > Install JetBrains plugin**\n"
            },
            "15": {
                "commit_sha_buggy": "aa3b804e842a5b2a5e0fae7d914cfe7a4d6c95ae",
                "commit_sha_fixed": "7dbd252f1ab5d31a600c981f638705e86886b7ad",
                "report_id": "14",
                "report_url": "https://github.com/gitbucket/markedj/issues/14",
                "issue_title": "Borders don't appear for blank table cells",
                "issue_description": "When a table cell is blank, `<td></td>` is not output for the cell, causing its borders not to show up.\n\n```\n|ID|name|note|\n|-|-|-|\n|1|foo|This is foo|\n|2|bar||\n|3|fizz|This is fizz|\n|4|buzz||\n```\n\n<img width=\"199\" alt=\"2016-05-11 18 46 57\" src=\"https://cloud.githubusercontent.com/assets/121462/15177009/d873f6d8-17a8-11e6-9df7-e96990da2c2a.png\">\n\nOutputted HTML:\n\n```\n<table>\n  <thead>\n    <tr><th>ID</th><th>name</th><th>note</th></tr>\n  </thead>\n  <tbody>\n    <tr><td>1</td><td>foo</td><td>This is foo</td></tr>\n    <tr><td>2</td><td>bar</td></tr><tr>\n    <td>3</td><td>fizz</td><td>This is fizz</td></tr>\n    <tr><td>4</td><td>buzz</td></tr>\n  </tbody>\n</table>\n```\n"
            },
            "16": {
                "commit_sha_buggy": "7dbd252f1ab5d31a600c981f638705e86886b7ad",
                "commit_sha_fixed": "e706c4846ea458903d8d403938d4897e4b293c9e",
                "report_id": "14",
                "report_url": "https://github.com/gitbucket/markedj/issues/14",
                "issue_title": "Borders don't appear for blank table cells",
                "issue_description": "When a table cell is blank, `<td></td>` is not output for the cell, causing its borders not to show up.\n\n```\n|ID|name|note|\n|-|-|-|\n|1|foo|This is foo|\n|2|bar||\n|3|fizz|This is fizz|\n|4|buzz||\n```\n\n<img width=\"199\" alt=\"2016-05-11 18 46 57\" src=\"https://cloud.githubusercontent.com/assets/121462/15177009/d873f6d8-17a8-11e6-9df7-e96990da2c2a.png\">\n\nOutputted HTML:\n\n```\n<table>\n  <thead>\n    <tr><th>ID</th><th>name</th><th>note</th></tr>\n  </thead>\n  <tbody>\n    <tr><td>1</td><td>foo</td><td>This is foo</td></tr>\n    <tr><td>2</td><td>bar</td></tr><tr>\n    <td>3</td><td>fizz</td><td>This is fizz</td></tr>\n    <tr><td>4</td><td>buzz</td></tr>\n  </tbody>\n</table>\n```\n"
            },
            "17": {
                "commit_sha_buggy": "446df963efc9d8e4d2d67b4dd393a14f1c39766a",
                "commit_sha_fixed": "f6bf339e3f691ca6ef17199335b8ce8088d4e416",
                "report_id": "19",
                "report_url": "https://github.com/gitbucket/markedj/issues/19",
                "issue_title": "can't support the <del> label",
                "issue_description": "how to parse the \"~~\""
            }
        }
    },
    "Retrofit": {
        "owner_repo": "square/retrofit",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bc304b3093193e79c9c2094b2caecde852888f1e",
                "commit_sha_fixed": "48de58dff4655c62f6d4f3988c97ce7f6a1c9b99",
                "report_id": "115",
                "report_url": "https://github.com/square/retrofit/pull/115",
                "issue_title": "Added code to not append a ? if the query string is empty.",
                "issue_description": "I found it strange that a request will have ? appended to it always. I changed the code and adapted the unit tests to ensure that ? is only appended if the query string has content.\n"
            },
            "2": {
                "commit_sha_buggy": "89fd13bbe7af39573cce9e6d3cfd61d3f5bb7b2d",
                "commit_sha_fixed": "f54d6ad8be61ffe53b578b54c52bf09aa86ad158",
                "report_id": "132",
                "report_url": "https://github.com/square/retrofit/pull/132",
                "issue_title": "Defer non-interface methods to normal invocation.",
                "issue_description": "Closes #130 \n"
            },
            "3": {
                "commit_sha_buggy": "a7755edc83d3907204093840a7c15d954120c926",
                "commit_sha_fixed": "d0b3d5bb8b377a6bf682b28e23622db3da7e4785",
                "report_id": "158",
                "report_url": "https://github.com/square/retrofit/pull/158",
                "issue_title": "Fix Url Escaping on GET Parameters",
                "issue_description": "This patch fixes #154, url escaping on url-encoded GET parameters. Query parameters will now be escaped. Test cases for common characters ?, #, and & are included.\n"
            }
        }
    },
    "Rocketmq_mqtt_ds": {
        "owner_repo": "apache/rocketmq-mqtt",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ac90d5c4918e92d5e096ba9d2e06489b49d7ceca",
                "commit_sha_fixed": "8e27eb2601ac9cde3e06a0f8d49fd78f199cefa6",
                "report_id": "97",
                "report_url": "https://github.com/apache/rocketmq-mqtt/issues/97",
                "issue_title": "Wrong judgment when toLmqMessage",
                "issue_description": "the 'else if' judgment is a fault or a typo, \r\nshould be 'mqMessage.getUserPro', not 'message.getUserPro'\r\n\r\n![image](https://user-images.githubusercontent.com/5182511/168474574-05bfee05-dbf1-462e-9fb8-1723acce2b32.png)"
            }
        }
    },
    "Dagger_core": {
        "owner_repo": "square/dagger",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "efdad40efb51e18b07764ee4428470b1e5947ca8",
                "commit_sha_fixed": "1141ed83dc75f6965f6030c6af8d027030909220",
                "report_id": "75",
                "report_url": "https://github.com/square/dagger/pull/75",
                "issue_title": "Handle modules with no constructor when passed in as a class",
                "issue_description": "Handle modules with no constructor when passed in as a class and add a test case to ensure that modules included by modules can be instantiated if they're not passed in as instances.\n"
            },
            "2": {
                "commit_sha_buggy": "9fb5411a88e78d3c766b77fc0daccd1192b87014",
                "commit_sha_fixed": "017ffd50341d8a732d52378ce2e7a16bc96c63a5",
                "report_id": "85",
                "report_url": "https://github.com/square/dagger/pull/85",
                "issue_title": "Don't require entry points to have injectable constructors.",
                "issue_description": "We were accidentally requiring this by using the regular\n(provider) key for entry points rather than the more lenient\nand more available members injector key.\n"
            },
            "3": {
                "commit_sha_buggy": "ec78a3f36983a47fd665129d3c3f01090dba8ed3",
                "commit_sha_fixed": "b736b24f67c990c411fb7b06c49cccc549661b44",
                "report_id": "100",
                "report_url": "https://github.com/square/dagger/pull/100",
                "issue_title": "Don't wrap runtime exceptions thrown by user code.",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "d8de3a7841193573e86f67e6ab766c35fa21815e",
                "commit_sha_fixed": "91af996450a68723e8a57fc33c9bd378eae60154",
                "report_id": "104",
                "report_url": "https://github.com/square/dagger/pull/104",
                "issue_title": "Fix validation for set bindings.",
                "issue_description": ""
            },
            "5": {
                "commit_sha_buggy": "a95ad22e0fe487fb8d9f4b1993b04c8332d54e41",
                "commit_sha_fixed": "22928a33d596959f4e90f80ce5bba6c52e05fbf4",
                "report_id": "169",
                "report_url": "https://github.com/square/dagger/pull/169",
                "issue_title": "Fix singleton behaviour when forced to link on graph.plus();",
                "issue_description": "Credit to @adennie who reported this issue here: \n\nhttps://plus.google.com/u/0/104032734670594482848/posts/L7222eSyEjo\n\nThe text of this is:\n\nI've got a library that builds its own object graph, including an entry point for an @Singleton-annotated class (e.g. MySingleton).  After creating that object graph, I can call get(MySingleton.class) on it successfully.  However, if instead of calling get() on that graph, I use plus() to expand it with another module, and then call get(MySingleton.class) on that extended object graph, I get an AssertionError thrown from Linker.requestBinding, here:\n\n```\nBinding<?> binding = null;\nfor (Linker linker = this; linker != null; linker = linker.base) {\n  binding = linker.bindings.get(key);\n  if (binding != null) {\n    if (linker != this && !binding.isLinked()) throw new AssertionError();\n    break;\n  }\n}\n```\n\nIn this case, it's the second time through the loop, such that linker == this.base, and the problem is that binding.isLinked is false.\n\nLooking through the code, it seemed that the original graph should have had all its bindings linked during plus, since it calls linkEverything.  So I stepped through that, down into linkAll, and then into linkRequested.  As that method works its way through the toLink list, when it gets to  the DeferredBinding for MySingleton, it creates a JIT binding (a ReflectiveAtInjectBinding) for it.  It adds that binding to the toLink linked list, then wraps it with a SingletonBinding and adds that to the bindings map.  Subsequently, as it it continues through the toLink list, linkRequested eventually comes to the ReflectiveAtInjectBinding it added earlier, and calls attach and setLinked on it.  But the SingletonBinding that wraps it, which is sitting in the bindings map, doesn't have setLinked called on it, so even though it wraps a linked binding, it fails the isLinked test I ran into above, which causes the AssertionError.\n\nAndy was right.  This PR adds a repro/regression test and fixes singleton.\n"
            },
            "6": {
                "commit_sha_buggy": "cdb58e65a0eb33883247106942e067424014bb73",
                "commit_sha_fixed": "b6197880f4637a4e7678617aba5c3e40b747ed09",
                "report_id": "181",
                "report_url": "https://github.com/square/dagger/issues/181",
                "issue_title": "Reflective plugin should explode if an injected field is private",
                "issue_description": "Currently we just let it pass, which makes for different behavior on reflection vs. code gen.\n\nSee also https://github.com/square/dagger/issues/113\n"
            },
            "7": {
                "commit_sha_buggy": "cdb58e65a0eb33883247106942e067424014bb73",
                "commit_sha_fixed": "ce4ae1a17832e311d17abf5c4247f53037702281",
                "report_id": "193",
                "report_url": "https://github.com/square/dagger/pull/193",
                "issue_title": "Add restrictions around injectable targets.",
                "issue_description": "- Private fields are not supported.\n- Private constructors are not supported.\n- Methods are not supported.\n\nCloses #181. Closes #113. Closes #112.\n"
            },
            "8": {
                "commit_sha_buggy": "ce4ae1a17832e311d17abf5c4247f53037702281",
                "commit_sha_fixed": "54079aeb0b2d9d348ddd127347da111bf5b100e8",
                "report_id": "188",
                "report_url": "https://github.com/square/dagger/issues/188",
                "issue_title": "inherited providers for qualified dependencies not found by compiler when checking for completeness",
                "issue_description": "If a base module class has a provider method for a qualified dependency, the derived module class is flagged with a compiler error if it has an entry point that depends on the qualified dependency. This gist shows the problem: https://gist.github.com/adennie/5199473.\n\nThe workaround is to override the qualified provider in the derived class and delegate to the base class' provider.\n\nThis problem doesn't arise if the provider and the dependency don't use qualifiers.\n"
            },
            "9": {
                "commit_sha_buggy": "6f2413a4e940b96b3b94bd0a104676b012f4a29b",
                "commit_sha_fixed": "079a3dc521c0a5bf3f818933d223ce6a11449062",
                "report_id": "196",
                "report_url": "https://github.com/square/dagger/pull/196",
                "issue_title": "Forbid modules who extend from non-Object class types.",
                "issue_description": "Closes #188.\n"
            },
            "10": {
                "commit_sha_buggy": "6682d768a61f19741f012c93b1e687f8e6031ad5",
                "commit_sha_fixed": "66cae0f7242594d559674b2adc13ee2bf268883d",
                "report_id": "290",
                "report_url": "https://github.com/square/dagger/pull/290",
                "issue_title": "Fix conditional that was inadvertently inverted in the FailoverLoader re-work. ",
                "issue_description": "Add a test to catch a rather subtle case that proves that failover is working where parts are generated and parts are not.  Also fix the GLARING error that was missed because we test all-reflectively, or all generated.\n"
            },
            "11": {
                "commit_sha_buggy": "5c3bf8fdce0c5426558b4174cde8e5327d1aac84",
                "commit_sha_fixed": "d6d3a60dd96dc4476ec5866dc1bd4b177ebaf947",
                "report_id": "347",
                "report_url": "https://github.com/square/dagger/pull/347",
                "issue_title": "Fix interactions between SetBindings and library settings.",
                "issue_description": "SetBindings weren't respecting the library settings of their contributing bindings.  This change fixes SetBindings' copy constructor, and ensures that all of the contributed bindings' library setting is ORed (in effect) so that if all of the bindings came from libraries, then the SetBinding is excluded from orphan analysis - else it is subject to orphan analysis. \n"
            },
            "12": {
                "commit_sha_buggy": "4b49b6461cd658a638656e454609b74c2acdd262",
                "commit_sha_fixed": "6f0d7828c2d2e3e9a2c22ce996f26d0784b02966",
                "report_id": "83",
                "report_url": "https://github.com/square/dagger/pull/83",
                "issue_title": "Unbreak Graph.plus. We broke it when we added synchronization.",
                "issue_description": ""
            },
            "13": {
                "commit_sha_buggy": "6f0d7828c2d2e3e9a2c22ce996f26d0784b02966",
                "commit_sha_fixed": "9fb5411a88e78d3c766b77fc0daccd1192b87014",
                "report_id": "84",
                "report_url": "https://github.com/square/dagger/pull/84",
                "issue_title": "Be more careful about mustBeInjectable.",
                "issue_description": "We introduced a bug where non-injectable superclasses prevented\ntheir subclasses from being injected.\n"
            },
            "14": {
                "commit_sha_buggy": "4812cca9b94793be55677683bc613cfcd92accfc",
                "commit_sha_fixed": "38ee3bf0973a7ffdc7d91b7fd8233d63f5676bd3",
                "report_id": "170",
                "report_url": "https://github.com/square/dagger/pull/170",
                "issue_title": "Change SingletonBinding to delegate to wrapped binding for getting/setting state",
                "issue_description": "also updated Linker.linkRequested and putBinding to be consistent about putting scoped bindings into both the toLink and bindings lists.\n"
            },
            "15": {
                "commit_sha_buggy": "11b7685a5a5f8ec323901cc24a24bb4f79622dbb",
                "commit_sha_fixed": "598ccad35c3f17d3338f0a8ad3adc4be75eb3e31",
                "report_id": "189",
                "report_url": "https://github.com/square/dagger/pull/189",
                "issue_title": "Add proper concurrency support to Singleton/Lazy bindings",
                "issue_description": "Fixes #159 by using double-check locking (with volatile) to guard Singleton and Lazy bindings from concurrent access without requiring the cost of a lock once the underlying object has been created.  Also write a test for each that uses a latch to force the race condition.  \n\nNote: The lock is on the Lazy<T> holder in the lazy case, or the SingletonBinding in the singleton case.  Since the former is injected, and the latter can be injected as a Provider<T>, there is a possibility of a deadlock if a developer locks on the injected instance and then calls get().  This is allowed since this is far less likely than the for sure likelihood that android will have additional costs of allocation.\n"
            },
            "16": {
                "commit_sha_buggy": "83dca9eb3166772f8d5203e6b6c55777975a24e7",
                "commit_sha_fixed": "bbec16a6b9731ff2c3d6375556ea986a0c9914d6",
                "report_id": "212",
                "report_url": "https://github.com/square/dagger/pull/212",
                "issue_title": "Forbid Provider and Lazy as provides return type.",
                "issue_description": ""
            },
            "17": {
                "commit_sha_buggy": "5a506f15f43ceda3d4c99a84e9c7291058065db0",
                "commit_sha_fixed": "e164faf91cdec7660ab2c26d424ea8a17abe5f20",
                "report_id": "222",
                "report_url": "https://github.com/square/dagger/pull/222",
                "issue_title": "Fix validation when passing an interface to the injects list.",
                "issue_description": "I admit that this fix is clumsy. The core problem is that\nthe 'injects' list serves double duty: it includes types that\nwe can call ObjectGraph.get() on (could be interfaces) and also\ntypes that we call ObjectGraph.inject() on (can't be interfaces).\n\nThe right fix is to rethink the way Dagger internally tracks\nand links these keys.\n"
            },
            "18": {
                "commit_sha_buggy": "085054e411a1475c5fffc4b3a93c7ab22d38551f",
                "commit_sha_fixed": "1c950f4792a1e66f51da5de40f141cefeb09b218",
                "report_id": "232",
                "report_url": "https://github.com/square/dagger/pull/232",
                "issue_title": "Don't create objects unless there's an @Inject annotation.",
                "issue_description": "We had a bug in our handling of entry points where we'd\nuse the no-args constructor even if there were no injected\nfields present.\n"
            },
            "19": {
                "commit_sha_buggy": "bd4c13ec6102dfeb64a4885d39023191a95635f9",
                "commit_sha_fixed": "2246f93cce050df97909f3693744a7b306944df5",
                "report_id": "332",
                "report_url": "https://github.com/square/dagger/pull/332",
                "issue_title": "Fix up set bindings to handle plus() graphs properly.",
                "issue_description": "Fixes #328\n\nSpecifically, Makes plus() resolve parent links, and adds those bindings into the initial binding map added-to by new modules.  SetBindings are special-cased and cloned-in, so new contributors can be added without affecting the parent graph.  SetBindings are also special-cased in the overrides map, and Dagger now throws if one attempts to add set bindings via overrides. \n\nAs a side-effect of the cloning of dependency maps, Linker now needs no parent-linker, since all the bindings are available to a given graph's linker.  So... graphs have a chain of parents, linkers do not. Simpler. \n"
            },
            "20": {
                "commit_sha_buggy": "7bf9796d63fb3455fdd83ecf685afd2303acd597",
                "commit_sha_fixed": "57b5809d34955920166efda7d3c61399b896e78d",
                "report_id": "383",
                "report_url": "https://github.com/square/dagger/pull/383",
                "issue_title": "Do not mask underlying exception message when binding.",
                "issue_description": "This change surfaces the exception message from the underlyng cause of a failure to fetch bindings. Prior to this, we assumed that all exceptions were due to overrides being unable to contribute set bindings.\n\nCloses #380.\n"
            }
        }
    },
    "Google_java_format_core": {
        "owner_repo": "google/google-java-format",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "00823e891efd2da8759e513af73406ce63042b6b",
                "commit_sha_fixed": "856b039364648705e0f378c0756c330b948b3257",
                "report_id": "203",
                "report_url": "https://github.com/google/google-java-format/issues/203",
                "issue_title": "Crash when there is whitespace on the last line",
                "issue_description": "The program (version 1.4) crashes on the following input:\r\n```\r\nclass A {}\r\n<whitespace (space or tab) >\r\n```\r\nwith the following error:\r\n```\r\nPlateau2.java: error: String index out of range: -1\r\njava.lang.StringIndexOutOfBoundsException: String index out of range: -1\r\n\tat java.lang.String.substring(String.java:1967)\r\n\tat com.google.googlejavaformat.java.JavaOutput.getFormatReplacements(JavaOutput.java:330)\r\n\tat com.google.googlejavaformat.java.Formatter.getFormatReplacements(Formatter.java:250)\r\n\tat com.google.googlejavaformat.java.Formatter.formatSource(Formatter.java:221)\r\n\tat com.google.googlejavaformat.java.FormatFileCallable.call(FormatFileCallable.java:46)\r\n\tat com.google.googlejavaformat.java.FormatFileCallable.call(FormatFileCallable.java:27)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n    \r\n          "
            }
        }
    },
    "Jimfs": {
        "owner_repo": "google/jimfs",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "93a6c6782a9fdf1365face2461876b8644b2a404",
                "commit_sha_fixed": "a9b336e3f1ef089951e02e469f164d15ae939315",
                "report_id": "105",
                "report_url": "https://github.com/google/jimfs/issues/105",
                "issue_title": "Files.list returns an entry which is then declared to not exist",
                "issue_description": "Consider the following code:\r\n\r\n\ttry (FileSystem jimFs = Jimfs.newFileSystem(Configuration.unix())) {\r\n\t\tfinal Path workDir = jimFs.getPath(\"\");\r\n\t\tFiles.createFile(workDir.resolve(\"file1.txt\"));\r\n\t\tfinal Path entry = Files.list(workDir).collect(MoreCollectors.onlyElement());\r\n\t\tLOGGER.info(\"Entry: {}, abs: {}, exists: {}, exists as abs: {}.\", entry, entry.toAbsolutePath(), Files.exists(entry), Files.exists(entry.toAbsolutePath()));\r\n\t}\r\n\r\nIt prints: `Entry: /file1.txt, abs: /work/file1.txt, exists: false, exists as abs: true.`\r\n\r\nI think that the entry name `/file1.txt` is incorrect. This seems to designate an absolute path, whereas a relative path is expected here (relative to the work dir). A bigger problem (maybe caused by the previous one) is that `Files.exists` reports this entry to not exist. Whereas the same entry is reported to exist when using its absolute form. Whether a file exists should not depend on the form of its path, and this entry does exist, in any case."
            },
            "2": {
                "commit_sha_buggy": "94ef329706347150b7fec23f45dc37fab6b254fa",
                "commit_sha_fixed": "24a71cc920572bcf3f7cf9bd739843460098dd17",
                "report_id": "77",
                "report_url": "https://github.com/google/jimfs/pull/77",
                "issue_title": "`Files.newOutputStream(path, CREATE, TRUNCATE_EXISTING)` does not truncate the existing file",
                "issue_description": "Hi there,\r\n\r\nI've found a bug in this library.\r\n\r\nWhen using the `Files..newOutputStream(path, CREATE, TRUNCATE_EXISTING)` method the existing files are not truncated (see the failing unit test in the first commit).\r\n\r\nI'd be very happy if you could merge and release this fix, 'cause I have to use some workarounds at the moment.\r\n\r\nThanks,\r\nVilmos"
            }
        }
    },
    "Tape": {
        "owner_repo": "square/tape",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "dc3f67dea820648e9c29cae6e0032a5c5de12005",
                "commit_sha_fixed": "51b36303762a0a413e7f0fc90dc65c8f176d11e3",
                "report_id": "39",
                "report_url": "https://github.com/square/tape/pull/39",
                "issue_title": "Erase records eagerly",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "5a74dcfd17e5376269c0b4481d304c05b31ce72b",
                "commit_sha_fixed": "0efa7ea3bfe1bf5f3b7875ca51b993e7600efcca",
                "report_id": "77",
                "report_url": "https://github.com/square/tape/pull/77",
                "issue_title": "Throw exception for negative file length in header.",
                "issue_description": "We're seeing cases where `RandomAccessFile#write(byte[] buffer, int byteOffset, int byteCount)` is being called with a negative `byteCount`.\n\n```\njava.lang.ArrayIndexOutOfBoundsException: length=4096; regionStart=0; regionLength=-1046\n       at java.util.Arrays.checkOffsetAndCount(Arrays.java:1719)\n       at libcore.io.IoBridge.write(IoBridge.java:491)\n       at java.io.RandomAccessFile.write(RandomAccessFile.java:688)\n       at com.segment.analytics.QueueFile.ringWrite(QueueFile.java:230)\n       at com.segment.analytics.QueueFile.ringErase(QueueFile.java:239)\n       at com.segment.analytics.QueueFile.remove(QueueFile.java:541)\n       at com.segment.analytics.Segment.performFlush(Segment.java:151)\n      ...\n```\n\nLooking at [`int beforeEof = fileLength - position;`](https://github.com/square/tape/blob/master/tape/src/main/java/com/squareup/tape/QueueFile.java#L228), this could happen when the fileLength is negative for some reason. This commit disallows a negative file length stored in the header during initialization.\n\nCouldn't build locally due to this error : https://cloudup.com/c37tz2rjqGj. I'll update the PR in case the CI fails.\n"
            },
            "3": {
                "commit_sha_buggy": "759ff273ef036d5dc70cb61b1a923ac5a20ebe9f",
                "commit_sha_fixed": "6bed87308bf7706eb7a2bc7b40e19096aada6e0f",
                "report_id": "79",
                "report_url": "https://github.com/square/tape/pull/79",
                "issue_title": "Disallow removing a non-positive number of elements from QueueFile",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "64dfc3140e5a86b142dfeb10baabca5edece061c",
                "commit_sha_fixed": "193e08dcdad385c5f2ab219702bc553e2d1886ed",
                "report_id": "107",
                "report_url": "https://github.com/square/tape/pull/107",
                "issue_title": "Remove element lengths from toString().",
                "issue_description": "Closes #103.\n"
            },
            "5": {
                "commit_sha_buggy": "193e08dcdad385c5f2ab219702bc553e2d1886ed",
                "commit_sha_fixed": "52e9782058033864562494255b927f1fc407d24f",
                "report_id": "105",
                "report_url": "https://github.com/square/tape/pull/105",
                "issue_title": "Small tweaks preparing for >2GB support.",
                "issue_description": ""
            },
            "6": {
                "commit_sha_buggy": "100249dac7bb21ce8c4fa6f8665ddff96d078e60",
                "commit_sha_fixed": "3c28f50aed5f370b9d572d7ba0da3d8f2248faf7",
                "report_id": "32",
                "report_url": "https://github.com/square/tape/pull/32",
                "issue_title": "Changing ElementInputStream read(byte[], int, int) to return -1 when no more data is available",
                "issue_description": "The current implementation of `ElementInputStream#read(byte[], int, int)` will return 0 when asked to read when no more bytes are remaining. However, the `InputStream` contract for that method specifies that it should return, \"-1 if there is no more data because the end of the stream has been reached.\"  This difference causes typical idioms for stream copying, which check for a -1 return value, to enter an infinite loop.\n"
            },
            "7": {
                "commit_sha_buggy": "3c28f50aed5f370b9d572d7ba0da3d8f2248faf7",
                "commit_sha_fixed": "52b24f2650ac23fdecfca7ee31f758d00bb823a5",
                "report_id": "30",
                "report_url": "https://github.com/square/tape/pull/30",
                "issue_title": "Changes QueueFile#ringRead to use the offset parameter in all cases",
                "issue_description": "When trying to use `forEach` and an `ElementReader` to read data into offset positions of a single byte array, I noticed that the bytes starting at offset 0 would be repeatedly overwritten, rather than subsequent elements' data being read into the expected offsets of my byte array.\n\nI believe the culprit is the use of the constant offset `0` in the first branch of the conditional logic in `QueueFile#ringRead`. I've included a test that should fail against the current logic in master, and pass with my changes.\n\nThanks for your time and consideration!\n"
            },
            "8": {
                "commit_sha_buggy": "65027b14fdd4967acd5abe68ae993e151413362b",
                "commit_sha_fixed": "2116ee3dba8610a22cb4d894cdd4943e32870705",
                "report_id": "43",
                "report_url": "https://github.com/square/tape/issues/43",
                "issue_title": "QueueFile hangs on a 'corrupt' file",
                "issue_description": "Still researching how we got here, but we have a file filled with zeros, even the header.  This causes `QueueFile.expandIfNecessary` to never complete, it's basically adding the fileLength each time through.\n\nI propose we add an additional check on fileLength when we read it in `readHeader`.  If zero (and less than zero? java ints _are_ signed, after all) it would throw an IOException, failing fast.\n"
            },
            "9": {
                "commit_sha_buggy": "65027b14fdd4967acd5abe68ae993e151413362b",
                "commit_sha_fixed": "d8a7b160b7f63a15f8c3da127e679081613b1e74",
                "report_id": "44",
                "report_url": "https://github.com/square/tape/pull/44",
                "issue_title": "Blow up early on a bad header",
                "issue_description": "Fixes #43.\n"
            },
            "10": {
                "commit_sha_buggy": "95315e7abc2ee75da400193b9f5499fa7a561b4e",
                "commit_sha_fixed": "ba22953f2a36f8c19d9c95e127746536a584fb5a",
                "report_id": "42",
                "report_url": "https://github.com/square/tape/pull/42",
                "issue_title": "Prevent corruption when expanding a perfectly saturated queue",
                "issue_description": "If a `QueueFile` has no unused space, and the first element begins somewhere other than at the beginning of the queue, elements at the beginning of the file are not copied after the existing elements as the file is expanded. The next `peek()` may then return no data or corrupted data.\n\nThis change contains a test to demonstrate the flaw and simple fix.\n"
            },
            "11": {
                "commit_sha_buggy": "3aa89d807c85b8f67ffe972de1c2b47e9d790497",
                "commit_sha_fixed": "33dc5aeaf1d2ae9b9ff5a221cf6fe2cc6ab434f4",
                "report_id": "53",
                "report_url": "https://github.com/square/tape/issues/53",
                "issue_title": "All Data Not Properly Zeroed Out",
                "issue_description": "From @casidiablo:\n\nLet me give you an example to make this even clearer and then we'll define what to test:\n\n```\n$ hexdump test_file\n00 00 00 39 00 00 00 05 00 00 00 19 00 00 00 35  <- file header\n66 66 66 00 00 00 00 00 00 00 00 00 03 62 62 62\n00 00 00 03 63 63 63 00 00 00 03 64 64 64 00 00\n00 03 65 65 65 00 00 00 03\n```\n\nIt's a 57B file length, 5 elems, first position is 0x19 (25), last position is 0x35 (53).\n\nWithout this commit, after adding an element (whose content is 0xFFs) of size 5 I got this:\n\n```\n$ hexdump test_file # file was doubled since it was not enough to save the element\n00 00 00 39 00 00 00 06 00 00 00 19 00 00 00 3C\n66 66 66 00 00 00 00 00 00 00 00 00 03 62 62 62\n00 00 00 03 63 63 63 00 00 00 03 64 64 64 00 00\n00 03 65 65 65 00 00 00 03 66 66 66 00 00 00 05  \nFF FF FF FF FF 03 62 62 00 00 00 00 00 00 00 00  <- queue ends in the last 0xFF\n00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00     '03 62 62' are from the second row\n00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n00 00 \n```\n\nIf we do it with this commit:\n\n```\n$ hexdump test_file\n00 00 00 39 00 00 00 06 00 00 00 19 00 00 00 3C\n66 66 66 00 00 00 00 00 00 00 00 00 03 62 62 62\n00 00 00 03 63 63 63 00 00 00 03 64 64 64 00 00\n00 03 65 65 65 00 00 00 03 66 66 66 00 00 00 05  \nFF FF FF FF FF 00 00 00 00 00 00 00 00 00 00 00  <- no garbage\n00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00     \n00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n00 00 \n```\n\nNote that both versions leave garbage in the second row (0x66s). Should we also remove that garbage? Should a test make sure that all unused areas is filled with zeros?\n"
            },
            "12": {
                "commit_sha_buggy": "3aa89d807c85b8f67ffe972de1c2b47e9d790497",
                "commit_sha_fixed": "d94f2a67587db009a16113ecb19819cd9fd4f3ea",
                "report_id": "57",
                "report_url": "https://github.com/square/tape/pull/57",
                "issue_title": "Properly zero out data. Closes #53.",
                "issue_description": ""
            },
            "13": {
                "commit_sha_buggy": "6310b29e05e71161cddde44d5745534c9baa1bfd",
                "commit_sha_fixed": "86f6af87e16cf07f24f4612c92f6a9a2f771e5e0",
                "report_id": "100",
                "report_url": "https://github.com/square/tape/pull/100",
                "issue_title": "Guard against concurrent modification if QueueFile is cleared during",
                "issue_description": "iteration.\n\nPreviously, calling `clear` during iteration would not throw a\n`ConcurrentModificationException`.\n"
            }
        }
    },
    "Jcabi_email": {
        "owner_repo": "jcabi/jcabi-email",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "e8ba5b1771575be72240b09b5e184a43ac822c98",
                "commit_sha_fixed": "5500312e18fb68a7110576c4093a34b3731fdce9",
                "report_id": "5",
                "report_url": "https://github.com/jcabi/jcabi-email/issues/5",
                "issue_title": "stamps ctor params are messed up",
                "issue_description": ""
            },
            "2": {
                "commit_sha_buggy": "1e01328d1d595dfdf988b90c49c2f7b4f07f94d9",
                "commit_sha_fixed": "9489fbaaa083f5ddb523c7422c39a32748e11e65",
                "report_id": "7",
                "report_url": "https://github.com/jcabi/jcabi-email/issues/7",
                "issue_title": "cacheable envelope",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "75fdba14c289b426bce1e9f1af29350bc503190d",
                "commit_sha_fixed": "9ca7457dbe55eb3dd21721db3125fe65710a7c44",
                "report_id": "15",
                "report_url": "https://github.com/jcabi/jcabi-email/issues/15",
                "issue_title": "Envelope.MIME(envelope) fails",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "274da08c262dff272dbb599e7b544c5cc6f9e217",
                "commit_sha_fixed": "1df8a7d6580ad82e42f39735de629765ad9ce3e2",
                "report_id": "16",
                "report_url": "https://github.com/jcabi/jcabi-email/issues/16",
                "issue_title": "Envelope.MIME wrapping fails with enclosures",
                "issue_description": ""
            }
        }
    },
    "Jcabi_aether": {
        "owner_repo": "jcabi/jcabi-aether",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "de19a05143646503af0baad7b6e7ce9393b881ce",
                "commit_sha_fixed": "7bb7c22bbfd915396c948f821ec129b6c241b441",
                "report_id": "11",
                "report_url": "https://github.com/jcabi/jcabi-aether/issues/11",
                "issue_title": " Aether doesn't read proxy information from maven",
                "issue_description": "Aether should read proxy information from maven settings.xml file.\n"
            }
        }
    },
    "Doubleclick_core": {
        "owner_repo": "google/openrtb-doubleclick",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "789f07f028e9d60ac75fcd45cddcc8f3e5eae353",
                "commit_sha_fixed": "e11616e4f6e9b9e9e2616a4882307324b7a0ebb6",
                "report_id": "4",
                "report_url": "https://github.com/google/openrtb-doubleclick/pull/4",
                "issue_title": "Finish IDFA fix: support any size",
                "issue_description": ""
            }
        }
    },
    "Gwtmockito": {
        "owner_repo": "google/gwtmockito",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "d1ce2f718b65582cecde0deb1707feefedfbb40c",
                "commit_sha_fixed": "dc26c843ce2b1de29dd0404ecbe90c6f62e63fff",
                "report_id": "55",
                "report_url": "https://github.com/google/gwtmockito/issues/55",
                "issue_title": "cannot use com.google.gwt.user.datepicker.client.DatePicker",
                "issue_description": "I am using gwtmockito 1.1.5\n\njava.lang.ClassCastException: com.google.gwt.core.client.JavaScriptObject$$EnhancerByMockitoWithCGLIB$$c39d8300 cannot be cast to com.google.gwt.dom.client.Element\n    at com.google.gwt.user.client.ui.HTMLTable$CellFormatter.getCellElement(HTMLTable.java:428)\n    at com.google.gwt.user.client.ui.HTMLTable$CellFormatter.getRawElement(HTMLTable.java:441)\n    at com.google.gwt.user.client.ui.HTMLTable$CellFormatter.access$400(HTMLTable.java:161)\n    at com.google.gwt.user.client.ui.HTMLTable.cleanCell(HTMLTable.java:1578)\n    at com.google.gwt.user.client.ui.HTMLTable.setText(HTMLTable.java:1175)\n    at com.google.gwt.user.datepicker.client.DefaultCalendarView.setup(DefaultCalendarView.java:249)\n    at com.google.gwt.user.datepicker.client.DatePicker.<init>(DatePicker.java:306)\n    at com.google.gwt.user.datepicker.client.DatePicker.<init>(DatePicker.java:285)\n    at com.kf.amplifire.modules.widgets.KfDatePickerCellTest.testImaMonkey(KfDatePickerCellTest.java:17)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:236)\n    at com.google.gwtmockito.GwtMockitoTestRunner.run(GwtMockitoTestRunner.java:301)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)\n\nMy test class looks like this:\npackage com.a.bc.modules.widgets;\n\nimport static org.junit.Assert.assertTrue;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\n\nimport com.google.gwt.user.datepicker.client.DatePicker;\nimport com.google.gwtmockito.GwtMockitoTestRunner;\n\n@RunWith(GwtMockitoTestRunner.class)\npublic class KfDatePickerCellTest {\n\n   @Test\n   public void testDatePicker() {\n\n```\n  DatePicker nosePicker = new DatePicker();\n  assertTrue(nosePicker != null);\n```\n\n   }\n\n}\n"
            },
            "2": {
                "commit_sha_buggy": "6dfd20639620dc1367d3f318f79ef65d563f4d1f",
                "commit_sha_fixed": "842d1e8dda23df9d895135dc16226232aa0be2a9",
                "report_id": "66",
                "report_url": "https://github.com/google/gwtmockito/pull/66",
                "issue_title": "Update to GWT 2.8.0",
                "issue_description": "Add stubbing for ValueListBox\r\nFix assertion in ValueBox.<init>"
            },
            "3": {
                "commit_sha_buggy": "f9829aca90c3bb73b78e66ffeed6e614ab0bd30d",
                "commit_sha_fixed": "51a95c0a52a697c1e7408ff0a94e6fc0b39b781d",
                "report_id": "83",
                "report_url": "https://github.com/google/gwtmockito/pull/83",
                "issue_title": "Allow ResourcePrototype methods in fake ClientBundle",
                "issue_description": "This PR allows you to mock ResourcePrototypes that have a method producing another ResourcePrototype (usecase: SVGResource that can produce SVGs in different colors)"
            }
        }
    },
    "Render_app": {
        "owner_repo": "saalfeldlab/render",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "484b017ab79e9d6bea037c128f0141a93137b145",
                "commit_sha_fixed": "00c9e09c0ddf6474449235fac17c82cbc71e42b5",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix label box render bug: sort tile specs by id to ensure consistent ordering before assigning label colors",
                "issue_description": "fix label box render bug: sort tile specs by id to ensure consistent ordering before assigning label colors"
            },
            "2": {
                "commit_sha_buggy": "d0a6b88f2dfc69c1a854456be29657b323790d5f",
                "commit_sha_fixed": "52049e889f7fb14dac573b454b8d0933de621a86",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Bug fixes from discussion with Stephan:\n(1) when applying warp field transform, use warp field offsets for affine lookup but not for actual translation\n(2) when calculating full scale relative affine, concatenate split stack translation after re-scaling",
                "issue_description": "Bug fixes from discussion with Stephan:\n(1) when applying warp field transform, use warp field offsets for affine lookup but not for actual translation\n(2) when calculating full scale relative affine, concatenate split stack translation after re-scaling"
            },
            "3": {
                "commit_sha_buggy": "b15b5d9817d9b4a72ccd567189e8fd0c60c36289",
                "commit_sha_fixed": "7e8515dd55604cfb85edab6307b5b82cd3db9b01",
                "report_id": "62",
                "report_url": "https://github.com/saalfeldlab/render/issues/62",
                "issue_title": "up-sampling mipmap sources is broken",
                "issue_description": "Need to look at Forrest's use case."
            },
            "4": {
                "commit_sha_buggy": "8a0b928823e0b293a72c373c039a0495b1fff9cd",
                "commit_sha_fixed": "28488381e9438ffe8c568be215d68171d8fd29b3",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "maybe? fix the ExponentialFunctionOffsetTransform - applying the inverse of it since applying it in its current form makes the alignment worse",
                "issue_description": "maybe? fix the ExponentialFunctionOffsetTransform - applying the inverse of it since applying it in its current form makes the alignment worse"
            },
            "5": {
                "commit_sha_buggy": "d561ac31442b23891c0cf8d90dccd8b28069eceb",
                "commit_sha_fixed": "9bfb808c6aac5f0814aeb1f8ade9d99584ad24ad",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix sign on b parameter for ExponentialFunctionOffsetTransform",
                "issue_description": "fix sign on b parameter for ExponentialFunctionOffsetTransform"
            }
        }
    },
    "Open_location_code_java": {
        "owner_repo": "google/open-location-code",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "864254893b1be108ae0d142f53a53009b1b43698",
                "commit_sha_fixed": "801a3e4c82719ddbb7e68b40392cd7ac135941c9",
                "report_id": "217",
                "report_url": "https://github.com/google/open-location-code/pull/217",
                "issue_title": "Fix precision when creating code to match other implementations.",
                "issue_description": "This would previously return a slightly off plus code from the other implementations."
            },
            "2": {
                "commit_sha_buggy": "852a63221b8522a2b741f521c0e0f1d4ceaa4b5b",
                "commit_sha_fixed": "fd88e9b9aa53b00aaf365f745712fdb4083b0b66",
                "report_id": "274",
                "report_url": "https://github.com/google/open-location-code/pull/274",
                "issue_title": "Fix isValid() to invalidate short codes with padding (issues/273)",
                "issue_description": "This PR updates all implementations with an additional check to `isValid(string)` to invalidate short codes with padding as discussed in Issue https://github.com/google/open-location-code/issues/273.\r\nThe Open Location Code Specification doc was also updated to clarify that padded codes cannot be shortened and that short codes cannot have padding.\r\nThe invalid padded short code `WC2300+` was also added to ` test_data/validityTests.csv` as an invalid test case.\r\n\r\nThe additional check is consistent between each contained implementation as much as possible and is structured like:\r\n```\r\nif (code contains padding) {\r\n    // Short codes cannot have padding\r\n    if (separatorIndex < SEPARATOR_POSITION) {\r\n        return false;\r\n    }\r\n    ...\r\n}\r\n```"
            },
            "3": {
                "commit_sha_buggy": "2f67d024111ac011b33e104cd6c3ba910636d9fd",
                "commit_sha_fixed": "3a0f20a6074e948ca4c88f180213ba034a972e82",
                "report_id": "272",
                "report_url": "https://github.com/google/open-location-code/pull/272",
                "issue_title": "Fix Java isValidCode() to validate separator position as defined by the spec",
                "issue_description": "The API reference for the isValid() method specifies:\r\n> There must be an even number of at most eight characters before the separator.\r\n\r\nThe current Java implementation fails to validate that there are at most eight characters before the separator.  For example, these invalid codes would pass the isValid check and ultimately break the operations.\r\n```\r\n8FWC2345G6+\r\n8FWC2345G600+\r\n8FWC2345G62222222222+\r\n```\r\nThis PR fixes this by checking that the separator position is also not greater than 8 just like the other implementations do.\r\nOne of the above examples was also added to `validityTests.csv` to validate this test case."
            },
            "4": {
                "commit_sha_buggy": "5537559b72d7262387de65b811ae8a2d4d765787",
                "commit_sha_fixed": "cd581570de7e3eb4984e78657068060e529527d1",
                "report_id": "347",
                "report_url": "https://github.com/google/open-location-code/pull/347",
                "issue_title": "Fix floating point handling in Java",
                "issue_description": "Updates Java library to pass tests. Addresses issues #345 and #307.\r\n\r\nRemoves BigDecimal by using integer (longs) calculation for encoding and decoding.\r\n\r\n(This change is built on #346.)"
            }
        }
    },
    "Burst": {
        "owner_repo": "square/burst",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "87689e850cb2c52af16117309959c7d24ecdc660",
                "commit_sha_fixed": "26475455976c2a4ba51d1c32ea9b8dacf5735d56",
                "report_id": "9",
                "report_url": "https://github.com/square/burst/pull/9",
                "issue_title": "Implicit constructors inherit class visibility.",
                "issue_description": "We can accurately see the default constructor when the class is properly visible. By fixing the visibility of the nested classes in the test the desired behavior is exhibited.\n"
            },
            "2": {
                "commit_sha_buggy": "08629234e54b58a5477fe85f3cb7ddc115e343db",
                "commit_sha_fixed": "53b7015817134764f9883247a4e67776a0479737",
                "report_id": "12",
                "report_url": "https://github.com/square/burst/pull/12",
                "issue_title": "Periods in exploded test names",
                "issue_description": ""
            },
            "3": {
                "commit_sha_buggy": "5401a143500a4266839dd5b45692279561ccbda3",
                "commit_sha_fixed": "701ec21c1b47860e30cceebfca1326b584f5f4fa",
                "report_id": "51",
                "report_url": "https://github.com/square/burst/pull/51",
                "issue_title": "Stop allowing extra default constructors",
                "issue_description": "Now that we've dropped Android support there's no need for an extra default constructor; all Burst tests should have one constructor.\n\nIt's possible this could break existing tests, but it's unavoidable unless we keep this leniency forever.\n"
            }
        }
    },
    "Jnagmp": {
        "owner_repo": "square/jna-gmp",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "636c65af1795265d6f9d00fcfd2adbcc92c60aff",
                "commit_sha_fixed": "c1667fbce6b356ed02b2e06587d55d538c5c22b4",
                "report_id": "27",
                "report_url": "https://github.com/square/jna-gmp/pull/27",
                "issue_title": "modPow: support negative base and exponent",
                "issue_description": ""
            }
        }
    },
    "Rocketmq_mqtt_cs": {
        "owner_repo": "apache/rocketmq-mqtt",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "18709f8b4cbf7a81cfc64d4539671280a6f2cb31",
                "commit_sha_fixed": "f5a8efa3b802ec8f47e54b73570d5ee4baf4eda2",
                "report_id": "22",
                "report_url": "https://github.com/apache/rocketmq-mqtt/issues/22",
                "issue_title": "codeCov is not very optimistic, need to increase code coverage",
                "issue_description": "in branch main codeCov 20%\r\n need add code coverage\r\n![image](https://user-images.githubusercontent.com/13758677/157836583-420803dc-d050-4eb3-afd7-0fd856712fbc.png)\r\n"
            },
            "2": {
                "commit_sha_buggy": "8ab5d785377142316af6bdb2bd4f23392e098afe",
                "commit_sha_fixed": "e9fe2ea893c77cdecd4079f586ce1a72d4d7ccc2",
                "report_id": "22",
                "report_url": "https://github.com/apache/rocketmq-mqtt/issues/22",
                "issue_title": "codeCov is not very optimistic, need to increase code coverage",
                "issue_description": "in branch main codeCov 20%\r\n need add code coverage\r\n![image](https://user-images.githubusercontent.com/13758677/157836583-420803dc-d050-4eb3-afd7-0fd856712fbc.png)\r\n"
            },
            "3": {
                "commit_sha_buggy": "4f3f12787aa0abbc42d92e0afbea5ed61839c5c0",
                "commit_sha_fixed": "0c20a2e970b1b6d1c8b7af9f379c3d7d15c59d3c",
                "report_id": "90",
                "report_url": "https://github.com/apache/rocketmq-mqtt/pull/90",
                "issue_title": "[ISSUE #22] codeCov for mqtt.cs.session",
                "issue_description": "continuously submit for #22"
            },
            "4": {
                "commit_sha_buggy": "344cb70dafd074b60e18e48fe63a436005c0339b",
                "commit_sha_fixed": "e0b5e20abbafb1369e54c80146e9e4190ca8f853",
                "report_id": "79",
                "report_url": "https://github.com/apache/rocketmq-mqtt/pull/79",
                "issue_title": "Define a subscription storage interface",
                "issue_description": "In order to realize the subscription storage capability in the session storage of the MQTT protocol, We define a subscription storage interface."
            }
        }
    },
    "Aws_maven": {
        "owner_repo": "spring-attic/aws-maven",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7b06826d9d88baab502010d7bcfd8a9365505278",
                "commit_sha_fixed": "7a9b3d627bea2e226ea22e9665f86fa3272720c9",
                "report_id": "14",
                "report_url": "https://github.com/spring-attic/aws-maven/issues/14",
                "issue_title": "Passphrase is not read if private key is not used in settings.xml",
                "issue_description": "In the settings.xml file, if the privateKey is not set, then the passphrase is ignored.\n"
            }
        }
    },
    "Snomed_owl_toolkit": {
        "owner_repo": "IHTSDO/snomed-owl-toolkit",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2714b1b61b24cb8b43eca2e6e05e82e0bd567f0e",
                "commit_sha_fixed": "ae89fe8ebe0edc6de85f7718b9bb74160c9fdacf",
                "report_id": "61",
                "report_url": "https://github.com/IHTSDO/snomed-owl-toolkit/issues/61",
                "issue_title": "JVM warning from Google Guice transient dependency will cause failures in future java versions",
                "issue_description": "When the OWL toolkit starts classification or OWL conversion it produces the following warning:\r\n```\r\n2022-02-21 11:51:27,907 [INFO  ] [main] org.snomed.otf.owltoolkit.conversion.RF2ToOWLService - Loading RF2 files\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (jar:file:/Users/kai/c/snomed-owl-toolkit/target/snomed-owl-toolkit-3.0.7-SNAPSHOT-executable.jar!/BOOT-INF/lib/guice-4.0.jar!/) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)\r\nWARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n```\r\nThese warnings are also shown during startup of Snowstorm.\r\nIn the near future I expect java will cause these applications to fail because of concerns.\r\n\r\nThe Guice library causing these issues is being pulled in by the old version of the OWL-API dependency."
            },
            "2": {
                "commit_sha_buggy": "2714b1b61b24cb8b43eca2e6e05e82e0bd567f0e",
                "commit_sha_fixed": "5dea831ef2eab5c6f3778b9abbf20938460a5a3e",
                "report_id": "62",
                "report_url": "https://github.com/IHTSDO/snomed-owl-toolkit/pull/62",
                "issue_title": "Fixes #61 Upgrade to latest minor version OWL-API.",
                "issue_description": "Upgrade to latest minor version of the OWL API to avoid old version of the Google Guice library that causes JVM warnings in Java 8 and later (also affects Snowstorm).\r\nAll unit tests pass. One new namespace handler method was needed for the new library but that just delegates to existing code.\r\nClassification of the Jan 2022 International release works as expected as does OWL file conversion. "
            }
        }
    },
    "Sonartsplugin": {
        "owner_repo": "Pablissimo/SonarTsPlugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "31bc8898c62934ce389746eb85db4509bdd4bad7",
                "commit_sha_fixed": "922ccf0ce7597ce419fe208e67078b4ed7a0d047",
                "report_id": "102",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/pull/102",
                "issue_title": "Tidy up parameter naming, add samples",
                "issue_description": "* Fixes #85 - tidying up parameter naming\r\n* Adds two new sample projects\r\n* Fixes relative paths output from `tslint` not being parsed properly"
            },
            "2": {
                "commit_sha_buggy": "21d9b0475245399448d185e17904ba7021dc0a48",
                "commit_sha_fixed": "106f19aa80e07eadd00058408025097f9cf2a049",
                "report_id": "114",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/issues/114",
                "issue_title": "sonar.ts.tslint.path config always needed, even when re-using tslint output",
                "issue_description": "When re-using a tslint output generated by the build process, sonar.ts.tslint.path still needs to be configured and pointing to an existing file. \r\nIf that is not the case, the plugin provides the message \"[WARNING] Path to tslint not defined or not found. Skipping tslint analysis.\" and stops the analysis."
            },
            "3": {
                "commit_sha_buggy": "b34e86afa7ff0337e8ab8e847b18fd754a9e326e",
                "commit_sha_fixed": "34df3ccb699e3fa73a552e08d4f1dff76ad05d24",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix #45 and make compatible with VSTS without further configuration",
                "issue_description": "Fix #45 and make compatible with VSTS without further configuration"
            },
            "4": {
                "commit_sha_buggy": "31c4601ab57d55c04c4ae1b716a765638c11f82c",
                "commit_sha_fixed": "ea2b2c48b3a3599771597f460d3b3b23bc3b02d5",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix issue #30 by falling back to local node_modules search for tslint if not configured",
                "issue_description": "Fix issue #30 by falling back to local node_modules search for tslint if not configured"
            },
            "5": {
                "commit_sha_buggy": "12c5c39198e7aef2297c014b08db33ffe6113a65",
                "commit_sha_fixed": "45edf463dbf2be18b6ae792e9b6447a495dd91c9",
                "report_id": "15",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/pull/15",
                "issue_title": "Ensure that sensor does not fail badly when it is not configured.",
                "issue_description": "Instead, it simply logs a warning that there is no path to tslint. This avoids failures\nwhen only some projects in a Sonar installation intend to use the plugin.\n"
            },
            "6": {
                "commit_sha_buggy": "35918a9bd3289dee11e2402f753402ed67a9eb9b",
                "commit_sha_fixed": "0daa50c8012c6faaea3af93b86fa52292e53add5",
                "report_id": "74",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/issues/74",
                "issue_title": "java.lang.NullPointerException after upgrade to Sonar v5.6 and plugin v0.96",
                "issue_description": "Hi,\r\n\r\nI've upgraded to Sonar v5.6 and I'm now using v0.96 of the plugin, this was from v5.1 and v0.90. With the old setup I was able to use the plugin, but now I'm getting the following exception. Nothing has changed in my source code or sonar-project.properties file after the upgrade.\r\n\r\nDo you have any ideas as to why this might be happening?\r\n\r\n`....\r\n....\r\n....\r\n11:19:12.676 INFO: 136/136 files analyzed\r\n11:19:12.676 INFO: Sensor SCM Sensor (wrapped) (done) | time=2000ms\r\n11:19:12.676 INFO: Sensor Linting sensor for TypeScript files (wrapped)\r\n11:19:12.676 DEBUG: Path sonar.ts.tslintpath not specified, falling back to node_modules/tslint/bin/tslint\r\n11:19:12.676 DEBUG: Found sonar.ts.tslintconfigpath Lint path to be 'tslint.json'\r\n11:19:12.676 DEBUG: Path sonar.ts.tslintrulesdir not specified, falling back to null\r\n11:19:12.676 DEBUG: Using a temporary path for TsLint output: C:\\git\\XXX\\WebComponents\\.sonar\\.sonartmp\\4237565016734021207.tmp\r\n11:19:12.676 DEBUG: Split 134 files into 4 batches for processing\r\n11:19:12.676 DEBUG: Executing TsLint with command: node ....\r\n11:19:16.005 DEBUG: Executing TsLint with command: node ....\r\n11:19:19.363 DEBUG: Executing TsLint with command: node ....\r\n11:19:22.379 DEBUG: Executing TsLint with command: node ....\r\n11:19:23.692 INFO: ------------------------------------------------------------------------\r\n11:19:23.692 INFO: EXECUTION FAILURE\r\n11:19:23.692 INFO: ------------------------------------------------------------------------\r\n11:19:23.692 INFO: Total time: 16.313s\r\n11:19:23.739 INFO: Final Memory: 42M/106M\r\n11:19:23.739 INFO: ------------------------------------------------------------------------\r\n11:19:23.739 ERROR: Error during SonarQube Scanner execution\r\n12:10:50.163 ERROR: Error during SonarQube Scanner execution\r\njava.lang.NullPointerException\r\n        at com.pablissimo.sonar.TsLintParserImpl.parse(TsLintParserImpl.java:26)\r\n        at com.pablissimo.sonar.TsLintSensor.execute(TsLintSensor.java:104)\r\n        at org.sonar.batch.sensor.SensorWrapper.analyse(SensorWrapper.java:57)\r\n        at org.sonar.batch.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:58)\r\n        at org.sonar.batch.phases.SensorsExecutor.execute(SensorsExecutor.java:50)\r\n        at org.sonar.batch.phases.AbstractPhaseExecutor.execute(AbstractPhaseExecutor.java:83)\r\n        at org.sonar.batch.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:192)\r\n        at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n        at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n        at org.sonar.batch.scan.ProjectScanContainer.scan(ProjectScanContainer.java:241)\r\n        at org.sonar.batch.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:236)\r\n        at org.sonar.batch.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:226)\r\n        at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n        at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n        at org.sonar.batch.task.ScanTask.execute(ScanTask.java:47)\r\n        at org.sonar.batch.task.TaskContainer.doAfterStart(TaskContainer.java:86)\r\n        at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n        at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n        at org.sonar.batch.bootstrap.GlobalContainer.executeTask(GlobalContainer.java:106)\r\n        at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:119)\r\n        at org.sonarsource.scanner.api.internal.batch.BatchIsolatedLauncher.execute(BatchIsolatedLauncher.java:62)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n        at java.lang.reflect.Method.invoke(Unknown Source)\r\n        at org.sonarsource.scanner.api.internal.IsolatedLauncherProxy.invoke(IsolatedLauncherProxy.java:60)\r\n        at com.sun.proxy.$Proxy0.execute(Unknown Source)\r\n        at org.sonarsource.scanner.api.EmbeddedScanner.doExecute(EmbeddedScanner.java:233)\r\n        at org.sonarsource.scanner.api.EmbeddedScanner.runAnalysis(EmbeddedScanner.java:151)\r\n        at org.sonarsource.scanner.cli.Main.runAnalysis(Main.java:110)\r\n        at org.sonarsource.scanner.cli.Main.execute(Main.java:74)\r\n        at org.sonarsource.scanner.cli.Main.main(Main.java:61)`"
            },
            "7": {
                "commit_sha_buggy": "0daa50c8012c6faaea3af93b86fa52292e53add5",
                "commit_sha_fixed": "7722e7a1940a2ca9182fc3cc5195aeff75e5d106",
                "report_id": "48",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/issues/48",
                "issue_title": "SonarTSPlugin does not show the coverage information in the LCOV file",
                "issue_description": "hello fellow, \n\nI installed the plugin in my SonarQube instance and configure the path to the LCOV file, I generate transpile the code from TS to JS, the I use Karma to generate a LCOV file, it points to JS sources, so after that I use remap-Istanbul to create other file that point the coverage to the TS files.\n\nI placed both files to be used for the plugin regarding the coverage of the tests but I always get 0% coverage.\n\nis there an configuration that I am missing?\n\n[Uploading coverage.7z\u2026]()\n"
            },
            "8": {
                "commit_sha_buggy": "99b61e839f340f8094376f089cb13e0815092880",
                "commit_sha_fixed": "6a86fcb79d07ddc933e8adabd1d16a58298c8835",
                "report_id": "100",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/pull/100",
                "issue_title": "Fixing scenario with multiple \"!\"s in the LCOV path.",
                "issue_description": "We have SF lines in the LCOV files generated by angular cli looking like:\r\n\r\nSF:/Users/xxx/xxx/xxxxx/yyyy/app/node_modules/angular2-template-loader/index.js!/Users/xxx/xxx/xxxxx/yyyy/app/node_modules/tslint-loader/index.js!/Users/xxx/xxx/xxxxx/yyyy/app/src/app/questions/loader.ts\r\n\r\nSo looking at the part of the path after the first ! won't solve our problem, however looking at part of the path after the final ! would."
            },
            "9": {
                "commit_sha_buggy": "99b61e839f340f8094376f089cb13e0815092880",
                "commit_sha_fixed": "cc5572ea740c7d5deb6c1ac6c02567e48f5d9f41",
                "report_id": "100",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/pull/100",
                "issue_title": "Fixing scenario with multiple \"!\"s in the LCOV path.",
                "issue_description": "We have SF lines in the LCOV files generated by angular cli looking like:\r\n\r\nSF:/Users/xxx/xxx/xxxxx/yyyy/app/node_modules/angular2-template-loader/index.js!/Users/xxx/xxx/xxxxx/yyyy/app/node_modules/tslint-loader/index.js!/Users/xxx/xxx/xxxxx/yyyy/app/src/app/questions/loader.ts\r\n\r\nSo looking at the part of the path after the first ! won't solve our problem, however looking at part of the path after the final ! would."
            },
            "10": {
                "commit_sha_buggy": "0b43b748bd2261af0488a5aa5bfafc7190d5ca31",
                "commit_sha_fixed": "62d7405dc9eb819baf9d45e414d589527ec458de",
                "report_id": "171",
                "report_url": "https://github.com/Pablissimo/SonarTsPlugin/pull/171",
                "issue_title": "fixing null pointer exception when no report path provided",
                "issue_description": "Several of my builds were breaking when I updated to the latest version yesterday. There was a null pointer exception being thrown when no report path was provided. I added a test to reproduce the bug and then added the fix in `parseReportsProperty()`, I did notice that there is no default value for the `TypeScriptPlugin.SETTING_LCOV_REPORT_PATH` property in `TypeScriptPlugin.java`. It could have been easily fixed by setting the default value to an empty string but I wasn't sure if you left it that way on purpose so I just fixed it in `TsCoverageSensorImpl` instead. Here is the error I was receving:\r\n\r\n```##[error]ERROR: Error during SonarQube Scanner execution\r\n##[error]java.lang.NullPointerException\r\n##[error]at com.pablissimo.sonar.TsCoverageSensorImpl.parseReportsProperty(TsCoverageSensorImpl.java:42)\r\n##[error]at com.pablissimo.sonar.TsCoverageSensorImpl.execute(TsCoverageSensorImpl.java:152)\r\n##[error]at com.pablissimo.sonar.CombinedCoverageSensor.execute(CombinedCoverageSensor.java:33)\r\n##[error]at org.sonar.scanner.sensor.SensorWrapper.analyse(SensorWrapper.java:53)\r\n##[error]at org.sonar.scanner.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:57)\r\n##[error]at org.sonar.scanner.phases.SensorsExecutor.execute(SensorsExecutor.java:49)\r\n##[error]at org.sonar.scanner.phases.AbstractPhaseExecutor.execute(AbstractPhaseExecutor.java:78)\r\n##[error]at org.sonar.scanner.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:182)\r\n##[error]at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n##[error]at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n##[error]at org.sonar.scanner.scan.ProjectScanContainer.scan(ProjectScanContainer.java:247)\r\n##[error]at org.sonar.scanner.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:242)\r\n##[error]at org.sonar.scanner.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:240)\r\n##[error]at org.sonar.scanner.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:232)\r\n##[error]at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n##[error]at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n##[error]at org.sonar.scanner.task.ScanTask.execute(ScanTask.java:47)\r\n##[error]at org.sonar.scanner.task.TaskContainer.doAfterStart(TaskContainer.java:86)\r\n##[error]at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:142)\r\n##[error]at org.sonar.core.platform.ComponentContainer.execute(ComponentContainer.java:127)\r\n##[error]at org.sonar.scanner.bootstrap.GlobalContainer.executeTask(GlobalContainer.java:115)\r\n##[error]at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:116)\r\n##[error]at org.sonarsource.scanner.api.internal.batch.BatchIsolatedLauncher.execute(BatchIsolatedLauncher.java:62)\r\n##[error]at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n##[error]at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n##[error]at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n##[error]at java.lang.reflect.Method.invoke(Unknown Source)\r\n##[error]at org.sonarsource.scanner.api.internal.IsolatedLauncherProxy.invoke(IsolatedLauncherProxy.java:60)\r\n##[error]at com.sun.proxy.$Proxy0.execute(Unknown Source)\r\n##[error]at org.sonarsource.scanner.api.EmbeddedScanner.doExecute(EmbeddedScanner.java:233)\r\n##[error]at org.sonarsource.scanner.api.EmbeddedScanner.runAnalysis(EmbeddedScanner.java:151)\r\n##[error]at org.sonarsource.scanner.cli.Main.runAnalysis(Main.java:110)\r\n##[error]at org.sonarsource.scanner.cli.Main.execute(Main.java:74)\r\n##[error]at org.sonarsource.scanner.cli.Main.main(Main.java:61)\r\n##[error]ERROR:\r\n##[error]ERROR: Re-run SonarQube Scanner using the -X switch to enable full debug logging.\r\n##[error]The SonarQube Scanner did not complete successfully```"
            }
        }
    },
    "Weak_lock_free": {
        "owner_repo": "raphw/weak-lock-free",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "be14c11c1f318f6a0a0dd154be9bf05349f0d334",
                "commit_sha_fixed": "e4195ac9faa33f121091a3c1b494d16fd411aac1",
                "report_id": "1",
                "report_url": "https://github.com/raphw/weak-lock-free/pull/1",
                "issue_title": "Fix NullPointerException when WCS.remove() is called without object present",
                "issue_description": ""
            }
        }
    },
    "Proj4J": {
        "owner_repo": "locationtech/proj4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "ae6e1f3c09ec1604ac5c11ed2e5cacb10b2be944",
                "commit_sha_fixed": "5bfde692c31ac5c0cce5e224a47490074f65a2b2",
                "report_id": "14",
                "report_url": "https://github.com/locationtech/proj4j/pull/14",
                "issue_title": "a fix to etmerc gatg increasing accuracy of etmerc",
                "issue_description": "Signed-off-by: Tore Halset <halset@pvv.ntnu.no>"
            },
            "2": {
                "commit_sha_buggy": "5ba8168a5e0346b79e5f7d2fd2bc25a68fba0670",
                "commit_sha_fixed": "96a1fab3e82ec949575b39c1d465e65bd7f4e1f8",
                "report_id": "55",
                "report_url": "https://github.com/locationtech/proj4j/pull/55",
                "issue_title": "Implement setRadius",
                "issue_description": "A projection may have a radius. This commit implements setRadius used in for example Equidistant Cylindrical where:\r\n+R=<value> Radius of the sphere given in meters. As per documentation this function is applied on the end, so it takes precedence over +ellps.\r\n\r\nFix #54 "
            },
            "3": {
                "commit_sha_buggy": "40c349bced74135c1e33b49cf3a4fa40b4ccfb88",
                "commit_sha_fixed": "7100c004e93b3655d2f65ac2dd53a14420d1f4d8",
                "report_id": "64",
                "report_url": "https://github.com/locationtech/proj4j/pull/64",
                "issue_title": "Fix NZ Map projection and add a test for it.",
                "issue_description": "Fixes https://github.com/locationtech/proj4j/issues/62"
            },
            "4": {
                "commit_sha_buggy": "8841a68f88340fef95641fde765deb9893f5404c",
                "commit_sha_fixed": "aa7f3b002104db17f53894a105e973e8e10ab47d",
                "report_id": "6",
                "report_url": "https://github.com/locationtech/proj4j/pull/6",
                "issue_title": "Extended Transverse Mercator",
                "issue_description": "Added support for Extended Transverse Mercator. Ported from proj.4\r\n\r\nThis is the same code as https://github.com/locationtech/proj4j/pull/5 , but with signed commits."
            },
            "5": {
                "commit_sha_buggy": "6d5403ed0c01b94b62538f27d548c2b3b4291133",
                "commit_sha_fixed": "16c9d3da5e75723825a5e3bc33dbfabfd15e9d91",
                "report_id": "45",
                "report_url": "https://github.com/locationtech/proj4j/pull/45",
                "issue_title": "Add Projection Equality",
                "issue_description": "This is follow-up PR to https://github.com/locationtech/proj4j/pull/33\r\n\r\nFurther testing revealed that `CoordinateReferenceSystem` was much too fragile because:\r\n- The `CoordinateReferenceSystem` name changes depending on how it was constructed. For instance name may be `EPSG:3857` if CRS was constructed by EPSG code or `merc-CS` if it constructed from Proj4 string.\r\n- Proj4 parameters are stored as provided. `+lat_0=0` and `+lat_0=0.0` are obviously the same but will trip up equality\r\n- Proj4 parameters are stored in order provided, this will trip up array equality check\r\n- Some parameters may be read from default file if `+no_def` is not present and thus will not be reflected in parameter string at all\r\n\r\nSo basically the situation is pretty dire and this PR attempts to remedy that.\r\n\r\nIt's worth noting that `Projection` class is highly mutable which makes checking for equality a little tricky. While the mutability is used primarily by the `Proj4Parser` to \"build up\" the projection its obviously possible that this is not the only place that mutation will happen because life.\r\n\r\nIn this PR:\r\n\r\n- Base `Projection.equals` checks that left and right side are the same class. This represents the implementation of `project` method.\r\n- Base `Projection.equals` checks the state of protected and private stateful fields that have setters\r\n- Subclasses of `Projection` check equality of their additional stateful fields and delegate to super equality afterwards.\r\n- `isSouth` and `heightOfOrbit` fields are moved to their corresponding subclasses. Getters and setters for those fields will throw `NoSuchElementException` if used at any other time.\r\n\r\nAlso ...\r\nCloses: https://github.com/locationtech/proj4j/issues/38\r\n"
            },
            "6": {
                "commit_sha_buggy": "c7d08b7edecbad038837a49993aa0a0d11515e62",
                "commit_sha_fixed": "440f3e889b74bc4e5b458611a5f100886a3f0d87",
                "report_id": "71",
                "report_url": "https://github.com/locationtech/proj4j/pull/71",
                "issue_title": "Fix UTM, LCC, Krovak and Stere projections",
                "issue_description": "## Summary\r\n\r\n- Fix UTM projection (it is backed by etmerc now, made tests much better (!))\r\n- Fix tests \r\n- Resurrect proj4-epsg tests and update them up to date\r\n\r\n### Test resurrection results\r\nBefore this PR [proj4-epsg.csv](https://github.com/locationtech/proj4j/blob/v1.1.1/src/test/resources/proj4-epsg.csv) contained the following amount of tests: \r\n- passing: 2899\r\n- failing: 1089\r\n- error: 292\r\n\r\nAfter:\r\n- passing: 3941 (893 tests were fixed due to the `ExtendedTransverseMercatorProjection`)\r\n- failing: 195\r\n- error: 144 (geocent projection is supported now)\r\n\r\n**UPD**\r\n\r\nAfter (with LCC projection fix):\r\n- passing: 4098\r\n- failing: 38\r\n- error: 144\r\n \r\n **UPD2**\r\n\r\nAfter (with Krovak projection fix):\r\n- passing: 4104\r\n- failing: 34\r\n- error: 144\r\n\r\nCloses #25\r\nCloses #58\r\nCloses #61\r\n "
            },
            "7": {
                "commit_sha_buggy": "f5a026edb57f79b88d6d3887b35f6417c4990c75",
                "commit_sha_fixed": "21c21b12756e9978c71a6ff899047c739c4faa96",
                "report_id": "72",
                "report_url": "https://github.com/locationtech/proj4j/pull/72",
                "issue_title": "Oblique Mercator Projection Improvements",
                "issue_description": "Oblique Mercator Projection functionality improvements modeled after [proj4js functionality](https://github.com/proj4js/proj4js/blob/master/lib/projections/omerc.js).\r\n* no_uoff support\r\n* gamma support\r\n* test updates\r\n\r\nFixes #21\r\n\r\nCC: ngageoint/geopackage-android#53"
            },
            "8": {
                "commit_sha_buggy": "5af1582846002ec9b30ce37cbf9804c965299540",
                "commit_sha_fixed": "03d31234b1e18ceabfe9eb53c4449838f4d9bcb9",
                "report_id": "74",
                "report_url": "https://github.com/locationtech/proj4j/pull/74",
                "issue_title": "OSGB36 datum and +nadgrids=@null support",
                "issue_description": "* Renamed `OSEB36` variable to `OSGB36` (Ordnance Survey of **G**reat Britain 1936)\r\n* Changed OSGB36 Transform\r\n  * from: `446.448, -125.157, 542.060, 0.1502, 0.2470, 0.8421, -20.4894`\r\n  * to: `446.448, -125.157, 542.06, 0.15, 0.247, 0.842, -20.489`\r\n* Added +nadgrids=@null support to grid parsing (based on [proj4js](https://github.com/proj4js/proj4js/blob/315398ea924c3169a257e3cf9796bc3d120039ee/lib/nadgrid.js#L44))\r\n\r\nThe OSGB36 change prevents the need to change EPSG:27700 proj parameters\r\n* from: `+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs`\r\n* to: `+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs`\r\n\r\nThere are two transformation versions floating around, but I believe this change is to the correct values and passes the added tests.\r\n* https://epsg.io/27700\r\n* https://github.com/OSGeo/gdal/blob/dbcb76893c728d7b711d353e689b683a81a2b6d7/autotest/gdrivers/ecw.py#L712\r\n* https://gis.stackexchange.com/questions/313761/why-does-r-set-crs-inconsistently\r\n* https://github.com/ngageoint/projections-java/blob/18ca270259a05e753d373d9fcf943a66ca75ebc8/src/main/resources/projections.epsg.properties#L10\r\n\r\nThis still does not resolve issue #32 (see TODO in added tests in CoordinateTransformTest)"
            },
            "9": {
                "commit_sha_buggy": "03d31234b1e18ceabfe9eb53c4449838f4d9bcb9",
                "commit_sha_fixed": "45fa5a1eeea3459e8a7049c73c3189c426e1c6eb",
                "report_id": "77",
                "report_url": "https://github.com/locationtech/proj4j/pull/77",
                "issue_title": "GeocentricConverter equality check after WGS param overrides",
                "issue_description": "* GeocentricConverter equality check after WGS param overrides\r\n* Previously failing tests\r\n  * EPSG:27700\r\n  * EPSG:31469\r\n  * EPSG:2056\r\n  * EPSG:4055\r\n\r\nFIXES #32 "
            }
        }
    },
    "Jmimemagic": {
        "owner_repo": "arimus/jmimemagic",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "7c0d1b1e7db2e49c40c7fb09ad53467b78d58929",
                "commit_sha_fixed": "646d8248188646b2bb8fa4d5bc031e1460f8624e",
                "report_id": "15",
                "report_url": "https://github.com/arimus/jmimemagic/pull/15",
                "issue_title": "SubMatches are added on every call",
                "issue_description": "If a Magic.getMagicMatch() is called for 2 files with a similar mimetype, the subMatches from the MagicMatch increases...\n"
            }
        }
    },
    "Docker_java_api": {
        "owner_repo": "amihaiemil/docker-java-api",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "81773b8ddc3361d3e6beea513c9a6bd4c9352c20",
                "commit_sha_fixed": "dac1ab277e9287450440a42c33ef2869f4699a1f",
                "report_id": "47",
                "report_url": "https://github.com/amihaiemil/docker-java-api/issues/47",
                "issue_title": "RtContainersTestCase.java:33-35: Write unit tests for all...",
                "issue_description": "The puzzle `26-a8980bc9` from #26 has to be resolved:\n\nhttps://github.com/amihaiemil/docker-java-api/blob/f5a14a642034a8bcde09e708cb5c27564061dfab/src/test/java/com/amihaiemil/docker/RtContainersTestCase.java#L33-L35\n\nThe puzzle was created by amihaiemil on 13-Mar-18. \n\nEstimate: 30 minutes, role: DEV.\n\nIf you have any technical questions, don't ask me, submit new tickets instead. The task will be \"done\" when the problem is fixed and the text of the puzzle is _removed_ from the source code. Here is more about [PDD](http://www.yegor256.com/2009/03/04/pdd.html) and [about me](http://www.yegor256.com/2017/04/05/pdd-in-action.html)."
            },
            "2": {
                "commit_sha_buggy": "d83c676f6db9ddb639ae7594b7b62f45624e74ff",
                "commit_sha_fixed": "3e5e4c9a81781d90f7a6283c8d24c7854a8cea77",
                "report_id": "109",
                "report_url": "https://github.com/amihaiemil/docker-java-api/issues/109",
                "issue_title": "URL encode the query parameters",
                "issue_description": "We need to make sure the query parameters are encoded properly, otherwise exceptions are thrown as seen [here](https://travis-ci.org/amihaiemil/docker-java-api/jobs/379218662#L1959)."
            },
            "3": {
                "commit_sha_buggy": "e72083bfec1c93bc53ae2d30720a305f0ef96693",
                "commit_sha_fixed": "9f4e4ee56d8c5ae03db599168edd4a53c1ceae8b",
                "report_id": "108",
                "report_url": "https://github.com/amihaiemil/docker-java-api/issues/108",
                "issue_title": "Let's add the body to the UnexpectedResponseException",
                "issue_description": "Let's also add the body to the exception message, not just the expected/actual status "
            },
            "4": {
                "commit_sha_buggy": "3089f5016397866a0f3bdb4b8c188a56245457aa",
                "commit_sha_fixed": "4f5301c9cceb3e80ca47d4f5a8ffad59d409ba72",
                "report_id": "234",
                "report_url": "https://github.com/amihaiemil/docker-java-api/pull/234",
                "issue_title": "Filter implemented for ListedVolumes.",
                "issue_description": "For https://github.com/amihaiemil/docker-java-api/issues/214:\r\n- `ListedVolumes` filter implemented;\r\n- `UncheckedUriBuilder` improvements;"
            },
            "5": {
                "commit_sha_buggy": "7dfd10635b4d7ba2a1929172c852706eefcaaa0e",
                "commit_sha_fixed": "767160231d0cf9810f33a39fe69f1b667fa65be1",
                "report_id": "236",
                "report_url": "https://github.com/amihaiemil/docker-java-api/issues/236",
                "issue_title": "Network.java:38-41: Implement Network methods: inspect,...",
                "issue_description": "The puzzle `225-64e49112` from #225 has to be resolved: \n\nhttps://github.com/amihaiemil/docker-java-api/blob/073e8158fe18a1b09b991ed09bd2ae05b20f423a/src/main/java/com/amihaiemil/docker/Network.java#L38-L41\n\nThe puzzle was created by Paulo Lobo on 18-Dec-18. \n\n  \n\nIf you have any technical questions, don't ask me, submit new tickets instead. The task will be \\\"done\\\" when the problem is fixed and the text of the puzzle is _removed_ from the source code. Here is more about [PDD](http://www.yegor256.com/2009/03/04/pdd.html) and [about me](http://www.yegor256.com/2017/04/05/pdd-in-action.html). \n"
            },
            "6": {
                "commit_sha_buggy": "eb6a2e2b2d939c3bb99af48bb9cc5529f1ead9c6",
                "commit_sha_fixed": "9197cdbd6fe0aadef1df08e62965867584d6e334",
                "report_id": "245",
                "report_url": "https://github.com/amihaiemil/docker-java-api/pull/245",
                "issue_title": "For #236: Added the rest of RtNetwork methods and fixed tests",
                "issue_description": "For #236:\r\n- Added the code remaining to `RtNetwork` related too all other operations\r\n- Fixed the tests, that were wrong; the actual tests check if we are making the correct request to docker API"
            },
            "7": {
                "commit_sha_buggy": "7ffa2921f6d0ee8740dbc1498744a25ff5adadb4",
                "commit_sha_fixed": "4b1b7608b798306e78bfeff11a21bf73eb075897",
                "report_id": "279",
                "report_url": "https://github.com/amihaiemil/docker-java-api/pull/279",
                "issue_title": "For #269: Implementing Plugin enable() and disable() methods",
                "issue_description": "For #269:\r\n\r\n- Implementing enable and disable methods\r\n- Fixing tests"
            },
            "8": {
                "commit_sha_buggy": "4b1b7608b798306e78bfeff11a21bf73eb075897",
                "commit_sha_fixed": "1968fbabdcd774600be253b1ecd0b173daba56e8",
                "report_id": "280",
                "report_url": "https://github.com/amihaiemil/docker-java-api/pull/280",
                "issue_title": "For #268: Implementing Plugin upgrade() and push() methods",
                "issue_description": "For #268:\r\n\r\n- Implementing `upgrade()` and `push()` methods\r\n- Added new class `ArrayPayloadOf` to extract Json request as `Iterator<JsonObject>`\r\n- Added new puzzles: to make tests for `ArrayPayloadOf` and to finish Plugin's `configure()` method"
            },
            "9": {
                "commit_sha_buggy": "d97e08ac2cb1a7130a0eacb3221e6a4bee811bc3",
                "commit_sha_fixed": "564cd5fe5fa04b7b59d00dfd1b8d10cd487ed78e",
                "report_id": "168",
                "report_url": "https://github.com/amihaiemil/docker-java-api/issues/168",
                "issue_title": "Continue with Exec API",
                "issue_description": "Let's continue with it. API is described [here](https://docs.docker.com/engine/api/v1.37/#tag/Exec).\r\n\r\nSee [contributing guidelines](https://github.com/amihaiemil/docker-java-api/blob/master/CONTRIBUTING.md). Also, [this](https://www.yegor256.com/2014/04/15/github-guidelines.html) might be helpful."
            },
            "10": {
                "commit_sha_buggy": "d98b3862218582cb579f369feacdcc393b6a902d",
                "commit_sha_fixed": "ea1edc15490dc417cf8db2510c54ef85f02b7933",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixing LocalDockerITCase for iterating volumes.",
                "issue_description": "Fixing LocalDockerITCase for iterating volumes."
            }
        }
    },
    "Github_release_plugin": {
        "owner_repo": "jutzig/github-release-plugin",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8f03ab5495e86c531aeb0c5589798a250664465e",
                "commit_sha_fixed": "3be13f786758f57e9aa8a6ba154aa0b0c287f490",
                "report_id": "41",
                "report_url": "https://github.com/jutzig/github-release-plugin/issues/41",
                "issue_title": "Multi module support",
                "issue_description": "I have a project with a parent defined multimodule project. (So I dont have separated parent and reactor project, and for some other reasons I can't). When I define that plugin that all module release it's artifacts, I've got the \r\n\r\n`org.kohsuke.github.HttpException: {\"message\":\"Validation Failed\",\"errors\":[{\"resource\":\"Release\",\"code\":\"already_exists\",\"field\":\"tag_name\"}],\"documentation_url\":\"https://developer.github.com/v3/repos/releases/#create-a-release\"} `\r\n\r\nas mention on #40 . On that issue there is a suggested solution, which is the delete release, which is not ok in my case because a would like to add all of submodule's artifacts."
            },
            "2": {
                "commit_sha_buggy": "8293177f3f8591785bf72e75cd78cfe38c84b8e4",
                "commit_sha_fixed": "e68bccd8f307a6abd453e6de7be20c006516a3f4",
                "report_id": "44",
                "report_url": "https://github.com/jutzig/github-release-plugin/pull/44",
                "issue_title": "Issue 41 Add multi-module support",
                "issue_description": "Fixes #41\r\n\r\nThe additional integration test needs fix for #40 due to `deleteRelease=false`."
            }
        }
    },
    "Spring_context_support": {
        "owner_repo": "alibaba/spring-context-support",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "1db3a1efd6c57b6449f5642d92fe3b7a5b49f294",
                "commit_sha_fixed": "7fab04eb3c51bf529341bc69a2541ce1967f87d9",
                "report_id": "16",
                "report_url": "https://github.com/alibaba/spring-context-support/issues/16",
                "issue_title": "Iterator \u505a\u65e0\u7528\u529f",
                "issue_description": "\u5728[registerBeans(BeanDefinitionRegistry registry, Class<?>... annotatedClasses)](https://github.com/alibaba/spring-context-support/blob/fcc533781fdfdf9285465865c7b295c3c1f731e4/src/main/java/com/alibaba/spring/util/AnnotatedBeanDefinitionRegistryUtils.java#L85) \u65b9\u6cd5\u4e2d \u672c\u610f\u662f\u79fb\u9664\u5df2\u7ecf\u6ce8\u518c\u8fc7\u7684 annotatedClass\r\n\r\n```java\r\n// Remove all annotated-classes that have been registered\r\nIterator<Class<?>> iterator = new ArrayList<Class<?>>(asList(annotatedClasses)).iterator();\r\nwhile (iterator.hasNext()) {\r\n    Class<?> annotatedClass = iterator.next();\r\n    if (isPresentBean(registry, annotatedClass)) {\r\n        iterator.remove();\r\n    }\r\n}\r\n```\r\n\r\n\u4f46\u662f\u5b9e\u9645\u4e0a Iterator \u5728\u505a\u65e0\u7528\u529f\r\n\r\n\u5728 `testRegisterBeans()` \u4e2d  \u91cd\u590d\u5411 registerBeans\r\n\r\n![image](https://user-images.githubusercontent.com/21981606/72121264-7c7e0a00-3395-11ea-98d5-bdfc41dfa269.png)\r\n\r\n\u63d0\u793a\r\n>  INFO support.DefaultListableBeanFactory - Overriding bean definition for bean 'annotatedBeanDefinitionRegistryUtilsTest': replacing [Generic bean: class [com.alibaba.spring.util.AnnotatedBeanDefinitionRegistryUtilsTest]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null] with [Generic bean: class [com.alibaba.spring.util.AnnotatedBeanDefinitionRegistryUtilsTest]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null]\r\n\r\n\u5728 debug\u4e2d  ` reader.register(annotatedClasses);` \u4ecd\u7136\u6ce8\u518c\u4e86\u91cd\u590d\u7684bean , \r\n`Iterator<Class<?>> iterator = new ArrayList<Class<?>>(asList(annotatedClasses)).iterator();`  \u7136\u540e `iterator.remove();` \u662f\u65e0\u610f\u4e49\u7684\r\n![image](https://user-images.githubusercontent.com/21981606/72121367-cc5cd100-3395-11ea-9806-a394eeca8684.png)\r\n\r\n\r\n"
            },
            "2": {
                "commit_sha_buggy": "256c78a640d72a80cc8537592eec8f69d71478be",
                "commit_sha_fixed": "43d6c786f77d1750aa2ee727eb55b0aa9027240b",
                "report_id": "22",
                "report_url": "https://github.com/alibaba/spring-context-support/issues/22",
                "issue_title": "[Refactor] Refactoring the overload methods of com.alibaba.spring.util.BeanUtils#getBeanNames(org.springframework.beans.factory.config.ConfigurableListableBeanFactory, java.lang.Class<?>)",
                "issue_description": "These methods should be implemented by Spring BeanFactory APIs."
            }
        }
    },
    "Metrics_opentsdb": {
        "owner_repo": "sps/metrics-opentsdb",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "bf240945cdbeda4a630c62deafda6dbec4025ad4",
                "commit_sha_fixed": "8f35488d70b0f28ee50996bccb11269e9636969d",
                "report_id": "5",
                "report_url": "https://github.com/sps/metrics-opentsdb/pull/5",
                "issue_title": "Don't send an empty set of metrics to OpenTSDB. Even though it is perfec...",
                "issue_description": "...tly valid JSON, it fails to parse an empty list. This is a problem with Dropwizard's jvm.threads.deadlocks metric which is empty under normal operating conditions.\n\nIt's a tough call on whether this is an actual bug in OpenTSDB but It looks like they are intentionally throwing the BadRequestException when content is empty (parsePutV1 explicitly states it will throw on empty content in the JavaDoc)\n\n$ curl 'http://localhost:4242/api/put' -d '{\"metric\":\"my-app.jvm.threads.deadlocks\",\"timestamp\":1409092196,\"value\":[],\"tags\":{\"type\":\"app\"}}'\n{\"error\":{\"code\":400,\"message\":\"Unable to parse the given JSON\",\"details\":\"com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.lang.String out of START_ARRAY token\\n at [Source: java.io.StringReader@4ced1dfe; line: 1, column: 84](through reference chain: net.opentsdb.core.IncomingDataPoint[\"value\"])\",\"trace\":\"net.opentsdb.tsd.BadRequestException: Unable to parse the given JSON\\n\\tat net.opentsdb.tsd.HttpJsonSerializer.parsePutV1(HttpJsonSerializer.java:143)\n....\n....\n\nI feel like OpenTSDB should handle this situation more gracefully than throwing an exception but I'm not comfortable enough with their codebase or philosophy to start that discussion with them yet and for now, it seems more efficient to not send an empty metric than to send more data on the wire.\n"
            },
            "2": {
                "commit_sha_buggy": "8f35488d70b0f28ee50996bccb11269e9636969d",
                "commit_sha_fixed": "bbce49846241e5c2a75e0c199fb3cd29165589ac",
                "report_id": "6",
                "report_url": "https://github.com/sps/metrics-opentsdb/pull/6",
                "issue_title": "Fixing buildGauge to include 'value' in the prefix and updated test.",
                "issue_description": "Gauge metrics were not being inserted into OpenTSDB with the 'value' field intact which causes de-serialization into an impl of com.codahale.metrics.Gauge to fail because the field was missing.\n"
            }
        }
    },
    "Hierarchical_clustering_java": {
        "owner_repo": "lbehnke/hierarchical-clustering-java",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "9922050a7434167ed417531da407853438bfd8f1",
                "commit_sha_fixed": "2a32d28ab30fc39629eb625a41eaf23f590ea30d",
                "report_id": "7",
                "report_url": "https://github.com/lbehnke/hierarchical-clustering-java/issues/7",
                "issue_title": "names duplicate",
                "issue_description": "The error shown when you perform clustering with an array of non unique names is pretty tough to track ...\n\nI suggest to add a check for uniqueness on the arguments [here](https://github.com/lbehnke/hierarchical-clustering-java/blob/master/src/main/java/com/apporiented/algorithm/clustering/DefaultClusteringAlgorithm.java#L38) using for instance a new Hashset initialized with the names and compare the size of the hashset with the size of the names array.\n"
            }
        }
    },
    "Iciql": {
        "owner_repo": "gitblit/iciql",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "c4c87e4ce044d84d5f2c4e7fa8709e5d699edf8f",
                "commit_sha_fixed": "13b08bb1e5a955650289c1c2d548883bfeac0de9",
                "report_id": "15",
                "report_url": "https://github.com/gitblit/iciql/issues/15",
                "issue_title": "IQColumn length with trim not working for DSL",
                "issue_description": "The behavior of the dsl should be the same as for db.insert(record)\n"
            },
            "2": {
                "commit_sha_buggy": "27979f07905dbf95b478a48babc99643d71bfdec",
                "commit_sha_fixed": "2523ad5454716a9e08f0d3220a92760aa50773e2",
                "report_id": "21",
                "report_url": "https://github.com/gitblit/iciql/issues/21",
                "issue_title": "Order by desc does not like primitives",
                "issue_description": ""
            }
        }
    },
    "Hive_funnel_udf": {
        "owner_repo": "yahoo/hive-funnel-udf",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "98ccfe420a83ea45057e656a4df928856ae08514",
                "commit_sha_fixed": "e80dcbf97fb384fa297722bd2f7467e979a0cf1a",
                "report_id": "4",
                "report_url": "https://github.com/yahoo/hive-funnel-udf/pull/4",
                "issue_title": "Allow scalar funnels",
                "issue_description": "For issue https://github.com/yahoo/hive-funnel-udf/issues/2\n"
            }
        }
    },
    "Sansorm": {
        "owner_repo": "brettwooldridge/SansOrm",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "16d9aa4b8fb20b9426a3c89355345739db8691f1",
                "commit_sha_fixed": "671b9a5bd84694bbe02a2e7b722b7b34de2cd418",
                "report_id": "12",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/12",
                "issue_title": "fixed default name behavior for Column and Table annotations",
                "issue_description": "@brettwooldridge, hi.\r\nrecently i've started to migrate my project from Hibernate (which finally disappointed me) to SansOrm.\r\nall entities in my project are annotated using only standard JPA annotations, and rely on the documented behavior that maps empty Table and Column names to entity and field names accordingly. but SansOrm expects explicit names for all of them. here's the fix to support standard documented behavior for those annotations to ease migration.\r\n\r\nPS: also, which minimal Java version should be supported by SansOrm? pom.xml says 1.8, but code looks like somewhat between 1.6 and 1.7"
            },
            "2": {
                "commit_sha_buggy": "23f3f0ba061920e5e37d963fde97cad9fcc48509",
                "commit_sha_fixed": "1e7049ced55f01b3f9c17a962162d5018a756bfb",
                "report_id": "15",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/15",
                "issue_title": "fixed case-sensitivity for column names",
                "issue_description": "fixes OrmElf result mapping in cases when column names are implicit (introduced in #12). tests included."
            },
            "3": {
                "commit_sha_buggy": "9ffe04fc1c96b399f085e0e4698c877acc9acac3",
                "commit_sha_fixed": "d8492ff5c2ed8834177f8a7dc9205b220d59df9a",
                "report_id": "6",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/6",
                "issue_title": "add support for custom type converters",
                "issue_description": "Hy, thanks for creating SansOrm, I really like the Idea and the Simplicity. One thing I am missing (or just haven't understood how it would be done) is how you would support more types.\n\nWhat do you think of this little demo implementation of type converters? The Interface is heavily inspired by what Hibernate offers.\n\nI created it to get a little demo with Postgres JSONB Type up and running, this would be the JSONB Converter:\n\n```\npackage at.paukl.springplay.domain.converter;\n\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.zaxxer.sansorm.Converter;\nimport org.postgresql.util.PGobject;\n\nimport java.io.IOException;\nimport java.util.Map;\n\n/**\n * @author Paul Klingelhuber\n */\npublic class PostgresJsonConverter implements Converter<Map, PGobject> {\n\n    private static final ObjectMapper objectMapper = new ObjectMapper();\n\n    @Override\n    public Map fromDb(PGobject dbValue) {\n        try {\n            return objectMapper.readValue(dbValue.getValue(), Map.class);\n        } catch (IOException e) {\n            throw new RuntimeException(\"problem reading json object\", e);\n        }\n    }\n\n    @Override\n    public PGobject toDb(Map javaValue) {\n        PGobject pGobject = new PGobject();\n        pGobject.setType(\"jsonb\");\n        try {\n            pGobject.setValue(objectMapper.writeValueAsString(javaValue));\n        } catch (Exception e) {\n            throw new RuntimeException(\"problem with json object\", e);\n        }\n        return pGobject;\n    }\n}\n```\n\nand this is an example class using it:\n\n```\n@Table(name=\"users\")\npublic class User {\n    @Id\n    @Column(name=\"id\")\n    public UUID id = UUID.randomUUID();\n\n    @Column(name=\"username\")\n    public String username;\n\n    @Column(name=\"email\")\n    public String email;\n\n    @Column(name=\"active\")\n    public boolean active;\n\n    @Column(name=\"config\")\n    @Convert(converter = PostgresJsonConverter.class)\n    public Map config;\n}\n```\n"
            },
            "4": {
                "commit_sha_buggy": "c7634fbb99a75d16a1c4642b65c8f35de80e9a8d",
                "commit_sha_fixed": "2f3f46f76c6d5bf1f9a2f6789adf97882a35fd89",
                "report_id": "16",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/16",
                "issue_title": "fixed id rewrite in OrmWriter::updateObject, fixed OrmWriter::insertListBatched",
                "issue_description": "- fixed generated id rewrite in OrmWriter::updateObject\r\n- fixed OrmWriter::insertListBatched\r\n- removed StringBuffer in OrmWriter::insertListNotBatched\r\n- removed string concat in OrmReader::countObjectsFromClause\r\n- more tests including SQLite-based in addition to H2-based"
            },
            "5": {
                "commit_sha_buggy": "4e91ac77aa5ddc4cb703eb1bded28018ec4f5097",
                "commit_sha_fixed": "d4f1a6673b2686d005e079cbf731ec3710886d8f",
                "report_id": "20",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/20",
                "issue_title": "fixed rollback behavior with TransactionManager, fixed RuntimeException handling",
                "issue_description": "- fixed RuntimeException handling in SqlClosure::execute\r\n- fixed rollback not rolling back anything when using TxTransactionManager"
            },
            "6": {
                "commit_sha_buggy": "42f37637fc5302b4964c2aec175be3ede197cf15",
                "commit_sha_fixed": "1d203160e79817c2d05c375cdf44c13a00b12076",
                "report_id": "22",
                "report_url": "https://github.com/brettwooldridge/SansOrm/issues/22",
                "issue_title": "Problem with upper case column names",
                "issue_description": "We use a sybase database with uppercase table and column names.\r\n\r\nIn Introspected#processColumnAnnotation the FieldColumnInfo.columnName is lower cased from the @Column annotation. This leads to errors with the SQL statements generated by SqlClosureElf. (changing the behavior of sybase requires a global modification of sorting on the sybase server and is not an option.)\r\n\r\nIs the toLowerCase() required for column names or can this be changed - in gereral or with a configurable default behavior?  \r\n\r\nBesides getting the column name from field name is not consistent.\r\nIf the field has a @Column annotation without name attribute, the field name is accepted as is. (line 475)\r\nIf the field has no annotation the field name will be lower cased. (line 501)"
            },
            "7": {
                "commit_sha_buggy": "cc5b6f98fdba83805e1c19173eeb57d3974a9286",
                "commit_sha_fixed": "efa96af07ff523db0728f1d017ab23f6fc5b82c5",
                "report_id": "24",
                "report_url": "https://github.com/brettwooldridge/SansOrm/pull/24",
                "issue_title": " Consistent case handling with regard to @Id and @Column annotations",
                "issue_description": "@brettwooldridge The PR fixes the inconsistent case handling of `@Id` annotated fields which have not also a `@Column` annotation. Now CaseSensitiveDatabasesTest#getIdColumnNames() behaves like CaseSensitiveDatabasesTest#getColumnsSansIds()."
            }
        }
    },
    "Snowleopard": {
        "owner_repo": "Nova41/SnowLeopard",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "edae59f210563ec8cd2588f7124b3a73d29109d8",
                "commit_sha_fixed": "743f8a43edc7757e9c1e8b9ea88d1b22ae16c418",
                "report_id": "8",
                "report_url": "https://github.com/Nova41/SnowLeopard/issues/8",
                "issue_title": "Cannot use command",
                "issue_description": "Same as the title, please fix. Ty!"
            }
        }
    },
    "Transmittable_thread_local": {
        "owner_repo": "alibaba/transmittable-thread-local",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8dbbbeb00ff9dce7fde0e08842d907c40d200a67",
                "commit_sha_fixed": "369eb23fd0b9bf28361526ba4df2ffdbf811e2ff",
                "report_id": "36",
                "report_url": "https://github.com/alibaba/transmittable-thread-local/issues/36",
                "issue_title": "com.alibaba.mtc.MtContextRunnable#get\u3001com.alibaba.mtc.MtContextCallable#get\u65b9\u6cd5\u4e0d\u5e94\u8be5\u5e42\u7b49",
                "issue_description": "\u8c03\u7528`com.alibaba.mtc.MtContextRunnable#get`\u3001`com.alibaba.mtc.MtContextCallable#get`\u65b9\u6cd5\u7684\u610f\u56fe\u662f\u4fdd\u5b58\u7684\u662f\u65b9\u6cd5\u8c03\u7528\u65f6\u7684\u7ebf\u7a0b\u4e0a\u4e0b\u6587\u3002\n\n\u8fd9\u6837\u65b9\u6cd5\u5982\u679c\u5e42\u7b49\uff0c\u5219\u5b9e\u9645\u6548\u679c\u662f\u4e4b\u524d\u751f\u6210\u7684`MtContextRunnable`\u3001`MtContextCallable`\u65f6\u6240\u4fdd\u5b58\u7684\u4e0a\u4e0b\u6587\u3002\u5373\u6293\u53d6\u7684\u4e0a\u4e0b\u6587\u662f\u9519\u7684\u3002\n\n\u5982\u679c\u4f20\u5165\u7684MtContextRunnable\u3001MtContextCallable\u5e94\u8be5 **FastFail**\uff01\u5b9e\u73b0\u4e0a\u53ef\u4ee5\u629b\u51fa`IllegalStateException`\u5f02\u5e38\u3002\n"
            },
            "2": {
                "commit_sha_buggy": "8845c164bbbe54bba9d85698e379f4b025d04e5a",
                "commit_sha_fixed": "acc0b3c0be6f2cdafdc7611b7b2ab977a10aeb2a",
                "report_id": "38",
                "report_url": "https://github.com/alibaba/transmittable-thread-local/issues/38",
                "issue_title": "MtContext\u7684\u8bbe\u7f6e\u548c\u6062\u590d\u65f6\u6ca1\u6709\u5904\u7406\u5b50\u4e2d\u591a\u4f59Key\u7684\u60c5\u51b5",
                "issue_description": "1. \u6062\u590d\u5b50\u65f6\u6ca1\u6709\u5904\u7406\u5b50\u4e2d\u591a\u4f59Key\u7684\u60c5\u51b5\uff0c\u7ed3\u679c\u662f\uff1a  \n   \u5b50\u6bd4\u7236\u591a\u7684MtContext\u88ab\u4fdd\u7559\u5728\u7559\u5728\u5b50\u4e2d\u3002\n2. \u8bbe\u7f6e\u5b50\u65f6\u6ca1\u6709\u5904\u7406\u5b50\u4e2d\u591a\u4f59Key\u7684\u60c5\u51b5\uff0c\u7ed3\u679c\u662f\uff1a  \n   \u5728\u8fd0\u884c\u5b50\u65f6\uff0c\u6709\u6bd4\u7236\u591a\u591a\u7684Context\uff01\n\n\u4e0a\u97622\u70b9\u5408\u8d77\u6765\uff0c\u7ed3\u679c\u662f\uff1a  \n\u5728\u5b50\u8fd0\u884c\u4e2d\u591a\u51fa\u6765\u7684Key\uff0c\u88ab\u4e00\u76f4\u4fdd\u7559\u4e86\u3002\n\n\u8fd9\u6253\u7834\u4e86MtContext\u6267\u884c\u65f6\u72ec\u7acb\u7684\u4e0a\u4e0b\u6587\u7684\u6548\u679c\u3002\n"
            },
            "3": {
                "commit_sha_buggy": "28b7a8858bd057ce8cf51602fd13e1c24f36c9f5",
                "commit_sha_fixed": "e5d5b73a949b4f3af3cbee3cd05fed17fc2f8f4f",
                "report_id": "54",
                "report_url": "https://github.com/alibaba/transmittable-thread-local/issues/54",
                "issue_title": "MtContextThreadLocal \u6ca1\u6709 afterExecute \u56de\u8c03",
                "issue_description": ""
            },
            "4": {
                "commit_sha_buggy": "acc0b3c0be6f2cdafdc7611b7b2ab977a10aeb2a",
                "commit_sha_fixed": "8845c164bbbe54bba9d85698e379f4b025d04e5a",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix extra context bug #38",
                "issue_description": "fix extra context bug #38"
            }
        }
    },
    "Xades4j": {
        "owner_repo": "luisgoncalves/xades4j",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "a6ba0f08195b3d2f79575a404af111189ecf38e7",
                "commit_sha_fixed": "02f0dde7d4ba81fc0224cdb2488c4e817855d165",
                "report_id": "135",
                "report_url": "https://github.com/luisgoncalves/xades4j/issues/135",
                "issue_title": "NullPointerException when processing SigPolicyQualifiers",
                "issue_description": "- https://stackoverflow.com/questions/47585633/xades4j-verify-signature-xades-epes-bad-xml-signature\r\n- Related to #63"
            },
            "2": {
                "commit_sha_buggy": "8707a45454fff25a136c6d39202210aa811fe656",
                "commit_sha_fixed": "195d2c273a880ce71d753e4785427f1e7e5e7ca1",
                "report_id": "152",
                "report_url": "https://github.com/luisgoncalves/xades4j/pull/152",
                "issue_title": "Added national certificate support if this contains ASN1 BMPString",
                "issue_description": "Added national certificate support if this contains ASN1 BMPString."
            },
            "3": {
                "commit_sha_buggy": "764cdc7c1742c2edd5bdf443f811d24801133765",
                "commit_sha_fixed": "e46aed92178e1775ad16ffb2677947f605c32c67",
                "report_id": "74",
                "report_url": "https://github.com/luisgoncalves/xades4j/issues/74",
                "issue_title": "CounterSignature with transforms on the SignatureValue reference",
                "issue_description": "```\nWhat steps will reproduce the problem?\n1. Verify a signature with a CounterSignature property that has transforms on \nthe SignatureValue reference.\n\nCounterSignatureVerifier assumes that the result of the reference after \ntransforms is a node. If not, getSubNode(9 returns null and the following \ncomparison fails:\n\nif (r.getContentsAfterTransformation().getSubNode() == targetSigValueElem)\n\nMaybe we could have some sort of fallback check: the content prior to \ntransforms has to be the SignatureValue element and then only a single C14N \ntransform is allowed.\n```\n\nOriginal issue reported on code.google.com by `luis.fgoncalv` on 12 Dec 2013 at 11:10\n"
            },
            "4": {
                "commit_sha_buggy": "7ba2a1879e75b5310019a320e7f0605d515bb382",
                "commit_sha_fixed": "9fcc76beaf33e75f447b248fc744fd6304d13357",
                "report_id": "199",
                "report_url": "https://github.com/luisgoncalves/xades4j/pull/199",
                "issue_title": "Fallback to SigningCertificate reference when processing KeyInfo",
                "issue_description": "Supports signatures without KeyInfo when the SigningCertificate property contains a single reference (most common use case)"
            }
        }
    },
    "Jchronic": {
        "owner_repo": "samtingleff/jchronic",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2c0e869d4c84141814f46af555dfab7c81255c30",
                "commit_sha_fixed": "90143a66460c006986d6f6f61c9d41d0aba5b309",
                "report_id": "9",
                "report_url": "https://github.com/samtingleff/jchronic/pull/9",
                "issue_title": "Improve parsing of two-digit years.",
                "issue_description": "This extends the behavior of ScalarYear when handling two digit years\r\n(and indeed any year in the range 1-137).  Previously, the code treated\r\nyears in the range 38-68 as errors, 69-99 as 19xx, and the rest as 20xx.\r\nThis change uses the PointerType value in the options to change the\r\nbehavior.  If PointerType.PAST is passed, 20-68 is treated as\r\n19xx (so you can parse birth dates for old people, for example).  If\r\nPointerType.FUTURE is passed then 1-68 is treated as 20xx.\r\nUsing PointerType.NONE treats 38-68 as an error, as before.\r\n\r\nNote that this is a change of behavior, because Options defaults to\r\nuse PointerType.FUTURE.  To get the old behavior back, you will need to\r\nset PointerType.NONE explicitly."
            }
        }
    },
    "Podam": {
        "owner_repo": "mtedone/podam",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "8603fca1b30246e5057547cbbc94c002792d95d0",
                "commit_sha_fixed": "0d7db70af839ee4ed8bcd4da7041fc2d1491f022",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Added test to check that Podam fills arrays and also fixed a problem\nwith checking accessibility of setter methods.",
                "issue_description": "Added test to check that Podam fills arrays and also fixed a problem\nwith checking accessibility of setter methods."
            }
        }
    },
    "Netconf_java": {
        "owner_repo": "Juniper/netconf-java",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "2d96b82a67feeabdcb930ae68b6148f1f2a04dc8",
                "commit_sha_fixed": "cf7e677116214f804e86455b53756d1f16b0904a",
                "report_id": "38",
                "report_url": "https://github.com/Juniper/netconf-java/pull/38",
                "issue_title": "Significantly improve performance",
                "issue_description": "I migrated from BufferedReader to InputStreamReader. It's faster in 7-10 times on some devices\r\n"
            }
        }
    },
    "Confluence_http_authenticator": {
        "owner_repo": "chauth/confluence_http_authenticator",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "42cafd4ef09b6b89ed836080daf0a5f82e5ba867",
                "commit_sha_fixed": "297439a52cf6aa143691d62ad9129cf8554f73d4",
                "report_id": "39",
                "report_url": "https://github.com/chauth/confluence_http_authenticator/pull/39",
                "issue_title": "#38: Added Test, fix StringUtils toList including empty string",
                "issue_description": "Test for issue 38, bugfix for last empty entry in remoteuser.replace config\n"
            }
        }
    },
    "Tempus_fugit": {
        "owner_repo": "tobyweston/tempus-fugit",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "690339611e13fe9fe9e00a3741bf6ca2cc5eef69",
                "commit_sha_fixed": "39636ac15f91cd3ab818aafe4f55efffaebbb658",
                "report_id": "14",
                "report_url": "https://github.com/tobyweston/tempus-fugit/pull/14",
                "issue_title": "Fix compareTo() method",
                "issue_description": "Pull request to fix https://github.com/tobyweston/tempus-fugit/issues/13\n"
            }
        }
    },
    "Jcabi_w3c": {
        "owner_repo": "jcabi/jcabi-w3c",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "64feb1ac523c5533910f345198b3132fb97b7df4",
                "commit_sha_fixed": "94a07dbaa8405615ab0ea38b661af5fd4f2c56df",
                "report_id": "49",
                "report_url": "https://github.com/jcabi/jcabi-w3c/issues/49",
                "issue_title": "fresh release",
                "issue_description": "let's release it"
            }
        }
    },
    "Jcabi_log": {
        "owner_repo": "jcabi/jcabi-log",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "3f02ba6d3517a22c94ce84518c0c983f4ab0d1cc",
                "commit_sha_fixed": "2aceab63f783f2d3df185ae91c63e24c8b8b9235",
                "report_id": "18",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/18",
                "issue_title": "VerboseRunnable doesn't restore interrupted status",
                "issue_description": "VerboseRunnable doesn't restore interrupted status of a thread\n"
            },
            "2": {
                "commit_sha_buggy": "73df1e85fb7c685d76116c1f2beb822fce5fba82",
                "commit_sha_fixed": "26c3188222aa135f719cb3341affdd833d49e65c",
                "report_id": "25",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/25",
                "issue_title": "SizeDecorTest.java:66-68: The SizeDecor class is not...",
                "issue_description": "Puzzle `26-9c2568b0` in `src/test/java/com/jcabi/log/SizeDecorTest.java:66-68` has to be resolved: The SizeDecor class is not implemented yet, that's why the test is not enabled at the moment. You should uncomment the lines below and make sure the test passes.\n"
            },
            "3": {
                "commit_sha_buggy": "89c9b350f04885cbbd2e825f1048d31feadea3e7",
                "commit_sha_fixed": "1dca5173252f1877cef07ead27d910c2eec173e6",
                "report_id": "31",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/31",
                "issue_title": "ObjectDecorTest.java:66-68: The ObjectDecor class is not...",
                "issue_description": "Puzzle `26-b04be6bf` in `src/test/java/com/jcabi/log/ObjectDecorTest.java:66-68` has to be resolved: The ObjectDecor class is not implemented yet, that's why the test is not enabled at the moment. You should uncomment the lines below and make sure the test passes.\n"
            },
            "4": {
                "commit_sha_buggy": "d4adbdb9378e2cc5e9b01d8e4e759f79c24b8891",
                "commit_sha_fixed": "80a6a8112664d68ca75bfcb0e613b0427a6bfe8d",
                "report_id": "20",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/20",
                "issue_title": "%n in Logger formatting string leads to problem",
                "issue_description": "Try this:\n\n```\nLogger.info(this, \"Number: %d %n Text: %s\", 1, \"foo\");\n```\n\nRuntime exception will be thrown.\n"
            },
            "5": {
                "commit_sha_buggy": "d4adbdb9378e2cc5e9b01d8e4e759f79c24b8891",
                "commit_sha_fixed": "9b4a79523ff6fde413c61d84b7d6612af9c09270",
                "report_id": "20",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/20",
                "issue_title": "%n in Logger formatting string leads to problem",
                "issue_description": "Try this:\n\n```\nLogger.info(this, \"Number: %d %n Text: %s\", 1, \"foo\");\n```\n\nRuntime exception will be thrown.\n"
            },
            "6": {
                "commit_sha_buggy": "9077b2e02b3811584824dc5a65854b400132e97d",
                "commit_sha_fixed": "5c0a3caebc55357a528378921d68ff9a582f5143",
                "report_id": "74",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/74",
                "issue_title": "VerboseProcess should fail if logging level was initialized to Level.ALL",
                "issue_description": "Very often `VerboseProcess` is used with following parameters:\n\n```\nnew VerboseProcess(builder, Level.ALL, Level.ALL);\n```\n\nWhich contrary to most people assumptions doesn't make the `VerboseProcess` log all the events but makes it log none of them (`Level.ALL` is lower than `Level.FINEST`, and very few projects set the log level to `FINEST`).\n\n`VerboseProcess` should fail if created with `Level.ALL` parameters.\n"
            },
            "7": {
                "commit_sha_buggy": "18989e89880a3a127861933bc51f008d787e566a",
                "commit_sha_fixed": "d970e85a4902390fd13474552a8274a19492eabe",
                "report_id": "74",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/74",
                "issue_title": "VerboseProcess should fail if logging level was initialized to Level.ALL",
                "issue_description": "Very often `VerboseProcess` is used with following parameters:\n\n```\nnew VerboseProcess(builder, Level.ALL, Level.ALL);\n```\n\nWhich contrary to most people assumptions doesn't make the `VerboseProcess` log all the events but makes it log none of them (`Level.ALL` is lower than `Level.FINEST`, and very few projects set the log level to `FINEST`).\n\n`VerboseProcess` should fail if created with `Level.ALL` parameters.\n"
            },
            "8": {
                "commit_sha_buggy": "8c3bf0e2cec2061da13a66bf8bfce32a07ab1f44",
                "commit_sha_fixed": "4ee530d5ff8f77439beb2b823ebd4842bcab9e60",
                "report_id": "100",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/100",
                "issue_title": "Logger.format() can't process args with positions",
                "issue_description": ""
            },
            "9": {
                "commit_sha_buggy": "93204bf9d308c72d939cfecd36fa5634c9bb5634",
                "commit_sha_fixed": "7949002287937af03e944ad74724211f02648474",
                "report_id": "103",
                "report_url": "https://github.com/jcabi/jcabi-log/issues/103",
                "issue_title": "Logger fails to build complex strings with positional substitutes",
                "issue_description": ""
            }
        }
    },
    "Jcabi_matchers": {
        "owner_repo": "jcabi/jcabi-matchers",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "66329fbcf8ab66a29969a49257c25ecaa14a7b11",
                "commit_sha_fixed": "466c60fc235186963f92d78ba1b2802d33cdc6f0",
                "report_id": "10",
                "report_url": "https://github.com/jcabi/jcabi-matchers/issues/10",
                "issue_title": "RegexMatchers",
                "issue_description": "When I was working on https://github.com/jcabi/jcabi-aspects/pull/88, I needed to create a unit test that used Regex matching as its assertion condition. I realized that Hamcrest did not have built-in matchers for regex. I think it will be very useful if we can have one as standard.\n\nI propose that we create a class `RegexMatchers`, which will initially have the following methods:\n- `Matcher<String> matchesPattern(String pattern)`: returns a `Matcher` that checks if the entire string matches the given pattern (should work like the [String.matches() method](http://docs.oracle.com/javase/7/docs/api/java/lang/String.html#matches%28java.lang.String%29)).\n- `Matcher<String> containsPattern(String pattern)`: returns a `Matcher` that checks if a string contains a subsequence that matches the given pattern (similar to [Matcher.find() method](http://docs.oracle.com/javase/7/docs/api/java/util/regex/Matcher.html#find%28%29)).\n"
            },
            "2": {
                "commit_sha_buggy": "466c60fc235186963f92d78ba1b2802d33cdc6f0",
                "commit_sha_fixed": "540d11dc42453ab14752a104cf6dfbfc540ccc7c",
                "report_id": "10",
                "report_url": "https://github.com/jcabi/jcabi-matchers/issues/10",
                "issue_title": "RegexMatchers",
                "issue_description": "When I was working on https://github.com/jcabi/jcabi-aspects/pull/88, I needed to create a unit test that used Regex matching as its assertion condition. I realized that Hamcrest did not have built-in matchers for regex. I think it will be very useful if we can have one as standard.\n\nI propose that we create a class `RegexMatchers`, which will initially have the following methods:\n- `Matcher<String> matchesPattern(String pattern)`: returns a `Matcher` that checks if the entire string matches the given pattern (should work like the [String.matches() method](http://docs.oracle.com/javase/7/docs/api/java/lang/String.html#matches%28java.lang.String%29)).\n- `Matcher<String> containsPattern(String pattern)`: returns a `Matcher` that checks if a string contains a subsequence that matches the given pattern (similar to [Matcher.find() method](http://docs.oracle.com/javase/7/docs/api/java/util/regex/Matcher.html#find%28%29)).\n"
            }
        }
    },
    "Leshan_core": {
        "owner_repo": "eclipse/leshan",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f8e3b9d984508be16fad90a990cd15533c3f59ff",
                "commit_sha_fixed": "8a4c9c7a63ebae24331c067c1c9e43b9220b36bc",
                "report_id": "200",
                "report_url": "https://github.com/eclipse/leshan/issues/200",
                "issue_title": "server cannot read null object link",
                "issue_description": "Hello there,\r\nI am testing the object link feature and found this issue.\r\n\r\nWhen a client sends an object link of MAX ID: MAX ID, that is, 65535:65535 to the server,\r\nthe server errs with\r\n```\r\n[2016-11-10 18:53:38,569 WARN ClientServlet] Invalid request or response\r\njava.lang.IllegalArgumentException: The validated expression is false\r\n        at org.eclipse.leshan.util.Validate.isTrue(Validate.java:182) ~[leshan-server-demo-0.1.11-M15-SNAPSHOT-jar-with-dependencies.jar:?]\r\n        at org.eclipse.leshan.core.node.ObjectLink.<init>(ObjectLink.java:46) ~[leshan-server-demo-0.1.11-M15-SNAPSHOT-jar-with-dependencies.jar:?]\r\n        at org.eclipse.leshan.tlv.TlvDecoder.decodeObjlnk(TlvDecoder.java:196) ~[leshan-server-demo-0.1.11-M15-SNAPSHOT-jar-with-dependencies.jar:?]\r\n```\r\n\r\nI doubt this is because TlvDecoder.decodeObjlnk() does not properly treat unsigned integer and converts 65535 into -1, which cannot pass the test at ObjectLink().\r\nHope that helps.\r\nThank you."
            },
            "2": {
                "commit_sha_buggy": "69881c0d1a588b268c6cdf70002931a16c9e6606",
                "commit_sha_fixed": "ba3a1039db31266b6747f0d20c0398a7c02accfd",
                "report_id": "416",
                "report_url": "https://github.com/eclipse/leshan/issues/416",
                "issue_title": "Server displaying incorrect for multiple object links information is sent from the client.",
                "issue_description": "Hello there,\r\n\r\nI am testing the object link feature and found this issue.\r\n\r\nWhen the client sends multiple object links of 0x00640001 (100:1) and 0x0065002(100:2) to the Leshan server, for some reason it only displays in the following format in the GUI. I don't see multiple object links in the server.\r\n\r\nResource 22           /3/0/22          Observe Read Write            0=0,0,6,5,0,0,0,2\r\n\r\nHere is the sample hexdump of the COAP + LWM2M packet being sent to the server. \r\n\r\n65 45 5d cf c1 99 af a5 d7 c2 2d 16 ff 88  \r\n16 0c 44 00 00 64 00 01 44 00 00 65 00 02 \r\n\r\nCan you please let me know if the scenario is supported or is there any issue from the server side.\r\n\r\nHope that helps.\r\n\r\nThank you."
            },
            "3": {
                "commit_sha_buggy": "ee77166041fc7afc843b432795663fde97d86eb9",
                "commit_sha_fixed": "b6bfe60c079cd3a66b96ff95870e11d78ea9673c",
                "report_id": "463",
                "report_url": "https://github.com/eclipse/leshan/issues/463",
                "issue_title": "Client responds TLV payload not including Object Instance ID",
                "issue_description": "When I send a Read request to leshan client demo to read object /3 and /6. The client responds TLV payload not including the Object Instance ID.\r\n\r\nBut in LwM2M Technical Specification. It show even Request on Single-Instance Object. The responds TLV payload should including the Object Instance ID and all its readable Resources. \r\n\r\nLwM2M Technical Specification 6.4.3.2:\r\n![tlv](https://user-images.githubusercontent.com/13583992/35675637-b7bc0fb2-0783-11e8-8b0d-a377ee7cc6f0.png)\r\n\r\nThe leshan client demo responds TLV payload:\r\n```\r\n// Read /3 with TLV Format\r\n<Buffer c8 00 12 4c 65 73 68 61 6e 20 44 65 6d 6f 20 44 65 76 69 63 65 c8 01 09 4d 6f 64 65 \r\n  6c 20 35 30 30 c8 02 0f 4c 54 2d 35 30 30 2d 30 30 30 2d 30 30 30 31 c5 03 31 2e 30 2e 30 \r\n  c1 09 34 c4 0a 00 00 94 dd 83 0b 41 00 00 c4 0d 5a 72 e9 26 c3 0e 2b 30 38 c8 0f 0b 41 73 \r\n  69 61 2f 54 61 69 70 65 69 c1 10 55 c4 11 44 65 6d 6f c5 12 31 2e 30 2e 31 c5 13 31 2e 30 \r\n  2e 32 c1 14 04 c4 15 00 00 b8 00 >\r\n\r\n// Read /6 with TLV Format\r\n<Buffer c8 00 08 c0 35 00 00 00 00 00 00 c8 01 08 40 59 00 00 00 00 00 00 c4 05 5a 72 eb df>\r\n```\r\n\r\n"
            },
            "4": {
                "commit_sha_buggy": "4b6c499be08e3afd0a83a38a58133b63ebec2702",
                "commit_sha_fixed": "932bd6bf72c40b7be487bf151fc1691132396e40",
                "report_id": "429",
                "report_url": "https://github.com/eclipse/leshan/issues/429",
                "issue_title": "Raise CodecExpection if 2 node has the same Id for the same parent",
                "issue_description": "a TLV (or JSON) payload could contain identifier conflict : 2 (or more) nodes with the same id for the same parent.\r\nIt that case Leshan just keep the last one and throw out the others silently.\r\nWe should raise a `CodecException` instead.\r\n\r\nThis issue was fixed for TLV at resource instance level : #426.\r\nBut we should check resource and instance level for TLV (and maybe JSON...)"
            },
            "5": {
                "commit_sha_buggy": "d2ff1dbee1b35bc6b8fdd25c39967b64e61e31e8",
                "commit_sha_fixed": "7ce3ead6608caebf5f542be845b22bc8c67f288d",
                "report_id": "429",
                "report_url": "https://github.com/eclipse/leshan/issues/429",
                "issue_title": "Raise CodecExpection if 2 node has the same Id for the same parent",
                "issue_description": "a TLV (or JSON) payload could contain identifier conflict : 2 (or more) nodes with the same id for the same parent.\r\nIt that case Leshan just keep the last one and throw out the others silently.\r\nWe should raise a `CodecException` instead.\r\n\r\nThis issue was fixed for TLV at resource instance level : #426.\r\nBut we should check resource and instance level for TLV (and maybe JSON...)"
            },
            "6": {
                "commit_sha_buggy": "77e0a3e1e05888a086ef4ecf03c053ce317242e4",
                "commit_sha_fixed": "2ba42bc8db8eca5fc3b7d85767b0c639c15027ff",
                "report_id": "460",
                "report_url": "https://github.com/eclipse/leshan/issues/460",
                "issue_title": "CodecException during read request with Id conflict between path and resource TLV.",
                "issue_description": "CodecException occurred while reading a single instance resource value (lifetime) of LWM2M server object.\r\nPath : [1/0/1].\r\n**Exception message:**\r\n```\r\norg.eclipse.leshan.core.request.exception.InvalidResponseException: Unable to decode response payload of request [ReadRequest [path=/10245/0/4 format=ContentFormat [name=TLV, code=11542]]] from client\r\n...\r\nCaused by: org.eclipse.leshan.core.node.codec.CodecException: Id conflict between path [/1/0/1] and resource TLV [0]\r\n\tat org.eclipse.leshan.core.node.codec.tlv.LwM2mNodeTlvDecoder.parseTlv(LwM2mNodeTlvDecoder.java:134) ~[LWM2M_Mediator-1.0.M3.jar:1.0]\r\n```\r\n\r\n**Response from the client:**\r\n<img width=\"470\" alt=\"tlv_response\" src=\"https://user-images.githubusercontent.com/22880479/35106558-8db29aaa-fc94-11e7-94d8-5f2ef05ffa3b.PNG\">\r\n\r\n**Full stack trace of exception**\r\n[TLVCodecException.log](https://github.com/eclipse/leshan/files/1643430/TLVCodecException.log)\r\n\r\nIs it server issue or invalid reponse from client"
            },
            "7": {
                "commit_sha_buggy": "f512b574797e852f8e883641ab0df852bebb7fcd",
                "commit_sha_fixed": "6817e749d5d32e9978e463008c362242c57bb540",
                "report_id": "775",
                "report_url": "https://github.com/eclipse/leshan/issues/775",
                "issue_title": "CoRE Link serialization",
                "issue_description": "Hi,\r\n\r\nI was using the Leshan Client to test something on my own Server implementation. But when I tried to connect it on the Server, I ended up with a 4.00 (Bad Request) from the Server just after it has received the Registration message.\r\n\r\n![image](https://user-images.githubusercontent.com/31616285/69233580-6fab1a00-0b8d-11ea-8c43-388511ec1159.png)\r\n\r\nAfter have checked in my code, it seems the issue was raised due to the whitespace in the CoRE Link payload which seems to come from https://github.com/eclipse/leshan/blob/master/leshan-core/src/main/java/org/eclipse/leshan/Link.java#L162.\r\n\r\nSo, I read the CoRE Link RFC (https://tools.ietf.org/html/rfc6690#section-2). From my understanding, I think the whitespace are not allowed in this format:\r\n\r\nThere seems to be a reference here:\r\n> In order to convert an HTTP Link Header field to this link format, first the \"Link:\" HTTP header is removed, any linear whitespace (LWS) is removed, the header value is converted to UTF-8, and any percent-encodings are decoded.\r\n\r\nBut I think this is just when an HTTP Link header field is converted into CoRE Link format.\r\n\r\nBut maybe I'm totally wrong :) I entered this issue to open a debate."
            },
            "8": {
                "commit_sha_buggy": "983b21eedc0cd9a18f789124987cba7231f4ab83",
                "commit_sha_fixed": "c8712dd99ef5e3ab9601de2b4dc6c4d85fe694bf",
                "report_id": "677",
                "report_url": "https://github.com/eclipse/leshan/pull/677",
                "issue_title": "LwM2mNodeSenMLEncoder for SenML-JSON in leshan-core with unit tests",
                "issue_description": "Signed-off-by: Boya Zhang <zhangboya@gmail.com>\r\n\r\nLwM2mNodeSenMLEncoder for SenML-JSON in leshan-core with unit tests\r\n- LwM2mNodeSenMLEncoder will use to encode LwM2M nodes with SenML-JSON and later SenML CBOR formats.\r\n- New test cases in LwM2mNodeEncoderTest hasn't use DefaultLwM2mNodeEncoder, because of it doesn't include SenML-JSON yet, as will be updated in later PR. "
            },
            "9": {
                "commit_sha_buggy": "64c0ba619498bba6db10797c3baac4749f82bc77",
                "commit_sha_fixed": "b6528f3fe1541e2b8965ee2f85e1803974f49d81",
                "report_id": "915",
                "report_url": "https://github.com/eclipse/leshan/issues/915",
                "issue_title": "Add support of empty multi instance resource to SenML format",
                "issue_description": "Wait clarification from OMA : https://github.com/OpenMobileAlliance/OMA_LwM2M_for_Developers/issues/494"
            },
            "10": {
                "commit_sha_buggy": "eb336976172cf943b4b8db4603352bd3dd0ebeab",
                "commit_sha_fixed": "ca740491db975b23e45475c9b8584ae40b799183",
                "report_id": "1170",
                "report_url": "https://github.com/eclipse/leshan/issues/1170",
                "issue_title": "LwM2mNodeSenMLDecoder sometimes fails trying to convert from double to long",
                "issue_description": "Hi,\r\n\r\nWe are using Leshan 2.0.0-M5.\r\nIn the log files I sometimes see that when reading currentTime resource from device object (3/0/13) decoding sometimes fails with the following exception:\r\n\r\n08:50:47 [CoapServer(main)#27] ERROR c.n.s.d.s.s.d.ManagerImpl - Endpoint 94193A0407000000: Read request for path 3 failed with exception: {}\r\norg.eclipse.leshan.core.request.exception.InvalidResponseException: Unable to decode response payload of request [ReadRequest [path=/3 format=null]] from client [94193A0407000000]\r\n\tat org.eclipse.leshan.server.californium.request.LwM2mResponseBuilder.decodeCoapResponse(LwM2mResponseBuilder.java:458)\r\n\tat org.eclipse.leshan.server.californium.request.LwM2mResponseBuilder.visit(LwM2mResponseBuilder.java:122)\r\n\tat org.eclipse.leshan.core.request.ReadRequest.accept(ReadRequest.java:187)\r\n\tat org.eclipse.leshan.server.californium.request.RequestSender$2.buildResponse(RequestSender.java:226)\r\n\tat org.eclipse.leshan.core.californium.AsyncRequestObserver$1.onResponse(AsyncRequestObserver.java:60)\r\n\tat org.eclipse.leshan.core.californium.CoapAsyncRequestObserver.onResponse(CoapAsyncRequestObserver.java:99)\r\n\tat org.eclipse.californium.core.coap.Request.setResponse(Request.java:931)\r\n\tat org.eclipse.californium.core.server.ServerMessageDeliverer.deliverResponse(ServerMessageDeliverer.java:258)\r\n\tat org.eclipse.californium.core.network.stack.BaseCoapStack$StackTopAdapter.receiveResponse(BaseCoapStack.java:217)\r\n\tat org.eclipse.californium.core.network.stack.AbstractLayer.receiveResponse(AbstractLayer.java:89)\r\n\tat org.eclipse.californium.core.network.stack.ExchangeCleanupLayer.receiveResponse(ExchangeCleanupLayer.java:105)\r\n\tat org.eclipse.californium.core.network.stack.ObserveLayer.receiveResponse(ObserveLayer.java:139)\r\n\tat org.eclipse.californium.core.network.stack.BlockwiseLayer.receiveResponse(BlockwiseLayer.java:776)\r\n\tat org.eclipse.californium.core.network.stack.ReliabilityLayer.receiveResponse(ReliabilityLayer.java:308)\r\n\tat org.eclipse.californium.core.network.stack.AbstractLayer.receiveResponse(AbstractLayer.java:89)\r\n\tat org.eclipse.californium.core.network.stack.BaseCoapStack.receiveResponse(BaseCoapStack.java:146)\r\n\tat org.eclipse.californium.core.network.CoapEndpoint$1.receiveResponse(CoapEndpoint.java:314)\r\n\tat org.eclipse.californium.core.network.UdpMatcher$4.run(UdpMatcher.java:457)\r\n\tat org.eclipse.californium.elements.util.SerialExecutor$1.run(SerialExecutor.java:290)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: org.eclipse.leshan.core.node.codec.CodecException: Invalid content [1.638435E9] for type TIME for path /3/0/13\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.parseResourceValue(LwM2mNodeSenMLDecoder.java:504)\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.extractLwM2mResources(LwM2mNodeSenMLDecoder.java:426)\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.parseRecords(LwM2mNodeSenMLDecoder.java:193)\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.decode(LwM2mNodeSenMLDecoder.java:97)\r\n\tat org.eclipse.leshan.core.node.codec.DefaultLwM2mDecoder.decode(DefaultLwM2mDecoder.java:156)\r\n\tat org.eclipse.leshan.core.node.codec.DefaultLwM2mDecoder.decode(DefaultLwM2mDecoder.java:138)\r\n\tat org.eclipse.leshan.server.californium.request.LwM2mResponseBuilder.decodeCoapResponse(LwM2mResponseBuilder.java:450)\r\n\t... 21 common frames omitted\r\nCaused by: java.lang.IllegalStateException: Can not convert 1.638435E9 to long safely : Unsupported number java.lang.Double\r\n\tat org.eclipse.leshan.core.util.datatype.NumberUtil.numberToLong(NumberUtil.java:59)\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.numberToLong(LwM2mNodeSenMLDecoder.java:527)\r\n\tat org.eclipse.leshan.core.node.codec.senml.LwM2mNodeSenMLDecoder.parseResourceValue(LwM2mNodeSenMLDecoder.java:493)\r\n\t... 27 common frames omitted\r\n\r\nBest regards,\r\nSonny"
            }
        }
    },
    "Geo": {
        "owner_repo": "davidmoten/geo",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "53df045efb373d892d228309ceba0353854e2e89",
                "commit_sha_fixed": "33c5f2f0ae0fc10d684065fccb2a4d2285f5cb9d",
                "report_id": "29",
                "report_url": "https://github.com/davidmoten/geo/issues/29",
                "issue_title": "GeoHash#encodeHash(double, double, int) allows invalid 'length'",
                "issue_description": "Nested call to GeoHash#fromLongToString(long) does a range check on a hash, but only catches some invalid cases. I can pass in 20 for the length in encodeHash() for example and I wind up with a shorter hash instead of an error. Passing in 13 for the length throws an error."
            },
            "2": {
                "commit_sha_buggy": "53df045efb373d892d228309ceba0353854e2e89",
                "commit_sha_fixed": "ae81f9ef3e906292c370d1f37d58eddd47accafa",
                "report_id": "30",
                "report_url": "https://github.com/davidmoten/geo/pull/30",
                "issue_title": "fix #29 add precondition check for encodeHash length parameter",
                "issue_description": "as per title, added 3 units and preconditions check"
            },
            "3": {
                "commit_sha_buggy": "b4b3e154775a68170e7f482967c472e792d995b9",
                "commit_sha_fixed": "3ba1a448525449c79137f51bfc5cf9bc489d3930",
                "report_id": "49",
                "report_url": "https://github.com/davidmoten/geo/pull/49",
                "issue_title": "Fix wrong coverage around antimeridian",
                "issue_description": "We cannot use `GeoHash.coverBoundingBox` method with a bounding box around antimeridian (180/-180) because it does not allow bottomRightLon to be lower than topLeftLon (Google Maps behavior) or it does not handle correctly longitude outside [-180, 180] range (Leaflet behavior).\r\n\r\nThis pull request addresses this use case and also fixes issues in #25 and #34.\r\n\r\nNow the `GeoHash.coverBoundingBoxLongs`  method allow more longitudes values in input. For instance, these values are accepted (see unit tests):\r\n- topLeftLon = 156 and bottomRightLon = -118\r\n- topLeftLon = -204 and bottomRightLon = -121\r\n- topLeftLon = -703 and bottomRightLon = 624\r\n"
            }
        }
    },
    "Jackson_annotations": {
        "owner_repo": "FasterXML/jackson-annotations",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "818991398a2270b9f132454ba52f2d56f3c87b47",
                "commit_sha_fixed": "dc91111f36cafa427a7b9d30da3a13cd43d1fb02",
                "report_id": "76",
                "report_url": "https://github.com/FasterXML/jackson-annotations/issues/76",
                "issue_title": "(2.7.0-rc1) JsonInclude.Value.withOverrides() not working wrt content inclusion",
                "issue_description": "Looks like testing for \"withOverrides()\" failed to find a problem, where content inclusion merging does not always work correctly. Needs to be fixed for2.7.0-rc2.\n"
            }
        }
    },
    "Rtree2": {
        "owner_repo": "davidmoten/rtree2",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "81a212e43e9649cf6181a6ef40572ee180509826",
                "commit_sha_fixed": "98bac668a8b3856d18ca6037886c4e7361d25d33",
                "report_id": "21",
                "report_url": "https://github.com/davidmoten/rtree2/pull/21",
                "issue_title": "Bump mockito-core from 4.4.0 to 4.5.0",
                "issue_description": "Bumps [mockito-core](https://github.com/mockito/mockito) from 4.4.0 to 4.5.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/mockito/mockito/releases\">mockito-core's releases</a>.</em></p>\n<blockquote>\n<h2>v4.5.0</h2>\n<p><!-- raw HTML omitted --><!-- raw HTML omitted --><em>Changelog generated by <a href=\"https://github.com/shipkit/shipkit-changelog\">Shipkit Changelog Gradle Plugin</a></em><!-- raw HTML omitted --><!-- raw HTML omitted --></p>\n<h4>4.5.0</h4>\n<ul>\n<li>2022-04-19 - <a href=\"https://github.com/mockito/mockito/compare/v4.4.0...v4.5.0\">15 commit(s)</a> by Andrei Silviu Dragnea, Rafael Winterhalter, Rick Ossendrijver, dependabot[bot]</li>\n<li>Bump versions.errorprone from 2.13.0 to 2.13.1 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2621\">#2621</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2621\">mockito/mockito#2621</a>)</li>\n<li>Bump versions.errorprone from 2.12.1 to 2.13.0 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2619\">#2619</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2619\">mockito/mockito#2619</a>)</li>\n<li>Groovy inline [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2618\">#2618</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2618\">mockito/mockito#2618</a>)</li>\n<li>Bump actions/setup-java from 2 to 3 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2615\">#2615</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2615\">mockito/mockito#2615</a>)</li>\n<li>Bump versions.bytebuddy from 1.12.8 to 1.12.9 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2614\">#2614</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2614\">mockito/mockito#2614</a>)</li>\n<li>Support subclass mocks on Graal VM. [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2613\">#2613</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2613\">mockito/mockito#2613</a>)</li>\n<li>Bump com.diffplug.spotless from 6.4.1 to 6.4.2 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2611\">#2611</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2611\">mockito/mockito#2611</a>)</li>\n<li>Bump kotlinx-coroutines-core from 1.6.0-native-mt to 1.6.1-native-mt [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2609\">#2609</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2609\">mockito/mockito#2609</a>)</li>\n<li>Bump versions.errorprone from 2.10.0 to 2.12.1 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2608\">#2608</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2608\">mockito/mockito#2608</a>)</li>\n<li>Bump kotlinVersion from 1.6.10 to 1.6.20 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2607\">#2607</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2607\">mockito/mockito#2607</a>)</li>\n<li>Bump com.diffplug.spotless from 6.4.0 to 6.4.1 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2606\">#2606</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2606\">mockito/mockito#2606</a>)</li>\n<li>Bump com.diffplug.spotless from 6.3.0 to 6.4.0 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2605\">#2605</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2605\">mockito/mockito#2605</a>)</li>\n<li>Bump org.eclipse.osgi from 3.17.100 to 3.17.200 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2597\">#2597</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2597\">mockito/mockito#2597</a>)</li>\n<li>Deprecate ListUtil and Fields classes [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2593\">#2593</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/pull/2593\">mockito/mockito#2593</a>)</li>\n<li>mockito-errorprone seems not compatible with ErrorProne 2.11.0 [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2554\">#2554</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2554\">mockito/mockito#2554</a>)</li>\n<li>NullPointerException from Groovy metaclass methods when using mockito-inline (but not mockito-core) [(<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2522\">#2522</a>)](<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2522\">mockito/mockito#2522</a>)</li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/mockito/mockito/commit/2c0bf94609300ed369198c3bd44c1555e88f8998\"><code>2c0bf94</code></a> Merge pull request <a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2613\">#2613</a> from mockito/graal-support</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/d23dc0e57a8360c8d80f69096cee24c20e4c7c26\"><code>d23dc0e</code></a> Support subclass mocks on Graal VM.</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/8314824b2c83aff91db140b58de7d9e7d9be5ebf\"><code>8314824</code></a> Bump versions.errorprone from 2.13.0 to 2.13.1 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2621\">#2621</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/20f16278286b23aa8101cc646b4567560a432224\"><code>20f1627</code></a> Bump kotlinx-coroutines-core from 1.6.0-native-mt to 1.6.1-native-mt (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2609\">#2609</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/d539af2d7afdcfaf1eda4a57911d7f9df107db2a\"><code>d539af2</code></a> Fix mockito-inline for Groovy projects (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2618\">#2618</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/2947e9daf76a97fe179606248d5f1f5e040129a0\"><code>2947e9d</code></a> Bump versions.errorprone from 2.12.1 to 2.13.0 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2619\">#2619</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/09ba42033e5d81385286fc8bb651bf3bb9865ec2\"><code>09ba420</code></a> Bump actions/setup-java from 2 to 3 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2615\">#2615</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/98b5ff9f4df143eb5bf91aae2ad51a1f91624b0b\"><code>98b5ff9</code></a> Bump versions.bytebuddy from 1.12.8 to 1.12.9 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2614\">#2614</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/e2fa1c95de728ef7e67f9be1e9a09f65fdac8d6a\"><code>e2fa1c9</code></a> Bump com.diffplug.spotless from 6.4.1 to 6.4.2 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2611\">#2611</a>)</li>\n<li><a href=\"https://github.com/mockito/mockito/commit/331ff01c5f840ff8a3c5b0859185ba78f9446cf0\"><code>331ff01</code></a> Bump versions.errorprone from 2.10.0 to 2.12.1 (<a href=\"https://github-redirect.dependabot.com/mockito/mockito/issues/2608\">#2608</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/mockito/mockito/compare/v4.4.0...v4.5.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.mockito:mockito-core&package-manager=maven&previous-version=4.4.0&new-version=4.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            },
            "2": {
                "commit_sha_buggy": "b17a51128636b6cbc24935c3eb2f33612dca1f7e",
                "commit_sha_fixed": "7019ef296bf1fa731ccea37eed2224d79618e62d",
                "report_id": "33",
                "report_url": "https://github.com/davidmoten/rtree2/pull/33",
                "issue_title": "Bump maven-bundle-plugin from 5.1.7 to 5.1.8",
                "issue_description": "Bumps maven-bundle-plugin from 5.1.7 to 5.1.8.\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.felix:maven-bundle-plugin&package-manager=maven&previous-version=5.1.7&new-version=5.1.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            },
            "3": {
                "commit_sha_buggy": "f158eab63606b7339bf6f94e3f6ded9b031f7257",
                "commit_sha_fixed": "bb3b0b3b773630a286a9e16797aad2861ebf0765",
                "report_id": "34",
                "report_url": "https://github.com/davidmoten/rtree2/pull/34",
                "issue_title": "Bump maven-site-plugin from 3.12.0 to 3.12.1",
                "issue_description": "Bumps [maven-site-plugin](https://github.com/apache/maven-site-plugin) from 3.12.0 to 3.12.1.\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/ecae28fb0990eb5a7fc8f2d4ffe07f348d927f4b\"><code>ecae28f</code></a> [maven-release-plugin] prepare release maven-site-plugin-3.12.1</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/d98569b083ded7a5182bf6cb5814ddcbd3150267\"><code>d98569b</code></a> [MSITE-908] Upgrade Maven Reporting API to 3.1.1</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/bd3376f52d0053e05c78327aad39353710702a7a\"><code>bd3376f</code></a> [MSITE-901] If precending standalone report has been run, site:jar does not r...</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/b99c0ef371774a414ade764f2921bdfe8918ed60\"><code>b99c0ef</code></a> [MSITE-902] Upgrade Plexus Utils to 3.4.2</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/3c6ff2e285063231b7042bfe7875871c9d339830\"><code>3c6ff2e</code></a> Update CI URL</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/f314e9da6ba0b5611fd5dd7dcff2d9ecc36dcd61\"><code>f314e9d</code></a> [MSITE-898] Upgrade Parent to 36</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/bce7458375464e58f5d2d6cff92f8dde5f45de67\"><code>bce7458</code></a> [MSITE-897] Upgrade Plexus Archiver to 4.2.7</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/3c8d426aae79c793a2a3acfddbd47a6826346382\"><code>3c8d426</code></a> keep only release month, drop day</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/6604ab3b53d3f4045cc755340aeb0c4feaeaf8df\"><code>6604ab3</code></a> also keep only Doxia versions changes</li>\n<li><a href=\"https://github.com/apache/maven-site-plugin/commit/789a7a1054babde3c5b01e48bbf8abca49f5af8f\"><code>789a7a1</code></a> lighten content: keep only meaningful values</li>\n<li>Additional commits viewable in <a href=\"https://github.com/apache/maven-site-plugin/compare/maven-site-plugin-3.12.0...maven-site-plugin-3.12.1\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.maven.plugins:maven-site-plugin&package-manager=maven&previous-version=3.12.0&new-version=3.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            },
            "4": {
                "commit_sha_buggy": "3f5a55d7fa0308cb7ceac846a2ae24be8799e0a8",
                "commit_sha_fixed": "c74e1b397b7caa3771c679eaf48b4d95c18cded4",
                "report_id": "40",
                "report_url": "https://github.com/davidmoten/rtree2/pull/40",
                "issue_title": "Bump maven-pmd-plugin from 3.18.0 to 3.19.0",
                "issue_description": "Bumps [maven-pmd-plugin](https://github.com/apache/maven-pmd-plugin) from 3.18.0 to 3.19.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/apache/maven-pmd-plugin/releases\">maven-pmd-plugin's releases</a>.</em></p>\n<blockquote>\n<h2>3.19.0</h2>\n<!-- raw HTML omitted -->\n<h2>\ud83d\udc1b Bug Fixes</h2>\n<ul>\n<li><a href=\"https://issues.apache.org/jira/browse/MPMD-353\">[MPMD-353]</a> - API incompatibility with jansi after upgrading m-shared-\u2026 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/91\">#91</a>) <a href=\"https://github.com/adangel\"><code>@\u200badangel</code></a></li>\n</ul>\n<h2>\ud83d\udce6 Dependency updates</h2>\n<ul>\n<li>Bump animal-sniffer-maven-plugin from 1.21 to 1.22 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/88\">#88</a>) <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a></li>\n<li>Bump wiremock from 1.49 to 2.27.2 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/57\">#57</a>) <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/MPMD-354\">[MPMD-354]</a> - Upgrade to PMD 6.49.0 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/92\">#92</a>) <a href=\"https://github.com/adangel\"><code>@\u200badangel</code></a></li>\n<li>Bump release-drafter/release-drafter from 5.20.0 to 5.20.1 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/86\">#86</a>) <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a></li>\n</ul>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/7033e9d80f30ac57699aa913b0adb0aa31c381a2\"><code>7033e9d</code></a> [maven-release-plugin] prepare release maven-pmd-plugin-3.19.0</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/0781fc8182c24f313d94aa078e53a7e4289200bb\"><code>0781fc8</code></a> (doc) Update release notes [skip ci]</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/d9be919d0ec44b8c9c6f40acf76a888a99a35489\"><code>d9be919</code></a> (doc) Update releasenotes.md</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/e8b49f4a4b9b62e8addd2bdd6bf85fc7b6957161\"><code>e8b49f4</code></a> Bump animal-sniffer-maven-plugin from 1.21 to 1.22 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/88\">#88</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/68b7ed94fe6580ce647501226eeddf6fd23a9c99\"><code>68b7ed9</code></a> Bump wiremock from 1.49 to 2.27.2 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/57\">#57</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/ebd3579da3099ab558e4414029ae2149eebc4178\"><code>ebd3579</code></a> [MPMD-354] - Upgrade to PMD 6.49.0 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/92\">#92</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/7b4c330399faa65b8800b6a3dfd9d60a661178b8\"><code>7b4c330</code></a> [MPMD-353] - API incompatibility with jansi after upgrading m-shared-utils (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/91\">#91</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/1d7a2fbff87b5f4b85a134d3c5ed9fed7bf3ad38\"><code>1d7a2fb</code></a> Set next dev version to 3.19.0-SNAPSHOT</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/584ac6dadab23e1c08399d9a6a89b5b0de7b3726\"><code>584ac6d</code></a> Bump release-drafter/release-drafter from 5.20.0 to 5.20.1 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/86\">#86</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/b55fb9a215ce37f47729e4aec92c813a3d597bf2\"><code>b55fb9a</code></a> (doc) Update releasenotes.md</li>\n<li>Additional commits viewable in <a href=\"https://github.com/apache/maven-pmd-plugin/compare/maven-pmd-plugin-3.18.0...maven-pmd-plugin-3.19.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.maven.plugins:maven-pmd-plugin&package-manager=maven&previous-version=3.18.0&new-version=3.19.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            },
            "5": {
                "commit_sha_buggy": "c0844a65fb081ffa1657ba98c96052ec74002bca",
                "commit_sha_fixed": "16400fc53d776a352ca65390c5e93e4e479f3d32",
                "report_id": "50",
                "report_url": "https://github.com/davidmoten/rtree2/pull/50",
                "issue_title": "Bump maven-pmd-plugin from 3.19.0 to 3.20.0",
                "issue_description": "Bumps [maven-pmd-plugin](https://github.com/apache/maven-pmd-plugin) from 3.19.0 to 3.20.0.\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/55c4d404a1109eded89ae760c92e0cad0b5be10e\"><code>55c4d40</code></a> [maven-release-plugin] prepare release maven-pmd-plugin-3.20.0</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/f3e188aed9812c38655b7c42ae5620f1d18705ab\"><code>f3e188a</code></a> [MPMD-361] Explicitly start and end tables with Doxia Sinks in report renderers</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/b65c7a6a7feb7ff25b6316e6aeb80114fc472648\"><code>b65c7a6</code></a> [MPMD-360] - Upgrade to PMD 6.53.0 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/109\">#109</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/3c7a47ef29d75ae5c4b0f50e7579c91ab8b9b867\"><code>3c7a47e</code></a> Remove method available from super class</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/6ee27fccaded3d5477e206f915ef1fe5370a245d\"><code>6ee27fc</code></a> [MPMD-358] - Upgrade to PMD 6.52.0 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/104\">#104</a>)</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/1dcc7c168f959947af10294ec9c8a7dfd46c42e5\"><code>1dcc7c1</code></a> Set next development version to 3.20.0-SNAPSHOT</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/255a35a9a5aee4cc5549915d55a4292eed85bb67\"><code>255a35a</code></a> (doc) Update releasenotes.md</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/cd954cc768c4bfc30440cda53c081a4640fe8548\"><code>cd954cc</code></a> [MPMD-335] - Aggregate mode doesn't use additional repositories</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/92434d0d96ebe37a5fb599fa6c3120ab5c7863f1\"><code>92434d0</code></a> add Reproducible Builds badge</li>\n<li><a href=\"https://github.com/apache/maven-pmd-plugin/commit/7b6623bb49d3bf48f5e8c6b57279bca1cc1e12ef\"><code>7b6623b</code></a> [MPMD-357] - Upgrade to PMD 6.51.0 (<a href=\"https://github-redirect.dependabot.com/apache/maven-pmd-plugin/issues/100\">#100</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/apache/maven-pmd-plugin/compare/maven-pmd-plugin-3.19.0...maven-pmd-plugin-3.20.0\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.maven.plugins:maven-pmd-plugin&package-manager=maven&previous-version=3.19.0&new-version=3.20.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            },
            "6": {
                "commit_sha_buggy": "9d11206b306f588ee9ce5a38c29e7121706cb2ad",
                "commit_sha_fixed": "3d5865ad5076ad45cde319c165acf62d5c716dc0",
                "report_id": "56",
                "report_url": "https://github.com/davidmoten/rtree2/pull/56",
                "issue_title": "Bump grumpy-core from 0.4.7 to 0.4.8",
                "issue_description": "Bumps [grumpy-core](https://github.com/davidmoten/grumpy) from 0.4.7 to 0.4.8.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/davidmoten/grumpy/releases\">grumpy-core's releases</a>.</em></p>\n<blockquote>\n<h2>0.4.8</h2>\n<h2>Enhancements</h2>\n<h3>Runtime</h3>\n<ul>\n<li>Bump geotools.version from 28.0 to 28.1 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/71\">davidmoten/grumpy#71</a></li>\n<li>Bump geotools.version from 28.1 to 28.2 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/75\">davidmoten/grumpy#75</a></li>\n</ul>\n<h3>Build</h3>\n<ul>\n<li>Bump jetty-maven-plugin from 9.4.49.v20220914 to 9.4.50.v20221201 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/69\">davidmoten/grumpy#69</a></li>\n<li>Bump maven-pmd-plugin from 3.19.0 to 3.20.0 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/70\">davidmoten/grumpy#70</a></li>\n<li>Bump maven-deploy-plugin from 3.0.0 to 3.1.0 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/73\">davidmoten/grumpy#73</a></li>\n<li>Bump maven-project-info-reports-plugin from 2.4 to 3.4.2 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/72\">davidmoten/grumpy#72</a></li>\n<li>Bump maven-javadoc-plugin from 3.4.1 to 3.5.0 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/74\">davidmoten/grumpy#74</a></li>\n<li>Bump maven-compiler-plugin from 3.10.1 to 3.11.0 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/76\">davidmoten/grumpy#76</a></li>\n<li>Bump jetty-maven-plugin from 9.4.50.v20221201 to 9.4.51.v20230217 by <a href=\"https://github.com/dependabot\"><code>@\u200bdependabot</code></a> in <a href=\"https://github-redirect.dependabot.com/davidmoten/grumpy/pull/77\">davidmoten/grumpy#77</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/davidmoten/grumpy/compare/0.4.7...0.4.8\">https://github.com/davidmoten/grumpy/compare/0.4.7...0.4.8</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/95c83f2bb197efdd1504d69c6d2a56263a8bb8a1\"><code>95c83f2</code></a> [maven-release-plugin] prepare release 0.4.8</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/20449cbe9ff169c4968c45594c55014288a6aa9f\"><code>20449cb</code></a> Bump jetty-maven-plugin from 9.4.50.v20221201 to 9.4.51.v20230217</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/2f9eaa95e3db745ac989aab4605c32b6035668d2\"><code>2f9eaa9</code></a> Bump maven-compiler-plugin from 3.10.1 to 3.11.0</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/5516315029d34cd390be28331d0004bad7a58930\"><code>5516315</code></a> Bump geotools.version from 28.1 to 28.2</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/60c48ab54099a585736c266fc214a2641bd4171e\"><code>60c48ab</code></a> Bump maven-javadoc-plugin from 3.4.1 to 3.5.0</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/0ca5e15b3a8842cad91bbd21221cbd8cacf2dadc\"><code>0ca5e15</code></a> Bump maven-project-info-reports-plugin from 2.4 to 3.4.2</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/ca29604681ec1131a905b975b0025bbb5cc6a363\"><code>ca29604</code></a> Bump maven-deploy-plugin from 3.0.0 to 3.1.0</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/e99e724d219c376fda1fb330e7a728242c44a991\"><code>e99e724</code></a> Bump geotools.version from 28.0 to 28.1</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/a4b3bc9273e8b2a9ae465713726308e06a37a5f9\"><code>a4b3bc9</code></a> Bump maven-pmd-plugin from 3.19.0 to 3.20.0</li>\n<li><a href=\"https://github.com/davidmoten/grumpy/commit/c88f34476633634528c0bc3aa3468f42980fecfa\"><code>c88f344</code></a> Bump jetty-maven-plugin from 9.4.49.v20220914 to 9.4.50.v20221201</li>\n<li>Additional commits viewable in <a href=\"https://github.com/davidmoten/grumpy/compare/0.4.7...0.4.8\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.davidmoten:grumpy-core&package-manager=maven&previous-version=0.4.7&new-version=0.4.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>"
            }
        }
    },
    "Subethasmtp": {
        "owner_repo": "davidmoten/subethasmtp",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "b47f7d30b0cdadb272783704a9d1be56abe66a4f",
                "commit_sha_fixed": "0313a20501a3a3c470d32c5975d3a8578c010c1f",
                "report_id": "17",
                "report_url": "https://github.com/davidmoten/subethasmtp/issues/17",
                "issue_title": "Support nested brackets in EmailUtils.extractEmailAddress",
                "issue_description": "_Originally posted on https://github.com/voodoodyne/subethasmtp/issues/97#issue-565021382:_\r\n\r\nI'm using Wiser to test the mail functionality of my Google App Engine app and discovered that there is an [issue](https://stackoverflow.com/q/19680910/) in the [Google App Engine SDK](https://cloud.google.com/appengine/docs/standard/python/tools/using-local-server#using_mail)'s usage of the Python [`smtplib.SMTP.sendmail`](https://docs.python.org/release/2.7.12/library/smtplib.html#smtplib.SMTP.sendmail) function such that when given a `FROM` header like `\"Foo Bar <foobar@example.com>\"`, it wraps the address string within another pair of angle brackets and issues an SMTP command like `mail FROM:<Foo Bar <foobar@example.com>>`, which is unusual, and Wiser returns a 553 / \"Invalid email address\" response.\r\n\r\nI found that changing the `address = address.substring(1, address.indexOf('>'))` line in [`org.subethamail.smtp.util.EmailUtils.extractEmailAddress`](https://github.com/voodoodyne/subethasmtp/blob/13fee16e0ce4325b4a79dd69fd44050d712d038c/src/main/java/org/subethamail/smtp/util/EmailUtils.java#L44) to use `lastIndexOf` instead of `indexOf` is a simple solution to the aforementioned problem,\r\n\r\n```\r\n  /**\r\n   * Extracts the email address within a <> after a specified offset.\r\n   */\r\n  public static String extractEmailAddress(String args, int offset) {\r\n    String address = args.substring(offset).trim();\r\n    if (address.indexOf('<') == 0) {\r\n      // address = address.substring(1, address.indexOf('>'));\r\n      // **this patch allows nested angle brackets (e.g. \"<Foo Bar <foobar@example.com>>\"):**\r\n      address = address.substring(1, address.lastIndexOf('>'));\r\n      // spaces within the <> are also possible, Postfix apparently\r\n      // trims these away:\r\n      return address.trim();\r\n    }\r\n\r\n    // find space (e.g. SIZE argument)\r\n    int nextarg = address.indexOf(\" \");\r\n    if (nextarg > -1) {\r\n      address = address.substring(0, nextarg).trim();\r\n    }\r\n    return address;\r\n  }\r\n```\r\n\r\nI believe that this change will not break compatibility with the [SMTP RFC](https://tools.ietf.org/html/rfc5321#section-3.3), which specifies only that:\r\n\r\n> The `<reverse-path>` portion of the first or only argument contains the source mailbox (between `<` and `>` brackets)\r\n\r\nThis spec does not appear to explicitly prohibit nested brackets.\r\n\r\nMy patched code still supports addresses without additional nested brackets (i.e.  both `MAIL FROM:Foo Bar <foobar@example.com>` and `MAIL FROM:<Foo Bar <foobar@example.com>>` will be accepted.\r\n\r\nI realize that the App Engine/Python peculiarity that I described doesn't have anything to do with subethasmtp, but I was wondering if you'd be willing to accept this tiny patch anyways.  Would be happy to create a pull request if you accept.\r\n\r\nSince Wiser is intended to be used for testing, I think it should be pretty lenient with what it accepts.  Another argument in favor of this patch is that Dumbster is able to handle such email addresses without a problem."
            }
        }
    },
    "Hilbert_curve": {
        "owner_repo": "davidmoten/hilbert-curve",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "299fdb33cbd4610c9207ad4e03f96d6044b520d9",
                "commit_sha_fixed": "657f158b797f776a0c7bb8b6bcf99f6bdb7edc4d",
                "report_id": "1",
                "report_url": "https://github.com/davidmoten/hilbert-curve/issues/1",
                "issue_title": "2D SmallHilbertCurve with 16 bits gives negative numbers for arguments with x > 2^15",
                "issue_description": "Up to nbits=15 all is fine. But for nbits=16 the whole right half plane gives negative coordinates.\r\nI am using the code from maven, but I suspect, looking at the source that this line (72) is to blame:\r\n\r\nb |= 1 << bIndex; \r\n\r\nIt should be\r\nb |= 1L << bIndex;"
            },
            "2": {
                "commit_sha_buggy": "c9d222d122ec7dbfae2d1d26c86caea28995b065",
                "commit_sha_fixed": "bdcec5956d9d6bc4dca6bf5af36fa2ef0d5d65b7",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix SmallHilbertCurve.maxOrdinate and SmallHilbertCurve.maxIndex",
                "issue_description": "fix SmallHilbertCurve.maxOrdinate and SmallHilbertCurve.maxIndex"
            },
            "3": {
                "commit_sha_buggy": "e64c664a325355a76e00824e0f2503d92b85dc1f",
                "commit_sha_fixed": "5f36f5d05ddb6d6e34be0476c514954af8f80d4f",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fix bugs",
                "issue_description": "fix bugs"
            }
        }
    },
    "Jcabi_http": {
        "owner_repo": "jcabi/jcabi-http",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "053f214b67e03bac2c95f3823aa3e269e128a8fa",
                "commit_sha_fixed": "7d9c74df89699940def9c0eeeab4dcd2c457ba58",
                "report_id": "1",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/1",
                "issue_title": "JsonResponse should be able to read non-Unicode JSON",
                "issue_description": "JsonResponse is now relying on a proper Unicode formatting of JSON documents (see line 95). When JSON contains non-Unicode characters, the class throws a runtime exception. For example, try this document (which is a valid JSON according to [RFC 4627](http://tools.ietf.org/html/rfc4627)):\n\n```\n{\"test\": \"\\u0000\"}\n```\n"
            },
            "2": {
                "commit_sha_buggy": "053f214b67e03bac2c95f3823aa3e269e128a8fa",
                "commit_sha_fixed": "f5953fc9076c8ef644e89d422600a8bc0ff8bae5",
                "report_id": "2",
                "report_url": "https://github.com/jcabi/jcabi-http/pull/2",
                "issue_title": "Issue #1 JsonResponse can now properly parse control characters",
                "issue_description": "As per [RFC 4627](http://tools.ietf.org/html/rfc4627) control characters `U+0000` to `U+001F` should be escaped. I created a custom function that does exactly that and used it before invoking `createReader`.\n"
            },
            "3": {
                "commit_sha_buggy": "f5953fc9076c8ef644e89d422600a8bc0ff8bae5",
                "commit_sha_fixed": "5bd74a21dfa8957c655afdf04f4a3ec79c75630b",
                "report_id": "3",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/3",
                "issue_title": "MkContainerTest.java:73-74: Grizzly container doesn't understand same-name...",
                "issue_description": "Puzzle `1-40eeff88` in `src/test/java/com/jcabi/http/mock/MkContainerTest.java:73-74` has to be resolved: Grizzly container doesn't understand same-name headers, or we don't fetch them correctly from GrizzlyRequest\n"
            },
            "4": {
                "commit_sha_buggy": "f5953fc9076c8ef644e89d422600a8bc0ff8bae5",
                "commit_sha_fixed": "f507d29e32cc064ffccd76a871d7db417d5959c1",
                "report_id": "4",
                "report_url": "https://github.com/jcabi/jcabi-http/pull/4",
                "issue_title": "Issue #3 JdkRequest now handles duplicate headers",
                "issue_description": "The test works fine as it is; I discovered the bug when I tried changing the type to `ApacheRequest` and it passed.\n\nThe difference is that `setRequestProperty` overrides the existing header while `addRequestProperty` appends to it. See [javadoc for URLConnection](http://docs.oracle.com/javase/7/docs/api/java/net/URLConnection.html#setRequestProperty%28java.lang.String, java.lang.String%29).\n"
            },
            "5": {
                "commit_sha_buggy": "5738be5d0b20171e7a50ad80310e20859865b959",
                "commit_sha_fixed": "551008083614d8c406443d58259d89caf9286a37",
                "report_id": "7",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/7",
                "issue_title": "JsonResponse.json() should be more verbose when parsing breaks",
                "issue_description": "`JsonResponse.json()` should be more verbose when parsing breaks. It has to log the content of JSON response to slf4j\n"
            },
            "6": {
                "commit_sha_buggy": "53d2034fa6897a70e1044f0a5394f644238bc785",
                "commit_sha_fixed": "27c01f8b68003c3bdd1fa56fe5352eed35e6d476",
                "report_id": "8",
                "report_url": "https://github.com/jcabi/jcabi-http/pull/8",
                "issue_title": "Issue #7 JsonResponse.json() now logs the JSON body",
                "issue_description": ""
            },
            "7": {
                "commit_sha_buggy": "a24ac0dbfe4de2ce78eeef37c2352689fd62e34b",
                "commit_sha_fixed": "469daf70f67bf975f928f148d262e3b50ab91930",
                "report_id": "12",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/12",
                "issue_title": "escaping of JSON breaks normal parsing",
                "issue_description": "after #1 we have a broken logic. normally formatted JSON can't be parsed, for example:\n\n```\n{\n  \"test\": \"hello\"\n}\n```\n\nLeads to runtime exception:\n\n```\njavax.json.stream.JsonParsingException: Unexpected char 92 at (line no=1, column no=21, offset=20)\n```\n"
            },
            "8": {
                "commit_sha_buggy": "a26ffc26fe62b809c87c0295a675fd4d2b513a8c",
                "commit_sha_fixed": "4b5645782efaa9b537162cb56b3d55508f816335",
                "report_id": "18",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/18",
                "issue_title": "ConnectionException is not descriptive",
                "issue_description": "I'm getting this exception sometimes:\n\n```\nCaused by: java.net.ConnectException: Connection refused\n    at java.net.PlainSocketImpl.socketConnect(Native Method)\n    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)\n    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)\n    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)\n    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n    at java.net.Socket.connect(Socket.java:579)\n    at java.net.Socket.connect(Socket.java:528)\n    at sun.net.NetworkClient.doConnect(NetworkClient.java:180)\n    at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)\n    at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)\n    at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)\n    at sun.net.www.http.HttpClient.New(HttpClient.java:308)\n    at sun.net.www.http.HttpClient.New(HttpClient.java:326)\n    at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)\n    at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)\n    at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1300)\n    at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)\n    at com.jcabi.http.request.JdkRequest$1.send(JdkRequest.java:117)\n    at com.jcabi.http.wire.BasicAuthWire.send(BasicAuthWire.java:138)\n    at com.jcabi.http.request.BaseRequest.fetch_aroundBody10(BaseRequest.java:197)\n    at com.jcabi.http.request.BaseRequest$AjcClosure11.run(BaseRequest.java:1)\n```\n\n\"Connection refused\" is not descriptive at all to me. I'd like to see where the connection was trying to be established to, with what HTTP method, etc. Would be nice to wrap all runtime exceptions flying out of `JdkRequest$1.send()` in IOException and add a message there, like:\n\n```\nfailed to POST to http://example.com\n```\n"
            },
            "9": {
                "commit_sha_buggy": "b419e8fd424f0542db6afed0629cd5208679a377",
                "commit_sha_fixed": "d34e39f3595b19079be3b919b78e0f2e40bf6305",
                "report_id": "20",
                "report_url": "https://github.com/jcabi/jcabi-http/pull/20",
                "issue_title": "#18 JdkRequest rethrows more descriptive error message",
                "issue_description": ""
            },
            "10": {
                "commit_sha_buggy": "4e852c5817048ae53e18eb6974b2a143eccd7596",
                "commit_sha_fixed": "9aa74bbefbc4113aa71240638166a5e31b9930cf",
                "report_id": "24",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/24",
                "issue_title": "MkContainer.java:87-89: Let's add methods take(Matcher )...",
                "issue_description": "Puzzle `19-a877bdce` in `src/main/java/com/jcabi/http/mock/MkContainer.java:87-89` has to be resolved: Let's add methods take(Matcher ) and takeAll(Matcher ), and a utility class MkAnswerMatchers. Intended usage is as follows:\n"
            },
            "11": {
                "commit_sha_buggy": "3dfa33a3a7513cb01949d2ba4504e92e071fa76e",
                "commit_sha_fixed": "d0d53cd64f54b66b3d718f6b83fe4f603ed41375",
                "report_id": "36",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/36",
                "issue_title": "Uploads should allow using streams",
                "issue_description": "The current API does not seem to have any efficient way of uploading the contents of a file or other local resource. \n\nThere is `RequestBody#set(byte[])`, but that requires loading the full file contents into memory. The array is then cloned in the `BaseBody(BaseRequest, byte[])` constructor, doubling the memory need.\n\nWhile this is currently feasible for what we do, we would prefer having something like `RequestBody#set(InputStream)`, allowing us to stream the contents of a resource directly to a HTTP server.\n"
            },
            "12": {
                "commit_sha_buggy": "3b544cbfd8bc588badf4c93262baac4f71afa63e",
                "commit_sha_fixed": "52e7b9b6d2ecadda4621a0bb5e50d502f4460854",
                "report_id": "47",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/47",
                "issue_title": "FakeRequest incorrectly uses request body as response body",
                "issue_description": "When the `RequestBody` of a `FakeRequest` is set, it incorrectly uses it in the body of the _ResponseBody_ instead of using the response body content that was specified.\n\nFor example, the following test will fail:\n\n``` java\n@Test\npublic void fakeRequestReturnsRequestBody() throws Exception {\n    MatcherAssert.assertThat(\n        new FakeRequest()\n            .withBody(\"foo\")  // Response body - should be returned\n            .body().set(\"bar\").back() // Request body\n            .fetch().body(),\n        Matchers.is(\"foo\")\n    );\n}\n```\n\nError:\n\n```\njava.lang.AssertionError: \nExpected: is \"foo\"\n     but: was \"bar\"\n\n```\n\nNote that the following test - if the `RequestBody` is not set - works fine:\n\n``` java\n@Test\npublic void fakeRequestReturnsRequestBody() throws Exception {\n    MatcherAssert.assertThat(\n        new FakeRequest()\n            .withBody(\"foo\")\n            .fetch().body(),\n        Matchers.is(\"foo\")\n    );\n}\n```\n"
            },
            "13": {
                "commit_sha_buggy": "55cdb9b431947072a45216ebbfa76271ed735db9",
                "commit_sha_fixed": "b8da4473a63b8f9800ef64667ff157ed175109c7",
                "report_id": "117",
                "report_url": "https://github.com/jcabi/jcabi-http/issues/117",
                "issue_title": "JsoupResponse doesn't close tags",
                "issue_description": ""
            },
            "14": {
                "commit_sha_buggy": "1bbe70811e1d27b37da1bfdec1631311450a090f",
                "commit_sha_fixed": "97378349b460b6e3ea7b04c813b4dcb04ae6e8f0",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fixed calculation of authorization header in BasicAuthWire",
                "issue_description": "Fixed calculation of authorization header in BasicAuthWire"
            },
            "15": {
                "commit_sha_buggy": "c99c1d0c388e8a370ddd4b560acf4545dcaa39bd",
                "commit_sha_fixed": "58884f4734ea86922f865e813003126d9f7ee0eb",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "fixed NPE if no protocol plus unit tests",
                "issue_description": "fixed NPE if no protocol plus unit tests"
            },
            "16": {
                "commit_sha_buggy": "52e7b9b6d2ecadda4621a0bb5e50d502f4460854",
                "commit_sha_fixed": "3b544cbfd8bc588badf4c93262baac4f71afa63e",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "#47 Fixed bug where FakeRequest body was being written to the Response",
                "issue_description": "#47 Fixed bug where FakeRequest body was being written to the Response"
            }
        }
    },
    "Jfreechart_fse": {
        "owner_repo": "jfree/jfreechart-fse",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "986bcecfd44c48b51710ae3d7b8ca6ec93bd03fc",
                "commit_sha_fixed": "7147fe78d6f60f1218c8a6af71389dfc29b54790",
                "report_id": "12",
                "report_url": "https://github.com/jfree/jfreechart-fse/pull/12",
                "issue_title": "fix CompassFormat constructor (to fix failing tests)",
                "issue_description": "CompassFormat was changed to allow localized Strings.\ncurrent localized constructor constructs a directions array of size 17, which fails the next constructor (that expects exactly 16).\nthis fix makes CompassFormat tests pass.\n\nalso, when running all of the tests (either via maven or an IDE) TimeSeriesTest would fail with:\njava.lang.AssertionError: \nExpected :-1\nActual   :null\napparently there's a mechanism in oracle JVMs that starts re-using the same exception instance after a while. disabling this mechanism for the junit runner makes the issue go away (see http://stackoverflow.com/questions/12582370/java-arrayindexoutofboundsexception-null-and-no-stack-trace)\n"
            },
            "2": {
                "commit_sha_buggy": "5dd6af16370c52b0ac08c4e65e36230ae03f6a67",
                "commit_sha_fixed": "20ab2037a52ff118cd0d7a406ff55bd6de8fdd74",
                "report_id": "unknown",
                "report_url": "unknown",
                "issue_title": "Fix rendering anomaly for XYDatasets.",
                "issue_description": "Fix rendering anomaly for XYDatasets."
            }
        }
    },
    "Jfreesvg": {
        "owner_repo": "jfree/jfreesvg",
        "bug_infos": {
            "1": {
                "commit_sha_buggy": "f47510085f140c86cfd0e25b2bf907ee516e1b15",
                "commit_sha_fixed": "74ced3ef5be3fcd8d32c9620dfb4573d200a56e3",
                "report_id": "6",
                "report_url": "https://github.com/jfree/jfreesvg/issues/6",
                "issue_title": "drawImage method (Line 2520) perhaps needs a null check",
                "issue_description": "I'm using PDFBox > PDFRenderer.renderPageToGraphics to create an SVG from a PDF page and i was getting a NullPointerException every time, then, after a long backtrace i found this: drawImage(img, null, null) on their code, and i'm not really sure if the problem is in your code but this is what i found on the Java Specification:\n\n(https://docs.oracle.com/javase/8/docs/api/java/awt/Graphics2D.html)\n\n> If an AffineTransform is passed to drawImage(Image, AffineTransform, ImageObserver), the AffineTransform is used to transform the bounding box from image space to user space. If no AffineTransform is supplied, the bounding box is treated as if it is already in user space.\n\nI'm guessing you need to do a null check on that method.\n\nThanks.\n"
            }
        }
    }
}